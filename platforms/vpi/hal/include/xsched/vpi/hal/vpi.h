// Merged header file - auto-generated by python3 ./merge_headers.py /opt/nvidia/vpi2/include/vpi

// Begin content from: detail/FormatUtils.h
/*
 * Copyright 2020-2021 NVIDIA Corporation. All rights reserved.
 *
 * NOTICE TO LICENSEE:
 *
 * This source code and/or documentation ("Licensed Deliverables") are
 * subject to NVIDIA intellectual property rights under U.S. and
 * international Copyright laws.
 *
 * These Licensed Deliverables contained herein is PROPRIETARY and
 * CONFIDENTIAL to NVIDIA and is being provided under the terms and
 * conditions of a form of NVIDIA software license agreement by and
 * between NVIDIA and Licensee ("License Agreement") or electronically
 * accepted by Licensee. Notwithstanding any terms or conditions to
 * the contrary in the License Agreement, reproduction or disclosure
 * of the Licensed Deliverables to any third party without the express
 * written consent of NVIDIA is prohibited.
 *
 * NOTWITHSTANDING ANY TERMS OR CONDITIONS TO THE CONTRARY IN THE
 * LICENSE AGREEMENT, NVIDIA MAKES NO REPRESENTATION ABOUT THE
 * SUITABILITY OF THESE LICENSED DELIVERABLES FOR ANY PURPOSE. IT IS
 * PROVIDED "AS IS" WITHOUT EXPRESS OR IMPLIED WARRANTY OF ANY KIND.
 * NVIDIA DISCLAIMS ALL WARRANTIES WITH REGARD TO THESE LICENSED
 * DELIVERABLES, INCLUDING ALL IMPLIED WARRANTIES OF MERCHANTABILITY,
 * NONINFRINGEMENT, AND FITNESS FOR A PARTICULAR PURPOSE.
 * NOTWITHSTANDING ANY TERMS OR CONDITIONS TO THE CONTRARY IN THE
 * LICENSE AGREEMENT, IN NO EVENT SHALL NVIDIA BE LIABLE FOR ANY
 * SPECIAL, INDIRECT, INCIDENTAL, OR CONSEQUENTIAL DAMAGES, OR ANY
 * DAMAGES WHATSOEVER RESULTING FROM LOSS OF USE, DATA OR PROFITS,
 * WHETHER IN AN ACTION OF CONTRACT, NEGLIGENCE OR OTHER TORTIOUS
 * ACTION, ARISING OUT OF OR IN CONNECTION WITH THE USE OR PERFORMANCE
 * OF THESE LICENSED DELIVERABLES.
 *
 * U.S. Government End Users. These Licensed Deliverables are a
 * "commercial item" as that term is defined at 48 C.F.R. 2.101 (OCT
 * 1995), consisting of "commercial computer software" and "commercial
 * computer software documentation" as such terms are used in 48
 * C.F.R. 12.212 (SEPT 1995) and is provided to the U.S. Government
 * only as a commercial end item. Consistent with 48 C.F.R.12.212 and
 * 48 C.F.R. 227.7202-1 through 227.7202-4 (JUNE 1995), all
 * U.S. Government End Users acquire the Licensed Deliverables with
 * only those rights set forth herein.
 *
 * Any use of the Licensed Deliverables in individual and commercial
 * software must include, in the user documentation and internal
 * comments to the code, the above Disclaimer and U.S. Government End
 * Users Notice.
 */

#ifndef NV_VPI_DETAIL_FORMATUTILS_H
#define NV_VPI_DETAIL_FORMATUTILS_H

#include <stdint.h>

// Utilities ================================

#define VPI_DETAIL_SET_BITFIELD(value, offset, size) (((uint64_t)(value) & ((1ULL << (size)) - 1)) << (offset))
#define VPI_DETAIL_GET_BITFIELD(value, offset, size) (((uint64_t)(value) >> (offset)) & ((1ULL << (size)) - 1))

#define VPI_DETAIL_ENCODE_BPP(bpp)             \
    ((bpp) <= 8 ? 0                            \
                : ((bpp) <= 32 ? (bpp) / 8 - 1 \
                               : ((bpp) <= 64 ? (bpp) / 16 + 1 : ((bpp) <= 128 ? (bpp) / 32 + 3 : (bpp) / 64 + 5))))

#define VPI_DETAIL_BPP_NCH(bpp, chcount)                                                                      \
    (VPI_DETAIL_SET_BITFIELD(VPI_DETAIL_ENCODE_BPP(bpp), 6, 4) | VPI_DETAIL_SET_BITFIELD((chcount)-1, 4, 2) | \
     VPI_DETAIL_SET_BITFIELD((bpp) <= 2 ? (bpp) : ((bpp) == 4 ? 3 : ((bpp) == 8 ? 4 : 0)), 0, 4))

#define VPI_DETAIL_MAKE_SWIZZLE(x, y, z, w)                                                                   \
    (VPI_DETAIL_SET_BITFIELD(x, 0, 3) | VPI_DETAIL_SET_BITFIELD(y, 3, 3) | VPI_DETAIL_SET_BITFIELD(z, 6, 3) | \
     VPI_DETAIL_SET_BITFIELD(w, 9, 3))

#define VPI_DETAIL_MAKE_SWZL(x, y, z, w) \
    VPI_DETAIL_MAKE_SWIZZLE(VPI_CHANNEL_##x, VPI_CHANNEL_##y, VPI_CHANNEL_##z, VPI_CHANNEL_##w)

#define VPI_DETAIL_DEF_SWIZZLE_ENUM(x, y, z, w) VPI_SWIZZLE_##x##y##z##w = VPI_DETAIL_MAKE_SWZL(x, y, z, w)

#define VPI_DETAIL_ADJUST_BPP_ENCODING(PACK, BPP, PACKLEN) \
    ((PACKLEN) == 0 && (BPP) == 0 && (PACK) == 4 ? (uint64_t)-1 : (BPP))

#define VPI_DETAIL_ENCODE_PACKING(P, CHLEN, PACKLEN, BPPLEN)                                                          \
    (VPI_DETAIL_SET_BITFIELD(                                                                                         \
         VPI_DETAIL_ADJUST_BPP_ENCODING(VPI_DETAIL_GET_BITFIELD(P, 0, 4), VPI_DETAIL_GET_BITFIELD(P, 6, 4), PACKLEN), \
         (PACKLEN) + (CHLEN), BPPLEN) |                                                                               \
     VPI_DETAIL_SET_BITFIELD(VPI_DETAIL_GET_BITFIELD(P, 4, 2), PACKLEN, CHLEN) |                                      \
     VPI_DETAIL_SET_BITFIELD(VPI_DETAIL_GET_BITFIELD(P, 0, 4), 0, PACKLEN))

#define VPI_DETAIL_EXTRACT_PACKING_CHANNELS(Packing) (VPI_DETAIL_GET_BITFIELD(Packing, 4, 2) + 1)

/* clang-format off */
#define VPI_DETAIL_MAKE_FMTTYPE(ColorModel, ColorSpecOrRawPattern, Subsampling, MemLayout, DataType, Swizzle, \
                               Packing0, Packing1, Packing2, Packing3)                                        \
    (                                                              \
        VPI_DETAIL_SET_BITFIELD(DataType, 61, 3) | VPI_DETAIL_SET_BITFIELD(Swizzle, 0, 4 * 3) |           \
        VPI_DETAIL_SET_BITFIELD(MemLayout, 12, 3) | \
        ((ColorModel) == VPI_COLOR_MODEL_YCbCr \
            ? VPI_DETAIL_SET_BITFIELD(ColorSpecOrRawPattern, 20, 15) | VPI_DETAIL_SET_BITFIELD(Subsampling, 17, 3) \
            : ((ColorModel) == VPI_COLOR_MODEL_UNDEFINED \
                ? VPI_DETAIL_SET_BITFIELD((1U<<19)-1, 16, 19) \
                : (VPI_DETAIL_SET_BITFIELD(1,16,1) | \
                     ((ColorModel)-2 < 0x7 \
                       ? VPI_DETAIL_SET_BITFIELD(ColorSpecOrRawPattern, 20, 15) \
                            | VPI_DETAIL_SET_BITFIELD((ColorModel)-2, 17, 3) \
                       : (VPI_DETAIL_SET_BITFIELD(0x7, 17, 3) | \
                            ((ColorModel) == VPI_COLOR_MODEL_RAW \
                              ? VPI_DETAIL_SET_BITFIELD(ColorSpecOrRawPattern, 21, 6) \
                              : (VPI_DETAIL_SET_BITFIELD(1, 20, 1) | VPI_DETAIL_SET_BITFIELD((ColorModel)-(7+2+1), 21, 6)) \
                            ) \
                         ) \
                     ) \
                  ) \
              ) \
        ) | \
        VPI_DETAIL_SET_BITFIELD(VPI_DETAIL_ENCODE_PACKING(Packing0, 2, 3, 4), 35, 9) |                           \
        VPI_DETAIL_SET_BITFIELD(VPI_DETAIL_ENCODE_PACKING(Packing1, 1, 3, 3), 44, 7) |                           \
        VPI_DETAIL_SET_BITFIELD(VPI_DETAIL_ENCODE_PACKING(Packing2, 1, 3, 3), 51, 7) |                           \
        VPI_DETAIL_SET_BITFIELD(VPI_DETAIL_ENCODE_PACKING(Packing3, 0, 0, 3), 58, 3))
/* clang-format on */

#define VPI_DETAIL_MAKE_FORMAT(ColorModel, ColorSpecOrRawPattern, Subsampling, MemLayout, DataType, Swizzle, Packing0, \
                               Packing1, Packing2, Packing3)                                                           \
    ((VPIImageFormat)VPI_DETAIL_MAKE_FMTTYPE(ColorModel, ColorSpecOrRawPattern, Subsampling, MemLayout, DataType,      \
                                             Swizzle, Packing0, Packing1, Packing2, Packing3))

#define VPI_DETAIL_MAKE_FMT(ColorModel, ColorSpec, CSS, MemLayout, DataType, Swizzle, P0, P1, P2, P3)   \
    VPI_DETAIL_MAKE_FORMAT(VPI_COLOR_MODEL_##ColorModel, VPI_COLOR_SPEC_##ColorSpec, VPI_CSS_##CSS,     \
                           VPI_MEM_LAYOUT_##MemLayout, VPI_DATA_TYPE_##DataType, VPI_SWIZZLE_##Swizzle, \
                           VPI_PACKING_##P0, VPI_PACKING_##P1, VPI_PACKING_##P2, VPI_PACKING_##P3)

// MAKE_COLOR ================================================

// Full arg name

#define VPI_DETAIL_MAKE_COLOR_FORMAT1(ColorModel, ColorSpec, MemLayout, DataType, Swizzle, P0) \
    VPI_DETAIL_MAKE_FORMAT(ColorModel, ColorSpec, VPI_CSS_NONE, MemLayout, DataType, Swizzle, P0, 0, 0, 0)

#define VPI_DETAIL_MAKE_COLOR_FORMAT2(ColorModel, ColorSpec, MemLayout, DataType, Swizzle, P0, P1) \
    VPI_DETAIL_MAKE_FORMAT(ColorModel, ColorSpec, VPI_CSS_NONE, MemLayout, DataType, Swizzle, P0, P1, 0, 0)

#define VPI_DETAIL_MAKE_COLOR_FORMAT3(ColorModel, ColorSpec, MemLayout, DataType, Swizzle, P0, P1, P2) \
    VPI_DETAIL_MAKE_FORMAT(ColorModel, ColorSpec, VPI_CSS_NONE, MemLayout, DataType, Swizzle, P0, P1, P2, 0)

#define VPI_DETAIL_MAKE_COLOR_FORMAT4(ColorModel, ColorSpec, MemLayout, DataType, Swizzle, P0, P1, P2, P3) \
    VPI_DETAIL_MAKE_FORMAT(ColorModel, ColorSpec, VPI_CSS_NONE, MemLayout, DataType, Swizzle, P0, P1, P2, P3)

#define VPI_DETAIL_MAKE_COLOR_FORMAT(ColorModel, ColorSpec, MemLayout, DataType, Swizzle, PlaneCount, ...) \
    VPI_DETAIL_MAKE_COLOR_FORMAT##PlaneCount(ColorModel, ColorSpec, MemLayout, DataType, Swizzle, __VA_ARGS__)

// Abbreviated

#define VPI_DETAIL_MAKE_COLOR_FMT1(ColorModel, ColorSpec, MemLayout, DataType, Swizzle, P0) \
    VPI_DETAIL_MAKE_FMT(ColorModel, ColorSpec, NONE, MemLayout, DataType, Swizzle, P0, 0, 0, 0)

#define VPI_DETAIL_MAKE_COLOR_FMT2(ColorModel, ColorSpec, MemLayout, DataType, Swizzle, P0, P1) \
    VPI_DETAIL_MAKE_FMT(ColorModel, ColorSpec, NONE, MemLayout, DataType, Swizzle, P0, P1, 0, 0)

#define VPI_DETAIL_MAKE_COLOR_FMT3(ColorModel, ColorSpec, MemLayout, DataType, Swizzle, P0, P1, P3) \
    VPI_DETAIL_MAKE_FMT(ColorModel, ColorSpec, NONE, MemLayout, DataType, Swizzle, P0, P1, P3, 0)

#define VPI_DETAIL_MAKE_COLOR_FMT4(ColorModel, ColorSpec, MemLayout, DataType, Swizzle, P0, P1, P3, P4) \
    VPI_DETAIL_MAKE_FMT(ColorModel, ColorSpec, NONE, MemLayout, DataType, Swizzle, P0, P1, P3, P4)

#define VPI_DETAIL_MAKE_COLOR_FMT(ColorModel, ColorSpec, MemLayout, DataType, Swizzle, PlaneCount, ...) \
    VPI_DETAIL_MAKE_COLOR_FMT##PlaneCount(ColorModel, ColorSpec, MemLayout, DataType, Swizzle, __VA_ARGS__)

// MAKE_PIXEL =========================

// Full arg name

#define VPI_DETAIL_MAKE_PIXEL_TYPE(MemLayout, DataType, Packing)                                                      \
    ((VPIPixelType)VPI_DETAIL_MAKE_FMTTYPE(                                                                           \
        VPI_COLOR_MODEL_UNDEFINED, VPI_COLOR_SPEC_UNDEFINED, VPI_CSS_NONE, MemLayout, DataType,                       \
        VPI_DETAIL_MAKE_SWIZZLE(VPI_CHANNEL_X, VPI_DETAIL_EXTRACT_PACKING_CHANNELS(Packing) >= 2 ? VPI_CHANNEL_Y : 0, \
                                VPI_DETAIL_EXTRACT_PACKING_CHANNELS(Packing) >= 3 ? VPI_CHANNEL_Z : 0,                \
                                VPI_DETAIL_EXTRACT_PACKING_CHANNELS(Packing) >= 4 ? VPI_CHANNEL_W : 0),               \
        Packing, 0, 0, 0))

// Abbreviated

#define VPI_DETAIL_MAKE_PIX_TYPE(MemLayout, DataType, Packing) \
    VPI_DETAIL_MAKE_PIXEL_TYPE(VPI_MEM_LAYOUT_##MemLayout, VPI_DATA_TYPE_##DataType, VPI_PACKING_##Packing)

// MAKE_NONCOLOR ==================================

// Full arg name

#define VPI_DETAIL_MAKE_NONCOLOR_FORMAT1(MemLayout, DataType, Swizzle, P0)                                         \
    VPI_DETAIL_MAKE_FORMAT(VPI_COLOR_MODEL_UNDEFINED, VPI_COLOR_SPEC_UNDEFINED, VPI_CSS_NONE, MemLayout, DataType, \
                           Swizzle, P0, 0, 0, 0)

#define VPI_DETAIL_MAKE_NONCOLOR_FORMAT2(MemLayout, DataType, Swizzle, P0, P1)                                     \
    VPI_DETAIL_MAKE_FORMAT(VPI_COLOR_MODEL_UNDEFINED, VPI_COLOR_SPEC_UNDEFINED, VPI_CSS_NONE, MemLayout, DataType, \
                           Swizzle, P0, P1, 0, 0)

#define VPI_DETAIL_MAKE_NONCOLOR_FORMAT3(MemLayout, DataType, Swizzle, P0, P1, P2)                                 \
    VPI_DETAIL_MAKE_FORMAT(VPI_COLOR_MODEL_UNDEFINED, VPI_COLOR_SPEC_UNDEFINED, VPI_CSS_NONE, MemLayout, DataType, \
                           Swizzle, P0, P1, P2, 0)

#define VPI_DETAIL_MAKE_NONCOLOR_FORMAT4(MemLayout, DataType, Swizzle, P0, P1, P2, P3)                             \
    VPI_DETAIL_MAKE_FORMAT(VPI_COLOR_MODEL_UNDEFINED, VPI_COLOR_SPEC_UNDEFINED, VPI_CSS_NONE, MemLayout, DataType, \
                           Swizzle, P0, P1, P2, P3)

#define VPI_DETAIL_MAKE_NONCOLOR_FORMAT(MemLayout, DataType, Swizzle, PlaneCount, ...) \
    VPI_DETAIL_MAKE_NONCOLOR_FORMAT##PlaneCount(MemLayout, DataType, Swizzle, __VA_ARGS__)

// Abbreviated

#define VPI_DETAIL_MAKE_NONCOLOR_FMT1(MemLayout, DataType, Swizzle, P0) \
    VPI_DETAIL_MAKE_FMT(UNDEFINED, UNDEFINED, NONE, MemLayout, DataType, Swizzle, P0, 0, 0, 0)

#define VPI_DETAIL_MAKE_NONCOLOR_FMT2(MemLayout, DataType, Swizzle, P0, P1) \
    VPI_DETAIL_MAKE_FMT(UNDEFINED, UNDEFINED, NONE, MemLayout, DataType, Swizzle, P0, P1, 0, 0)

#define VPI_DETAIL_MAKE_NONCOLOR_FMT3(MemLayout, DataType, Swizzle, P0, P1, P2) \
    VPI_DETAIL_MAKE_FMT(UNDEFINED, UNDEFINED, NONE, MemLayout, DataType, Swizzle, P0, P1, P2, 0)

#define VPI_DETAIL_MAKE_NONCOLOR_FMT4(MemLayout, DataType, Swizzle, P0, P1, P2, P3) \
    VPI_DETAIL_MAKE_FMT(UNDEFINED, UNDEFINED, NONE, MemLayout, DataType, Swizzle, P0, P1, P2, P3)

#define VPI_DETAIL_MAKE_NONCOLOR_FMT(MemLayout, DataType, Swizzle, PlaneCount, ...) \
    VPI_DETAIL_MAKE_NONCOLOR_FMT##PlaneCount(MemLayout, DataType, Swizzle, __VA_ARGS__)

// MAKE_RAW =============================================

// Full arg name

#define VPI_DETAIL_MAKE_RAW_FORMAT1(RawPattern, MemLayout, DataType, Swizzle, P0) \
    VPI_DETAIL_MAKE_FORMAT(VPI_COLOR_MODEL_RAW, RawPattern, VPI_CSS_NONE, MemLayout, DataType, Swizzle, P0, 0, 0, 0)

#define VPI_DETAIL_MAKE_RAW_FORMAT2(RawPattern, MemLayout, DataType, Swizzle, P0, P1) \
    VPI_DETAIL_MAKE_FORMAT(VPI_COLOR_MODEL_RAW, RawPattern, VPI_CSS_NONE, MemLayout, DataType, Swizzle, P0, P1, 0, 0)

#define VPI_DETAIL_MAKE_RAW_FORMAT3(RawPattern, MemLayout, DataType, Swizzle, P0, P1, P2) \
    VPI_DETAIL_MAKE_FORMAT(VPI_COLOR_MODEL_RAW, RawPattern, VPI_CSS_NONE, MemLayout, DataType, Swizzle, P0, P1, P2, 0)

#define VPI_DETAIL_MAKE_RAW_FORMAT4(RawPattern, MemLayout, DataType, Swizzle, P0, P1, P2, P3) \
    VPI_DETAIL_MAKE_FORMAT(VPI_COLOR_MODEL_RAW, RawPattern, VPI_CSS_NONE, MemLayout, DataType, Swizzle, P0, P1, P2, P3)

#define VPI_DETAIL_MAKE_RAW_FORMAT(RawPattern, MemLayout, DataType, Swizzle, PlaneCount, ...) \
    VPI_DETAIL_MAKE_RAW_FORMAT##PlaneCount(RawPattern, MemLayout, DataType, Swizzle, __VA_ARGS__)

// Abbreviated

#define VPI_DETAIL_MAKE_RAW_FMT1(RawPattern, MemLayout, DataType, Swizzle, P0)                              \
    VPI_DETAIL_MAKE_RAW_FORMAT1(VPI_RAW_##RawPattern, VPI_MEM_LAYOUT_##MemLayout, VPI_DATA_TYPE_##DataType, \
                                VPI_SWIZZLE_##Swizzle, VPI_PACKING_##P0)

#define VPI_DETAIL_MAKE_RAW_FMT2(RawPattern, MemLayout, DataType, Swizzle, P0, P1)                          \
    VPI_DETAIL_MAKE_RAW_FORMAT2(VPI_RAW_##RawPattern, VPI_MEM_LAYOUT_##MemLayout, VPI_DATA_TYPE_##DataType, \
                                VPI_SWIZZLE_##Swizzle, VPI_PACKING_##P0, VPI_PACKING_##P1)

#define VPI_DETAIL_MAKE_RAW_FMT3(RawPattern, MemLayout, DataType, Swizzle, P0, P1, P2)                      \
    VPI_DETAIL_MAKE_RAW_FORMAT3(VPI_RAW_##RawPattern, VPI_MEM_LAYOUT_##MemLayout, VPI_DATA_TYPE_##DataType, \
                                VPI_SWIZZLE_##Swizzle, VPI_PACKING_##P0, VPI_PACKING_##P1, VPI_PACKING_##P2)

#define VPI_DETAIL_MAKE_RAW_FMT4(RawPattern, MemLayout, DataType, Swizzle, P0, P1, P2, P3)                   \
    VPI_DETAIL_MAKE_RAW_FORMAT4(VPI_RAW_##RawPattern, VPI_MEM_LAYOUT_##MemLayout, VPI_DATA_TYPE_##DataType,  \
                                VPI_SWIZZLE_##Swizzle, VPI_PACKING_##P0, VPI_PACKING_##P1, VPI_PACKING_##P2, \
                                VPI_PACKING_##P3)

#define VPI_DETAIL_MAKE_RAW_FMT(RawPattern, MemLayout, DataType, Swizzle, PlaneCount, ...) \
    VPI_DETAIL_MAKE_RAW_FMT##PlaneCount(RawPattern, MemLayout, DataType, Swizzle, __VA_ARGS__)

// MAKE_YCbCr ===============================================

// Full arg name

#define VPI_DETAIL_MAKE_YCbCr_FORMAT1(ColorSpec, ChromaSubsamp, MemLayout, DataType, Swizzle, P0) \
    VPI_DETAIL_MAKE_FORMAT(VPI_COLOR_MODEL_##YCbCr, ColorSpec, ChromaSubsamp, MemLayout, DataType, Swizzle, P0, 0, 0, 0)

#define VPI_DETAIL_MAKE_YCbCr_FORMAT2(ColorSpec, ChromaSubsamp, MemLayout, DataType, Swizzle, P0, P1)                  \
    VPI_DETAIL_MAKE_FORMAT(VPI_COLOR_MODEL_##YCbCr, ColorSpec, ChromaSubsamp, MemLayout, DataType, Swizzle, P0, P1, 0, \
                           0)

#define VPI_DETAIL_MAKE_YCbCr_FORMAT3(ColorSpec, ChromaSubsamp, MemLayout, DataType, Swizzle, P0, P1, P2)           \
    VPI_DETAIL_MAKE_FORMAT(VPI_COLOR_MODEL_##YCbCr, ColorSpec, ChromaSubsamp, MemLayout, DataType, Swizzle, P0, P1, \
                           P2, 0)

#define VPI_DETAIL_MAKE_YCbCr_FORMAT4(ColorSpec, ChromaSubsamp, MemLayout, DataType, Swizzle, P0, P1, P2, P3)       \
    VPI_DETAIL_MAKE_FORMAT(VPI_COLOR_MODEL_##YCbCr, ColorSpec, ChromaSubsamp, MemLayout, DataType, Swizzle, P0, P1, \
                           P2, P3)

#define VPI_DETAIL_MAKE_YCbCr_FORMAT(ColorSpec, ChromaSubsamp, MemLayout, DataType, Swizzle, PlaneCount, ...) \
    VPI_DETAIL_MAKE_YCbCr_FORMAT##PlaneCount(ColorSpec, ChromaSubsamp, MemLayout, DataType, Swizzle, __VA_ARGS__)

// Abbreviated

#define VPI_DETAIL_MAKE_YCbCr_FMT1(ColorSpec, ChromaSubsamp, MemLayout, DataType, Swizzle, P0) \
    VPI_DETAIL_MAKE_FMT(YCbCr, ColorSpec, ChromaSubsamp, MemLayout, DataType, Swizzle, P0, 0, 0, 0)

#define VPI_DETAIL_MAKE_YCbCr_FMT2(ColorSpec, ChromaSubsamp, MemLayout, DataType, Swizzle, P0, P1) \
    VPI_DETAIL_MAKE_FMT(YCbCr, ColorSpec, ChromaSubsamp, MemLayout, DataType, Swizzle, P0, P1, 0, 0)

#define VPI_DETAIL_MAKE_YCbCr_FMT3(ColorSpec, ChromaSubsamp, MemLayout, DataType, Swizzle, P0, P1, P2) \
    VPI_DETAIL_MAKE_FMT(YCbCr, ColorSpec, ChromaSubsamp, MemLayout, DataType, Swizzle, P0, P1, P2, 0)

#define VPI_DETAIL_MAKE_YCbCr_FMT4(ColorSpec, ChromaSubsamp, MemLayout, DataType, Swizzle, P0, P1, P2, P3) \
    VPI_DETAIL_MAKE_FMT(YCbCr, ColorSpec, ChromaSubsamp, MemLayout, DataType, Swizzle, P0, P1, P2, P3)

#define VPI_DETAIL_MAKE_YCbCr_FMT(ColorSpec, ChromaSubsamp, MemLayout, DataType, Swizzle, PlaneCount, ...) \
    VPI_DETAIL_MAKE_YCbCr_FMT##PlaneCount(ColorSpec, ChromaSubsamp, MemLayout, DataType, Swizzle, __VA_ARGS__)

// MAKE_COLOR_SPEC --------------------------------------------

#define VPI_DETAIL_MAKE_COLOR_SPEC(CSpace, Encoding, XferFunc, Range, LocHoriz, LocVert)  \
    (VPI_DETAIL_SET_BITFIELD((CSpace), 0, 3) | VPI_DETAIL_SET_BITFIELD(XferFunc, 3, 4) |  \
     VPI_DETAIL_SET_BITFIELD(Encoding, 7, 3) | VPI_DETAIL_SET_BITFIELD(LocHoriz, 10, 2) | \
     VPI_DETAIL_SET_BITFIELD(LocVert, 12, 2) | VPI_DETAIL_SET_BITFIELD(Range, 14, 1))

#define VPI_DETAIL_MAKE_CSPC(CSpace, Encoding, XferFunc, Range, LocHoriz, LocVert)                                \
    VPI_DETAIL_MAKE_COLOR_SPEC(VPI_COLOR_##CSpace, VPI_YCbCr_##Encoding, VPI_COLOR_##XferFunc, VPI_COLOR_##Range, \
                               VPI_CHROMA_##LocHoriz, VPI_CHROMA_##LocVert)

#endif /* NV_VPI_DETAIL_FORMATUTILS_H */
// End content from: detail/FormatUtils.h

// Begin content from: Export.h
/*
 * Copyright 2019-2021 NVIDIA Corporation. All rights reserved.
 *
 * NOTICE TO LICENSEE:
 *
 * This source code and/or documentation ("Licensed Deliverables") are
 * subject to NVIDIA intellectual property rights under U.S. and
 * international Copyright laws.
 *
 * These Licensed Deliverables contained herein is PROPRIETARY and
 * CONFIDENTIAL to NVIDIA and is being provided under the terms and
 * conditions of a form of NVIDIA software license agreement by and
 * between NVIDIA and Licensee ("License Agreement") or electronically
 * accepted by Licensee. Notwithstanding any terms or conditions to
 * the contrary in the License Agreement, reproduction or disclosure
 * of the Licensed Deliverables to any third party without the express
 * written consent of NVIDIA is prohibited.
 *
 * NOTWITHSTANDING ANY TERMS OR CONDITIONS TO THE CONTRARY IN THE
 * LICENSE AGREEMENT, NVIDIA MAKES NO REPRESENTATION ABOUT THE
 * SUITABILITY OF THESE LICENSED DELIVERABLES FOR ANY PURPOSE. IT IS
 * PROVIDED "AS IS" WITHOUT EXPRESS OR IMPLIED WARRANTY OF ANY KIND.
 * NVIDIA DISCLAIMS ALL WARRANTIES WITH REGARD TO THESE LICENSED
 * DELIVERABLES, INCLUDING ALL IMPLIED WARRANTIES OF MERCHANTABILITY,
 * NONINFRINGEMENT, AND FITNESS FOR A PARTICULAR PURPOSE.
 * NOTWITHSTANDING ANY TERMS OR CONDITIONS TO THE CONTRARY IN THE
 * LICENSE AGREEMENT, IN NO EVENT SHALL NVIDIA BE LIABLE FOR ANY
 * SPECIAL, INDIRECT, INCIDENTAL, OR CONSEQUENTIAL DAMAGES, OR ANY
 * DAMAGES WHATSOEVER RESULTING FROM LOSS OF USE, DATA OR PROFITS,
 * WHETHER IN AN ACTION OF CONTRACT, NEGLIGENCE OR OTHER TORTIOUS
 * ACTION, ARISING OUT OF OR IN CONNECTION WITH THE USE OR PERFORMANCE
 * OF THESE LICENSED DELIVERABLES.
 *
 * U.S. Government End Users. These Licensed Deliverables are a
 * "commercial item" as that term is defined at 48 C.F.R. 2.101 (OCT
 * 1995), consisting of "commercial computer software" and "commercial
 * computer software documentation" as such terms are used in 48
 * C.F.R. 12.212 (SEPT 1995) and is provided to the U.S. Government
 * only as a commercial end item. Consistent with 48 C.F.R.12.212 and
 * 48 C.F.R. 227.7202-1 through 227.7202-4 (JUNE 1995), all
 * U.S. Government End Users acquire the Licensed Deliverables with
 * only those rights set forth herein.
 *
 * Any use of the Licensed Deliverables in individual and commercial
 * software must include, in the user documentation and internal
 * comments to the code, the above Disclaimer and U.S. Government End
 * Users Notice.
 */

#ifndef NV_VPI_EXPORT_H
#define NV_VPI_EXPORT_H

#if defined _WIN32 || defined __CYGWIN__
#    ifdef VPI_EXPORTING
#        define VPI_PUBLIC __declspec(dllexport)
#    elif defined(VPI_STATIC)
#        define VPI_PUBLIC
#    else
#        define VPI_PUBLIC __declspec(dllimport)
#    endif
#else
#    if __GNUC__ >= 4
#        define VPI_PUBLIC __attribute__((visibility("default")))
#    else
#        define VPI_PUBLIC
#    endif
#endif

#endif /* NV_VPI_EXPORT_H */
// End content from: Export.h

// Begin content from: DataLayout.h
/*
 * Copyright 2020-2021 NVIDIA Corporation. All rights reserved.
 *
 * NOTICE TO LICENSEE:
 *
 * This source code and/or documentation ("Licensed Deliverables") are
 * subject to NVIDIA intellectual property rights under U.S. and
 * international Copyright laws.
 *
 * These Licensed Deliverables contained herein is PROPRIETARY and
 * CONFIDENTIAL to NVIDIA and is being provided under the terms and
 * conditions of a form of NVIDIA software license agreement by and
 * between NVIDIA and Licensee ("License Agreement") or electronically
 * accepted by Licensee. Notwithstanding any terms or conditions to
 * the contrary in the License Agreement, reproduction or disclosure
 * of the Licensed Deliverables to any third party without the express
 * written consent of NVIDIA is prohibited.
 *
 * NOTWITHSTANDING ANY TERMS OR CONDITIONS TO THE CONTRARY IN THE
 * LICENSE AGREEMENT, NVIDIA MAKES NO REPRESENTATION ABOUT THE
 * SUITABILITY OF THESE LICENSED DELIVERABLES FOR ANY PURPOSE. IT IS
 * PROVIDED "AS IS" WITHOUT EXPRESS OR IMPLIED WARRANTY OF ANY KIND.
 * NVIDIA DISCLAIMS ALL WARRANTIES WITH REGARD TO THESE LICENSED
 * DELIVERABLES, INCLUDING ALL IMPLIED WARRANTIES OF MERCHANTABILITY,
 * NONINFRINGEMENT, AND FITNESS FOR A PARTICULAR PURPOSE.
 * NOTWITHSTANDING ANY TERMS OR CONDITIONS TO THE CONTRARY IN THE
 * LICENSE AGREEMENT, IN NO EVENT SHALL NVIDIA BE LIABLE FOR ANY
 * SPECIAL, INDIRECT, INCIDENTAL, OR CONSEQUENTIAL DAMAGES, OR ANY
 * DAMAGES WHATSOEVER RESULTING FROM LOSS OF USE, DATA OR PROFITS,
 * WHETHER IN AN ACTION OF CONTRACT, NEGLIGENCE OR OTHER TORTIOUS
 * ACTION, ARISING OUT OF OR IN CONNECTION WITH THE USE OR PERFORMANCE
 * OF THESE LICENSED DELIVERABLES.
 *
 * U.S. Government End Users. These Licensed Deliverables are a
 * "commercial item" as that term is defined at 48 C.F.R. 2.101 (OCT
 * 1995), consisting of "commercial computer software" and "commercial
 * computer software documentation" as such terms are used in 48
 * C.F.R. 12.212 (SEPT 1995) and is provided to the U.S. Government
 * only as a commercial end item. Consistent with 48 C.F.R.12.212 and
 * 48 C.F.R. 227.7202-1 through 227.7202-4 (JUNE 1995), all
 * U.S. Government End Users acquire the Licensed Deliverables with
 * only those rights set forth herein.
 *
 * Any use of the Licensed Deliverables in individual and commercial
 * software must include, in the user documentation and internal
 * comments to the code, the above Disclaimer and U.S. Government End
 * Users Notice.
 */

/**
 * @file DataLayout.h
 *
 * Defines types and functions to handle data layouts.
 */

#ifndef NV_VPI_DATALAYOUT_H
#define NV_VPI_DATALAYOUT_H

// #include "Export.h"
// #include "detail/FormatUtils.h"

#ifdef __cplusplus
extern "C" {
#endif

/**
* @defgroup VPI_DataLayout Data layout utilities 
* @ingroup VPI_API_Misc
* @{
*
*/

/** 
 * Maximum VPI channel count
 */
#define VPI_MAX_CHANNEL_COUNT (4)

/** Defines how channels are packed into an image plane element.
 *
 * Packing encodes how many channels the plane element has, and how they
 * are arranged in memory.
 * 
 * Up to 4 channels (denoted by X, Y, Z, W) can be packed into an image
 * plane element, each one occupying a specified number of bits.
 *
 * When two channels are specified one right after the other, they are
 * ordered from most-significant bit to least-significant bit. Words are
 * separated by underscores. For example:
 *
 * X8Y8Z8W8 = a single 32-bit word containing 4 channels, 8 bits each.
 *
 * In little-endian architectures:
 * <pre>
 *      Address  0   ||  1   ||  2   ||  3
 *            WWWWWWWWZZZZZZZZYYYYYYYYXXXXXXXX
 * </pre>
 *
 * In big-endian architectures:
 * <pre>
 *      Address  0   ||  1   ||  2   ||  3
 *            XXXXXXXXYYYYYYYYZZZZZZZZWWWWWWWW
 * </pre>
 *
 * X8_Y8_Z8_W8 = four consecutive 8-bit words, corresponding to 4 channels, 8 bits each.
 *
 * In little-endian architectures:
 * <pre>
 *      Address  0   ||  1   ||  2   ||  3
 *            XXXXXXXXYYYYYYYYZZZZZZZZWWWWWWWW
 * </pre>
 *
 * In big-endian architectures:
 * <pre>
 *      Address  0   ||  1   ||  2   ||  3
 *            XXXXXXXXYYYYYYYYZZZZZZZZWWWWWWWW
 * </pre>
 *
 * In cases where a word is less than 8 bits (e.g., X1 1-bit channel), channels
 * are ordered from LSB to MSB within a word.
 *
 * @note Also note equivalences such as the following:
 * @note In little-endian: X8_Y8_Z8_W8 = W8Z8Y8X8.
 * @note In big-endian: X8_Y8_Z8_W8 = X8Y8Z8W8.
 *
 * Some formats allow different packings when pixels' horizontal coordinate is
 * even or odd. For instance, every pixel of YUV422 packed format contains an Y
 * channel, while only even pixels contain the U channel, and odd pixels contain
 * V channel. Such formats use a double-underscore to separate the even pixels from the odd
 * pixels. The packing just described might be referred to X8_Y8__X8_Z8, where X = luma, 
 * Y = U chroma, Z = V chroma.
 */
typedef enum
{
    /** No channels. */
    VPI_PACKING_0 = 0,

    /** One 1-bit channel. */
    VPI_PACKING_X1 = VPI_DETAIL_BPP_NCH(1, 1),
    /** One 2-bit channel. */
    VPI_PACKING_X2 = VPI_DETAIL_BPP_NCH(2, 1),
    /** One 4-bit channel. */
    VPI_PACKING_X4 = VPI_DETAIL_BPP_NCH(4, 1),
    /** One 8-bit channel. */
    VPI_PACKING_X8 = VPI_DETAIL_BPP_NCH(8, 1),
    /** Two 4-bit channels in one word. */
    VPI_PACKING_X4Y4 = VPI_DETAIL_BPP_NCH(8, 2),
    /** Three 3-, 3- and 2-bit channels in one 8-bit word. */
    VPI_PACKING_X3Y3Z2 = VPI_DETAIL_BPP_NCH(8, 3),

    /** One 16-bit channel. */
    VPI_PACKING_X16 = VPI_DETAIL_BPP_NCH(16, 1),
    /** One LSB 10-bit channel in one 16-bit word. */
    VPI_PACKING_b6X10,
    /** One MSB 10-bit channel in one 16-bit word. */
    VPI_PACKING_X10b6,
    /** One LSB 12-bit channel in one 16-bit word. */
    VPI_PACKING_b4X12,
    /** One MSB 12-bit channel in one 16-bit word. */
    VPI_PACKING_X12b4,
    /** One LSB 14-bit channel in one 16-bit word. */
    VPI_PACKING_b2X14,

    /** Two 8-bit channels in two 8-bit words. */
    VPI_PACKING_X8_Y8 = VPI_DETAIL_BPP_NCH(16, 2),

    /** Three 5-, 5- and 6-bit channels in one 16-bit word. */
    VPI_PACKING_X5Y5Z6 = VPI_DETAIL_BPP_NCH(16, 3),
    /** Three 5-, 6- and 5-bit channels in one 16-bit word. */
    VPI_PACKING_X5Y6Z5,
    /** Three 6-, 5- and 5-bit channels in one 16-bit word. */
    VPI_PACKING_X6Y5Z5,
    /** Three 4-bit channels in one 16-bit word. */
    VPI_PACKING_b4X4Y4Z4,
    /** Three 5-bit channels in one 16-bit word. */
    VPI_PACKING_b1X5Y5Z5,
    /** Three 5-bit channels in one 16-bit word. */
    VPI_PACKING_X5Y5b1Z5,

    /** Four 1-, 5-, 5- and 5-bit channels in one 16-bit word. */
    VPI_PACKING_X1Y5Z5W5 = VPI_DETAIL_BPP_NCH(16, 4),
    /** Four 4-bit channels in one 16-bit word. */
    VPI_PACKING_X4Y4Z4W4,
    /** Four 5-, 1-, 5- and 5-bit channels in one 16-bit word. */
    VPI_PACKING_X5Y1Z5W5,
    /** Four 5-, 5-, 1- and 5-bit channels in one 16-bit word. */
    VPI_PACKING_X5Y5Z1W5,
    /** Four 5-, 5-, 5- and 1-bit channels in one 16-bit word. */
    VPI_PACKING_X5Y5Z5W1,

    /** 2 pixels of 2 8-bit channels each, totalling 4 8-bit words. */
    VPI_PACKING_X8_Y8__X8_Z8,
    /** 2 pixels of 2 swapped 8-bit channels each, totalling 4 8-bit words. */
    VPI_PACKING_Y8_X8__Z8_X8,

    /** One 24-bit channel. */
    VPI_PACKING_X24 = VPI_DETAIL_BPP_NCH(24, 1),

    /** Three 8-bit channels in three 8-bit words. */
    VPI_PACKING_X8_Y8_Z8 = VPI_DETAIL_BPP_NCH(24, 3),

    /** One 32-bit channel. */
    VPI_PACKING_X32 = VPI_DETAIL_BPP_NCH(32, 1),
    /** One LSB 20-bit channel in one 32-bit word. */
    VPI_PACKING_b12X20,

    /** Two 16-bit channels in two 16-bit words. */
    VPI_PACKING_X16_Y16 = VPI_DETAIL_BPP_NCH(32, 2),
    /** Two MSB 10-bit channels in two 16-bit words. */
    VPI_PACKING_X10b6_Y10b6,
    /** Two MSB 12-bit channels in two 16-bit words. */
    VPI_PACKING_X12b4_Y12b4,

    /** Three 10-, 11- and 11-bit channels in one 32-bit word. */
    VPI_PACKING_X10Y11Z11 = VPI_DETAIL_BPP_NCH(32, 3),
    /** Three 11-, 11- and 10-bit channels in one 32-bit word. */
    VPI_PACKING_X11Y11Z10,

    /** Four 8-bit channels in one 32-bit word. */
    VPI_PACKING_X8_Y8_Z8_W8 = VPI_DETAIL_BPP_NCH(32, 4),
    /** Four 2-, 10-, 10- and 10-bit channels in one 32-bit word. */
    VPI_PACKING_X2Y10Z10W10,
    /** Four 10-, 10-, 10- and 2-bit channels in one 32-bit word. */
    VPI_PACKING_X10Y10Z10W2,

    /** One 48-bit channel. */
    VPI_PACKING_X48 = VPI_DETAIL_BPP_NCH(48, 1),
    /** Three 16-bit channels in three 16-bit words. */
    VPI_PACKING_X16_Y16_Z16 = VPI_DETAIL_BPP_NCH(48, 3),

    /** One 64-bit channel. */
    VPI_PACKING_X64 = VPI_DETAIL_BPP_NCH(64, 1),
    /** Two 32-bit channels in two 32-bit words. */
    VPI_PACKING_X32_Y32 = VPI_DETAIL_BPP_NCH(64, 2),
    /** Four 16-bit channels in one 64-bit word. */
    VPI_PACKING_X16_Y16_Z16_W16 = VPI_DETAIL_BPP_NCH(64, 4),

    /** One 96-bit channel. */
    VPI_PACKING_X96 = VPI_DETAIL_BPP_NCH(96, 1),
    /** Three 32-bit channels in three 32-bit words. */
    VPI_PACKING_X32_Y32_Z32 = VPI_DETAIL_BPP_NCH(96, 3),

    /** One 128-bit channel. */
    VPI_PACKING_X128 = VPI_DETAIL_BPP_NCH(128, 1),
    /** Two 64-bit channels in two 64-bit words. */
    VPI_PACKING_X64_Y64 = VPI_DETAIL_BPP_NCH(128, 2),
    /** Four 32-bit channels in three 32-bit words. */
    VPI_PACKING_X32_Y32_Z32_W32 = VPI_DETAIL_BPP_NCH(128, 4),

    /** One 192-bit channel. */
    VPI_PACKING_X192 = VPI_DETAIL_BPP_NCH(192, 1),
    /** Three 64-bit channels in three 64-bit words. */
    VPI_PACKING_X64_Y64_Z64 = VPI_DETAIL_BPP_NCH(192, 3),

    /** One 128-bit channel. */
    VPI_PACKING_X256 = VPI_DETAIL_BPP_NCH(256, 1),
    /** Four 64-bit channels in four 64-bit words. */
    VPI_PACKING_X64_Y64_Z64_W64 = VPI_DETAIL_BPP_NCH(256, 4),

    /** Denotes an invalid packing. */
    VPI_PACKING_INVALID = INT32_MAX
} VPIPacking;

/** Defines the channel data type. */
typedef enum
{
    /** Represents an invalid data type.
     *  Used in some function to represent error return values. */
    VPI_DATA_TYPE_INVALID = 0,

    VPI_DATA_TYPE_UNSIGNED, /**< Channels are unsigned integer values. */
    VPI_DATA_TYPE_SIGNED,   /**< Channels are signed integer values. */
    VPI_DATA_TYPE_FLOAT,    /**< Channel are floating point values. */
    VPI_DATA_TYPE_FLOATISP  /**< Proprietary floating point format from NVIDIA. */
} VPIDataType;

/** Defines how the 2D plane pixels are laid out in memory.
 * This defines how a pixel are addressed, i.e., given its \f$(x,y)\f$ coordinate,
 * what's its memory address.
 * Block-linear formats have a proprietary memory representation and aren't supposed to
 * be addressed by the user directly.
 */
typedef enum
{
    /** Represents an invalid memory layout. */
    VPI_MEM_LAYOUT_INVALID = 0,

    /** Pixels are laid out in row-major order.
     * \f$(x,y) = y \times \mathit{pitch} + x \times \mathit{pixel stride}\f$. */
    VPI_MEM_LAYOUT_PITCH_LINEAR,

    /** Pixels are laid out in block-linear format with height = 1. */
    VPI_MEM_LAYOUT_BLOCK1_LINEAR,

    /** Pixels are laid out in block-linear format with height = 2. */
    VPI_MEM_LAYOUT_BLOCK2_LINEAR,

    /** Pixels are laid out in block-linear format with height = 4. */
    VPI_MEM_LAYOUT_BLOCK4_LINEAR,

    /** Pixels are laid out in block-linear format with height = 8. */
    VPI_MEM_LAYOUT_BLOCK8_LINEAR,

    /** Pixels are laid out in block-linear format with height = 16. */
    VPI_MEM_LAYOUT_BLOCK16_LINEAR,

    /** Pixels are laid out in block-linear format with height = 32. */
    VPI_MEM_LAYOUT_BLOCK32_LINEAR,

    /** Default block-linear format.
     * It's guaranteed to be valid in all algorithms that support block-linear format. */
    VPI_MEM_LAYOUT_BLOCK_LINEAR = VPI_MEM_LAYOUT_BLOCK2_LINEAR,

    /** @{ Useful aliases. */
    VPI_MEM_LAYOUT_PL = VPI_MEM_LAYOUT_PITCH_LINEAR,
    VPI_MEM_LAYOUT_BL = VPI_MEM_LAYOUT_BLOCK_LINEAR
    /** @} */
} VPIMemLayout;

/** Defines the format channel names.
 * The channels are color model-agnostic. */
typedef enum
{
    VPI_CHANNEL_INVALID = 7, /**< Represents an invalid swizzle channel. */

    VPI_CHANNEL_0 = 0, /**< Don't select a channel. */
    VPI_CHANNEL_X,     /**< Selects the first channel of the color model. */
    VPI_CHANNEL_Y,     /**< Selects the second channel of the color model. */
    VPI_CHANNEL_Z,     /**< Selects the third channel of the color model. */
    VPI_CHANNEL_W,     /**< Selects the fourth channel of the color model. */
    VPI_CHANNEL_1      /**< Sets the corresponding channel to have its maximum value. */
} VPIChannel;

/** Defines the supported channel swizzle operations.
 *
 * The operations map an input vector \f$(x,y,z,w)\f$ into an output vector
 * \f$(x',y',z',w')\f$. Any output channel can select any of the input
 * channels, or the constants zero or one. For example, the swizzle "X000"
 * selects the first channel, whereas swizzle "ZYXW" swaps the X and Z
 * channels, needed for conversion between RGBA and BGRA image formats.
 */
typedef enum
{
    /** Represents an invalid swizzle. */
    VPI_SWIZZLE_INVALID = VPI_DETAIL_MAKE_SWZL(INVALID, INVALID, INVALID, INVALID),

    /** @{ Swizzle operation. */
    VPI_DETAIL_DEF_SWIZZLE_ENUM(0, 0, 0, 0),
    VPI_DETAIL_DEF_SWIZZLE_ENUM(1, 0, 0, 0),
    VPI_DETAIL_DEF_SWIZZLE_ENUM(0, 0, 0, 1),
    VPI_DETAIL_DEF_SWIZZLE_ENUM(X, Y, Z, W),
    VPI_DETAIL_DEF_SWIZZLE_ENUM(Z, Y, X, W),
    VPI_DETAIL_DEF_SWIZZLE_ENUM(W, X, Y, Z),
    VPI_DETAIL_DEF_SWIZZLE_ENUM(W, Z, Y, X),
    VPI_DETAIL_DEF_SWIZZLE_ENUM(Y, Z, W, X),
    VPI_DETAIL_DEF_SWIZZLE_ENUM(X, Y, Z, 1),
    VPI_DETAIL_DEF_SWIZZLE_ENUM(X, Y, Z, 0),
    VPI_DETAIL_DEF_SWIZZLE_ENUM(Y, Z, W, 1),
    VPI_DETAIL_DEF_SWIZZLE_ENUM(X, X, X, 1),
    VPI_DETAIL_DEF_SWIZZLE_ENUM(X, Z, Y, 1),
    VPI_DETAIL_DEF_SWIZZLE_ENUM(Z, Y, X, 1),
    VPI_DETAIL_DEF_SWIZZLE_ENUM(Z, Y, X, 0),
    VPI_DETAIL_DEF_SWIZZLE_ENUM(W, Z, Y, 1),
    VPI_DETAIL_DEF_SWIZZLE_ENUM(X, 0, 0, 0),
    VPI_DETAIL_DEF_SWIZZLE_ENUM(0, X, 0, 0),
    VPI_DETAIL_DEF_SWIZZLE_ENUM(0, 0, X, 0),
    VPI_DETAIL_DEF_SWIZZLE_ENUM(0, 0, 0, X),
    VPI_DETAIL_DEF_SWIZZLE_ENUM(Y, 0, 0, 0),
    VPI_DETAIL_DEF_SWIZZLE_ENUM(0, Y, 0, 0),
    VPI_DETAIL_DEF_SWIZZLE_ENUM(0, 0, Y, 0),
    VPI_DETAIL_DEF_SWIZZLE_ENUM(0, 0, 0, Y),
    VPI_DETAIL_DEF_SWIZZLE_ENUM(0, X, Y, 0),
    VPI_DETAIL_DEF_SWIZZLE_ENUM(X, X, X, Y),
    VPI_DETAIL_DEF_SWIZZLE_ENUM(Y, Y, Y, X),
    VPI_DETAIL_DEF_SWIZZLE_ENUM(0, Y, X, 0),
    VPI_DETAIL_DEF_SWIZZLE_ENUM(X, 0, 0, Y),
    VPI_DETAIL_DEF_SWIZZLE_ENUM(Y, 0, 0, X),
    VPI_DETAIL_DEF_SWIZZLE_ENUM(X, 0, 0, 1),
    VPI_DETAIL_DEF_SWIZZLE_ENUM(X, Y, 0, 1),
    VPI_DETAIL_DEF_SWIZZLE_ENUM(X, Y, 0, 0),
    VPI_DETAIL_DEF_SWIZZLE_ENUM(0, X, Z, 0),
    VPI_DETAIL_DEF_SWIZZLE_ENUM(0, Z, X, 0),
    VPI_DETAIL_DEF_SWIZZLE_ENUM(X, Z, Y, 0),
    VPI_DETAIL_DEF_SWIZZLE_ENUM(Y, Z, X, 1),
    VPI_DETAIL_DEF_SWIZZLE_ENUM(Z, Y, W, 1),
    VPI_DETAIL_DEF_SWIZZLE_ENUM(0, Y, X, 1),
    VPI_DETAIL_DEF_SWIZZLE_ENUM(X, Y, X, Z),
    VPI_DETAIL_DEF_SWIZZLE_ENUM(Y, X, Z, X),
    VPI_DETAIL_DEF_SWIZZLE_ENUM(X, Z, 0, 0),
    VPI_DETAIL_DEF_SWIZZLE_ENUM(W, Y, X, Z),
    VPI_DETAIL_DEF_SWIZZLE_ENUM(Y, X, 0, 0),
    VPI_DETAIL_DEF_SWIZZLE_ENUM(Y, X, 0, 1),
    VPI_DETAIL_DEF_SWIZZLE_ENUM(0, 0, Y, X),
    VPI_DETAIL_DEF_SWIZZLE_ENUM(0, 0, X, Y),
    VPI_DETAIL_DEF_SWIZZLE_ENUM(0, X, Y, 1),
    VPI_DETAIL_DEF_SWIZZLE_ENUM(0, X, 0, 1),
    VPI_DETAIL_DEF_SWIZZLE_ENUM(Y, Z, X, W),
    VPI_DETAIL_DEF_SWIZZLE_ENUM(Y, W, 0, 0),
    VPI_DETAIL_DEF_SWIZZLE_ENUM(X, Y, W, 0),
    VPI_DETAIL_DEF_SWIZZLE_ENUM(Y, Z, W, 0),
    /** @} */
} VPISwizzle;

/** Creates a user-defined swizzle operation, using abbreviated parameters.
 * This macro is used to create a user-defined swizzle operation.
 * Parameters are specified literally by X, Y, Z, 0, 1. They correpond to \ref VPIChannel values.
 * Example:
 * \code{.c}
 *   VPISwizzle sw = VPI_MAKE_SWIZZLE_ABBREV(0,Y,Z,W);
 * \endcode
 *
 * @param[in] x Channel that will correspond to the first component, without the VPI_CHANNEL prefix.
 * @param[in] y Channel that will correspond to the second component, without the VPI_CHANNEL prefix.
 * @param[in] z Channel that will correspond to the third component, without the VPI_CHANNEL prefix.
 * @param[in] w Channel that will correspond to the fourth component, without the VPI_CHANNEL prefix.
 *
 * @returns the user-defined \ref VPISwizzle operation.
 */
#ifdef VPI_DOXYGEN
#    define VPI_MAKE_SWIZZLE_ABBREV(x, y, z, w)
#else
#    define VPI_MAKE_SWIZZLE_ABBREV (VPISwizzle) VPI_DETAIL_MAKE_SWZL
#endif

/** Creates a user-defined swizzle operation.
 * This macro is used to create a user-defined swizzle operation if it's not predefined.
 * Example:
 * \code{.c}
 *   VPISwizzle sw = VPI_MAKE_SWIZZLE(VPI_CHANNEL_0,VPI_CHANNEL_Y,VPI_CHANNEL_Z,VPI_CHANNEL_W);
 * \endcode
 *
 * @param[in] x Channel that will correspond to the first component.
 * @param[in] y Channel that will correspond to the second component.
 * @param[in] z Channel that will correspond to the third component.
 * @param[in] w Channel that will correspond to the fourth component.
 *
 * @returns the user-defined \ref VPISwizzle operation.
 */
#ifdef VPI_DOXYGEN
#    define VPI_MAKE_SWIZZLE(x, y, z, w)
#else
#    define VPI_MAKE_SWIZZLE (VPISwizzle) VPI_DETAIL_MAKE_SWIZZLE
#endif

/** Creates a user-defined \ref VPISwizzle operation.
 * This is similar to \ref VPI_MAKE_SWIZZLE, but accepts the swizzle channels as runtime variables.
 * 
 * @param[in] x Channel that will correspond to the first component.
 *
 * @param[in] y Channel that will correspond to the second component.
 *
 * @param[in] z Channel that will correspond to the third component.
 *
 * @param[in] w Channel that will correspond to the fourth component.
 *
 * @returns Swizzle operation as defined by the given channel order.
 * @retval #VPI_SWIZZLE_INVALID Input channel is invalid.
 */
VPI_PUBLIC VPISwizzle vpiMakeSwizzle(VPIChannel x, VPIChannel y, VPIChannel z, VPIChannel w);

/** Get the swizzle channels.
 *
 * For example, given swizzle \ref VPI_SWIZZLE_YZWX, it returns
 * \ref VPI_CHANNEL_Y, \ref VPI_CHANNEL_Z, \ref VPI_CHANNEL_W and
 * \ref VPI_CHANNEL_X.
 *
 * @param[in] swizzle Swizzle to be queried.
 *
 * @param[out] channels Output channel array with 4 elements.
 */
VPI_PUBLIC void vpiSwizzleGetChannels(VPISwizzle swizzle, VPIChannel *channels);

/** Get the number of channels specified by the given swizzle.
 *
 * Only the following count as channels:
 * - \ref VPI_CHANNEL_X
 * - \ref VPI_CHANNEL_Y
 * - \ref VPI_CHANNEL_Z
 * - \ref VPI_CHANNEL_W
 *
 * @param[in] swizzle Swizzle to be queried.
 *
 * @returns The channel count specified by swizzle.
 */
VPI_PUBLIC int vpiSwizzleGetChannelCount(VPISwizzle swizzle);

/** Endianness of a \ref VPIPacking value. */
typedef enum
{
    VPI_INVALID_ENDIAN, /**< Invalid endianness value. */
    VPI_HOST_ENDIAN,    /**< Endianness of the host machine. */
    VPI_BIG_ENDIAN      /**< Big endian, where most significant byte has lower memory address. */
} VPIEndianness;

/** Defines the parameters encoded in a \ref VPIPacking. */
typedef struct
{
    /** Component ordering in a word. */
    VPIEndianness endianness;

    /** Channel ordering.  */
    VPISwizzle swizzle;

    /** Number of bits in each channel.
     *  If channel doesn't exist, corresponding bits==0. */
    int bits[VPI_MAX_CHANNEL_COUNT];

} VPIPackingParams;

/** Returns a pre-defined \ref VPIPacking given its params.
 *
 * This function calculates the \ref VPIPacking based on the channel characteristics at run time.
 *
 *
 * @param[in] params Packing parameters.
 *                   If \ref VPIPackingParams::swizzle is set to \ref VPI_SWIZZLE_0000 or \ref VPI_SWIZZLE_INVALID, 
 *                   the swizzle will be inferred from \ref VPIPackingParams::bits
 *
 * @returns The packing enum corresponding to \p params.
 *
 * @retval #VPI_PACKING_INVALID Requested packing isn't defined or is malformed.
 * @retval #VPI_PACKING_INVALID \p params is NULL.
 */
VPI_PUBLIC VPIPacking vpiMakePacking(const VPIPackingParams *params);

/** Returns channels' information from a format packing.
 *
 * @param[in] packing The format packing to be queried.
 * 
 * @param[out] params The packing parameters.
 *                    Passing NULL is allowed, to which the function simply does nothing.
 */
VPI_PUBLIC void vpiPackingGetParams(VPIPacking packing, VPIPackingParams *params);

/** Returns the number of components defined by the given packing.
 *
 * @param[in] packing The format packing to be queried.
 *
 * @returns Number of components from the given format packing. It's value between 0 and 4.
 */
VPI_PUBLIC int vpiPackingGetComponentCount(VPIPacking packing);

/** Returns the number of bits per packing component.
 *
 * @param[in] packing The format packing to be queried.
 * 
 * @param[out] bits Pointer to an int32_t array with 4 elements where output will be stored. 
 *                  Passing NULL is allowed, to which the function simply does nothing.
 *
 */
VPI_PUBLIC void vpiPackingGetBitsPerComponent(VPIPacking packing, int32_t *bits);

/** Returns the number of bits per pixel of the given packing.
 *
 * @param[in] packing The format packing to be queried.
 *
 * @returns Total number of bits per pixel of the given packing. 
 *          It's the sum of number of bits occupied by all packing channels.
 */
VPI_PUBLIC int vpiPackingGetBitsPerPixel(VPIPacking packing);

/** @} */

#ifdef __cplusplus
}
#endif

#endif /* NV_VPI_DATALAYOUT_H */
// End content from: DataLayout.h

// Begin content from: PixelType.h
/*
 * Copyright 2020-2021 NVIDIA Corporation. All rights reserved.
 *
 * NOTICE TO LICENSEE:
 *
 * This source code and/or documentation ("Licensed Deliverables") are
 * subject to NVIDIA intellectual property rights under U.S. and
 * international Copyright laws.
 *
 * These Licensed Deliverables contained herein is PROPRIETARY and
 * CONFIDENTIAL to NVIDIA and is being provided under the terms and
 * conditions of a form of NVIDIA software license agreement by and
 * between NVIDIA and Licensee ("License Agreement") or electronically
 * accepted by Licensee. Notwithstanding any terms or conditions to
 * the contrary in the License Agreement, reproduction or disclosure
 * of the Licensed Deliverables to any third party without the express
 * written consent of NVIDIA is prohibited.
 *
 * NOTWITHSTANDING ANY TERMS OR CONDITIONS TO THE CONTRARY IN THE
 * LICENSE AGREEMENT, NVIDIA MAKES NO REPRESENTATION ABOUT THE
 * SUITABILITY OF THESE LICENSED DELIVERABLES FOR ANY PURPOSE. IT IS
 * PROVIDED "AS IS" WITHOUT EXPRESS OR IMPLIED WARRANTY OF ANY KIND.
 * NVIDIA DISCLAIMS ALL WARRANTIES WITH REGARD TO THESE LICENSED
 * DELIVERABLES, INCLUDING ALL IMPLIED WARRANTIES OF MERCHANTABILITY,
 * NONINFRINGEMENT, AND FITNESS FOR A PARTICULAR PURPOSE.
 * NOTWITHSTANDING ANY TERMS OR CONDITIONS TO THE CONTRARY IN THE
 * LICENSE AGREEMENT, IN NO EVENT SHALL NVIDIA BE LIABLE FOR ANY
 * SPECIAL, INDIRECT, INCIDENTAL, OR CONSEQUENTIAL DAMAGES, OR ANY
 * DAMAGES WHATSOEVER RESULTING FROM LOSS OF USE, DATA OR PROFITS,
 * WHETHER IN AN ACTION OF CONTRACT, NEGLIGENCE OR OTHER TORTIOUS
 * ACTION, ARISING OUT OF OR IN CONNECTION WITH THE USE OR PERFORMANCE
 * OF THESE LICENSED DELIVERABLES.
 *
 * U.S. Government End Users. These Licensed Deliverables are a
 * "commercial item" as that term is defined at 48 C.F.R. 2.101 (OCT
 * 1995), consisting of "commercial computer software" and "commercial
 * computer software documentation" as such terms are used in 48
 * C.F.R. 12.212 (SEPT 1995) and is provided to the U.S. Government
 * only as a commercial end item. Consistent with 48 C.F.R.12.212 and
 * 48 C.F.R. 227.7202-1 through 227.7202-4 (JUNE 1995), all
 * U.S. Government End Users acquire the Licensed Deliverables with
 * only those rights set forth herein.
 *
 * Any use of the Licensed Deliverables in individual and commercial
 * software must include, in the user documentation and internal
 * comments to the code, the above Disclaimer and U.S. Government End
 * Users Notice.
 */

/**
 * @file PixelType.h
 *
 * Defines types and functions to handle pixel types.
 */

#ifndef NV_VPI_PIXEL_TYPE_H
#define NV_VPI_PIXEL_TYPE_H

// #include "DataLayout.h"
// #include "detail/FormatUtils.h"

#ifdef __cplusplus
extern "C" {
#endif

/**
 * @ingroup VPI_ImageFormat
 * @{
 */

/**
 * Pre-defined pixel types.
 * Pixel types defines the geometry of pixels in a image plane without taking into account what the value represents.
 * For example, a \ref VPI_IMAGE_FORMAT_NV12 is composed of 2 planes, each one with the following pixel types:
 * + \ref VPI_PIXEL_TYPE_U8 representing pixels as 8-bit unsigned values.
 * + \ref VPI_PIXEL_TYPE_2U8 representing pixels as two interleaved 32-bit floating-point values.
 */
typedef uint64_t VPIPixelType;

/* clang-format off */

/** Used to signal that the pixel type must be inferred from image format. */
#define VPI_PIXEL_TYPE_DEFAULT ((VPIPixelType)0)
/** Signal format conversion errors. */
#define VPI_PIXEL_TYPE_INVALID VPI_PIXEL_TYPE_DEFAULT

/** One channel of unsigned 8-bit value. */
#define VPI_PIXEL_TYPE_U8   VPI_DETAIL_MAKE_PIX_TYPE(PL, UNSIGNED, X8)
/** Two interleaved channels of unsigned 8-bit values. */
#define VPI_PIXEL_TYPE_2U8  VPI_DETAIL_MAKE_PIX_TYPE(PL, UNSIGNED, X8_Y8)
/** Three interleaved channels of unsigned 8-bit values. */
#define VPI_PIXEL_TYPE_3U8  VPI_DETAIL_MAKE_PIX_TYPE(PL, UNSIGNED, X8_Y8_Z8)
/** Four interleaved channels of unsigned 8-bit values. */
#define VPI_PIXEL_TYPE_4U8  VPI_DETAIL_MAKE_PIX_TYPE(PL, UNSIGNED, X8_Y8_Z8_W8)

/** One channel of signed 8-bit value. */
#define VPI_PIXEL_TYPE_S8   VPI_DETAIL_MAKE_PIX_TYPE(PL, SIGNED, X8)
/** Two interleaved channels of signed 8-bit values. */
#define VPI_PIXEL_TYPE_2S8  VPI_DETAIL_MAKE_PIX_TYPE(PL, SIGNED, X8_Y8)
/** Three interleaved channels of signed 8-bit values. */
#define VPI_PIXEL_TYPE_3S8  VPI_DETAIL_MAKE_PIX_TYPE(PL, SIGNED, X8_Y8_Z8)
/** Four interleaved channels of signed 8-bit values. */
#define VPI_PIXEL_TYPE_4S8  VPI_DETAIL_MAKE_PIX_TYPE(PL, SIGNED, X8_Y8_Z8_W8)

/** One channel of unsigned 16-bit value. */
#define VPI_PIXEL_TYPE_U16  VPI_DETAIL_MAKE_PIX_TYPE(PL, UNSIGNED, X16)
/** Two interleaved channels of unsigned 16-bit values. */
#define VPI_PIXEL_TYPE_2U16 VPI_DETAIL_MAKE_PIX_TYPE(PL, UNSIGNED, X16_Y16)
/** Three interleaved channels of unsigned 16-bit values. */
#define VPI_PIXEL_TYPE_3U16 VPI_DETAIL_MAKE_PIX_TYPE(PL, UNSIGNED, X16_Y16_Z16)
/** Four interleaved channels of unsigned 16-bit values. */
#define VPI_PIXEL_TYPE_4U16 VPI_DETAIL_MAKE_PIX_TYPE(PL, UNSIGNED, X16_Y16_Z16_W16)

/** One channel of signed 16-bit value. */
#define VPI_PIXEL_TYPE_S16  VPI_DETAIL_MAKE_PIX_TYPE(PL, SIGNED, X16)
/** Two interleaved channels of signed 16-bit values. */
#define VPI_PIXEL_TYPE_2S16 VPI_DETAIL_MAKE_PIX_TYPE(PL, SIGNED, X16_Y16)
/** Three interleaved channels of signed 16-bit values. */
#define VPI_PIXEL_TYPE_3S16 VPI_DETAIL_MAKE_PIX_TYPE(PL, SIGNED, X16_Y16_Z16)
/** Four interleaved channels of signed 16-bit values. */
#define VPI_PIXEL_TYPE_4S16 VPI_DETAIL_MAKE_PIX_TYPE(PL, SIGNED, X16_Y16_Z16_W16)

/** One channel of unsigned 32-bit value. */
#define VPI_PIXEL_TYPE_U32  VPI_DETAIL_MAKE_PIX_TYPE(PL, UNSIGNED, X32)
/** Two interleaved channels of unsigned 32-bit values. */
#define VPI_PIXEL_TYPE_2U32 VPI_DETAIL_MAKE_PIX_TYPE(PL, UNSIGNED, X32_Y32)
/** Three interleaved channels of unsigned 32-bit values. */
#define VPI_PIXEL_TYPE_3U32 VPI_DETAIL_MAKE_PIX_TYPE(PL, UNSIGNED, X32_Y32_Z32)
/** Four interleaved channels of unsigned 32-bit values. */
#define VPI_PIXEL_TYPE_4U32 VPI_DETAIL_MAKE_PIX_TYPE(PL, UNSIGNED, X32_Y32_Z32_W32)

/** One channel of signed 32-bit value. */
#define VPI_PIXEL_TYPE_S32  VPI_DETAIL_MAKE_PIX_TYPE(PL, SIGNED, X32)
/** Two interleaved channels of signed 32-bit values. */
#define VPI_PIXEL_TYPE_2S32 VPI_DETAIL_MAKE_PIX_TYPE(PL, SIGNED, X32_Y32)
/** Three interleaved channels of signed 32-bit values. */
#define VPI_PIXEL_TYPE_3S32 VPI_DETAIL_MAKE_PIX_TYPE(PL, SIGNED, X32_Y32_Z32)
/** Four interleaved channels of signed 32-bit values. */
#define VPI_PIXEL_TYPE_4S32 VPI_DETAIL_MAKE_PIX_TYPE(PL, SIGNED, X32_Y32_Z32_W32)

/** One channel of 32-bit IEEE 754 floating-point value. */
#define VPI_PIXEL_TYPE_F32  VPI_DETAIL_MAKE_PIX_TYPE(PL, FLOAT, X32)
/** Two interleaved channels of 32-bit IEEE 754 floating-point values. */
#define VPI_PIXEL_TYPE_2F32 VPI_DETAIL_MAKE_PIX_TYPE(PL, FLOAT, X32_Y32)
/** Three interleaved channels of 32-bit IEEE 754 floating-point values. */
#define VPI_PIXEL_TYPE_3F32 VPI_DETAIL_MAKE_PIX_TYPE(PL, FLOAT, X32_Y32_Z32)
/** Four interleaved channels of 32-bit IEEE 754 floating-point values. */
#define VPI_PIXEL_TYPE_4F32 VPI_DETAIL_MAKE_PIX_TYPE(PL, FLOAT, X32_Y32_Z32_W32)

/** One channel of unsigned 64-bit value. */
#define VPI_PIXEL_TYPE_U64  VPI_DETAIL_MAKE_PIX_TYPE(PL, UNSIGNED, X64)
/** Two interleaved channels of unsigned 64-bit values. */
#define VPI_PIXEL_TYPE_2U64 VPI_DETAIL_MAKE_PIX_TYPE(PL, UNSIGNED, X64_Y64)
/** Three interleaved channels of unsigned 64-bit values. */
#define VPI_PIXEL_TYPE_3U64 VPI_DETAIL_MAKE_PIX_TYPE(PL, UNSIGNED, X64_Y64_Z64)
/** Four interleaved channels of unsigned 64-bit values. */
#define VPI_PIXEL_TYPE_4U64 VPI_DETAIL_MAKE_PIX_TYPE(PL, UNSIGNED, X64_Y64_Z64_W64)

/** One channel of signed 64-bit value. */
#define VPI_PIXEL_TYPE_S64  VPI_DETAIL_MAKE_PIX_TYPE(PL, SIGNED, X64)
/** Two interleaved channels of signed 64-bit values. */
#define VPI_PIXEL_TYPE_2S64 VPI_DETAIL_MAKE_PIX_TYPE(PL, SIGNED, X64_Y64)
/** Three interleaved channels of signed 64-bit values. */
#define VPI_PIXEL_TYPE_3S64 VPI_DETAIL_MAKE_PIX_TYPE(PL, SIGNED, X64_Y64_Z64)
/** Four interleaved channels of signed 64-bit values. */
#define VPI_PIXEL_TYPE_4S64 VPI_DETAIL_MAKE_PIX_TYPE(PL, SIGNED, X64_Y64_Z64_W64)

/** One channel of 64-bit IEEE 754 floating-point value. */
#define VPI_PIXEL_TYPE_F64  VPI_DETAIL_MAKE_PIX_TYPE(PL, FLOAT, X64)
/** Two interleaved channels of 64-bit IEEE 754 floating-point values. */
#define VPI_PIXEL_TYPE_2F64 VPI_DETAIL_MAKE_PIX_TYPE(PL, FLOAT, X64_Y64)
/** Three interleaved channels of 64-bit IEEE 754 floating-point values. */
#define VPI_PIXEL_TYPE_3F64 VPI_DETAIL_MAKE_PIX_TYPE(PL, FLOAT, X64_Y64_Z64)
/** Four interleaved channels of 64-bit IEEE 754 floating-point values. */
#define VPI_PIXEL_TYPE_4F64 VPI_DETAIL_MAKE_PIX_TYPE(PL, FLOAT, X64_Y64_Z64_W64)

/* clang-format on */

/** Creates a user-defined pixel type constant using abbreviated parameters.
 *
 * This macro allows passing abbreviated format parameters (without the parameter type prefix).
 * Example to create a block-linear format two interleaved 32-bit floating point channels:
 * \code{.c}
 *     VPIPixelType type = VPI_MAKE_PIXEL_TYPE_ABBREV(BL, FLOAT, X32_Y32);
 * \endcode
 *
 * @param[in] memLayout \ref VPIMemLayout to be used, without the VPI_MEM_LAYOUT_ prefix.
 * @param[in] dataType  \ref VPIDataType to be used, without the VPI_DATA_TYPE_ prefix.
 * @param[in] packing   Format packing used, which also defines the number of channels, without the VPI_PACKING_ prefix.
 *
 * @returns The user-defined pixel type.
 */
#ifdef VPI_DOXYGEN
#    define VPI_MAKE_PIXEL_TYPE_ABBREV(memLayout, dataType, packing)
#else
#    define VPI_MAKE_PIXEL_TYPE_ABBREV (VPIPixelType) VPI_DETAIL_MAKE_PIX_TYPE
#endif

/** Creates a user-defined pixel type constant.
 *
 * Example to create a block-linear format two interleaved 32-bit floating point channels:
 * \code{.c}
 *     VPIPixelType type = VPI_MAKE_PIXEL_TYPE(VPI_MEM_LAYOUT_BL, VPI_DATA_TYPE_FLOAT, VPI_PACKING_X32_Y32);
 * \endcode
 *
 * @param[in] memLayout \ref VPIMemLayout to be used.
 * @param[in] dataType  \ref VPIDataType to be used.
 * @param[in] packing   Format packing used, which also defines the number of channels.
 *
 * @returns The user-defined pixel type.
 */
#ifdef VPI_DOXYGEN
#    define VPI_MAKE_PIXEL_TYPE(memLayout, dataType, packing)
#else
#    define VPI_MAKE_PIXEL_TYPE (VPIPixelType) VPI_DETAIL_MAKE_PIXEL_TYPE
#endif

/** Creates a user-defined pixel type.
 * When the pre-defined pixel types aren't enough, user-defined formats can be created.
 *
 * @param[in] memLayout \ref VPIMemLayout to be used.
 *                     + Mandatory, must not be \ref VPI_MEM_LAYOUT_INVALID.
 * 
 * @param[in] dataType \ref VPIDataType to be used.
 *                     + Mandatory, must not be \ref VPI_DATA_TYPE_INVALID.
 * 
 * @param[in] packing Format packing used, which also defines the number of channels.
 *                     + Mandatory, must not be \ref VPI_PACKING_INVALID.
 *
 * @returns The user-defined pixel type.
 *
 * @retval #VPI_PIXEL_TYPE_INVALID Invalid \p memLayout.
 * @retval #VPI_PIXEL_TYPE_INVALID Invalid \p dataType.
 * @retval #VPI_PIXEL_TYPE_INVALID Invalid \p packing.
 */
VPI_PUBLIC VPIPixelType vpiMakePixelType(VPIMemLayout memLayout, VPIDataType dataType, VPIPacking packing);

/** Get the packing of a pixel type.
 *
 * @param[in] type Pixel type to be queried.
 *                 + Mandatory, must not be \ref VPI_PIXEL_TYPE_INVALID.
 *
 * @returns The format's packing.
 *
 * @retval #VPI_PACKING_0 \p type is invalid.
 */
VPI_PUBLIC VPIPacking vpiPixelTypeGetPacking(VPIPixelType type);

/** Get the number of bits per pixel of a pixel type.
 *
 * @param[in] type Pixel type to be queried.
 *                 + Mandatory, must not be \ref VPI_PIXEL_TYPE_INVALID.
 *
 * @returns The number of bits per pixel.
 *
 * @retval 0 \p type is invalid.
 */
VPI_PUBLIC int vpiPixelTypeGetBitsPerPixel(VPIPixelType type);

/** Get the number of bits per channel of a pixel type.
 *
 * @param[in] type Pixel type to be queried.
 *                 + Mandatory, must not be \ref VPI_PIXEL_TYPE_INVALID.
 *
 * @param[out] bits Pointer to an int32_t array with 4 elements where output will be stored.
 *                  If it is NULL, the function is a no-op, i.e., buffer pointed by \p bits is unchanged.
 */
VPI_PUBLIC void vpiPixelTypeGetBitsPerChannel(VPIPixelType type, int32_t *bits);

/** Get the data type of a pixel type.
 *
 * @param[in] type Pixel type to be queried.
 *                 + Mandatory, must not be \ref VPI_PIXEL_TYPE_INVALID.
 *
 * @returns The data type of the pixel type.
 *
 * @retval #VPI_DATA_TYPE_INVALID \p type is invalid.
 */
VPI_PUBLIC VPIDataType vpiPixelTypeGetDataType(VPIPixelType type);

/** Get the memory layout of a pixel type.
 *
 * @param[in] type Pixel type to be queried.
 *                 + Mandatory, must not be \ref VPI_PIXEL_TYPE_INVALID.
 *
 * @returns The memory layout of the pixel type.
 *
 * @retval #VPI_MEM_LAYOUT_INVALID \p type is invalid.
 */
VPI_PUBLIC VPIMemLayout vpiPixelTypeGetMemLayout(VPIPixelType type);

/** Set the memory layout of a pixel type.
 *
 * @param[in] type Pixel type to have its memory layout set.
 *                 + Mandatory, must not be \ref VPI_PIXEL_TYPE_INVALID.
 *
 * @param[in] layout The memory layout to be set.
 *                 + Mandatory, must not be \ref VPI_MEM_LAYOUT_INVALID.
 *
 * @returns The pixel type with the requested memory layout.
 *
 * @retval #VPI_PIXEL_TYPE_INVALID \p type or layout are invalid.
 */
VPI_PUBLIC VPIPixelType vpiPixelTypeSetMemLayout(VPIPixelType type, VPIMemLayout layout);

/** Get the number of channels of a pixel type.
 *
 * @param[in] type Pixel type to be queried.
 *                 + Mandatory, must not be \ref VPI_PIXEL_TYPE_INVALID.
 *
 * @returns The number of channels of the pixel type.
 *
 * @retval 0 \p type is invalid.
 */
VPI_PUBLIC int vpiPixelTypeGetChannelCount(VPIPixelType type);

/** Returns a string representation of the pixel type.
 *
 * @param[in] type Pixel type to be returned.
 *
 * @returns The string representation of the pixel type.
 *          Returned string is valid until next call of this function from the same calling thread.
 *          Returned pointer must not be freed.
 */
VPI_PUBLIC const char *vpiPixelTypeGetName(VPIPixelType type);

/** Get the pixel type for a given channel index.
 *
 * It returns a single-channel pixel type that corresponds to the given channel
 * of the input pixel type.
 *
 * For instance: The channel #2 of \ref VPI_PIXEL_TYPE_3U8 is \ref VPI_PIXEL_TYPE_U8.
 *
 * + The requested channel must have a type whose packing is one of the following:
 *   - \ref VPI_PACKING_X1
 *   - \ref VPI_PACKING_X2
 *   - \ref VPI_PACKING_X4
 *   - \ref VPI_PACKING_X8
 *   - \ref VPI_PACKING_X16
 *   - \ref VPI_PACKING_X24
 *   - \ref VPI_PACKING_X32
 *   - \ref VPI_PACKING_X48
 *   - \ref VPI_PACKING_X64
 *   - \ref VPI_PACKING_X96
 *   - \ref VPI_PACKING_X128
 *   - \ref VPI_PACKING_X192
 *   - \ref VPI_PACKING_X256
 *
 * @param[in] type Pixel type to be queried.
 *                 + Mandatory, must not be \ref VPI_PIXEL_TYPE_INVALID.
 *
 * @param[in] channel Channel whose pixel type is to be returned.
 *                 + Must be between 0 and the maximum number of channels in \p type.
 *
 * @returns The pixel type of the given channel. The memory layout and data type are the same as \p type.
 *
 * @retval VPI_PIXEL_TYPE_INVALID \p type is invalid.
 * @retval VPI_PIXEL_TYPE_INVALID \p channel is outside valid range.
 */
VPI_PUBLIC VPIPixelType vpiPixelTypeGetChannelType(VPIPixelType type, int channel);

/** @} */

#ifdef __cplusplus
}
#endif

#endif /* NV_VPI_PIXEL_TYPE_H */
// End content from: PixelType.h

// Begin content from: ColorSpec.h
/*
 * Copyright 2020-2021 NVIDIA Corporation. All rights reserved.
 *
 * NOTICE TO LICENSEE:
 *
 * This source code and/or documentation ("Licensed Deliverables") are
 * subject to NVIDIA intellectual property rights under U.S. and
 * international Copyright laws.
 *
 * These Licensed Deliverables contained herein is PROPRIETARY and
 * CONFIDENTIAL to NVIDIA and is being provided under the terms and
 * conditions of a form of NVIDIA software license agreement by and
 * between NVIDIA and Licensee ("License Agreement") or electronically
 * accepted by Licensee. Notwithstanding any terms or conditions to
 * the contrary in the License Agreement, reproduction or disclosure
 * of the Licensed Deliverables to any third party without the express
 * written consent of NVIDIA is prohibited.
 *
 * NOTWITHSTANDING ANY TERMS OR CONDITIONS TO THE CONTRARY IN THE
 * LICENSE AGREEMENT, NVIDIA MAKES NO REPRESENTATION ABOUT THE
 * SUITABILITY OF THESE LICENSED DELIVERABLES FOR ANY PURPOSE. IT IS
 * PROVIDED "AS IS" WITHOUT EXPRESS OR IMPLIED WARRANTY OF ANY KIND.
 * NVIDIA DISCLAIMS ALL WARRANTIES WITH REGARD TO THESE LICENSED
 * DELIVERABLES, INCLUDING ALL IMPLIED WARRANTIES OF MERCHANTABILITY,
 * NONINFRINGEMENT, AND FITNESS FOR A PARTICULAR PURPOSE.
 * NOTWITHSTANDING ANY TERMS OR CONDITIONS TO THE CONTRARY IN THE
 * LICENSE AGREEMENT, IN NO EVENT SHALL NVIDIA BE LIABLE FOR ANY
 * SPECIAL, INDIRECT, INCIDENTAL, OR CONSEQUENTIAL DAMAGES, OR ANY
 * DAMAGES WHATSOEVER RESULTING FROM LOSS OF USE, DATA OR PROFITS,
 * WHETHER IN AN ACTION OF CONTRACT, NEGLIGENCE OR OTHER TORTIOUS
 * ACTION, ARISING OUT OF OR IN CONNECTION WITH THE USE OR PERFORMANCE
 * OF THESE LICENSED DELIVERABLES.
 *
 * U.S. Government End Users. These Licensed Deliverables are a
 * "commercial item" as that term is defined at 48 C.F.R. 2.101 (OCT
 * 1995), consisting of "commercial computer software" and "commercial
 * computer software documentation" as such terms are used in 48
 * C.F.R. 12.212 (SEPT 1995) and is provided to the U.S. Government
 * only as a commercial end item. Consistent with 48 C.F.R.12.212 and
 * 48 C.F.R. 227.7202-1 through 227.7202-4 (JUNE 1995), all
 * U.S. Government End Users acquire the Licensed Deliverables with
 * only those rights set forth herein.
 *
 * Any use of the Licensed Deliverables in individual and commercial
 * software must include, in the user documentation and internal
 * comments to the code, the above Disclaimer and U.S. Government End
 * Users Notice.
 */

/**
 * @file ColorSpec.h
 *
 * Defines types and functions to handle color specs.
 */

#ifndef NV_VPI_COLORSPEC_H
#define NV_VPI_COLORSPEC_H

// #include "Export.h"
// #include "detail/FormatUtils.h"

#ifdef __cplusplus
extern "C" {
#endif

/**
* @defgroup VPI_ColorSpec Color Spaces
* @ingroup VPI_API_Misc
* @{
*/

/** Defines color models.
 * A color model gives meaning to each channel of an image format. They are specified
 * in a canonical XYZW ordering that can then be swizzled to the desired ordering. 
 */
typedef enum
{
    VPI_COLOR_MODEL_UNDEFINED = 0,     /**< Color model is undefined. */
    VPI_COLOR_MODEL_YCbCr     = 1,     /**< Luma + chroma (blue-luma, red-luma). */
    VPI_COLOR_MODEL_RGB       = 2,     /**< red, green, blue components. */
    VPI_COLOR_MODEL_RAW       = 2 + 7, /**< RAW color model, used for Bayer image formats. */
    VPI_COLOR_MODEL_XYZ,               /**< CIE XYZ tristimulus color spec. */
} VPIColorModel;

/** Defines the color primaries and the white point of a \ref VPIColorSpec. */
typedef enum
{
    VPI_COLOR_SPACE_SENSOR, /**< Color space from the sensor used to capture the image. */
    VPI_COLOR_SPACE_BT601,  /**< Color primaries from ITU-R BT.601/625 lines standard, also known as EBU 3213-E. */
    VPI_COLOR_SPACE_BT709,  /**< Color primaries from ITU-R BT.709 standard, D65 white point. */
    VPI_COLOR_SPACE_BT2020, /**< Color primaries from ITU-R BT.2020 standard, D65 white point. */
    VPI_COLOR_SPACE_DCIP3,  /**< Color primaries from DCI-P3 standard, D65 white point. */

    VPI_COLOR_SPACE_UNDEFINED = INT32_MAX, /**< Color space not defined. */
} VPIColorSpace;

/** Defines the white point associated with a \ref VPIColorSpace. */
typedef enum
{
    VPI_WHITE_POINT_D65, /**< D65 white point, K = 6504. */

    VPI_WHITE_POINT_UNDEFINED = INT32_MAX /**< White point not defined. */
} VPIWhitePoint;

/** Defines the YCbCr encoding used in a particular \ref VPIColorSpec. */
typedef enum
{
    VPI_YCbCr_ENC_UNDEFINED = 0, /**< Encoding not defined. Usually used by non-YCbCr color specs. */
    VPI_YCbCr_ENC_BT601,         /**< Encoding specified by ITU-R BT.601 standard. */
    VPI_YCbCr_ENC_BT709,         /**< Encoding specified by ITU-R BT.709 standard. */
    VPI_YCbCr_ENC_BT2020,        /**< Encoding specified by ITU-R BT.2020 standard. */
    VPI_YCbCr_ENC_BT2020c,       /**< Encoding specified by ITU-R BT.2020 with constant luminance. */
    VPI_YCbCr_ENC_SMPTE240M,     /**< Encoding specified by SMPTE 240M standard. */
} VPIYCbCrEncoding;

/** Defines the color transfer function in a particular \ref VPIColorSpec. */
typedef enum
{
    VPI_COLOR_XFER_LINEAR,    /**< Linear color transfer function. */
    VPI_COLOR_XFER_sRGB,      /**< Color transfer function specified by sRGB standard. */
    VPI_COLOR_XFER_sYCC,      /**< Color transfer function specified by sYCC standard. */
    VPI_COLOR_XFER_PQ,        /**< Perceptual quantizer color transfer function. */
    VPI_COLOR_XFER_BT709,     /**< Color transfer function specified by ITU-R BT.709 standard. */
    VPI_COLOR_XFER_BT2020,    /**< Color transfer function specified by ITU-R BT.2020 standard. */
    VPI_COLOR_XFER_SMPTE240M, /**< Color transfer function specified by SMPTE 240M standard. */
} VPIColorTransferFunction;

/** Defines the color range of a particular \ref VPIColorSpec. */
typedef enum
{
    VPI_COLOR_RANGE_FULL,   /**< Values cover the full underlying type range. */
    VPI_COLOR_RANGE_LIMITED /**< Values cover a limited range of the underlying type. */
} VPIColorRange;

/** Chroma sampling location. */
typedef enum
{
    VPI_CHROMA_LOC_EVEN   = 0, /**< Sample the chroma with even coordinate. */
    VPI_CHROMA_LOC_CENTER = 1, /**< Sample the chroma exactly between the even and odd coordinate. */
    VPI_CHROMA_LOC_ODD    = 2, /**< Sample the chroma with odd coordinate. */
    VPI_CHROMA_LOC_BOTH   = 3, /**< Sample chroma from even and odd coordinates.
                                    This is used when no sub-sampling is taking place. */
} VPIChromaLocation;

/** Color spec definitions.
 * These color specs define how color information is to be interpreted.
 * It is defined by several parameters:
 * - \ref VPIColorModel
 * - \ref VPIColorSpace
 * - \ref VPIWhitePoint
 * - \ref VPIYCbCrEncoding
 * - \ref VPIColorTransferFunction
 * - \ref VPIColorRange
 * - \ref VPIChromaLocation
 *
 * These parameters together defines how the color representation maps to its
 * corresponding absolute color in a chromacity diagram.
 */

/* clang-format off */
typedef enum
{
    /** Invalid color spec. This is to be used when no color spec is selected. */
    VPI_COLOR_SPEC_INVALID = INT32_MAX,

    /** Default color spec. Informs that the color spec is to be inferred. */
    VPI_COLOR_SPEC_DEFAULT          = VPI_DETAIL_MAKE_CSPC(SPACE_UNDEFINED, ENC_UNDEFINED, XFER_LINEAR, RANGE_FULL,    LOC_BOTH,   LOC_BOTH),

    /** No color spec defined. Used when color spec isn't relevant or is not defined.
     *  The color spec may be inferred from the context. If this isn't possible, the values for each
     *  color spec component defined below will be used. */
    VPI_COLOR_SPEC_UNDEFINED        = VPI_DETAIL_MAKE_CSPC(SPACE_BT709,  ENC_UNDEFINED, XFER_LINEAR,    RANGE_FULL,    LOC_BOTH,   LOC_BOTH),

    /** Color spec defining ITU-R BT.601 standard, limited range, with BT.709 chrominancies and transfer function. */
    VPI_COLOR_SPEC_BT601            = VPI_DETAIL_MAKE_CSPC(SPACE_BT709,  ENC_BT601,     XFER_BT709,     RANGE_LIMITED, LOC_EVEN,   LOC_EVEN),

    /** Color spec defining ITU-R BT.601 standard, full range, with BT.709 chrominancies and transfer function. */
    VPI_COLOR_SPEC_BT601_ER         = VPI_DETAIL_MAKE_CSPC(SPACE_BT709,  ENC_BT601,     XFER_BT709,     RANGE_FULL,    LOC_EVEN,   LOC_EVEN),

    /** Color spec defining ITU-R BT.709 standard, limited range. */
    VPI_COLOR_SPEC_BT709            = VPI_DETAIL_MAKE_CSPC(SPACE_BT709,  ENC_BT709,     XFER_BT709,     RANGE_LIMITED, LOC_EVEN,   LOC_EVEN),

    /** Color spec defining ITU-R BT.709 standard, full range. */
    VPI_COLOR_SPEC_BT709_ER         = VPI_DETAIL_MAKE_CSPC(SPACE_BT709,  ENC_BT709,     XFER_BT709,     RANGE_FULL,    LOC_EVEN,   LOC_EVEN),

    /** Color spec defining ITU-R BT.709 standard, limited range and linear transfer function. */
    VPI_COLOR_SPEC_BT709_LINEAR     = VPI_DETAIL_MAKE_CSPC(SPACE_BT709,  ENC_BT709,     XFER_LINEAR,    RANGE_LIMITED, LOC_EVEN,   LOC_EVEN),

    /** Color spec defining ITU-R BT.2020 standard, limited range. */
    VPI_COLOR_SPEC_BT2020           = VPI_DETAIL_MAKE_CSPC(SPACE_BT2020, ENC_BT2020,    XFER_BT2020,    RANGE_LIMITED, LOC_EVEN,   LOC_EVEN),

    /** Color spec defining ITU-R BT.2020 standard, full range. */
    VPI_COLOR_SPEC_BT2020_ER        = VPI_DETAIL_MAKE_CSPC(SPACE_BT2020, ENC_BT2020,    XFER_BT2020,    RANGE_FULL,    LOC_EVEN,   LOC_EVEN),

    /** Color spec defining ITU-R BT.2020 standard, limited range and linear transfer function. */
    VPI_COLOR_SPEC_BT2020_LINEAR    = VPI_DETAIL_MAKE_CSPC(SPACE_BT2020, ENC_BT2020,    XFER_LINEAR,    RANGE_LIMITED, LOC_EVEN,   LOC_EVEN),

    /** Color spec defining ITU-R BT.2020 standard, limited range and perceptual quantizer transfer function. */
    VPI_COLOR_SPEC_BT2020_PQ        = VPI_DETAIL_MAKE_CSPC(SPACE_BT2020, ENC_BT2020,    XFER_PQ,        RANGE_LIMITED, LOC_EVEN,   LOC_EVEN),

    /** Color spec defining ITU-R BT.2020 standard, full range and perceptual quantizer transfer function. */
    VPI_COLOR_SPEC_BT2020_PQ_ER     = VPI_DETAIL_MAKE_CSPC(SPACE_BT2020, ENC_BT2020,    XFER_PQ,        RANGE_FULL,    LOC_EVEN,   LOC_EVEN),

    /** Color spec defining ITU-R BT.2020 standard for constant luminance, limited range. */
    VPI_COLOR_SPEC_BT2020c          = VPI_DETAIL_MAKE_CSPC(SPACE_BT2020, ENC_BT2020c,   XFER_BT2020,    RANGE_LIMITED, LOC_EVEN,   LOC_EVEN),

    /** Color spec defining ITU-R BT.2020 standard for constant luminance, full range. */
    VPI_COLOR_SPEC_BT2020c_ER       = VPI_DETAIL_MAKE_CSPC(SPACE_BT2020, ENC_BT2020c,   XFER_BT2020,    RANGE_FULL,    LOC_EVEN,   LOC_EVEN),

    /** Color spec defining MPEG2 standard using ITU-R BT.601 encoding. */
    VPI_COLOR_SPEC_MPEG2_BT601      = VPI_DETAIL_MAKE_CSPC(SPACE_BT709,  ENC_BT601,     XFER_BT709,     RANGE_FULL,    LOC_EVEN,   LOC_CENTER),

    /** Color spec defining MPEG2 standard using ITU-R BT.709 encoding. */
    VPI_COLOR_SPEC_MPEG2_BT709      = VPI_DETAIL_MAKE_CSPC(SPACE_BT709,  ENC_BT709,     XFER_BT709,     RANGE_FULL,    LOC_EVEN,   LOC_CENTER),

    /** Color spec defining MPEG2 standard using SMPTE 240M encoding. */
    VPI_COLOR_SPEC_MPEG2_SMPTE240M  = VPI_DETAIL_MAKE_CSPC(SPACE_BT709,  ENC_SMPTE240M, XFER_SMPTE240M, RANGE_FULL,    LOC_EVEN,   LOC_CENTER),

    /** Color spec defining sRGB standard. */
    VPI_COLOR_SPEC_sRGB             = VPI_DETAIL_MAKE_CSPC(SPACE_BT709,  ENC_UNDEFINED, XFER_sRGB,      RANGE_FULL,    LOC_BOTH,   LOC_BOTH),

    /** Color spec defining sYCC standard. */
    VPI_COLOR_SPEC_sYCC             = VPI_DETAIL_MAKE_CSPC(SPACE_BT709,  ENC_BT601,     XFER_sYCC,      RANGE_FULL,    LOC_CENTER, LOC_CENTER),

    /** Color spec defining SMPTE 240M standard, limited range. */
    VPI_COLOR_SPEC_SMPTE240M        = VPI_DETAIL_MAKE_CSPC(SPACE_BT709,  ENC_SMPTE240M, XFER_SMPTE240M, RANGE_LIMITED, LOC_EVEN,   LOC_EVEN),

    /** Color spec defining Display P3 standard, with sRGB color transfer function. */
    VPI_COLOR_SPEC_DISPLAYP3        = VPI_DETAIL_MAKE_CSPC(SPACE_DCIP3,  ENC_UNDEFINED, XFER_sRGB,      RANGE_FULL,    LOC_BOTH,   LOC_BOTH),

    /** Color spec defining Display P3 standard, with linear color transfer function. */
    VPI_COLOR_SPEC_DISPLAYP3_LINEAR = VPI_DETAIL_MAKE_CSPC(SPACE_DCIP3,  ENC_UNDEFINED, XFER_LINEAR,    RANGE_FULL,    LOC_BOTH,   LOC_BOTH),

    /** Color spec used for images coming from an image sensor, right after demosaicing. */
    VPI_COLOR_SPEC_SENSOR           = VPI_DETAIL_MAKE_CSPC(SPACE_SENSOR, ENC_UNDEFINED, XFER_LINEAR,    RANGE_FULL,    LOC_BOTH,   LOC_BOTH),
} VPIColorSpec;
/* clang-format on */

/** Creates a user-defined color spec constant using abbreviated parameters.
 *
 * Example:
 * \code{.c}
 *   VPIColorSpec cspec = VPI_MAKE_COLOR_SPEC_ABBREV(SPACE_BT709, ENC_sRGB, XFER_sYCC, RANGE_FULL, LOC_ODD, LOC_EVEN);
 * \endcode
 *
 * @param[in] cspace   Color Space.
 * @param[in] encoding R'G'B' <-> Y'CbCr encoding.
 * @param[in] xferFunc Color transfer function.
 * @param[in] range    Color quantization range.
 * @param[in] locHoriz Horizontal chroma location.
 * @param[in] locVert  Vertical chroma location.
 *
 * @returns The user-defined \ref VPIColorSpec constant.
 */
#ifdef VPI_DOXYGEN
#    define VPI_MAKE_COLOR_SPEC_ABBREV(cspace, encoding, xferFunc, range, locHoriz, locVert)
#else
#    define VPI_MAKE_COLOR_SPEC_ABBREV (VPIColorSpec) VPI_DETAIL_MAKE_CSPC
#endif

/** Creates a user-defined color spec constant.
 *
 * Example:
 * \code{.c}
 *   VPIColorSpec cspec = VPI_MAKE_COLOR_SPEC_ABBREV(VPI_COLOR_SPACE_BT709, VPI_YCbCr_ENC_sRGB, VPI_COLOR_XFER_sYCC,
 *                                                      VPI_COLOR_RANGE_FULL, VPI_CHROMA_LOC_ODD, VPI_CHROMA_LOC_EVEN);
 * \endcode
 *
 * @param[in] cspace   Color Space.
 * @param[in] encoding R'G'B' <-> Y'CbCr encoding.
 * @param[in] xferFunc Color transfer function.
 * @param[in] range    Color quantization range.
 * @param[in] locHoriz Horizontal chroma location.
 * @param[in] locVert  Vertical chroma location.
 *
 * @returns The user-defined \ref VPIColorSpec constant.
 */
#ifdef VPI_DOXYGEN
#    define VPI_MAKE_COLOR_SPEC(cspace, encoding, xferFunc, range, locHoriz, locVert)
#else
#    define VPI_MAKE_COLOR_SPEC (VPIColorSpec) VPI_DETAIL_MAKE_COLOR_SPEC
#endif

/** Creates a user-defined \ref VPIColorSpec.
 *
 * @param[in] cspace   Color space.
 * @param[in] encoding R'G'B' <-> Y'CbCr encoding.
 * @param[in] xferFunc Color transfer function.
 * @param[in] range    Color quantization range.
 * @param[in] locHoriz Horizontal chroma location.
 * @param[in] locVert  Vertical chroma location.
 *
 * @returns The user-defined \ref VPIColorSpec.
 */
VPI_PUBLIC VPIColorSpec vpiMakeColorSpec(VPIColorSpace cspace, VPIYCbCrEncoding encoding,
                                         VPIColorTransferFunction xferFunc, VPIColorRange range,
                                         VPIChromaLocation locHoriz, VPIChromaLocation locVert);

/** Defines Bayer patterns used by RAW color model.
 * R,G,B represent the color primaries red, green, blue.
 * C represent a clear channel, it lets all light pass. */
typedef enum
{
    VPI_RAW_INVALID, /**< Invalid raw pattern. */

    /** Bayer format with X channel mapped to samples as follows:
     * - span 1: R G R G R G R G
     * - span 2: G B G B G B G B
     * (Y,Z,W are discarded) */
    VPI_RAW_BAYER_RGGB,
    /** Bayer format with X channel mapped to samples as follows:
     * - span 1: B G B G B G B G
     * - span 2: G R G R G R G R
     * \n(Y,Z,W are discarded)
     */
    VPI_RAW_BAYER_BGGR,
    /** Bayer format with X channel mapped to samples as follows:
     * - span 1: G R G R G R G R
     * - span 2: B G B G B G B G
     * \n(Y,Z,W are discarded)
     */
    VPI_RAW_BAYER_GRBG,
    /** Bayer format with X channel mapped to samples as follows:
     * - span 1: G B G B G B G B
     * - span 2: R G R G R G R G
     * \n(Y,Z,W are discarded)
     */
    VPI_RAW_BAYER_GBRG,

    /** Bayer format with X channel mapped to samples as follows:
     * - span 1: R C R C R C R C
     * - span 2: C B C B C B C B
     * \n(Y,Z,W are discarded)
     */
    VPI_RAW_BAYER_RCCB,
    /** Bayer format with X channel mapped to samples as follows:
     * - span 1: B C B C B C B C
     * - span 2: C R C R C R C R
     * \n(Y,Z,W are discarded)
     */
    VPI_RAW_BAYER_BCCR,
    /** Bayer format with X channel mapped to samples as follows:
     * - span 1: C R C R C R C R
     * - span 2: B C B C B C B C
     * \n(Y,Z,W are discarded)
     */
    VPI_RAW_BAYER_CRBC,
    /** Bayer format with X channel mapped to samples as follows:
     * - span 1: C B C B C B C B
     * - span 2: R C R C R C R C
     * \n(Y,Z,W are discarded)
     */
    VPI_RAW_BAYER_CBRC,

    /** Bayer format with X channel mapped to samples as follows:
     * - span 1: R C R C R C R C
     * - span 2: C C C C C C C C
     * \n(Y,Z,W are discarded)
     */
    VPI_RAW_BAYER_RCCC,
    /** Bayer format with X channel mapped to samples as follows:
     * - span 1: C R C R C R C R
     * - span 2: C C C C C C C C
     * \n(Y,Z,W are discarded)
     */
    VPI_RAW_BAYER_CRCC,
    /** Bayer format with X channel mapped to samples as follows:
     * - span 1: C C C C C C C C
     * - span 2: R C R C R C R C
     * \n(Y,Z,W are discarded)
     */
    VPI_RAW_BAYER_CCRC,
    /** Bayer format with X channel mapped to samples as follows:
     * - span 1: C C C C C C C C
     * - span 2: C R C R C R C R
     * \n(Y,Z,W are discarded)
     */
    VPI_RAW_BAYER_CCCR,

    /** Bayer format with X channel mapped to samples as follows:
     * - span 1: C C C C C C C C
     * - span 2: C C C C C C C C
     * \n(Y,Z,W are discarded)
     */
    VPI_RAW_BAYER_CCCC,

    /** \cond Do not use. */
    VPI_RAW_FORCE8 = UINT8_MAX
    /* \endcond */
} VPIRawPattern;

/** Defines how chroma-subsampling is done.
 * This is only applicable to image formats whose color model is YUV.
 * Other image formats must use \ref VPI_CSS_NONE.
 * Chroma subsampling is defined by 2 parameters:
 * - Horizontal resolution relative to luma resolution.
 * - Vertical resolution relative to luma resolution.
 */
typedef enum
{
    VPI_CSS_INVALID = -1, /**< Invalid chroma subsampling. */

    /** Used when no chroma subsampling takes place, specially for color specs without chroma components. */
    VPI_CSS_NONE = 0,

    /** 4:4:4 sub-sampling. Chroma has full horizontal and vertical resolution, meaning no chroma subsampling. */
    VPI_CSS_444 = VPI_CSS_NONE,

    /** 4:2:2 BT.601 sub-sampling. Chroma has half horizontal and full vertical resolutions.*/
    VPI_CSS_422,

    /** 4:2:2R BT.601 sub-sampling. Chroma has full horizontal and half vertical resolutions.*/
    VPI_CSS_422R,

    /** 4:1:1 sub-sampling. Chroma has 1/4 horizontal and full vertical resolutions.*/
    VPI_CSS_411,

    /** 4:1:1 sub-sampling. Chroma has full horizontal and 1/4 vertical resolutions.*/
    VPI_CSS_411R,

    /** 4:2:0 sub-sampling. Chroma has half horizontal and vertical resolutions.*/
    VPI_CSS_420,
} VPIChromaSubsampling;

/** Creates a \ref VPIChromaSubsampling given the horizontal and vertical sampling.
 *
 * @param[in] samplesHoriz Number of horizontal samples, 1, 2 or 4.
 * 
 * @param[in] samplesVert Number of vertical samples, 1, 2 or 4.
 *
 * @returns The chroma subsampling enumeration.
 * @retval #VPI_CSS_NONE Chroma subsampling isn't defined.
 */
VPI_PUBLIC VPIChromaSubsampling vpiMakeChromaSubsampling(int samplesHoriz, int samplesVert);

/** Get the number of chroma samples for each group of 4 horizontal luma samples.
 *
 * @param[in] css Chroma subsampling to be queried.
 *                + \p css must be valid.
 * 
 *
 * @returns The number of chroma samples for each group of 4 horizontal luma samples.
 * @retval 0 \p css is invalid.
 */
VPI_PUBLIC int vpiChromaSubsamplingGetSamplesHoriz(VPIChromaSubsampling css);

/** Get the number of chroma samples for each group of 4 vertical luma samples.
 *
 * @param[in] css Chroma subsampling to be queried.
 *                + \p css must be valid.
 *
 * @returns The number of chroma samples for each group of 4 vertical luma samples.
 * @retval 0 \p css is invalid.
 */
VPI_PUBLIC int vpiChromaSubsamplingGetSamplesVert(VPIChromaSubsampling css);

/** Get the chroma horizontal sampling location of a given color spec.
 *
 * @param[in] cspec Color spec to be queried.
 *                  + Color spec must be valid.
 *
 * @returns Chroma sample location with respect to luma horizontal coordinate.
 * @retval #VPI_CHROMA_LOC_BOTH \p cspec is invalid.
 */
VPI_PUBLIC VPIChromaLocation vpiColorSpecGetChromaLocHoriz(VPIColorSpec cspec);

/** Get the chroma vertical sample location of a given color spec
 *
 * @param[in] cspec Color spec to be queried.
 *                  + Color spec must be valid.
 *
 * @returns Chroma sample location with respect to luma vertical coordinate.
 * @retval #VPI_CHROMA_LOC_BOTH \p cspec is invalid.
 */
VPI_PUBLIC VPIChromaLocation vpiColorSpecGetChromaLocVert(VPIColorSpec cspec);

/** Set the chroma sample location of a given color spec
 *
 * @param[in] cspec The color spec to be modified.
 *                  + \p cspec must be valid.
 * 
 * @param[in] locHoriz Horizontal chroma sampling location with respect to luma coordinate.
 * 
 * @param[in] locVert Vertical chroma sampling location with respect to luma coordinate.
 *
 * @returns The new color spec with the updated chroma location.
 * @retval #VPI_COLOR_SPEC_INVALID \p cspec is invalid.
 */
VPI_PUBLIC VPIColorSpec vpiColorSpecSetChromaLoc(VPIColorSpec cspec, VPIChromaLocation locHoriz,
                                                 VPIChromaLocation locVert);

/** Get the color_space of a given color spec.
 *
 * @param[in] cspec Color spec to be queried.
 *                  + \p cspec must be valid.
 *
 * @returns The color_space associated with the color spec.
 * @retval #VPI_COLOR_SPACE_UNDEFINED \p cspec is invalid.
 */
VPI_PUBLIC VPIColorSpace vpiColorSpecGetSpace(VPIColorSpec cspec);

/** Set the color_space of a given color spec.
 *
 * @param[in] cspec Color spec to be updated.
 *                  + \p cspec must be valid.
 * 
 * @param[in] cspace The new color_space.
 *
 * @returns The new color spec with the updated color_space.
 * @retval #VPI_COLOR_SPEC_INVALID \p cspec is invalid.
 * @retval #VPI_COLOR_SPEC_INVALID \p cspace is invalid.
 */
VPI_PUBLIC VPIColorSpec vpiColorSpecSetSpace(VPIColorSpec cspec, VPIColorSpace cspace);

/** Get the R'G'B' <-> Y'CbCr encoding scheme of a given color spec.
 *
 * @param[in] cspec Color spec to be queried.
 *                  + \p cspec must be valid.
 *
 * @returns The Y'CbCr encoding scheme associated with the color spec.
 * @retval #VPI_YCbCr_ENC_UNDEFINED \p cspec is invalid.
 */
VPI_PUBLIC VPIYCbCrEncoding vpiColorSpecGetYCbCrEncoding(VPIColorSpec cspec);

/** Set the R'G'B' <-> Y'CbCr encoding scheme of a given color spec.
 *
 * @param[in] cspec Color spec to be updated.
 *                  + \p cspec must be valid.
 * 
 * @param[in] encoding The new Y'CbCr encoding scheme.
 *
 * @returns The new color spec with the updated Y'CbCr encoding scheme.
 * @retval #VPI_COLOR_SPEC_INVALID \p cspec is invalid.
 */
VPI_PUBLIC VPIColorSpec vpiColorSpecSetYCbCrEncoding(VPIColorSpec cspec, VPIYCbCrEncoding encoding);

/** Get the color transfer function of a given color spec.
 *
 * @param[in] cspec Color spec to be queried.
 *                  + \p cspec must be valid.
 *
 * @returns The color transfer function of a given color spec.
 * @retval #VPI_COLOR_XFER_LINEAR if \p cspec is invalid.
 */
VPI_PUBLIC VPIColorTransferFunction vpiColorSpecGetTransferFunction(VPIColorSpec cspec);

/** Set the color transfer function of a given color spec.
 *
 * @param[in] cspec Color spec to be updated.
 *                  + \p cspec must be valid.
 * 
 * @param[in] xferFunc The new color transfer function.
 *
 * @returns The new color spec with the updated color transfer function.
 * @retval #VPI_COLOR_SPEC_INVALID \p cspec is invalid.
 */
VPI_PUBLIC VPIColorSpec vpiColorSpecSetTransferFunction(VPIColorSpec cspec, VPIColorTransferFunction xferFunc);

/** Get the color quantization range of a given color spec.
 *
 * @param[in] cspec Color spec to be queried.
 *                  + \p cspec must be valid.
 *
 * @returns The color quantization range of a given color spec.
 * @retval #VPI_COLOR_RANGE_FULL \p cspec is invalid.
 */
VPI_PUBLIC VPIColorRange vpiColorSpecGetRange(VPIColorSpec cspec);

/** Set the color quantization range of a given color spec.
 *
 * @param[in] cspec Color spec to be updated.
 *                  + \p cspec must be valid.
 * 
 * @param[in] range The new color quantization range. 
 *
 * @returns The new color spec with the updated color quantization range.
 * @retval #VPI_COLOR_SPEC_INVALID \p cspec is invalid.
 */
VPI_PUBLIC VPIColorSpec vpiColorSpecSetRange(VPIColorSpec cspec, VPIColorRange range);

/** Returns a string representation of the color spec.
 *
 * @param[in] cspec Color spec whose name is to be returned.
 *
 * @returns The string representation of the color spec.
 *          Returned string is valid until next call of this function from the same calling thread.
 *          Returned pointer must not be freed.
 */
VPI_PUBLIC const char *vpiColorSpecGetName(VPIColorSpec cspec);

/** @} */

#ifdef __cplusplus
}
#endif

#endif /* NV_VPI_COLORSPEC_H */
// End content from: ColorSpec.h

// Begin content from: Version.h
/*
 * Copyright 2019-2021 NVIDIA Corporation. All rights reserved.
 *
 * NOTICE TO LICENSEE:
 *
 * This source code and/or documentation ("Licensed Deliverables") are
 * subject to NVIDIA intellectual property rights under U.S. and
 * international Copyright laws.
 *
 * These Licensed Deliverables contained herein is PROPRIETARY and
 * CONFIDENTIAL to NVIDIA and is being provided under the terms and
 * conditions of a form of NVIDIA software license agreement by and
 * between NVIDIA and Licensee ("License Agreement") or electronically
 * accepted by Licensee. Notwithstanding any terms or conditions to
 * the contrary in the License Agreement, reproduction or disclosure
 * of the Licensed Deliverables to any third party without the express
 * written consent of NVIDIA is prohibited.
 *
 * NOTWITHSTANDING ANY TERMS OR CONDITIONS TO THE CONTRARY IN THE
 * LICENSE AGREEMENT, NVIDIA MAKES NO REPRESENTATION ABOUT THE
 * SUITABILITY OF THESE LICENSED DELIVERABLES FOR ANY PURPOSE. IT IS
 * PROVIDED "AS IS" WITHOUT EXPRESS OR IMPLIED WARRANTY OF ANY KIND.
 * NVIDIA DISCLAIMS ALL WARRANTIES WITH REGARD TO THESE LICENSED
 * DELIVERABLES, INCLUDING ALL IMPLIED WARRANTIES OF MERCHANTABILITY,
 * NONINFRINGEMENT, AND FITNESS FOR A PARTICULAR PURPOSE.
 * NOTWITHSTANDING ANY TERMS OR CONDITIONS TO THE CONTRARY IN THE
 * LICENSE AGREEMENT, IN NO EVENT SHALL NVIDIA BE LIABLE FOR ANY
 * SPECIAL, INDIRECT, INCIDENTAL, OR CONSEQUENTIAL DAMAGES, OR ANY
 * DAMAGES WHATSOEVER RESULTING FROM LOSS OF USE, DATA OR PROFITS,
 * WHETHER IN AN ACTION OF CONTRACT, NEGLIGENCE OR OTHER TORTIOUS
 * ACTION, ARISING OUT OF OR IN CONNECTION WITH THE USE OR PERFORMANCE
 * OF THESE LICENSED DELIVERABLES.
 *
 * U.S. Government End Users. These Licensed Deliverables are a
 * "commercial item" as that term is defined at 48 C.F.R. 2.101 (OCT
 * 1995), consisting of "commercial computer software" and "commercial
 * computer software documentation" as such terms are used in 48
 * C.F.R. 12.212 (SEPT 1995) and is provided to the U.S. Government
 * only as a commercial end item. Consistent with 48 C.F.R.12.212 and
 * 48 C.F.R. 227.7202-1 through 227.7202-4 (JUNE 1995), all
 * U.S. Government End Users acquire the Licensed Deliverables with
 * only those rights set forth herein.
 *
 * Any use of the Licensed Deliverables in individual and commercial
 * software must include, in the user documentation and internal
 * comments to the code, the above Disclaimer and U.S. Government End
 * Users Notice.
 */

/**
 * @file Version.h
 *
 * Functions and structures for handling VPI library version.
 */


#ifndef NV_VPI_VERSION_H
#define NV_VPI_VERSION_H

// #include "Export.h"

/**
 * Declarations of entities to handle VPI versioning.
 *
 * These utilities allow querying the VPI header and library versions and
 * properly handle VPI forward- or backward-compatibility .
 *
 * @defgroup VPI_Version Versioning
 * @ingroup VPI_API_Misc
 * @{
 */

#ifdef __cplusplus
extern "C" {
#endif

/** Make a VPI version identifier with four components.
 * @param[in] major,minor,patch,tweak Version components to be converted to a number.
 * @returns The numeric version representation.
 */
#define NV_VPI_MAKE_VERSION4(major, minor, patch, tweak) \
    ((major)*1000000 + (minor)*10000 + (patch)*100 + (tweak))

/** Make a VPI version identifier with three components.
 *
 * The tweak version component is considered to be 0.
 *
 * @param[in] major,minor,patch Version components to be converted to a number.
 * @returns The numeric version representation.
 */
#define NV_VPI_MAKE_VERSION3(major, minor, patch) \
    NV_VPI_MAKE_VERSION4(major, minor, patch, 0)

/** Make a VPI version identifier with two components.
 *
 * The patch and tweak version components are considered to be 0.
 *
 * @param[in] major,minor Version components to be converted to a number.
 * @returns The numeric version representation.
 */
#define NV_VPI_MAKE_VERSION2(major, minor) \
    NV_VPI_MAKE_VERSION4(major, minor, 0, 0)

/** Make a VPI version identifier with one component.
 *
 * The minor, patch and tweak version components are considered to be 0.
 *
 * @param[in] major Major version component to be converted to a number.
 * @returns The numeric version representation.
 */
#define NV_VPI_MAKE_VERSION1(major) \
    NV_VPI_MAKE_VERSION4(major, 0, 0, 0)

/** Assemble an integer version from its components.
 * This makes it easy to conditionally compile code for different VPI versions, e.g:
 * \code
 * #if NV_VPI_VERSION < NV_VPI_MAKE_VERSION(1,0,0)
 *    // code that runs on versions prior 1.0.0
 * #else
 *    // code that runs on versions after that, including 1.0.0
 * #endif
 * \endcode
 *
 * @param[in] major Major version component, mandatory.
 * @param[in] minor Minor version component. If ommitted, it's considered to be 0.
 * @param[in] patch Patch version component. If ommitted, it's considered to be 0.
 * @param[in] tweak Tweak version component. If ommitted, it's considered to be 0.
 * @returns The numeric version representation.
 */
#if VPI_DOXYGEN
#   define NV_VPI_MAKE_VERSION(major,minor,patch,tweak)
#else
#define NV_VPI_DETAIL_GET_MACRO(_1,_2,_3,_4,NAME,...) NAME
#define NV_VPI_MAKE_VERSION(...) \
    NV_VPI_DETAIL_GET_MACRO(__VA_ARGS__, NV_VPI_MAKE_VERSION4, NV_VPI_MAKE_VERSION3, NV_VPI_MAKE_VERSION2, NV_VPI_MAKE_VERSION1)(__VA_ARGS__)
#endif

/** Major version number component.
 * This is incremented every time there's a incompatible ABI change.
 * In the special case of major version 0, compatibility between minor versions
 * is not guaranteed.
 */
#define NV_VPI_VERSION_MAJOR 2

/** Minor version number component.
 * This is incremented every time there's a new feature added to VPI that
 * doesn't break backward compatibility. This number is reset to zero when
 * major version changes.
 */
#define NV_VPI_VERSION_MINOR 4

/** Patch version number component.
 * This is incremented every time a bug is fixed, but no new functionality is added
 * to the library. This number is reset to zero when minor version changes.
 */
#define NV_VPI_VERSION_PATCH 8

/** Tweak version number component.
 * Incremented for packaging or documentation updates, etc. The library itself isn't updated.
 * Gets reset to zero when patch version changes.
 */
#define NV_VPI_VERSION_TWEAK 0

/** Version suffix.
 * String appended to version number to designate special builds.
 */
#define NV_VPI_VERSION_SUFFIX 

/** VPI library version.
  * It's an integer value computed from `MAJOR*1000000 + MINOR*10000 + PATCH*100 + TWEAK`. 
  * Integer versions can be compared, recent versions are greater than older ones.
  */
#define NV_VPI_VERSION 2040800

/** VPI library version number represented as a string. */
#define NV_VPI_VERSION_STRING "2.4.8"

/** Selected API version to use.
 * This macro selects which of the supported APIs the code will use.
 *
 * By default this equals to the highest supported API, corresponding to the current major and
 * minor versions of the library.
 *
 * User can override the version by defining this macro before including VPI headers.
 */
#if VPI_DOXYGEN
#   define NV_VPI_VERSION_API
#else
#ifdef NV_VPI_VERSION_API
#   if NV_VPI_VERSION_API < NV_VPI_MAKE_VERSION(NV_VPI_VERSION_MAJOR) || \
        NV_VPI_VERSION_API > NV_VPI_MAKE_VERSION(NV_VPI_VERSION_MAJOR, NV_VPI_VERSION_MINOR)
#       error Selected VPI API version not supported.
#   endif
#else
#   define NV_VPI_VERSION_API NV_VPI_MAKE_VERSION(NV_VPI_VERSION_MAJOR, NV_VPI_VERSION_MINOR)
#endif
#endif

/** Conditionally enable code when selected API version is exactly given version.
 *
 * @param[in] major,minor API version that will be considered.
 */
#define NV_VPI_VERSION_API_IS(major,minor) \
    (NV_VPI_MAKE_VERSION(major,minor) == NV_VPI_VERSION_API)

/** Conditionally enable code when selected API version is at least given version.
 *
 * @param[in] major,minor Minimum API version that will be considered.
 */
#define NV_VPI_VERSION_API_AT_LEAST(major,minor) \
    (NV_VPI_MAKE_VERSION(major,minor) <= NV_VPI_VERSION_API)

/** Conditionally enable code when selected API version is at most given version.
 *
 * @param[in] major,minor Maximum API version that will be considered.
 */
#define NV_VPI_VERSION_API_AT_MOST(major,minor) \
    (NV_VPI_MAKE_VERSION(major,minor) >= NV_VPI_VERSION_API)

/** Conditionally enable code when selected API version is between two versions.
 *
 * @param[in] min_major,min_minor Minimum API version that will be considered.
 * @param[in] max_major,max_minor Maximum API version that will be considered.
 */
#define NV_VPI_VERSION_API_IN_RANGE(min_major,min_minor,max_major,max_minor) \
    (NV_VPI_VERSION_API_AT_LEAST(min_major, min_minor) && NV_VPI_VERSION_API_AT_MOST(max_major, max_minor))

/** Retrieves the library's version number.
 * The number is represented as a integer. It may differ from \ref NV_VPI_VERSION if
 * header doesn't correspond to VPI binary. This can be used by user's program
 * to handle semantic differences between library versions.
 */
VPI_PUBLIC int vpiGetVersion(void);

#ifdef __cplusplus
}
#endif

/** @} */

#endif // NV_VPI_VERSION_H
// End content from: Version.h

// Begin content from: Status.h
/*
 * Copyright 2019-2021 NVIDIA Corporation. All rights reserved.
 *
 * NOTICE TO LICENSEE:
 *
 * This source code and/or documentation ("Licensed Deliverables") are
 * subject to NVIDIA intellectual property rights under U.S. and
 * international Copyright laws.
 *
 * These Licensed Deliverables contained herein is PROPRIETARY and
 * CONFIDENTIAL to NVIDIA and is being provided under the terms and
 * conditions of a form of NVIDIA software license agreement by and
 * between NVIDIA and Licensee ("License Agreement") or electronically
 * accepted by Licensee. Notwithstanding any terms or conditions to
 * the contrary in the License Agreement, reproduction or disclosure
 * of the Licensed Deliverables to any third party without the express
 * written consent of NVIDIA is prohibited.
 *
 * NOTWITHSTANDING ANY TERMS OR CONDITIONS TO THE CONTRARY IN THE
 * LICENSE AGREEMENT, NVIDIA MAKES NO REPRESENTATION ABOUT THE
 * SUITABILITY OF THESE LICENSED DELIVERABLES FOR ANY PURPOSE. IT IS
 * PROVIDED "AS IS" WITHOUT EXPRESS OR IMPLIED WARRANTY OF ANY KIND.
 * NVIDIA DISCLAIMS ALL WARRANTIES WITH REGARD TO THESE LICENSED
 * DELIVERABLES, INCLUDING ALL IMPLIED WARRANTIES OF MERCHANTABILITY,
 * NONINFRINGEMENT, AND FITNESS FOR A PARTICULAR PURPOSE.
 * NOTWITHSTANDING ANY TERMS OR CONDITIONS TO THE CONTRARY IN THE
 * LICENSE AGREEMENT, IN NO EVENT SHALL NVIDIA BE LIABLE FOR ANY
 * SPECIAL, INDIRECT, INCIDENTAL, OR CONSEQUENTIAL DAMAGES, OR ANY
 * DAMAGES WHATSOEVER RESULTING FROM LOSS OF USE, DATA OR PROFITS,
 * WHETHER IN AN ACTION OF CONTRACT, NEGLIGENCE OR OTHER TORTIOUS
 * ACTION, ARISING OUT OF OR IN CONNECTION WITH THE USE OR PERFORMANCE
 * OF THESE LICENSED DELIVERABLES.
 *
 * U.S. Government End Users. These Licensed Deliverables are a
 * "commercial item" as that term is defined at 48 C.F.R. 2.101 (OCT
 * 1995), consisting of "commercial computer software" and "commercial
 * computer software documentation" as such terms are used in 48
 * C.F.R. 12.212 (SEPT 1995) and is provided to the U.S. Government
 * only as a commercial end item. Consistent with 48 C.F.R.12.212 and
 * 48 C.F.R. 227.7202-1 through 227.7202-4 (JUNE 1995), all
 * U.S. Government End Users acquire the Licensed Deliverables with
 * only those rights set forth herein.
 *
 * Any use of the Licensed Deliverables in individual and commercial
 * software must include, in the user documentation and internal
 * comments to the code, the above Disclaimer and U.S. Government End
 * Users Notice.
 */

/**
 * @file Status.h
 *
 * Declaration of VPI status codes handling functions.
 */

#ifndef NV_VPI_STATUS_H
#define NV_VPI_STATUS_H

// #include "Export.h"

#include <stdint.h>

/**
 * Declares entities to handle return status codes used in VPI.
 *
 * VPI functions uses status codes to return if they succeeded or not.
 *
 * @defgroup VPI_Status Status Codes
 * @ingroup VPI_API_Misc
 * @{
 */

#ifdef __cplusplus
extern "C" {
#endif

/**
 * Status codes.
 */
typedef enum
{
    VPI_SUCCESS = 0,                /**< Operation completed successfully. */
    VPI_ERROR_NOT_IMPLEMENTED,      /**< Operation isn't implemented. */
    VPI_ERROR_INVALID_ARGUMENT,     /**< Invalid argument, either wrong range or value not accepted. */
    VPI_ERROR_INVALID_IMAGE_FORMAT, /**< Image type not accepted. */
    VPI_ERROR_INVALID_ARRAY_TYPE,   /**< Array type not accepted. */
    VPI_ERROR_INVALID_PAYLOAD_TYPE, /**< Payload not created for this algorithm. */
    VPI_ERROR_INVALID_OPERATION,    /**< Operation isn't valid in this context. */
    VPI_ERROR_INVALID_CONTEXT,      /**< Context is invalid or is already destroyed. */
    VPI_ERROR_DEVICE,               /**< Device backend error. */
    VPI_ERROR_NOT_READY,            /**< Operation not completed yet, try again later. */
    VPI_ERROR_BUFFER_LOCKED,        /**< Invalid operation on a locked buffer. */
    VPI_ERROR_OUT_OF_MEMORY,        /**< Not enough free memory to allocate object. */
    VPI_ERROR_INTERNAL              /**< Internal, non specific error. */
} VPIStatus;

/** Maximum status message length in bytes.
 *
 * This is the maximum number of bytes that will be written by \ref
 * vpiGetLastStatusMessage and \ref vpiPeekAtLastStatusMessage to the status
 * message output buffer.
 */
#define VPI_MAX_STATUS_MESSAGE_LENGTH 256

/**
 * Returns a string representation of the status code.
 *
 * @param [in] code Status code whose string representation is to be returned.
 *
 * @returns The string representation of the status code.
 *          Returned string is valid until next call of this function from the same calling thread.
 *          Returned pointer must not be freed.
 */
VPI_PUBLIC const char *vpiStatusGetName(VPIStatus code);

/** Returns and resets the status of the last VPI function call in current thread.
 *
 * A new call to this function will return \ref VPI_SUCCESS, as the thread-specific
 * status was reset. This operation doesn't affect the statuses in other threads.
 *
 * @returns The status of the last VPI function call in current thread.
 */
VPI_PUBLIC VPIStatus vpiGetLastStatus();

/** Returns and resets the status code and message of the last VPI function call in current thread.
 *
 * A new call to this function will return \ref VPI_SUCCESS, as the thread-specific
 * status was reset. This operation doesn't affect the status in other threads.
 *
 * It's guaranteed that the message is never larger than
 * \ref VPI_MAX_STATUS_MESSAGE_LENGTH bytes, including the '\0' string terminator.
 *
 * @param[out] msgBuffer Pointer to memory where the status message will be written to.
 *                       If NULL, no message is returned.
 * 
 * @param[in] lenBuffer Size in bytes of msgBuffer.
 *                      + If less than zero, \p lenBuffer is assumed to be 0.
 *
 * @returns The status of the last VPI function call in current thread.
 */
VPI_PUBLIC VPIStatus vpiGetLastStatusMessage(char *msgBuffer, int32_t lenBuffer);

/** Returns the status of the last VPI function call in current thread.
 *
 * The status code won't be reset.
 *
 * @returns The status of the last VPI function call in current thread.
 */
VPI_PUBLIC VPIStatus vpiPeekAtLastStatus();

/** Returns and status code and message of the last VPI function call in current thread.
 *
 * The status code and message won't be reset.
 *
 * It's guaranteed that the message is never larger than
 * \ref VPI_MAX_STATUS_MESSAGE_LENGTH bytes, including the '\0' string terminator.
 *
 * @param[out] msgBuffer Pointer to memory where the status message will be written to.
 *                       If NULL, no message is returned.
 * 
 * @param[in] lenBuffer Size in bytes of msgBuffer.
 *                      + If less than zero, lenBuffer is assumed to be 0.
 *
 * @returns The status of the last VPI function call in current thread.
 */
VPI_PUBLIC VPIStatus vpiPeekAtLastStatusMessage(char *msgBuffer, int32_t lenBuffer);

/** @} */

#ifdef __cplusplus
}
#endif

#endif /* NV_VPI_STATUS_H */
// End content from: Status.h

// Begin content from: Interpolation.h
/*
 * Copyright 2020 NVIDIA Corporation. All rights reserved.
 *
 * NOTICE TO LICENSEE:
 *
 * This source code and/or documentation ("Licensed Deliverables") are
 * subject to NVIDIA intellectual property rights under U.S. and
 * international Copyright laws.
 *
 * These Licensed Deliverables contained herein is PROPRIETARY and
 * CONFIDENTIAL to NVIDIA and is being provided under the terms and
 * conditions of a form of NVIDIA software license agreement by and
 * between NVIDIA and Licensee ("License Agreement") or electronically
 * accepted by Licensee. Notwithstanding any terms or conditions to
 * the contrary in the License Agreement, reproduction or disclosure
 * of the Licensed Deliverables to any third party without the express
 * written consent of NVIDIA is prohibited.
 *
 * NOTWITHSTANDING ANY TERMS OR CONDITIONS TO THE CONTRARY IN THE
 * LICENSE AGREEMENT, NVIDIA MAKES NO REPRESENTATION ABOUT THE
 * SUITABILITY OF THESE LICENSED DELIVERABLES FOR ANY PURPOSE. IT IS
 * PROVIDED "AS IS" WITHOUT EXPRESS OR IMPLIED WARRANTY OF ANY KIND.
 * NVIDIA DISCLAIMS ALL WARRANTIES WITH REGARD TO THESE LICENSED
 * DELIVERABLES, INCLUDING ALL IMPLIED WARRANTIES OF MERCHANTABILITY,
 * NONINFRINGEMENT, AND FITNESS FOR A PARTICULAR PURPOSE.
 * NOTWITHSTANDING ANY TERMS OR CONDITIONS TO THE CONTRARY IN THE
 * LICENSE AGREEMENT, IN NO EVENT SHALL NVIDIA BE LIABLE FOR ANY
 * SPECIAL, INDIRECT, INCIDENTAL, OR CONSEQUENTIAL DAMAGES, OR ANY
 * DAMAGES WHATSOEVER RESULTING FROM LOSS OF USE, DATA OR PROFITS,
 * WHETHER IN AN ACTION OF CONTRACT, NEGLIGENCE OR OTHER TORTIOUS
 * ACTION, ARISING OUT OF OR IN CONNECTION WITH THE USE OR PERFORMANCE
 * OF THESE LICENSED DELIVERABLES.
 *
 * U.S. Government End Users. These Licensed Deliverables are a
 * "commercial item" as that term is defined at 48 C.F.R. 2.101 (OCT
 * 1995), consisting of "commercial computer software" and "commercial
 * computer software documentation" as such terms are used in 48
 * C.F.R. 12.212 (SEPT 1995) and is provided to the U.S. Government
 * only as a commercial end item. Consistent with 48 C.F.R.12.212 and
 * 48 C.F.R. 227.7202-1 through 227.7202-4 (JUNE 1995), all
 * U.S. Government End Users acquire the Licensed Deliverables with
 * only those rights set forth herein.
 *
 * Any use of the Licensed Deliverables in individual and commercial
 * software must include, in the user documentation and internal
 * comments to the code, the above Disclaimer and U.S. Government End
 * Users Notice.
 */

/**
 * @file Interpolation.h
 *
 * Defines all interpolation types used in VPI.
 */

#ifndef NV_VPI_INTERPOLATION_H
#define NV_VPI_INTERPOLATION_H

#include <stdint.h>

#ifdef __cplusplus
extern "C" {
#endif

/**
 * Interpolation types supported by several algorithms
 * @ingroup VPI_Types
 */
typedef enum
{
    VPI_INTERP_NULL = 0,

    /** Nearest neighbor interpolation.
       \f[
          P(x,y) = \mathit{in}[\lfloor x+0.5 \rfloor, \lfloor y+0.5 \rfloor]
       \f]
     */
    VPI_INTERP_NEAREST = 1,

    /** Linear interpolation.
        Interpolation weights are defined as:
        \f{align*}{
            w_0(t)& \triangleq t-\lfloor t \rfloor \\
            w_1(t)& \triangleq 1 - w_0(t) \\
        \f}

        Bilinear-interpolated value is given by the formula below:

        \f[
            P(x,y) = \sum_{p=0}^1 \sum_{q=0}^1 \mathit{in}[\lfloor x \rfloor+p, \lfloor y \rfloor+q]w_p(x)w_q(y)
        \f]
    */
    VPI_INTERP_LINEAR = 2,

    /** Catmull-Rom cubic interpolation.
       Catmull-Rom interpolation weights with \f$A=-0.5\f$ are defined as follows:
      \f{eqnarray*}{
          w_0(t) &\triangleq& A(t+1)^3 &-& 5A(t+1)^2 &+& 8A(t+1) &-& 4A \\
          w_1(t) &\triangleq& (A+2)t^3 &-& (A+3)t^2 &\nonumber& &+& 1 \\
          w_2(t) &\triangleq& (A+2)(1-t)^3 &-& (A+3)(1-t)^2 &\nonumber& &+& 1 \\
          w_3(t) &\triangleq& \rlap{1 - w_0(t) - w_1(t) - w_2(t) }
      \f}

      Bicubic-interpolated value is given by the formula below:
      \f[
          P(x,y) = \sum_{p=-1}^2 \sum_{q=-1}^2 \mathit{in}[\lfloor x \rfloor+p, \lfloor y \rfloor+q]w_p(x)w_q(y)
      \f]
    */
    VPI_INTERP_CATMULL_ROM = 3,
} VPIInterpolationType;

#ifdef __cplusplus
}
#endif

#endif /* NV_VPI_INTERPOLATION_H */
// End content from: Interpolation.h

// Begin content from: ImageFormat.h
/*
 * Copyright 2020-2021 NVIDIA Corporation. All rights reserved.
 *
 * NOTICE TO LICENSEE:
 *
 * This source code and/or documentation ("Licensed Deliverables") are
 * subject to NVIDIA intellectual property rights under U.S. and
 * international Copyright laws.
 *
 * These Licensed Deliverables contained herein is PROPRIETARY and
 * CONFIDENTIAL to NVIDIA and is being provided under the terms and
 * conditions of a form of NVIDIA software license agreement by and
 * between NVIDIA and Licensee ("License Agreement") or electronically
 * accepted by Licensee. Notwithstanding any terms or conditions to
 * the contrary in the License Agreement, reproduction or disclosure
 * of the Licensed Deliverables to any third party without the express
 * written consent of NVIDIA is prohibited.
 *
 * NOTWITHSTANDING ANY TERMS OR CONDITIONS TO THE CONTRARY IN THE
 * LICENSE AGREEMENT, NVIDIA MAKES NO REPRESENTATION ABOUT THE
 * SUITABILITY OF THESE LICENSED DELIVERABLES FOR ANY PURPOSE. IT IS
 * PROVIDED "AS IS" WITHOUT EXPRESS OR IMPLIED WARRANTY OF ANY KIND.
 * NVIDIA DISCLAIMS ALL WARRANTIES WITH REGARD TO THESE LICENSED
 * DELIVERABLES, INCLUDING ALL IMPLIED WARRANTIES OF MERCHANTABILITY,
 * NONINFRINGEMENT, AND FITNESS FOR A PARTICULAR PURPOSE.
 * NOTWITHSTANDING ANY TERMS OR CONDITIONS TO THE CONTRARY IN THE
 * LICENSE AGREEMENT, IN NO EVENT SHALL NVIDIA BE LIABLE FOR ANY
 * SPECIAL, INDIRECT, INCIDENTAL, OR CONSEQUENTIAL DAMAGES, OR ANY
 * DAMAGES WHATSOEVER RESULTING FROM LOSS OF USE, DATA OR PROFITS,
 * WHETHER IN AN ACTION OF CONTRACT, NEGLIGENCE OR OTHER TORTIOUS
 * ACTION, ARISING OUT OF OR IN CONNECTION WITH THE USE OR PERFORMANCE
 * OF THESE LICENSED DELIVERABLES.
 *
 * U.S. Government End Users. These Licensed Deliverables are a
 * "commercial item" as that term is defined at 48 C.F.R. 2.101 (OCT
 * 1995), consisting of "commercial computer software" and "commercial
 * computer software documentation" as such terms are used in 48
 * C.F.R. 12.212 (SEPT 1995) and is provided to the U.S. Government
 * only as a commercial end item. Consistent with 48 C.F.R.12.212 and
 * 48 C.F.R. 227.7202-1 through 227.7202-4 (JUNE 1995), all
 * U.S. Government End Users acquire the Licensed Deliverables with
 * only those rights set forth herein.
 *
 * Any use of the Licensed Deliverables in individual and commercial
 * software must include, in the user documentation and internal
 * comments to the code, the above Disclaimer and U.S. Government End
 * Users Notice.
 */

/**
 * @file ImageFormat.h
 *
 * Defines types and functions to handle image formats.
 */

#ifndef NV_VPI_IMAGE_FORMAT_H
#define NV_VPI_IMAGE_FORMAT_H

// #include "ColorSpec.h"
// #include "DataLayout.h"
// #include "PixelType.h"

#include <assert.h>

#ifdef __cplusplus
extern "C" {
#endif

/**
 * @ingroup VPI_ImageFormat
 * @{
 */

/**
 * Pre-defined image formats.
 * An image format defines how image pixels are interpreted.
 * Each image format is defined by the following components:
 * - \ref VPIColorModel
 * - \ref VPIColorSpec
 * - \ref VPIChromaSubsampling method (when applicable)
 * - \ref VPIMemLayout
 * - \ref VPIDataType
 * - \ref VPISwizzle
 * - Number of planes
 * - Format packing of each plane.
 *
 * These pre-defined formats are guaranteed to work with algorithms that explicitly support them.
 * Image formats can also be user-defined using the vpiMakeImageFormat family of functions.
 *
 * Using user-defined image formats with algorithms can lead to undefined behavior (segfaults, etc),
 * but usually it works as expected. Result of algorithms using these image formats must be checked
 * for correctness, as it's not guaranteed that they will work.
 */
typedef uint64_t VPIImageFormat;

/** Denotes an invalid image format. */
#define VPI_IMAGE_FORMAT_INVALID ((VPIImageFormat)0)

/** Single plane with one 8-bit unsigned integer channel. */
#define VPI_IMAGE_FORMAT_U8 VPI_DETAIL_MAKE_NONCOLOR_FMT1(PL, UNSIGNED, X000, X8)

/** Single plane with one block-linear 8-bit unsigned integer channel. */
#define VPI_IMAGE_FORMAT_U8_BL VPI_DETAIL_MAKE_NONCOLOR_FMT1(BL, UNSIGNED, X000, X8)

/** Single plane with one 8-bit signed integer channel. */
#define VPI_IMAGE_FORMAT_S8 VPI_DETAIL_MAKE_NONCOLOR_FMT1(PL, SIGNED, X000, X8)

/** Single plane with one 16-bit unsigned integer channel. */
#define VPI_IMAGE_FORMAT_U16 VPI_DETAIL_MAKE_NONCOLOR_FMT1(PL, UNSIGNED, X000, X16)

/** Single plane with one 32-bit unsigned integer channel. */
#define VPI_IMAGE_FORMAT_U32 VPI_DETAIL_MAKE_NONCOLOR_FMT1(PL, UNSIGNED, X000, X32)

/** Single plane with one 32-bit signed integer channel.*/
#define VPI_IMAGE_FORMAT_S32 VPI_DETAIL_MAKE_NONCOLOR_FMT1(PL, SIGNED, X000, X32)

/** Single plane with one 16-bit signed integer channel.*/
#define VPI_IMAGE_FORMAT_S16 VPI_DETAIL_MAKE_NONCOLOR_FMT1(PL, SIGNED, X000, X16)

/** Single plane with one block-linear 16-bit signed integer channel.*/
#define VPI_IMAGE_FORMAT_S16_BL VPI_DETAIL_MAKE_NONCOLOR_FMT1(BL, SIGNED, X000, X16)

/** Single plane with two interleaved 16-bit signed integer channel.*/
#define VPI_IMAGE_FORMAT_2S16 VPI_DETAIL_MAKE_NONCOLOR_FMT1(PL, SIGNED, XY00, X16_Y16)

/** Single plane with two interleaved block-linear 16-bit signed integer channel.*/
#define VPI_IMAGE_FORMAT_2S16_BL VPI_DETAIL_MAKE_NONCOLOR_FMT1(BL, SIGNED, XY00, X16_Y16)

/** Single plane with one 32-bit floating point channel. */
#define VPI_IMAGE_FORMAT_F32 VPI_DETAIL_MAKE_NONCOLOR_FMT1(PL, FLOAT, X000, X32)

/** Single plane with one 64-bit floating point channel. */
#define VPI_IMAGE_FORMAT_F64 VPI_DETAIL_MAKE_NONCOLOR_FMT1(PL, FLOAT, X000, X64)

/** Single plane with two interleaved 32-bit floating point channels. */
#define VPI_IMAGE_FORMAT_2F32 VPI_DETAIL_MAKE_NONCOLOR_FMT1(PL, FLOAT, XY00, X32_Y32)

/** Single plane with one pitch-linear 8-bit unsigned integer channel with limited-range luma (grayscale) information.
 * Values range from 16 to 235. Below this range is considered black, above is considered white.
 */
#define VPI_IMAGE_FORMAT_Y8 VPI_DETAIL_MAKE_YCbCr_FMT1(BT601, NONE, PL, UNSIGNED, X000, X8)

/** Single plane with one block-linear 8-bit unsigned integer channel with limited-range luma (grayscale) information.
 * Values range from 16 to 235. Below this range is considered black, above is considered white.
 */
#define VPI_IMAGE_FORMAT_Y8_BL VPI_DETAIL_MAKE_YCbCr_FMT1(BT601, NONE, BL, UNSIGNED, X000, X8)

/** Single plane with one pitch-linear 8-bit unsigned integer channel with full-range luma (grayscale) information.
 * Values range from 0 to 255.
 */
#define VPI_IMAGE_FORMAT_Y8_ER VPI_DETAIL_MAKE_YCbCr_FMT1(BT601_ER, NONE, PL, UNSIGNED, X000, X8)

/** Single plane with one block-linear 8-bit unsigned integer channel with full-range luma (grayscale) information.
 * Values range from 0 to 255.
 */
#define VPI_IMAGE_FORMAT_Y8_ER_BL VPI_DETAIL_MAKE_YCbCr_FMT1(BT601_ER, NONE, BL, UNSIGNED, X000, X8)

/** Single plane with one pitch-linear 16-bit unsigned integer channel with limited-range luma (grayscale) information.
 * Values range from 4096 to 60160. Below this range is considered black, above is considered white.
 */
#define VPI_IMAGE_FORMAT_Y16 VPI_DETAIL_MAKE_YCbCr_FMT1(BT601, NONE, PL, UNSIGNED, X000, X16)

/** Single plane with one block-linear 16-bit unsigned integer channel with limited-range luma (grayscale) information.
 * Values range from 4096 to 60160. Below this range is considered black, above is considered white.
 */
#define VPI_IMAGE_FORMAT_Y16_BL VPI_DETAIL_MAKE_YCbCr_FMT1(BT601, NONE, BL, UNSIGNED, X000, X16)

/** Single plane with one pitch-linear 16-bit unsigned integer channel with full-range luma (grayscale) information.
 * Values range from 0 to 65535.
 */
#define VPI_IMAGE_FORMAT_Y16_ER VPI_DETAIL_MAKE_YCbCr_FMT1(BT601_ER, NONE, PL, UNSIGNED, X000, X16)

/** Single plane with one block-linear 16-bit unsigned integer channel with full-range luma (grayscale) information.
 * Values range from 0 to 65535.
 */
#define VPI_IMAGE_FORMAT_Y16_ER_BL VPI_DETAIL_MAKE_YCbCr_FMT1(BT601_ER, NONE, BL, UNSIGNED, X000, X16)

/** YUV420sp 8-bit pitch-linear format with limited range.
 * Format is composed of two planes:
 * 1. One 8-bit channel with luma (Y'). Values range from 16 to 235.
 * 2. Two interleaved 8-bit channels with chroma (Cb,Cr).
 *    Values range from 16 to 240. Resolution is half of luma plane,
 *    both horizontally and vertically.
 *    For a given pixel, Cb channel has lower memory address than Cr.
 */
#define VPI_IMAGE_FORMAT_NV12 VPI_DETAIL_MAKE_YCbCr_FMT2(BT601, 420, PL, UNSIGNED, XYZ0, X8, X8_Y8)

/** YUV420sp 8-bit block-linear format with limited range.
 * Format is composed of two planes:
 * 1. One 8-bit channel with luma (Y'). Values range from 16 to 235.
 * 2. Two interleaved 8-bit channels with chroma (Cb,Cr).
 *    Values range from 0 to 255. Resolution is half of luma plane,
 *    both horizontally and vertically.
 *    For a given pixel, Cb channel has lower memory address than Cr.
 */
#define VPI_IMAGE_FORMAT_NV12_BL VPI_DETAIL_MAKE_YCbCr_FMT2(BT601, 420, BL, UNSIGNED, XYZ0, X8, X8_Y8)

/** YUV420sp 8-bit pitch-linear format with full range.
 * Format is composed of two planes:
 * 1. One 8-bit channel with luma (Y'). Values range from 0 to 255.
 * 2. Two interleaved 8-bit channels with chroma (Cb,Cr).
 *    Values range from 0 to 255. Resolution is half of luma plane,
 *    both horizontally and vertically.
 *    For a given pixel, Cb channel has lower memory address than Cr.
 */
#define VPI_IMAGE_FORMAT_NV12_ER VPI_DETAIL_MAKE_YCbCr_FMT2(BT601_ER, 420, PL, UNSIGNED, XYZ0, X8, X8_Y8)

/** YUV420sp 8-bit block-linear format with full range.
 * Format is composed of two planes:
 * 1. One 8-bit channel with luma (Y'). Values range from 0 to 255.
 * 2. Two interleaved 8-bit channels with chroma (Cb,Cr).
 *    Values range from 0 to 255. Resolution is half of luma plane,
 *    both horizontally and vertically.
 *    For a given pixel, Cb channel has lower memory address than Cr.
 */
#define VPI_IMAGE_FORMAT_NV12_ER_BL VPI_DETAIL_MAKE_YCbCr_FMT2(BT601_ER, 420, BL, UNSIGNED, XYZ0, X8, X8_Y8)

/** YUV444sp 8-bit pitch-linear format with limited range.
 * Format is composed of two planes:
 * 1. One 8-bit channel with luma (Y'). Values range from 16 to 235.
 * 2. Two interleaved 8-bit channels with chroma (Cb,Cr).
 *    Values range from 16 to 240. It has the same resolution as luma plane.
 *    For a given pixel, Cb channel has lower memory address than Cr.
 */
#define VPI_IMAGE_FORMAT_NV24 VPI_DETAIL_MAKE_YCbCr_FMT2(BT601, 444, PL, UNSIGNED, XYZ0, X8, X8_Y8)

/** YUV444sp 8-bit block-linear format with limited range.
 * Format is composed of two planes:
 * 1. One 8-bit channel with luma (Y'). Values range from 16 to 235.
 * 2. Two interleaved 8-bit channels with chroma (Cb,Cr).
 *    Values range from 0 to 255. It has the same resolution as luma plane.
 *    For a given pixel, Cb channel has lower memory address than Cr.
 */
#define VPI_IMAGE_FORMAT_NV24_BL VPI_DETAIL_MAKE_YCbCr_FMT2(BT601, 444, BL, UNSIGNED, XYZ0, X8, X8_Y8)

/** YUV444sp 8-bit pitch-linear format with full range.
 * Format is composed of two planes:
 * 1. One 8-bit channel with luma (Y'). Values range from 0 to 255.
 * 2. Two interleaved 8-bit channels with chroma (Cb,Cr).
 *    Values range from 0 to 255. It has the same resolution as luma plane.
 *    For a given pixel, Cb channel has lower memory address than Cr.
 */
#define VPI_IMAGE_FORMAT_NV24_ER VPI_DETAIL_MAKE_YCbCr_FMT2(BT601_ER, 444, PL, UNSIGNED, XYZ0, X8, X8_Y8)

/** YUV444sp 8-bit block-linear format with full range.
 * Format is composed of two planes:
 * 1. One 8-bit channel with luma (Y'). Values range from 0 to 255.
 * 2. Two interleaved 8-bit channels with chroma (Cb,Cr).
 *    Values range from 0 to 255. It has the same resolution as luma plane.
 *    For a given pixel, Cb channel has lower memory address than Cr.
 */
#define VPI_IMAGE_FORMAT_NV24_ER_BL VPI_DETAIL_MAKE_YCbCr_FMT2(BT601_ER, 444, BL, UNSIGNED, XYZ0, X8, X8_Y8)

/** YUV422 8-bit pitch-linear format in one plane with UYVY ordering and limited range. */
#define VPI_IMAGE_FORMAT_UYVY VPI_DETAIL_MAKE_YCbCr_FMT1(BT601, 422, PL, UNSIGNED, XYZ1, Y8_X8__Z8_X8)

/** YUV422 8-bit block-linear format in one plane with UYVY ordering and limited range. */
#define VPI_IMAGE_FORMAT_UYVY_BL VPI_DETAIL_MAKE_YCbCr_FMT1(BT601, 422, BL, UNSIGNED, XYZ1, Y8_X8__Z8_X8)

/** YUV422 8-bit pitch-linear format in one plane with UYVY ordering and full range. */
#define VPI_IMAGE_FORMAT_UYVY_ER VPI_DETAIL_MAKE_YCbCr_FMT1(BT601_ER, 422, PL, UNSIGNED, XYZ1, Y8_X8__Z8_X8)

/** YUV422 8-bit block-linear format in one plane with UYVY ordering and full range. */
#define VPI_IMAGE_FORMAT_UYVY_ER_BL VPI_DETAIL_MAKE_YCbCr_FMT1(BT601_ER, 422, BL, UNSIGNED, XYZ1, Y8_X8__Z8_X8)

/** YUV422 8-bit pitch-linear format in one plane with YUYV ordering and limited range.
 * Also known as YUY2 format.
 */
#define VPI_IMAGE_FORMAT_YUYV VPI_DETAIL_MAKE_YCbCr_FMT1(BT601, 422, PL, UNSIGNED, XYZ1, X8_Y8__X8_Z8)

/** YUV422 8-bit block-linear format in one plane with YUYV ordering and limited range.
 * Also known as YUY2 format.
 */
#define VPI_IMAGE_FORMAT_YUYV_BL VPI_DETAIL_MAKE_YCbCr_FMT1(BT601, 422, BL, UNSIGNED, XYZ1, X8_Y8__X8_Z8)

/** YUV422 8-bit pitch-linear format in one plane with YUYV ordering and full range.
 * Also known as YUY2 format.
 */
#define VPI_IMAGE_FORMAT_YUYV_ER VPI_DETAIL_MAKE_YCbCr_FMT1(BT601_ER, 422, PL, UNSIGNED, XYZ1, X8_Y8__X8_Z8)

/** YUV422 8-bit block-linear format in one plane with YUYV ordering and full range.
 * Also known as YUY2 format.
 */
#define VPI_IMAGE_FORMAT_YUYV_ER_BL VPI_DETAIL_MAKE_YCbCr_FMT1(BT601_ER, 422, BL, UNSIGNED, XYZ1, X8_Y8__X8_Z8)

/** Single plane with interleaved RGB 8-bit channel. */
#define VPI_IMAGE_FORMAT_RGB8 VPI_DETAIL_MAKE_COLOR_FMT1(RGB, UNDEFINED, PL, UNSIGNED, XYZ1, X8_Y8_Z8)

/** Single plane with interleaved BGR 8-bit channel. */
#define VPI_IMAGE_FORMAT_BGR8 VPI_DETAIL_MAKE_COLOR_FMT1(RGB, UNDEFINED, PL, UNSIGNED, ZYX1, X8_Y8_Z8)

/** Single plane with interleaved RGBA 8-bit channel. */
#define VPI_IMAGE_FORMAT_RGBA8 VPI_DETAIL_MAKE_COLOR_FMT1(RGB, UNDEFINED, PL, UNSIGNED, XYZW, X8_Y8_Z8_W8)

/** Single plane with interleaved BGRA 8-bit channel. */
#define VPI_IMAGE_FORMAT_BGRA8 VPI_DETAIL_MAKE_COLOR_FMT1(RGB, UNDEFINED, PL, UNSIGNED, ZYXW, X8_Y8_Z8_W8)

/** Planar RGB with unsigned 8-bit channels. */
#define VPI_IMAGE_FORMAT_RGB8p VPI_DETAIL_MAKE_COLOR_FMT3(RGB, UNDEFINED, PL, UNSIGNED, XYZ1, X8, X8, X8)

/** Planar BGR with unsigned 8-bit channels. */
#define VPI_IMAGE_FORMAT_BGR8p VPI_DETAIL_MAKE_COLOR_FMT3(RGB, UNDEFINED, PL, UNSIGNED, ZYX1, X8, X8, X8)

/** Planar RGBA with unsigned 8-bit channels. */
#define VPI_IMAGE_FORMAT_RGBA8p VPI_DETAIL_MAKE_COLOR_FMT4(RGB, UNDEFINED, PL, UNSIGNED, XYZW, X8, X8, X8, X8)

/** Planar BGRA with unsigned 8-bit channels. */
#define VPI_IMAGE_FORMAT_BGRA8p VPI_DETAIL_MAKE_COLOR_FMT4(RGB, UNDEFINED, PL, UNSIGNED, ZYXW, X8, X8, X8, X8)

/** Creates a user-defined YCbCr color image format constant using abbreviated parameters.
 *
 * This macro allows passing abbreviated format parameters (without the parameter type prefix).
 * Example to create a YUV422 ITU-R BT.709 studio-range block-linear format.
 * \code{.c}
 * VPIImageFormat fmt = VPI_MAKE_YCbCr_IMAGE_FORMAT_ABBREV(BT709, 422, BL, UNSIGNED, XYZ0, 2, X8, X8_Y8);
 * \endcode
 *
 * Fourth plane, packing3, must have at most 64bpp.
 *
 * @param[in] colorSpec     \ref VPIColorSpec to be used, without the VPI_COLOR_SPEC_ prefix.
 * @param[in] chromaSubsamp \ref VPIChromaSubsampling to be used, without the VPI_CSS_ prefix.
 * @param[in] memLayout     \ref VPIMemLayout to be used, without the VPI_MEM_LAYOUT_ prefix.
 * @param[in] dataType      \ref VPIDataType to be used, without the VPI_DATA_TYPE_ prefix.
 * @param[in] swizzle       \ref VPISwizzle operation to be performed on the channels, without the VPI_SWIZZLE_ prefix.
 * @param[in] numPlanes     Number of planes this format has.
 * @param[in] packing0,packing1,... Format packing of each plane, without the VPI_PACKING_ prefix.
 *
 * @returns The user-defined image format.
 */
#ifdef VPI_DOXYGEN
#    define VPI_MAKE_YCbCr_IMAGE_FORMAT_ABBREV(colorSpec, chromaSubsamp, memLayout, dataType, swizzle, numPlanes, \
                                               packing0, packing1, ...)
#else
#    define VPI_MAKE_YCbCr_IMAGE_FORMAT_ABBREV (VPIImageFormat) VPI_DETAIL_MAKE_YCbCr_FMT
#endif

/** Creates a user-defined YCbCr color image format constant.
 *
 * Example to create a YUV422R ITU-R BT.709 full-range with SMPTE240M transfer function, block-linear format.
 * \code{.c}
 * VPIImageFormat fmt = VPI_MAKE_YCbCr_IMAGE_FORMAT(VPI_MAKE_COLOR_SPEC_ABBREV(BT601, SMPTE240M, FULL),
 *                                                  VPI_CSS_422R, VPI_BLOCK_LINEAR, VPI_DATA_TYPE_UNSIGNED, VPI_SWIZZLE_XYZ0,
 *                                                  2, VPI_PACKING_X8, VPI_PACKING_X8_Y8);
 * \endcode
 *
 * Fourth plane (packing3) must have at most 64bpp.
 *
 * @param[in] colorModel    \ref VPIColorModel to be used.
 * @param[in] colorSpec     \ref VPIColorSpec to be used.
 * @param[in] chromaSubsamp \ref VPIChromaSubsampling to be used.
 * @param[in] memLayout     \ref VPIMemLayout to be used.
 * @param[in] dataType      \ref VPIDataType to be used.
 * @param[in] swizzle       \ref VPISwizzle operation to be performed on the channels.
 * @param[in] numPlanes     Number of planes this format has.
 * @param[in] packing0,packing1,... Format packing of each plane.
 *
 * @returns The user-defined image format.
 */
#ifdef VPI_DOXYGEN
#    define VPI_MAKE_YCbCr_IMAGE_FORMAT(colorModel, colorSpec, chromaSubsamp, memLayout, dataType, swizzle, numPlanes, \
                                        packing0, packing1, ...)
#else
#    define VPI_MAKE_YCbCr_IMAGE_FORMAT (VPIImageFormat) VPI_DETAIL_MAKE_YCbCr_FORMAT
#endif

/** Creates a user-defined color image format constant using abbreviated parameters.
 *
 * This macro allows passing abbreviated format parameters (without the parameter type prefix).
 * Example to create a RGB planar ITU-R BT.709 studio-range block-linear format.
 * \code{.c}
 * VPIImageFormat fmt = VPI_MAKE_COLOR_IMAGE_FORMAT_ABBREV(RGB, BT709, BL, UNSIGNED, XYZ0, 3, X8, X8, Y8);
 * \endcode
 *
 * If the color model is \ref VPI_COLOR_MODEL_YCbCr, it's assumed that the chroma subsampling is 4:4:4,
 * i.e, \ref VPI_CSS_444.
 *
 * @param[in] colorModel \ref VPIColorModel to be used, without the VPI_COLOR_MODEL_ prefix.
 * @param[in] colorSpec  \ref VPIColorSpec to be used, without the VPI_COLOR_SPEC_ prefix.
 * @param[in] memLayout  \ref VPIMemLayout to be used, without the VPI_MEM_LAYOUT_ prefix.
 * @param[in] dataType   \ref VPIDataType to be used, without the VPI_DATA_TYPE_ prefix.
 * @param[in] swizzle    \ref VPISwizzle operation to be performed on the channels, without the VPI_SWIZZLE_ prefix.
 * @param[in] numPlanes  Number of planes this format has.
 * @param[in] packing0,packing1,... Format packing of each plane, without the VPI_PACKING_ prefix.
 *                                    + Fourth plane (packing3) must have at most 64bpp.
 *
 * @returns The user-defined image format.
 */
#ifdef VPI_DOXYGEN
#    define VPI_MAKE_COLOR_IMAGE_FORMAT_ABBREV(colorModel, colorSpec, memLayout, dataType, swizzle, numPlanes, \
                                               packing0, packing1, ...)
#else
#    define VPI_MAKE_COLOR_IMAGE_FORMAT_ABBREV (VPIImageFormat) VPI_DETAIL_MAKE_COLOR_FMT
#endif

/** Creates a user-defined color image format constant.
 *
 * Example to create a RGB planar ITU-R BT.709 full-range with SMPTE240M encoding, block-linear format.
 * \code{.c}
 * VPIImageFormat fmt = VPI_MAKE_COLOR_IMAGE_FORMAT(VPI_COLOR_MODEL_RGB, VPI_MAKE_COLOR_SPEC_ABBREV(BT601, SMPTE240M, FULL),
 *                                                  VPI_MEM_LAYOUT_BL, VPI_DATA_TYPE_UNSIGNED, VPI_SWIZZLE_XYZ0,
 *                                                  2, VPI_PACKING_X8, VPI_PACKING_X8, VPI_PACKING_Y8);
 * \endcode
 *
 * If the color model is \ref VPI_COLOR_MODEL_YCbCr, it's assumed that the chroma subsampling is 4:4:4,
 * i.e, \ref VPI_CSS_444.
 *
 * @param[in] colorModel \ref VPIColorModel to be used.
 * @param[in] colorSpec  \ref VPIColorSpec to be used.
 * @param[in] memLayout  \ref VPIMemLayout to be used.
 * @param[in] dataType   \ref VPIDataType to be used.
 * @param[in] swizzle    \ref VPISwizzle operation to be performed on the channels.
 * @param[in] numPlanes  Number of planes this format has.
 * @param[in] packing0,packing1,... Format packing of each plane.
 *                                    + Fourth plane (packing3) must have at most 64bpp.
 *
 * @returns The user-defined image format.
 */
#ifdef VPI_DOXYGEN
#    define VPI_MAKE_COLOR_IMAGE_FORMAT(colorModel, colorSpec, memLayout, dataType, swizzle, numPlanes, packing0, \
                                        packing1, ...)
#else
#    define VPI_MAKE_COLOR_IMAGE_FORMAT (VPIImageFormat) VPI_DETAIL_MAKE_COLOR_FORMAT
#endif

/** Creates a user-defined non-color image format constant using abbreviated parameters.
 *
 * This macro allows passing abbreviated format parameters (without the parameter type prefix).
 *
 * Example to create 3-plane float block-linear image, 1st: 8-bit, 2nd: 16-bit, 3rd: 32-bit
 * \code{.c}
 * VPIImageFormat fmt = VPI_MAKE_NONCOLOR_IMAGE_FORMAT_ABBREV(BL, UNSIGNED, 3, X8, X16, X32);
 * \endcode
 *
 * @param[in] memLayout \ref VPIMemLayout to be used, without the VPI_MEM_LAYOUT_ prefix.
 * @param[in] dataType  \ref VPIDataType to be used, without the VPI_DATA_TYPE_ prefix.
 * @param[in] swizzle   \ref VPISwizzle operation to be performed on the channels.
 * @param[in] numPlanes Number of planes this format has.
 * @param[in] packing0,packing1,... Format packing of each plane, without the VPI_PACKING_ prefix.
 *                                    + Fourth plane (packing3) must have at most 64bpp.
 *
 * @returns The user-defined image format.
 */
#ifdef VPI_DOXYGEN
#    define VPI_MAKE_NONCOLOR_IMAGE_FORMAT_ABBREV(memLayout, dataType, swizzle, numPlanes, packing0, packing1, ...)
#else
#    define VPI_MAKE_NONCOLOR_IMAGE_FORMAT_ABBREV (VPIImageFormat) VPI_DETAIL_MAKE_NONCOLOR_FMT
#endif

/** Creates a user-defined non-color image format constant.
 *
 * Example to create 3-plane float block-linear image, 1st: 8-bit, 2nd: 16-bit, 3rd: 32-bit
 * \code{.c}
 * VPIImageFormat fmt = VPI_MAKE_NONCOLOR_IMAGE_FORMAT(VPI_MEM_LAYOUT_BL, VPI_DATA_TYPE_UNSIGNED,
 *                                                    3, VPI_PACKING_X8, VPI_PACKING_X16, VPI_PACKING_X32);
 * \endcode
 *
 * @param[in] memLayout \ref VPIMemLayout to be used.
 * @param[in] dataType  \ref VPIDataType to be used.
 * @param[in] swizzle   \ref VPISwizzle operation to be performed on the channels.
 * @param[in] numPlanes Number of planes this format has.
 * @param[in] packing0,packing1,... Format packing of each plane.
 *                                    + Fourth plane (packing3) must have at most 64bpp.
 *
 * @returns The user-defined image format.
 */
#ifdef VPI_DOXYGEN
#    define VPI_MAKE_NONCOLOR_IMAGE_FORMAT(memLayout, dataType, swizzle, numPlanes, packing0, packing1, ...)
#else
#    define VPI_MAKE_NONCOLOR_IMAGE_FORMAT (VPIImageFormat) VPI_DETAIL_MAKE_NONCOLOR_FORMAT
#endif

/** Creates a user-defined raw (Bayer pattern) image format constant using abbreviated parameters.
 *
 * This macro allows passing abbreviated format parameters (without the parameter type prefix).
 *
 * Example to create a RGGB Bayer pattern format:
 * \code{.c}
 * VPIImageFormat fmt = VPI_MAKE_RAW_IMAGE_FORMAT_ABBREV(BAYER_RGGB, BL, UNSIGNED, X000, 1, X8);
 * \endcode
 *
 * @param[in] rawPattern \ref VPIRawPattern to be used, without the VPI_RAW_ prefix.
 * @param[in] memLayout  \ref VPIMemLayout to be used, without the VPI_MEM_LAYOUT_ prefix.
 * @param[in] dataType   \ref VPIDataType to be used, without the VPI_DATA_TYPE_ prefix.
 * @param[in] swizzle    \ref VPISwizzle operation to be performed on the channels, without the VPI_SWIZZLE_ prefix.
 * @param[in] numPlanes  Number of planes this format has.
 * @param[in] packing    Format packing of image plane plane, without the VPI_PACKING_ prefix.
 *
 * @returns The user-defined image format.
 */
#ifdef VPI_DOXYGEN
#    define VPI_MAKE_RAW_IMAGE_FORMAT_ABBREV(rawPattern, memLayout, dataType, numPlanes, swizzle, packing)
#else
#    define VPI_MAKE_RAW_IMAGE_FORMAT_ABBREV (VPIImageFormat) VPI_DETAIL_MAKE_RAW_FMT
#endif

/** Creates a user-defined raw (Bayer pattern) image format constant.
 *
 * Example to create a RGGB Bayer pattern format:
 * \code{.c}
 * VPIImageFormat fmt = VPI_MAKE_RAW_IMAGE_FORMAT(VPI_RAW_BAYER_RGGB, VPI_MEM_LAYOUT_BL,
 *                                                VPI_DATA_TYPE_UNSIGNED, VPI_SWIZZLE_X000,
 *                                                1, VPI_PACKING_X8);
 * \endcode
 *
 * @param[in] rawPattern \ref VPIRawPattern to be used.
 * @param[in] memLayout  \ref VPIMemLayout to be used.
 * @param[in] dataType   \ref VPIDataType to be used.
 * @param[in] swizzle    \ref VPISwizzle operation to be performed on the channels.
 * @param[in] numPlanes  Number of planes this format has.
 * @param[in] packing    Format packing of image plane.
 *
 * @returns The user-defined image format.
 */
#ifdef VPI_DOXYGEN
#    define VPI_MAKE_RAW_IMAGE_FORMAT(rawPattern, memLayout, dataType, numPlanes, swizzle, packing)
#else
#    define VPI_MAKE_RAW_IMAGE_FORMAT (VPIImageFormat) VPI_DETAIL_MAKE_RAW_FORMAT
#endif

/** Creates a user-defined YCbCr color image format.
 *
 * When the pre-defined image formats aren't enough, user-defined image formats can be created.
 * @warning It's not guaranteed that algorithms will work correctly with use-defined image formats. It's recommended
 * to check if the results are correct prior deploying the solution in a production environment.
 *
 * Fourth plane (packing3) must have at most 64bpp.
 *
 * @param[in] colorSpec \ref VPIColorSpec to be used.
 * @param[in] chromaSub \ref VPIChromaSubsampling to be used.
 * @param[in] memLayout \ref VPIMemLayout to be used.
 * @param[in] dataType  \ref VPIDataType to be used.
 * @param[in] swizzle   \ref VPISwizzle operation to be performed on the channels.
 * @param[in] packing0,packing1,packing2,packing3 Format packing of each plane. 
 *                                                + When remaining planes aren't needed,
 *                                                  pass \ref VPI_PACKING_0 for them.
 *
 * @returns The user-defined image format.
 * @retval #VPI_IMAGE_FORMAT_INVALID Swizzle packing is invalid.
 * @retval #VPI_IMAGE_FORMAT_INVALID \p colorSpec and \p chromaSub are undefined.
 */
VPI_PUBLIC VPIImageFormat vpiMakeYCbCrImageFormat(VPIColorSpec colorSpec, VPIChromaSubsampling chromaSub,
                                                  VPIMemLayout memLayout, VPIDataType dataType, VPISwizzle swizzle,
                                                  VPIPacking packing0, VPIPacking packing1, VPIPacking packing2,
                                                  VPIPacking packing3);

/** Creates a user-defined color image format.
 *
 * When the pre-defined image formats aren't enough, user-defined image formats can be created.
 * @warning It's not guaranteed that algorithms will work correctly with use-defined image formats. It's recommended
 * to check if the results are correct prior deploying the solution in a production environment.
 *
 * If the color model is \ref VPI_COLOR_MODEL_YCbCr, it's assumed that the chroma subsampling is 4:4:4,
 * i.e, \ref VPI_CSS_444.
 *
 * @param[in] colorModel \ref VPIColorModel to be used.
 * @param[in] colorSpec  \ref VPIColorSpec to be used.
 * @param[in] memLayout  \ref VPIMemLayout to be used.
 * @param[in] dataType   \ref VPIDataType to be used.
 * @param[in] swizzle    \ref VPISwizzle operation to be performed on the channels.
 * @param[in] packing0,packing1,packing2,packing3 Format packing of each plane. 
 *                                                + When remaining planes aren't needed, pass \ref VPI_PACKING_0 for them.
 *                                                + Fourth plane (packing3) must have at most 64bpp.
 *
 * @returns The user-defined image format.
 * @retval #VPI_IMAGE_FORMAT_INVALID \p colorModel is \ref VPI_COLOR_MODEL_UNDEFINED . 
 * @retval #VPI_IMAGE_FORMAT_INVALID \p colorModel is \ref VPI_COLOR_MODEL_RAW .
 * @retval #VPI_IMAGE_FORMAT_INVALID \p colorSpec is \ref VPI_COLOR_SPEC_UNDEFINED .
 * @retval #VPI_IMAGE_FORMAT_INVALID Swizzle packing is invalid.
 * @retval #VPI_IMAGE_FORMAT_INVALID \p colorModel, \p colorSpec and \p chromaSub are undefined.
 * @retval #VPI_IMAGE_FORMAT_INVALID Image format invalid; 4th plane cannot have a 128 bit channel.
 */
VPI_PUBLIC VPIImageFormat vpiMakeColorImageFormat(VPIColorModel colorModel, VPIColorSpec colorSpec,
                                                  VPIMemLayout memLayout, VPIDataType dataType, VPISwizzle swizzle,
                                                  VPIPacking packing0, VPIPacking packing1, VPIPacking packing2,
                                                  VPIPacking packing3);

/** Creates a user-defined non-color image format.
 *
 * When the pre-defined non-color image formats aren't enough, it is possible to define new ones.
 *
 * @warning It's not guaranteed that algorithms will work correctly with use-defined image formats. It's recommended
 * to check if the results are correct prior deploying the solution in a production environment.
 *
 * @param[in] memLayout \ref VPIMemLayout to be used.
 * @param[in] dataType  \ref VPIDataType to be used.
 * @param[in] swizzle   \ref VPISwizzle operation to be performed on the channels.
 * @param[in] packing0,packing1,packing2,packing3 Format packing of each plane. 
 *                                                + When remaining planes aren't needed, pass \ref VPI_PACKING_0 for them.
 *                                                + Fourth plane (packing3) must have at most 64bpp.
 *
 * @returns The user-defined image format.
 *
 * @retval #VPI_IMAGE_FORMAT_INVALID Image format to be queried is invalid.
 * @retval #VPI_IMAGE_FORMAT_INVALID Swizzle packing is invalid. 
 */
VPI_PUBLIC VPIImageFormat vpiMakeNonColorImageFormat(VPIMemLayout memLayout, VPIDataType dataType, VPISwizzle swizzle,
                                                     VPIPacking packing0, VPIPacking packing1, VPIPacking packing2,
                                                     VPIPacking packing3);

/** Creates a user-defined raw image format.
 *
 * When the pre-defined raw image formats aren't enough, it is possible to define new ones.
 * @warning It's not guaranteed that algorithms will work correctly with use-defined image formats. It's recommended
 * to check if the results are correct prior deploying the solution in a production environment.
 *
 * @param[in] rawPattern \ref VPIRawPattern to be used.
 * @param[in] memLayout  \ref VPIMemLayout to be used.
 * @param[in] dataType   \ref VPIDataType to be used.
 * @param[in] swizzle    \ref VPISwizzle operation to be performed on the channels.
 * @param[in] packing0,packing1,packing2,packing3 Format packing of each plane. 
 *                                                + When remaining planes aren't needed, pass \ref VPI_PACKING_0 for them.
 *                                                + Fourth plane (packing3) must have at most 64bpp.
 *
 * @returns The user-defined image format.
 *
 * @retval #VPI_IMAGE_FORMAT_INVALID Image format to be queried is invalid. 
 * @retval #VPI_IMAGE_FORMAT_INVALID \p rawPattern is invalid. 
 * @retval #VPI_IMAGE_FORMAT_INVALID Swizzle packing is invalid. 
 */
VPI_PUBLIC VPIImageFormat vpiMakeRawImageFormat(VPIRawPattern rawPattern, VPIMemLayout memLayout, VPIDataType dataType,
                                                VPISwizzle swizzle, VPIPacking packing0, VPIPacking packing1,
                                                VPIPacking packing2, VPIPacking packing3);

/** Creates a image format from a FourCC code.
 *
 * See https://www.fourcc.org for more information about FourCC.
 *
 * @param[in] fourcc FourCC code.
 * @param[in] colorSpec \ref VPIColorSpec to be used.
 * @param[in] memLayout \ref VPIMemLayout to be used.
 *
 * @returns The image format corresponding to the FourCC code.
 *
 * @retval #VPI_IMAGE_FORMAT_INVALID Invalid \p fourcc. 
 */
VPI_PUBLIC VPIImageFormat vpiMakeImageFormatFromFourCC(uint32_t fourcc, VPIColorSpec colorSpec, VPIMemLayout memLayout);

/** Returns the FourCC code corresponding to an image format.
 *
 * @param[in] fmt Image format to be queried.
 *
 * @returns The FourCC code corresponding to the image format.
 *
 * @retval 0 No FourCC associated with \p fmt, e.g. \ref VPI_IMAGE_FORMAT_2F32.
 */
VPI_PUBLIC uint32_t vpiImageFormatGetFourCC(VPIImageFormat fmt);

/** Get the packing for a given plane of an image format.
 *
 * @param[in] fmt   Image format to be queried.
 * @param[in] plane Which plane whose packing must be returned. 
 *                  + Valid values range from 0 (first plane) to 3 (fourth plane).
 *
 * @returns The plane's format packing.
 *
 * @retval #VPI_PACKING_0 \p fmt to be queried is invalid. 
 * @retval #VPI_PACKING_0 \p plane outside valid range.
 */
VPI_PUBLIC VPIPacking vpiImageFormatGetPlanePacking(VPIImageFormat fmt, int plane);

/** Get the plane width of an image with the given image format and width.
 *
 * @param[in] fmt      Image format to be queried.
 * @param[in] imgWidth Width of the image.
 *                      + Must be >= 1.
 * @param[in] plane    Image plane to be queried.
 *                      + Must be >= 0 and < the number of planes in the image format.
 *
 * @returns The image plane's width.
 *
 * @retval 0 \p fmt is invalid.
 * @retval 0 \p imgWidth is outside valid range.
 * @retval 0 \p plane is outside valid range.
 */
VPI_PUBLIC int32_t vpiImageFormatGetPlaneWidth(VPIImageFormat fmt, int32_t imgWidth, int plane);

/** Get the plane height of an image with the given image format and height.
 *
 * @param[in] fmt      Image format to be queried.
 * @param[in] imgHeight Height of the image.
 *                      + Must be >= 1.
 * @param[in] plane    Image plane to be queried.
 *                      + Must be >= 0 and < the number of planes in the image format.
 *
 * @returns The image plane's height.
 *
 * @retval 0 \p fmt is invalid.
 * @retval 0 \p imgHeight is outside valid range.
 * @retval 0 \p plane is outside valid range.
 */
VPI_PUBLIC int32_t vpiImageFormatGetPlaneHeight(VPIImageFormat fmt, int32_t imgHeight, int plane);

/** Replaces the swizzle and packing of an existing image format.
 *
 * The number of channels represented by the swizzle must be equal to the sum of the number of channels
 * represented by the packings. For instance, XYZ1,X8,X8Y8 is a valid combination with 3 channels.
 * XYZW,X8,X8Y8 isn't as swizzle has 4 channels, and X8,X8Y8 represents in total 3 channels.
 *
 * @param[in] fmt     Image format to have its packing replaced.
 * @param[in] swizzle The new swizzle.
 *                    + Pass \ref VPI_SWIZZLE_INVALID if swizzle must not be updated.
 * 
 * @param[in] packing0,packing1,packing2,packing3 New packing.
 *                                                + Pass \ref VPI_PACKING_INVALID if the packing for
 *                                                  a particular plane must not be updated.
 *                                                + If replacing the fourth packing (packing3),
 *                                                  the packing's bits per pixel must be at most 64.
 *
 * 
 * @returns Updated image format.
 *
 * @retval #VPI_IMAGE_FORMAT_INVALID \p fmt to be queried is invalid. 
 */
VPI_PUBLIC VPIImageFormat vpiImageFormatSetSwizzleAndPacking(VPIImageFormat fmt, VPISwizzle swizzle,
                                                             VPIPacking packing0, VPIPacking packing1,
                                                             VPIPacking packing2, VPIPacking packing3);

/** Get the image format's plane bits per pixel count.
 *
 * @param[in] fmt   Image format to be queried.
 * @param[in] plane Which plane is to be queried.
 *                  + Valid values range from 0 (first plane) to 3 (fourth plane).
 *
 * @returns The number of bits per pixel the given format plane has.
 *
 * @retval 0 \p fmt is invalid.
 * @retval 0 \p plane outside valid range.
 */
VPI_PUBLIC int vpiImageFormatGetPlaneBitsPerPixel(VPIImageFormat fmt, int plane);

/** Set the image format's data type.
 *
 * @param[in] fmt      Image format have its data type replaced.
 * @param[in] dataType The new data type.
 *
 * @returns The new image format based on input's, but with the user-provided data type.
 *
 * @retval #VPI_IMAGE_FORMAT_INVALID \p fmt to be queried is invalid. 
 * @retval #VPI_IMAGE_FORMAT_INVALID \p dataType is invalid.
 */
VPI_PUBLIC VPIImageFormat vpiImageFormatSetDataType(VPIImageFormat fmt, VPIDataType dataType);

/** Get the image format's data type.
 *
 * @param[in] fmt Image format to be queried.
 *
 * @returns The image format's data type.
 *
 * @retval #VPI_DATA_TYPE_INVALID \p fmt to be queried is invalid. 
 */
VPI_PUBLIC VPIDataType vpiImageFormatGetDataType(VPIImageFormat fmt);

/** Get the image format's channel swizzle operation.
 *
 * @param[in] fmt Image format to be queried.
 *
 * @returns The image format's swizzle operation.
 *
 * @retval #VPI_SWIZZLE_0000 \p fmt to be queried is invalid. 
 */
VPI_PUBLIC VPISwizzle vpiImageFormatGetSwizzle(VPIImageFormat fmt);

/** Get the swizzle operation of the given image format's plane.
 *
 * @param[in] fmt   Image format to be queried.
 *                  + Image format should have less packing channels and swizzle channels.
 * @param[in] plane Plane to be queried. 
 *                  + Valid values range from 0 (first) to 3 (fourth and last) plane.
 *
 * @returns The channel swizzle operation performed in the given plane.
 *
 * @retval #VPI_SWIZZLE_0000    \p fmt to be queried is invalid.
 * @retval #VPI_SWIZZLE_INVALID More packing channels than Swizzle channels.
 */
VPI_PUBLIC VPISwizzle vpiImageFormatGetPlaneSwizzle(VPIImageFormat fmt, int plane);

/** Set the image format's memory layout.
 *
 * @param[in] fmt       Image format have its memory layout replaced.
 * @param[in] memLayout The new memory layout.
 *
 * @returns The new image format based on input's, but with the user-provided memory layout.
 *
 * @retval #VPI_IMAGE_FORMAT_INVALID \p fmt to be queried is invalid. 
 * @retval #VPI_IMAGE_FORMAT_INVALID \p memLayout is invalid.
 */
VPI_PUBLIC VPIImageFormat vpiImageFormatSetMemLayout(VPIImageFormat fmt, VPIMemLayout memLayout);

/** Get the image format's memory layout.
 *
 * @param[in] fmt Image format to be queried.
 *
 * @returns The image format's memory layout.
 *
 * @retval #VPI_MEM_LAYOUT_INVALID \p fmt to be queried is invalid. 
 */
VPI_PUBLIC VPIMemLayout vpiImageFormatGetMemLayout(VPIImageFormat fmt);

/** Set the image format's color standard.
 *
 * Only valid for color models that represent image coding systems, such as RGB, Y'CrCb, HSV, etc.
 * For other color models, it'll return VPI_IMAGE_FORMAT_INVALID.
 *
 * @param[in] fmt       Image format have its color spec replaced.
 * @param[in] colorSpec The new color standard.
 *
 * @returns The new image format based on input's, but with the user-provided color spec.
 *
 * @retval #VPI_IMAGE_FORMAT_INVALID \p fmt to be queried is invalid. 
 * @retval #VPI_IMAGE_FORMAT_INVALID \p colorSpec is invalid.
 * @retval #VPI_IMAGE_FORMAT_INVALID Color standard isn't applicable to format's color model..
 */
VPI_PUBLIC VPIImageFormat vpiImageFormatSetColorSpec(VPIImageFormat fmt, VPIColorSpec colorSpec);

/** Get the image format's color standard.
 *
 * @param[in] fmt Image format to be queried.
 *
 * @returns The image format's color standard.
 *
 * @retval #VPI_COLOR_SPEC_INVALID   \p fmt to be queried is invalid. 
 * @retval #VPI_COLOR_SPEC_UNDEFINED It's not applicable, i.e., format model isn't RGB, YCbCr, HSV or HSL.
 */
VPI_PUBLIC VPIColorSpec vpiImageFormatGetColorSpec(VPIImageFormat fmt);

/** Get the image format's color model.
 *
 * @param[in] fmt Image format to be queried.
 *
 * @returns The image format's color model.
 *
 * @retval #VPI_COLOR_MODEL_UNDEFINED \p fmt to be queried is invalid. 
 */
VPI_PUBLIC VPIColorModel vpiImageFormatGetColorModel(VPIImageFormat fmt);

/** Set the image format's chroma subsampling type.
 *
 *
 * @param[in] fmt Image format have its chroma subsampling type replaced.
 *                + It's only applicable if format has YCbCr color model.
 * @param[in] css The new chroma subsampling type.
 *
 * @returns The new image format based on input's, but with the user-provided chroma subsampling type.
 *
 * @retval #VPI_IMAGE_FORMAT_INVALID \p fmt to be queried is invalid. 
 * @retval #VPI_IMAGE_FORMAT_INVALID \p css is invalid.
 * @retval #VPI_CSS_NONE             Format's color model is NOT \ref VPI_COLOR_MODEL_YCbCr.
 */
VPI_PUBLIC VPIImageFormat vpiImageFormatSetChromaSubsampling(VPIImageFormat fmt, VPIChromaSubsampling css);

/** Get the image format's chroma subsampling type.
 *
 * @param[in] fmt Image format to be queried.
 *
 * @returns The image format's chroma subsampling type.
 * @retval #VPI_CSS_INVALID \p fmt is not supported.
 * @retval #VPI_CSS_NONE \p fmt color model is NOT \ref VPI_COLOR_MODEL_YCbCr.
 */
VPI_PUBLIC VPIChromaSubsampling vpiImageFormatGetChromaSubsampling(VPIImageFormat fmt);

/** Get the number of channels in a plane of an image format.
 *
 * @param[in] fmt Image format to be queried.
 * 
 * @param[in] plane Plane to be queried. Valid values range from 0 (first) to 3 (fourth and last) plane.
 *
 * @returns Number of channels in the given plane.
 */
VPI_PUBLIC int vpiImageFormatGetPlaneChannelCount(VPIImageFormat fmt, int plane);

/** Get the number of planes of an image format.
 *
 * @param[in] fmt Image format to be queried.
 *
 * @returns Number of planes defined by the given image format.
 */
VPI_PUBLIC int vpiImageFormatGetPlaneCount(VPIImageFormat fmt);

/** Get the total number of channels of an image format.
 *
 * @param[in] fmt Image format to be queried.
 *
 * @returns The sum of all channel counts in all planes.
 */
VPI_PUBLIC int vpiImageFormatGetChannelCount(VPIImageFormat fmt);

/** Get the image format's bit size for each channel.
 *
 * @param[in] fmt Image format to be queried.
 * 
 * @param[out] bits Pointer to an int32_t array with 4 elements where output will be stored.
 *                  + If it's NULL, the function is a no-op.
 */
VPI_PUBLIC void vpiImageFormatGetBitsPerChannel(VPIImageFormat fmt, int32_t *bits);

/** Get the pixel type of image format's plane.
 *
 * @param[in] fmt   Image format to be queried.
 * @param[in] plane Plane to be queried.
 *                  + Valid values range from 0 (first) to 3 (fourth and last) plane.
 *
 * @returns The pixel type of the given plane.
 *
 * @retval #VPI_PIXEL_TYPE_INVALID \p fmt to be queried is invalid. 
 * @retval #VPI_PIXEL_TYPE_INVALID \p plane is outside range.
 */
VPI_PUBLIC VPIPixelType vpiImageFormatGetPlanePixelType(VPIImageFormat fmt, int plane);

/** Get the plane format of an image format.
 *
 * @param[in] fmt   Image format to be queried.
 * @param[in] plane Plane to be queried. 
 *                  + Valid values range from 0 (first) to 3 (fourth and last) plane.
 *
 * @returns The image format of the given plane.
 *
 * @retval #VPI_IMAGE_FORMAT_INVALID \p fmt packing is invalid. 
 * @retval #VPI_IMAGE_FORMAT_INVALID \p plane is outside range.
 */
VPI_PUBLIC VPIImageFormat vpiImageFormatGetPlaneFormat(VPIImageFormat fmt, int plane);

/** Constructs an image format given the format of each plane.
 *
 * @param[in] plane0,plane1,plane2,plane3 Image format of each plane.
 *                                        + When plane doesn't exist, pass \ref VPI_IMAGE_FORMAT_INVALID.
 *                                        + All plane types must have only 1 plane.
 *                                        + First plane must have a valid packing.
 *                                        + Total number of channels must be at most 4.
 *                                        + Color spec, mem layout and data type of all planes must be the same.
 *                                        + Only one kind of chroma subsampling is allowed.
 *                                        + At least one channel is allowed.
 *                                        + All planes after the first invalid one must be invalid.
 *
 * @returns The image format whose planes has the given formats.
 *
 * @retval #VPI_IMAGE_FORMAT_INVALID Image format to be queried is invalid.
 * @retval #VPI_IMAGE_FORMAT_INVALID All plane types must have only 1 plane.
 * @retval #VPI_IMAGE_FORMAT_INVALID First plane must have a valid packing.
 * @retval #VPI_IMAGE_FORMAT_INVALID Total number of channels must be atmost 4.
 * @retval #VPI_IMAGE_FORMAT_INVALID Color spec, mem layout and data type of all planes must be the same.
 * @retval #VPI_IMAGE_FORMAT_INVALID Only one kind of chroma subsampling is allowed.
 * @retval #VPI_IMAGE_FORMAT_INVALID At least one channel is allowed.
 * @retval #VPI_IMAGE_FORMAT_INVALID All planes after the first invalid one must be invalid.
 */
VPI_PUBLIC VPIImageFormat vpiMakeImageFormatFromPlanes(VPIImageFormat plane0, VPIImageFormat plane1,
                                                       VPIImageFormat plane2, VPIImageFormat plane3);

/** Returns a string representation of the image format.
 *
 * @param[in] fmt Image format whose name is to be returned.
 *
 * @returns The string representation of the image format.
 *          Returned string is valid until next call of this function from the same calling thread.
 *          Returned pointer must not be freed.
 */
VPI_PUBLIC const char *vpiImageFormatGetName(VPIImageFormat fmt);

/** Returns the raw color pattern of the image format.
 *
 * @param[in] fmt Image format to be queried.
 *                + Its color model must be \ref VPI_COLOR_MODEL_RAW .
 * 
 * @returns The raw pattern of given raw image format.
 *
 * @retval #VPI_RAW_INVALID Color model of \p fmt is not \ref VPI_COLOR_MODEL_RAW. 
 */
VPI_PUBLIC VPIRawPattern vpiImageFormatGetRawPattern(VPIImageFormat fmt);

/** Sets the raw color pattern of the image format.
 *
 * @param[in] fmt        Image format to be updated.
 *                       + Its color model must be \ref VPI_COLOR_MODEL_RAW.
 * @param[in] rawPattern The new raw pattern.
 * 
 * @returns The new image format with the updated raw pattern will be returned.
 *
 * @retval #VPI_IMAGE_FORMAT_INVALID \p fmt to be queried is invalid or its color model isn't \ref VPI_COLOR_MODEL_RAW.
 * @retval #VPI_IMAGE_FORMAT_INVALID \p rawPattern is invalid.
 */
VPI_PUBLIC VPIImageFormat vpiImageFormatSetRawPattern(VPIImageFormat fmt, VPIRawPattern rawPattern);

/** Returns whether the image formats have the same data layout.
 *
 * Data layout referts to how pixels are laid out in memory. It doesn't take into account
 * the format's color information.
 *
 * The following characteristics are taken into account:
 * - memory layout (block linear, pitch linear, ...)
 * - data type (signed, unsigned, float, ...)
 * - Swizzle (except for 1/0 in 4th channel)
 * - number of planes
 * - packings (X8_Y8, X16, ...)
 * - chroma subsampling (4:4:4, 4:2:0, ...)
 *
 * @param[in] a, b Image formats to be compared.
 * 
 * @retval 1 Both image formats compares equal with respect to how pixels are laid out in memory.
 * @retval 0 Both image formats compares differently.
 */
VPI_PUBLIC int vpiImageFormatHasSameDataLayout(VPIImageFormat a, VPIImageFormat b);

/** @} */

#ifdef __cplusplus
}
#endif

#endif /* NV_VPI_IMAGE_FORMAT_H */
// End content from: ImageFormat.h

// Begin content from: Types.h
/*
 * Copyright 2019-2023 NVIDIA Corporation. All rights reserved.
 *
 * NOTICE TO LICENSEE:
 *
 * This source code and/or documentation ("Licensed Deliverables") are
 * subject to NVIDIA intellectual property rights under U.S. and
 * international Copyright laws.
 *
 * These Licensed Deliverables contained herein is PROPRIETARY and
 * CONFIDENTIAL to NVIDIA and is being provided under the terms and
 * conditions of a form of NVIDIA software license agreement by and
 * between NVIDIA and Licensee ("License Agreement") or electronically
 * accepted by Licensee. Notwithstanding any terms or conditions to
 * the contrary in the License Agreement, reproduction or disclosure
 * of the Licensed Deliverables to any third party without the express
 * written consent of NVIDIA is prohibited.
 *
 * NOTWITHSTANDING ANY TERMS OR CONDITIONS TO THE CONTRARY IN THE
 * LICENSE AGREEMENT, NVIDIA MAKES NO REPRESENTATION ABOUT THE
 * SUITABILITY OF THESE LICENSED DELIVERABLES FOR ANY PURPOSE. IT IS
 * PROVIDED "AS IS" WITHOUT EXPRESS OR IMPLIED WARRANTY OF ANY KIND.
 * NVIDIA DISCLAIMS ALL WARRANTIES WITH REGARD TO THESE LICENSED
 * DELIVERABLES, INCLUDING ALL IMPLIED WARRANTIES OF MERCHANTABILITY,
 * NONINFRINGEMENT, AND FITNESS FOR A PARTICULAR PURPOSE.
 * NOTWITHSTANDING ANY TERMS OR CONDITIONS TO THE CONTRARY IN THE
 * LICENSE AGREEMENT, IN NO EVENT SHALL NVIDIA BE LIABLE FOR ANY
 * SPECIAL, INDIRECT, INCIDENTAL, OR CONSEQUENTIAL DAMAGES, OR ANY
 * DAMAGES WHATSOEVER RESULTING FROM LOSS OF USE, DATA OR PROFITS,
 * WHETHER IN AN ACTION OF CONTRACT, NEGLIGENCE OR OTHER TORTIOUS
 * ACTION, ARISING OUT OF OR IN CONNECTION WITH THE USE OR PERFORMANCE
 * OF THESE LICENSED DELIVERABLES.
 *
 * U.S. Government End Users. These Licensed Deliverables are a
 * "commercial item" as that term is defined at 48 C.F.R. 2.101 (OCT
 * 1995), consisting of "commercial computer software" and "commercial
 * computer software documentation" as such terms are used in 48
 * C.F.R. 12.212 (SEPT 1995) and is provided to the U.S. Government
 * only as a commercial end item. Consistent with 48 C.F.R.12.212 and
 * 48 C.F.R. 227.7202-1 through 227.7202-4 (JUNE 1995), all
 * U.S. Government End Users acquire the Licensed Deliverables with
 * only those rights set forth herein.
 *
 * Any use of the Licensed Deliverables in individual and commercial
 * software must include, in the user documentation and internal
 * comments to the code, the above Disclaimer and U.S. Government End
 * Users Notice.
 */

/**
 * @file Types.h
 *
 * Defines all types needed for programming with VPI.
 */

#ifndef NV_VPI_TYPES_H
#define NV_VPI_TYPES_H

// #include "ImageFormat.h"
// #include "Interpolation.h"
// #include "PixelType.h"
// #include "Status.h"
// #include "Version.h"

#include <stdint.h>

#ifdef __cplusplus
extern "C" {
#endif

/**
 * Defines common types used by several components.
 *
 * @defgroup VPI_Types Common Types
 * @ingroup VPI_API_Misc
 */

/** @name Memory creation flags.
 * These flags can be used when creating images, pyramids or arrays.
 *
 * @ingroup VPI_Types
 * @{
 */

/** VPI Backend types.
 *
 * @ingroup VPI_Stream
 *
 */
typedef enum
{
    VPI_BACKEND_CPU     = (1ULL << 0), /**< CPU backend. */
    VPI_BACKEND_CUDA    = (1ULL << 1), /**< CUDA backend. */
    VPI_BACKEND_PVA     = (1ULL << 2), /**< PVA backend. */
    VPI_BACKEND_VIC     = (1ULL << 3), /**< VIC backend. */
    VPI_BACKEND_NVENC   = (1ULL << 4), /**< NVENC backend. */
    VPI_BACKEND_OFA     = (1ULL << 5), /**< OFA backend. */
    VPI_BACKEND_INVALID = (1ULL << 15) /**< Invalid backend. */
} VPIBackend;

/** Tegra-only backends. */
#define VPI_BACKEND_TEGRA (VPI_BACKEND_VIC | VPI_BACKEND_NVENC | VPI_BACKEND_OFA)

#define VPI_BACKEND_MASK ((VPI_BACKEND_INVALID << 1) - 1)

/** All backends. */
#define VPI_BACKEND_ALL \
    (VPI_BACKEND_CPU | VPI_BACKEND_CUDA | VPI_BACKEND_PVA | VPI_BACKEND_VIC | VPI_BACKEND_NVENC | VPI_BACKEND_OFA)

/** @} */

/** @anchor common_flags @name Common object flags.
 *
 * These flags can be passed to the creation function of the following objects:
 * - \ref VPIImage
 * - \ref VPIPyramid
 * - \ref VPIArray
 * - \ref VPIContext
 * - \ref VPIStream
 * - \ref VPIEvent
 *
 * They might change some of the characteristics of the created object to conform
 * to some expected behavior.
 */
/**@{*/

/**
 * Specifies that the memory will be accessed by only one stream at a time.
 *
 * By default memories are created up so that at multiple streams can access it
 * for reading simultaneously. Doing so might incur in increased system
 * resources utilization. By specifying this flag when creating a VPIImage,
 * VPIArray or VPIPyramid, when it's known that they won't be used concurrently
 * by different streams, better resource allocation is achieved.
 */
#define VPI_EXCLUSIVE_STREAM_ACCESS (1ULL << 16)

/** 
 * Flag to restrict memory resources usage.
 *
 * When passed as flags to certain VPI functions, it will instruct them to use
 * less memory resources, in exchange of limiting their functionality.  Please
 * refer to documentation of these functions for further explanation on the
 * trade-offs involved.
 */
#define VPI_RESTRICT_MEM_USAGE (1ULL << 17)

/** 
 * Require creation of requested backends.
 *
 * With this flag set, the creation functions will require that the given
 * backends are created. If any fail, the creation function will return an
 * error.
 * If not set, it'll try to enable the given backends, but disable the ones that are
 * incompatible with the object parameters or not enabled in current context.
 * @note When applied to a context, this flag isn't propagated to objects created
 *       when this context is active.
 */
#define VPI_REQUIRE_BACKENDS (1ULL << 18)

/**@}*/

/**
 * Parallel task function pointer type.
 * @ingroup VPI_Context
 */
typedef void (*VPIParallelTask)(int taskId, int threadId, void *vpiData);

/**
 * Parallel for callback function pointer type. A serial (reference) implementation of this
 * function might looks as follows:
 *
 * @code
 * void parallel_for(VPIParallelTask task, int taskCount, void *vpiData, void *userData)
 * {
 *    for (int i = 0; i < taskCount; ++i)
 *    {
 *      task(i, 0, vpiData);
 *    }
 * }
 * @endcode
 *
 * Parallel implementation should have equivalent behavior; that is, run all tasks
 * between 0 and taskCount-1 and block the calling thread until all tasks have been
 * completed. `threadId` parameter should be between 0 and maxThreads-1 (\see vpiContextSetParallelFor).
 * Implementations that have `maxThreads` set to zero can pass an arbitrary `threadId` value to
 * task functions.
 *
 * @ingroup VPI_Context
 */
typedef void (*VPIParallelForCallback)(VPIParallelTask task, int taskCount, void *vpiData, void *userData);

/**
 * Stores the ParallelFor configuration.
 *
 * @ingroup VPI_Context
 */
typedef struct
{
    /**
     * The maximum number of threads used by the parallel_for implementation code. Has to be larger than 0.
     * Setting the number to N means that the parallel for implementation will call task functors with task id
     * between 0 and N-1. Calling task functors with thread id outside of this range is not legal and will result
     * in undefined behavior.
     */
    int maxThreads;

    /**
     * A pointer to the parallel_for implementation. If null is passed, the context will fallback to the default
     * internal parallel_for implementation. parallel_for implementation is required to be thread-safe.
     * Internal API implementation might call this function from different threads at the same time.
     */
    VPIParallelForCallback callback;

    /**
     * A user defined opaque pointer passed to callback function unaltered.
     */
    void *userData;
} VPIParallelForConfig;

/**
 * A handle to OS-specific thread handle.
 *
 * @ingroup VPI_Context
 */
typedef void *VPINativeThreadHandle;

/**
 * A handle to an array.
 * @ingroup VPI_Array
 */
typedef struct VPIArrayImpl *VPIArray;

/**
 * A handle to a context.
 * @ingroup VPI_Context
 */
typedef struct VPIContextImpl *VPIContext;

/**
 * A handle to an event.
 * @ingroup VPI_Event
 */
typedef struct VPIEventImpl *VPIEvent;

/**
 * A handle to a stream.
 * @ingroup VPI_Stream
 */
typedef struct VPIStreamImpl *VPIStream;

/**
 * A handle to an image.
 * @ingroup VPI_Image
 */
typedef struct VPIImageImpl *VPIImage;

/**
 * A handle to an image pyramid.
 * @ingroup VPI_Pyramid
 */
typedef struct VPIPyramidImpl *VPIPyramid;

/**
 * A handle to an algorithm payload.
 * @ingroup VPI_Payload
 */
typedef struct VPIPayloadImpl *VPIPayload;

/**
 * Image border extension specify how pixel values outside of the image domain should be
 * constructed.
 *
 * @ingroup VPI_Types
 */
typedef enum
{
    VPI_BORDER_ZERO = 0, /**< All pixels outside the image are considered to be zero. */
    VPI_BORDER_CLAMP,    /**< Border pixels are repeated indefinitely. */
    VPI_BORDER_REFLECT,  /**< edcba|abcde|edcba */
    VPI_BORDER_MIRROR,   /**< dedcb|abcde|dcbab */
    VPI_BORDER_LIMITED,  /**< Consider image as limited to not access outside pixels. */
    VPI_BORDER_INVALID,  /**< Invalid border. */
} VPIBorderExtension;

/**
 * Policy used when converting between image types.
 * @ingroup VPI_ConvertImageFormat
 */
typedef enum
{
    /** Clamps input to output's type range. Overflows
        and underflows are mapped to the output type's
        maximum and minimum representable value,
        respectively. When output type is floating point,
        clamp behaves like cast. */
    VPI_CONVERSION_CLAMP = 0,

    /** Casts input to the output type. Overflows and
        underflows are handled as per C specification,
        including situations of undefined behavior. */
    VPI_CONVERSION_CAST,

    /** Invalid conversion. */
    VPI_CONVERSION_INVALID = 255,
} VPIConversionPolicy;

/**
 * Stores a float32 keypoint coordinate
 * The coordinate is relative to the top-left corner of an image.
 *
 * @ingroup VPI_Types
 */
typedef struct
{
    float x; /**< Keypoint's x coordinate. */
    float y; /**< Keypoint's y coordinate. */
} VPIKeypointF32;

#if NV_VPI_VERSION_API_AT_MOST(2, 0)
typedef VPIKeypointF32 VPIKeypoint; /**< Alias to \ref VPIKeypointF32. */
#endif

/**
 * Stores a U32 keypoint coordinate
 * The coordinate is relative to the top-left corner of an image.
 *
 * @ingroup VPI_Types
 */
typedef struct
{
    uint32_t x; /**< Keypoint's x coordinate. */
    uint32_t y; /**< Keypoint's y coordinate. */
} VPIKeypointU32;

/**
 * Defines different types of corner scores
 */
typedef enum
{
    VPI_CORNER_SCORE_HARRIS = 0, /**< Use Harris response corner scores. */
    VPI_CORNER_SCORE_FAST   = 1  /**< Use FAST corner scores. */
} VPICornerScore;

/**
 * Length of Brief Descriptor Array
 */
#define VPI_BRIEF_DESCRIPTOR_ARRAY_LENGTH 32

/**
 * Length of Brief Descriptor in bits
 */
#define VPI_BRIEF_DESCRIPTOR_BIT_WIDTH (VPI_BRIEF_DESCRIPTOR_ARRAY_LENGTH * 8)

/**
 * Stores a BRIEF Descriptor 
 */
typedef struct
{
    uint8_t data[VPI_BRIEF_DESCRIPTOR_ARRAY_LENGTH];
} VPIBriefDescriptor;

/**
 * Stores a generic 2D homography transform.
 * When only scale and translation transformation is needed,
 * these parameters must be arranged in the matrix as follows:
 *
 * \f[ \begin{bmatrix}
 *     s_x &   0 & p_x \\
 *       0 & s_y & p_y \\
 *       0 &   0 &   1
 *   \end{bmatrix}
 * \f]
 *
 * Scaling \f$(s_x,s_y)\f$ is relative to the center of the patch,
 * position \f$(p_x,p_y)\f$ is relative to the top-left of the image.
 *
 * In the general case, given an homogeneous 2D point \f$P(x,y,1)\f$
 * and the matrix \f$M^{3x3}\f$, the Euclidean 2D point \f$O(x,y)\f$ is defined as
 * \f{align}{
 *  T &= M \cdot P \\
 *  O &= (T_x/T_z, T_y/T_z)
 * \f}
 *
 * @ingroup VPI_Types
 */
typedef struct
{
    float mat3[3][3]; /**< 3x3 homogeneous matrix that defines the homography. */
} VPIHomographyTransform2D;

/**
 * Stores a generic 2D bounding box.
 * Although this structure can store a 2D bounding box transformed
 * by any homography, most of the time it stores an axis-aligned bounding box.
 * To retrieve it, do the following:
 *
 * @code
 *   float x = xform.mat3[0][2];
 *   float y = xform.mat3[1][2];
 *   float w = width  * xform.mat3[0][0];
 *   float h = height * xform.mat3[1][1];
 * @endcode
 *
 * @ingroup VPI_Types
 */
typedef struct
{
    VPIHomographyTransform2D xform; /**< Defines the bounding box top left corner and its homography. */
    float width,                    /**< Bounding box width. */
        height;                     /**< Bounding box height. */
} VPIBoundingBox;

/**
 * Stores a bounding box that is being tracked by \ref algo_klt_tracker "KLT Tracker".
 * @ingroup VPI_KLTFeatureTracker
 */
typedef struct
{
    /** Bounding box being tracked. */
    VPIBoundingBox bbox;

    /** Tracking status of this bounding box.
     * Accepted values:
     * - `1` tracking information is invalid and shouldn't be relied upon.
     * - `0` tracking information is valid.
     */
    int8_t trackingStatus;

    /** Status of the template related to this bounding box.
     * Accepted values:
     * - `1` template needs updating.
     * - `0` existing template still can be used for tracking, it doesn't need to be updated.
     */
    int8_t templateStatus;

    /*! @{ */
    /** Reserved for future use. */
    uint8_t reserved1, reserved2;
    /*! @} */
} VPIKLTTrackedBoundingBox;

/**
 * Stores the statistics of an image.
 * @ingroup VPI_Types
 */

typedef struct
{
    /** Per channel mean */
    float mean[4];

    /** Per-channel covariance matrix, the square root of the diagonal is the standard deviation.*/
    float covariance[4][4];

    /** Total pixel count*/
    int32_t pixelCount;

    /** Per channel sum*/
    float sum[4];

} VPIStats;

/**
 * Maximum number of matches per descriptor
 */
#define VPI_MAX_MATCHES_PER_DESCRIPTOR (3)

/**
 * Stores the matches between 2 descriptors.
 * @ingroup VPI_Types
 */

typedef struct
{
    /** Match reference index */
    int refIndex[VPI_MAX_MATCHES_PER_DESCRIPTOR];

    /** Distance between query and reference descriptor */
    float distance[VPI_MAX_MATCHES_PER_DESCRIPTOR];

} VPIMatches;

/**
 * Stores the geometric information of a rectangle.
 * @ingroup VPI_Types
 */
typedef struct VPIRectangleIRec
{
    int32_t x, y;          /*< Rectangle origin position (x, y). */
    int32_t width, height; /*< Rectangle size dimensions (width, height). */
} VPIRectangleI;

/**
 * Defines the quality of the optical flow algorithm
 * @ingroup VPI_Types
 */
typedef enum
{
    /** Fast but low quality optical flow implementation. */
    VPI_OPTICAL_FLOW_QUALITY_LOW,

    /** Speed and quality in between of \ref VPI_OPTICAL_FLOW_QUALITY_LOW and \ref VPI_OPTICAL_FLOW_QUALITY_HIGH. */
    VPI_OPTICAL_FLOW_QUALITY_MEDIUM,

    /** Slow but high quality optical flow implementation. */
    VPI_OPTICAL_FLOW_QUALITY_HIGH
} VPIOpticalFlowQuality;

/**
 * Defines the lock modes used by memory lock functions.
 * @ingroup VPI_Types
 */
typedef enum
{
    /** Lock memory only for reading.
     * Writing to the memory when locking for reading leads to undefined behavior. */
    VPI_LOCK_READ = 1,

    /** Lock memory only for writing.
     * Reading to the memory when locking for reading leads to undefined behavior.
     * It is expected that the whole memory is written to. If there are regions not
     * written, it might not be updated correctly during unlock. In this case, it's
     * better to use VPI_LOCK_READ_WRITE.
     *
     * It might be slightly efficient to lock only for writing, specially when
     * performing non-shared memory mapping.
     */
    VPI_LOCK_WRITE = 2,

    /** Lock memory for reading and writing. */
    VPI_LOCK_READ_WRITE = 3
} VPILockMode;

/**
 * Defines the termination criteria macros.
 * @ingroup VPI_Types
 */
#define VPI_TERMINATION_CRITERIA_ITERATIONS (1u << 0) /**< Termination based on maximum number of iterations. */
#define VPI_TERMINATION_CRITERIA_EPSILON (1u << 1)    /**< Termination based on maximum error (epsilon). */

/** Camera intrinsic matrix.
 * \f{bmatrix}{
 *    f_x & s & c_x \\
 *    0 & f_y & c_y
 * \f}
 *
 * Where:
 * - \f$f_x, f_y\f$: focal length in pixels.
 * - \f$s\f$: skew, used to model slanted pixels.
 * - \f$c_x, c_y\f$: principal point.
 *
 * @ingroup VPI_LDC
 *
 */
typedef float VPICameraIntrinsic[2][3];

/** Camera extrinsic matrix.
 * \f{bmatrix}{
 *   R_{3\times3} & T_{3\times1}
 * \f}
 *
 * Where:
 * \f$R_{3\times3}\f$: Rotation matrix.
 * \f$T_{3\times1}\f$: 3D position of the origin of world coordinate system expressed in coordinates of camera-centered system.
 *
 * @ingroup VPI_LDC
 */
typedef float VPICameraExtrinsic[3][4];

/** Represents a 2D perspective transform.
 * \verbatim
   [vx]   [a11 a12 tx] [ux]
   [vy] = [a21 a22 ty] [uy]
   [vw]   [ p0  p1  p] [ 1]
   u'x  = vx/vw
   u'y  = vy/vw
   \endverbatim
 *
 * In these equations,
 * - ux, uy are the inhomogeneous coordinates in the source image.
 * - u'x, u'y are the inhomogeneous coordinates in the destination image.
 * - vx,vy,vw are the homogeneous coordinates in the destination image.
 * - a11,a12,a21,a22 are the2x2 non-singular matrix with the linear component of the transform.
 * - tx,ty is the translation component of the transform.
 * - p0,p1,p are the projective components of the transform. p is usually 1.
 *
 * @ingroup VPI_PerspectiveWarp
 */
typedef float VPIPerspectiveTransform[3][3];

/**
 * Defines the states of the event.
 * @ingroup VPI_Types
 */
typedef enum
{
    /** Event is not signaled yet. */
    VPI_EVENT_STATE_NOT_SIGNALED,

    /** Event has been signaled. */
    VPI_EVENT_STATE_SIGNALED

} VPIEventState;

/** Defines image flip directions.
 * This is used by algorithms such as \ref algo_image_flip
 */
typedef enum
{
    /** Flip horizontally. */
    VPI_FLIP_HORIZ = 1U << 0,

    /** Flip vertically. */
    VPI_FLIP_VERT = 1U << 1,

    /** Flip horizontally and vertically.
     *  This effectively rotates the image 180 degrees.
     */
    VPI_FLIP_BOTH = VPI_FLIP_HORIZ | VPI_FLIP_VERT

} VPIFlipMode;

/** Defines the magnitude of vectors.
 * This is used by algorithms such as \ref algo_canny_edge_detector
 */
typedef enum
{
    /** L1 norm. */
    VPI_NORM_L1,

    /** L2 norm. */
    VPI_NORM_L2,

    /** Hamming norm. */
    VPI_NORM_HAMMING

} VPINormType;

/**
 * Different method to generate gradients.
 */
typedef enum
{
    /** Generate the gradient in x direction and y direction via sobel operator */
    VPI_GRADIENT_SOBEL,

    /** Generate the gradient by using prewitt operator on blurred input image */
    VPI_GRADIENT_BLUR_PREWITT
} VPIGradientMethod;

/** Defines which statistics to be calculated.
 */

/** Calculate pixel count */
#define VPI_STAT_PIXEL_COUNT (1U << 0)

/** Calculate per-channel sum */
#define VPI_STAT_SUM (1U << 1)

/** Calculate per-channel mean */
#define VPI_STAT_MEAN ((1U << 2) | VPI_STAT_SUM | VPI_STAT_PIXEL_COUNT)

/** Calculate covariance matrix with variance of each channel */
#define VPI_STAT_VARIANCE ((1U << 3) | VPI_STAT_MEAN)

/** Calculate full covariance matrix */
#define VPI_STAT_COVARIANCE ((1U << 4) | VPI_STAT_VARIANCE)

#ifdef __cplusplus
}
#endif

#endif /* NV_VPI_TYPES_H */
// End content from: Types.h

// Begin content from: WarpGrid.h
/*
 * Copyright 2020 NVIDIA Corporation. All rights reserved.
 *
 * NOTICE TO LICENSEE:
 *
 * This source code and/or documentation ("Licensed Deliverables") are
 * subject to NVIDIA intellectual property rights under U.S. and
 * international Copyright laws.
 *
 * These Licensed Deliverables contained herein is PROPRIETARY and
 * CONFIDENTIAL to NVIDIA and is being provided under the terms and
 * conditions of a form of NVIDIA software license agreement by and
 * between NVIDIA and Licensee ("License Agreement") or electronically
 * accepted by Licensee. Notwithstanding any terms or conditions to
 * the contrary in the License Agreement, reproduction or disclosure
 * of the Licensed Deliverables to any third party without the express
 * written consent of NVIDIA is prohibited.
 *
 * NOTWITHSTANDING ANY TERMS OR CONDITIONS TO THE CONTRARY IN THE
 * LICENSE AGREEMENT, NVIDIA MAKES NO REPRESENTATION ABOUT THE
 * SUITABILITY OF THESE LICENSED DELIVERABLES FOR ANY PURPOSE. IT IS
 * PROVIDED "AS IS" WITHOUT EXPRESS OR IMPLIED WARRANTY OF ANY KIND.
 * NVIDIA DISCLAIMS ALL WARRANTIES WITH REGARD TO THESE LICENSED
 * DELIVERABLES, INCLUDING ALL IMPLIED WARRANTIES OF MERCHANTABILITY,
 * NONINFRINGEMENT, AND FITNESS FOR A PARTICULAR PURPOSE.
 * NOTWITHSTANDING ANY TERMS OR CONDITIONS TO THE CONTRARY IN THE
 * LICENSE AGREEMENT, IN NO EVENT SHALL NVIDIA BE LIABLE FOR ANY
 * SPECIAL, INDIRECT, INCIDENTAL, OR CONSEQUENTIAL DAMAGES, OR ANY
 * DAMAGES WHATSOEVER RESULTING FROM LOSS OF USE, DATA OR PROFITS,
 * WHETHER IN AN ACTION OF CONTRACT, NEGLIGENCE OR OTHER TORTIOUS
 * ACTION, ARISING OUT OF OR IN CONNECTION WITH THE USE OR PERFORMANCE
 * OF THESE LICENSED DELIVERABLES.
 *
 * U.S. Government End Users. These Licensed Deliverables are a
 * "commercial item" as that term is defined at 48 C.F.R. 2.101 (OCT
 * 1995), consisting of "commercial computer software" and "commercial
 * computer software documentation" as such terms are used in 48
 * C.F.R. 12.212 (SEPT 1995) and is provided to the U.S. Government
 * only as a commercial end item. Consistent with 48 C.F.R.12.212 and
 * 48 C.F.R. 227.7202-1 through 227.7202-4 (JUNE 1995), all
 * U.S. Government End Users acquire the Licensed Deliverables with
 * only those rights set forth herein.
 *
 * Any use of the Licensed Deliverables in individual and commercial
 * software must include, in the user documentation and internal
 * comments to the code, the above Disclaimer and U.S. Government End
 * Users Notice.
 */

/**
 * @file WarpGrid.h
 *
 * Declares structures and constants used for warp grid definition.
 */

#ifndef NV_VPI_WARPGRID_H
#define NV_VPI_WARPGRID_H

#include <stdint.h>

#ifdef __cplusplus
extern "C" {
#endif

/**
 * @ingroup VPI_WarpMap
 * @{
 * */

#define VPI_WARPGRID_MAX_HORIZ_REGIONS_COUNT 4 /**< Maximum number of regions horizontally in a warp grid. */
#define VPI_WARPGRID_MAX_VERT_REGIONS_COUNT 4  /**< Maximum number of regions vertically in a warp grid. */
#define VPI_WARPGRID_MIN_REGION_WIDTH 64       /**< Minimum warp grid region width. */
#define VPI_WARPGRID_MIN_REGION_HEIGHT 16      /**< Minimum warp grid region height. */

/**
 * Holds VPI's warp grid definition.
 *
 * @ingroup VPI_WarpMap
 * This structure defines the layout of the control points in the destination
 * image of a remap operation.
 *
 * The control points are used as the basis for geometric transformation from
 * source image to destination image. The remaining points are transformed
 * based on the interpolation. Thus the density of the control points controls
 * the quality of the geometric transformation.
 *
 * This is an example of defining regions in the image:
 * \code
 *               warp grid width
 *         /                         \
 *        /                           \
 *       /                             \
 *
 *    regionWidth[0]    regionWidth[numHorizRegions-1]
 *       /    \                  /    \
 *      |------|                |------|
 *      --------------------------------                                 \
 *      |******* *******        *******|--                                \
 *      |* . . * *     *        *     *|  \                                \
 *      |* . . * *     *  ...   *     *|   regionHeight[0]                  \
 *      |* . . * *     *        *     *|  /                                  \
 *      |******* *******        *******|--                                    \
 *      |                              |                                       \
 *      |   .       .              .   |                                  
 *      |   .       .              .   |                                         warp grid height
 *      |   .       .              .   |
 *      |                              |                                       /
 *      |******* *******        *******|--                                    /
 *      |*     * *     *        *     *|  \                                  /
 *      |*     * *     *  ...   *     *|   regionHeight[numVertRegions-1]   /
 *      |*     * *     *        *     *|  /                                /
 *      |******* *******        *******|--                                /  
 *      --------------------------------                                 /
 *
 * \endcode
 *
 * This is an example of defining control points in one region:
 * \code
 *      *********
 *      *  +  + *-- \
 *      *       *    vertInterval
 *      *  +  + *-- /
 *      *       *
 *      *********
 *         |--|
 *     horizInterval
 *
 * \endcode
 *
 * Here's an example of a WxH dense grid definition:
 * \code
 * VPIWarpGrid grid;
 * grid.numHorizRegions  = 1;
 * grid.numVertRegions   = 1;
 * grid.horizInterval[0] = 1;
 * grid.vertInterval[0]  = 1;
 * grid.regionWidth[0]   = W;
 * grid.regionHeight[0]  = H;
 * \endcode
 *
 * ### Restrictions
 *
 * * numHorizRegions cannot exceed \ref VPI_WARPGRID_MAX_HORIZ_REGIONS_COUNT.
 * * numVertRegions cannot exceed \ref VPI_WARPGRID_MAX_VERT_REGIONS_COUNT.
 * * Intervals must be power-of-two.
 * * Alignment restrictions:
 *   + `regionWidth[0]` to `regionWidth[numHorizRegions-2]` must be
 *     aligned to \ref VPI_WARPGRID_MIN_REGION_WIDTH and at least \ref VPI_WARPGRID_MIN_REGION_WIDTH.
 *   + `regionWidth[numHorizRegions-1]` must be at least \ref VPI_WARPGRID_MIN_REGION_WIDTH.
 *   + `regionHeight[0]` to `regionHeight[numVertRegions-2]` must be
 *     aligned to \ref VPI_WARPGRID_MIN_REGION_HEIGHT and at least \ref VPI_WARPGRID_MIN_REGION_HEIGHT.
 *   + `regionHeight[numVertRegions-1]` must be at least \ref VPI_WARPGRID_MIN_REGION_HEIGHT.
 *
 */

typedef struct
{
    /** Number of regions horizontally. */
    int8_t numHorizRegions;

    /** Number of regions vertically. */
    int8_t numVertRegions;

    /** Width of each region. */
    int16_t regionWidth[VPI_WARPGRID_MAX_HORIZ_REGIONS_COUNT];

    /** Height of each region. */
    int16_t regionHeight[VPI_WARPGRID_MAX_VERT_REGIONS_COUNT];

    /** Horizontal spacing between control points within a given region.
     *  + Must be power-of-two.
     *  + Must be >= 1.
     *  + On PVA, maximum is 128. */
    int16_t horizInterval[VPI_WARPGRID_MAX_HORIZ_REGIONS_COUNT];

    /** Vertical spacing between control points within a given region.
     *  + Must be power-of-two.
     *  + Must be >= 1.
     *  + On PVA, maximum is 128. */
    int16_t vertInterval[VPI_WARPGRID_MAX_VERT_REGIONS_COUNT];

} VPIWarpGrid;

/** @} */

#ifdef __cplusplus
}
#endif

#endif /* NV_VPI_WARPGRID_H */
// End content from: WarpGrid.h

// Begin content from: Image.h
/*
 * Copyright 2019-2021 NVIDIA Corporation. All rights reserved.
 *
 * NOTICE TO LICENSEE:
 *
 * This source code and/or documentation ("Licensed Deliverables") are
 * subject to NVIDIA intellectual property rights under U.S. and
 * international Copyright laws.
 *
 * These Licensed Deliverables contained herein is PROPRIETARY and
 * CONFIDENTIAL to NVIDIA and is being provided under the terms and
 * conditions of a form of NVIDIA software license agreement by and
 * between NVIDIA and Licensee ("License Agreement") or electronically
 * accepted by Licensee. Notwithstanding any terms or conditions to
 * the contrary in the License Agreement, reproduction or disclosure
 * of the Licensed Deliverables to any third party without the express
 * written consent of NVIDIA is prohibited.
 *
 * NOTWITHSTANDING ANY TERMS OR CONDITIONS TO THE CONTRARY IN THE
 * LICENSE AGREEMENT, NVIDIA MAKES NO REPRESENTATION ABOUT THE
 * SUITABILITY OF THESE LICENSED DELIVERABLES FOR ANY PURPOSE. IT IS
 * PROVIDED "AS IS" WITHOUT EXPRESS OR IMPLIED WARRANTY OF ANY KIND.
 * NVIDIA DISCLAIMS ALL WARRANTIES WITH REGARD TO THESE LICENSED
 * DELIVERABLES, INCLUDING ALL IMPLIED WARRANTIES OF MERCHANTABILITY,
 * NONINFRINGEMENT, AND FITNESS FOR A PARTICULAR PURPOSE.
 * NOTWITHSTANDING ANY TERMS OR CONDITIONS TO THE CONTRARY IN THE
 * LICENSE AGREEMENT, IN NO EVENT SHALL NVIDIA BE LIABLE FOR ANY
 * SPECIAL, INDIRECT, INCIDENTAL, OR CONSEQUENTIAL DAMAGES, OR ANY
 * DAMAGES WHATSOEVER RESULTING FROM LOSS OF USE, DATA OR PROFITS,
 * WHETHER IN AN ACTION OF CONTRACT, NEGLIGENCE OR OTHER TORTIOUS
 * ACTION, ARISING OUT OF OR IN CONNECTION WITH THE USE OR PERFORMANCE
 * OF THESE LICENSED DELIVERABLES.
 *
 * U.S. Government End Users. These Licensed Deliverables are a
 * "commercial item" as that term is defined at 48 C.F.R. 2.101 (OCT
 * 1995), consisting of "commercial computer software" and "commercial
 * computer software documentation" as such terms are used in 48
 * C.F.R. 12.212 (SEPT 1995) and is provided to the U.S. Government
 * only as a commercial end item. Consistent with 48 C.F.R.12.212 and
 * 48 C.F.R. 227.7202-1 through 227.7202-4 (JUNE 1995), all
 * U.S. Government End Users acquire the Licensed Deliverables with
 * only those rights set forth herein.
 *
 * Any use of the Licensed Deliverables in individual and commercial
 * software must include, in the user documentation and internal
 * comments to the code, the above Disclaimer and U.S. Government End
 * Users Notice.
 */

/**
 * @file Image.h
 *
 * Functions and structures for dealing with VPI images.
 */

#ifndef NV_VPI_IMAGE_H
#define NV_VPI_IMAGE_H

// #include "Export.h"
// #include "ImageFormat.h"
// #include "PixelType.h"
// #include "Status.h"
// #include "Types.h"

#include <stdint.h>

/**
 * An abstract representation of a 2D image.
 *
 * There are two ways of creating 2D image containers with the API. The most
 * basic one is to use \ref vpiImageCreate to allocate and initialize an empty
 * (zeroed) \ref VPIImage object. The memory for the image data is allocated
 * and managed by VPI. Parameters such as width, height and pixel type are
 * immutable and specified at the construction time. The internal memory layout
 * is also backend-specific. More importantly, efficient exchange of image data
 * between different hardware backends might force the implementation to
 * allocate the memory in multiple memory pools (e.g. dGPU and system DRAM). In
 * some scenarios (to optimize performance and memory use), it might be
 * beneficial to constrain the internal allocation policy to support only a
 * particular set of backends. 
 *
 * To enable interop with existing memory buffers, the user can also
 * create an image object that wraps a user-allocated (and managed) image
 * data using \ref vpiImageCreateWrapper. Similarly to \ref vpiImageCreate,
 * image parameters passed to it are fixed. 
 *
 * The wrapped memory can be redefined by calling \ref vpiImageSetWrapper
 * corresponding to the image wrapper creation function used, as long as the
 * new wrapped memory has the same capacity and type as the one originally
 * wrapped. It's more efficient to create the VPIImage wrapper once and reuse
 * it later then creating and destroying it all the time.
 *
 * The set of \ref vpiImageLockData / \ref vpiImageUnlock allows the user to read
 * from/write to the image data from the host. These functions are non-blocking
 * and oblivious to the stream command queue, so it's up to the user to make
 * sure that all pending operations using this image as input or output are
 * finished. Also, depending on which device the memory is allocated,
 * lock/unlock operation might be time-consuming and, for example, involve
 * copying data over PCIe bus for dGPUs.
 *
 * @defgroup VPI_Image Image
 * @ingroup VPI_API_Core
 * @{
 */

#ifdef __cplusplus
extern "C" {
#endif

/** Represents one image plane in pitch-linear layout. */
typedef struct VPIImagePlanePitchLinearRec
{
    /** Type of each pixel within this plane.
     *  If it is \ref VPI_PIXEL_TYPE_INVALID, it will be inferred from \ref VPIImageBufferPitchLinear::format. */
    VPIPixelType pixelType;

    /** Width of this plane in pixels.
     *  + It must be >= 1. */
    int32_t width;

    /** Height of this plane in pixels.
     *  + It must be >= 1. */
    int32_t height;

    /** Difference in bytes of beginning of one row and the beginning of the previous.
         This is used to address every row (and ultimately every pixel) in the plane.
         @code
            T *pix_addr = (T *)((uint8_t *)data + pitchBytes*height)+width;
         @endcode
         where T is the C type related to pixelType.

         + It must be at least `(width * \ref vpiPixelTypeGetBitsPerPixel(pixelType) + 7)/8`.
    */
    int32_t pitchBytes;

    /** Pointer to the first row of this plane.
         This points to the actual data represented by this plane.
         Depending on how the plane is used, the pointer might be
         addressing a GPU memory or host memory. Care is needed to
         know when it is allowed to dereference this memory. */
    void *data;

} VPIImagePlanePitchLinear;

/** Maximum number of data planes an image can have. */
#define VPI_MAX_PLANE_COUNT (6)

/** Stores the image plane contents. */
typedef struct VPIImageBufferPitchLinearRec
{
    /** Image format. */
    VPIImageFormat format;

    /** Number of planes.
     *  + Must be >= 1. */
    int32_t numPlanes;

    /** Data of all image planes in pitch-linear layout.
     *  + Only the first \ref numPlanes elements must have valid data. */
    VPIImagePlanePitchLinear planes[VPI_MAX_PLANE_COUNT];

} VPIImageBufferPitchLinear;

/** Represents how the image data is stored. */
typedef enum
{
    /** Invalid buffer type.
     *  This is commonly used to inform that no buffer type was selected. */
    VPI_IMAGE_BUFFER_INVALID,

    /** Host-accessible with planes in pitch-linear memory layout. */
    VPI_IMAGE_BUFFER_HOST_PITCH_LINEAR,

    /** CUDA-accessible with planes in pitch-linear memory layout. */
    VPI_IMAGE_BUFFER_CUDA_PITCH_LINEAR,

    /** Buffer stored in a cudaArray_t.
     * Please consult <a href="https://docs.nvidia.com/cuda/cuda-c-programming-guide/index.html#cuda-arrays">cudaArray_t</a>
     * for more information. */
    VPI_IMAGE_BUFFER_CUDA_ARRAY,

    /** EGLImage.
     * Please consult <a href="https://www.khronos.org/registry/EGL/extensions/KHR/EGL_KHR_image_base.txt">EGLImageKHR</a>
     * for more information. */
    VPI_IMAGE_BUFFER_EGLIMAGE,

    /** NvBuffer.
     * Please consult <a href="https://docs.nvidia.com/metropolis/deepstream/sdk-api/group__ds__nvbuf__api.html">NvBuffer</a>
     * for more information.
     * @note Interop with NvBuffer objects created with older
     *       <a href="https://docs.nvidia.com/jetson/l4t-multimedia/nvbuf__utils_8h.html">nvbuf_utils</a> isn't supported anymore.
     */

    VPI_IMAGE_BUFFER_NVBUFFER,

} VPIImageBufferType;

typedef void *EGLImageKHR;
typedef struct cudaArray *cudaArray_t;

/** Represents the available methods to access image contents.
 * The correct method depends on \ref VPIImageData::bufferType. */
typedef union VPIImageBufferRec
{
    /** Image stored in pitch-linear layout.
     * To be used when \ref VPIImageData::bufferType is:
     * - \ref VPI_IMAGE_BUFFER_HOST_PITCH_LINEAR
     * - \ref VPI_IMAGE_BUFFER_CUDA_PITCH_LINEAR
     */
    VPIImageBufferPitchLinear pitch;

    /** Image stored in a `cudaArray_t`.
     * To be used when \ref VPIImageData::bufferType is:
     * - \ref VPI_IMAGE_BUFFER_CUDA_ARRAY
     */
    cudaArray_t cudaarray;

    /** Image stored as an EGLImageKHR.
     * To be used when \ref VPIImageData::bufferType is:
     * - \ref VPI_IMAGE_BUFFER_EGLIMAGE
     */
    EGLImageKHR egl;

    /** Image stored as an NvBuffer file descriptor.
     * To be used when \ref VPIImageData::bufferType is:
     * - \ref VPI_IMAGE_BUFFER_NVBUFFER
     */
    int fd;

} VPIImageBuffer;

/** Stores information about image characteristics and content. */
typedef struct VPIImageDataRec
{
    /** Type of image buffer.
     *  It defines which member of the \ref VPIImageBuffer tagged union that
     *  must be used to access the image contents. */
    VPIImageBufferType bufferType;

    /** Stores the image contents. */
    VPIImageBuffer buffer;

} VPIImageData;

/**
 * Create an empty image instance with the specified flags. Image data is zeroed.
 *
 * The following flags affect the behavior of the allocated image
 *
 * @param[in] width,height Dimensions of the created image.
 *                         + Width and height must be > 0.
 * 
 * @param[in] fmt Format of the created image.
 *                + Must be a valid format.
 * 
 * @param[in] flags Bit field specifying the desired characteristics of the image.
 *                  + The field must be a combination of zero or more of the following flags:
 *                    - \ref VPIBackend flags.
 *                      This image can be used in algorithms running in these backends.
 *                      If no backend flags are given and \ref VPI_REQUIRE_BACKENDS is not set,
 *                      it'll consider all backends supported by the active \ref VPIContext,
 *                      but disable the backends that are incompatible with the given image parameters.
 *                    - \ref VPI_RESTRICT_MEM_USAGE
 *                      For block-linear formats, this flag will avoid an internal pitch-linear buffer alocation.
 *                      The downside is that \ref vpiImageLockData will fail for these formats.
 *                      Pass this flag if system is under memory restrictions, and no image locking is required.
 *                    - \ref common_flags "Common object flags".
 *                  + If flag \ref VPI_REQUIRE_BACKENDS is given, user must pass at least one valid backend that is 
 *                    enabled in current context *AND* is compatible with the given image parameters.
 * 
 * @param[out] img Pointer to memory that will receive the created image handle.
 *
 * @retval #VPI_ERROR_INVALID_ARGUMENT  Output \p img handle is NULL.
 * @retval #VPI_ERROR_INVALID_ARGUMENT  \p width or \p height outside valid range.
 * @retval #VPI_ERROR_INVALID_ARGUMENT  \p fmt is invalid or not supported.
 * @retval #VPI_ERROR_INVALID_ARGUMENT  \p flags is invalid.
 * @retval #VPI_ERROR_INVALID_ARGUMENT  No backend were given and \ref VPI_REQUIRE_BACKENDS is set.
 * @retval #VPI_ERROR_OUT_OF_MEMORY     Not enough resources to allocate image.
 * @retval #VPI_ERROR_INVALID_CONTEXT   Current context was destroyed.
 * @retval #VPI_ERROR_INVALID_OPERATION Some requested backend isn't enabled in current context.
 * @retval #VPI_ERROR_INVALID_OPERATION Some requested backend can't be created with given image parameters.
 * @retval #VPI_SUCCESS                 Operation executed successfully.
 */
VPI_PUBLIC VPIStatus vpiImageCreate(int32_t width, int32_t height, VPIImageFormat fmt, uint64_t flags, VPIImage *img);

/** Parameters for customizing image wrapping.
 *
 * These parameters are used to customize how image wrapping will be made.
 * Make sure to call \ref vpiInitImageWrapperParams to initialize this
 * structure before updating its attributes. This guarantees that new attributes
 * added in future versions will have a suitable default value assigned.
 */
typedef struct
{
    /** Color spec to override the one defined by the \ref VPIImageData wrapper.
     * If set to \ref VPI_COLOR_SPEC_DEFAULT, infer the color spec from \ref VPIImageData,
     * i.e., no overriding will be done. */
    VPIColorSpec colorSpec;
} VPIImageWrapperParams;

/** Initialize \ref VPIImageWrapperParams with default values.
 *
 * Default values are:
 * - colorSpec: \ref VPI_COLOR_SPEC_DEFAULT, color spec won't be overriden.
 *
 * @param[in] params Structure to be initialized with default values.
 *                   - Mandatory, can't be NULL.
 *
 * @retval #VPI_ERROR_INVALID_ARGUMENT \p params is NULL.
 * @retval #VPI_SUCCESS                Operation executed successfully.
 */
VPI_PUBLIC VPIStatus vpiInitImageWrapperParams(VPIImageWrapperParams *params);

/**
 * Create an image that wraps an axis-aligned rectangular sub-region of an existing image.
 *
 * Create an image instance that is a view of the input image with specific position (x, y), dimensions (width, height) and flags.
 * The resulting image shares the underlying data with the input image, i.e. there is no copy involved in the creation of a view.
 * Similarly to creating image instances that wrap around external buffers, the resulting image view instances do not own the data.
 * It is legal to create a view from another image view instance.
 *
 * @param[in] imgParent Handle to the input parent image.
 *                  + Mandatory, it can't be NULL.
 *                  + On Tegra devices: parent image must be either wrapping CPU or CUDA buffer,
 *                    or have only CPU or CUDA backends enabled.
 *                  + It must not be destroyed while there are image views associated with it.
 *
 * @param[in] clipBounds Rectangle defining the clip bounds of the created image view.
 *                       + The rectangle must be inside input parent image.
 *
 * @param[in] flags Flags with the characteristics of the created image view.
 *                  + They must be combination of zero or more of the following flags:
 *                    - \ref VPIBackend flags.
 *                      This image view will work with streams with these backends enabled.
 *                      The enable backends must have some common backend with the input image flags.
 *                      If no backend flags are passed, it'll consider all backends supported by the active \ref VPIContext.
 *
 * @param[out] imgView Pointer to memory that will receive the created image view handle.
 *                     + Mandatory, it can't be NULL.
 *
 * @retval #VPI_ERROR_INVALID_OPERATION \p imgView cannot be created with the given \p imgParent.
 * @retval #VPI_ERROR_INVALID_OPERATION The backends in \p imgParent and \p flags are not compatible.
 * @retval #VPI_ERROR_INVALID_ARGUMENT  Input parent image \p imgParent is NULL.
 * @retval #VPI_ERROR_INVALID_ARGUMENT  \p imgParent has no backends.
 * @retval #VPI_ERROR_INVALID_ARGUMENT  \p output handle is NULL.
 * @retval #VPI_ERROR_INVALID_ARGUMENT  \p clipBounds is NULL or outside the valid range.
 * @retval #VPI_ERROR_INVALID_ARGUMENT  \p flags are invalid.
 * @retval #VPI_ERROR_NOT_IMPLEMENTED   Image view is not implemented for the given input parent image.
 * @retval #VPI_ERROR_INVALID_CONTEXT   \p imgParent and \p imgView contexts are different.
 * @retval #VPI_ERROR_INVALID_CONTEXT   Current context was destroyed.
 * @retval #VPI_SUCCESS                 Operation executed successfully.
 */
VPI_PUBLIC VPIStatus vpiImageCreateView(VPIImage imgParent, const VPIRectangleI *clipBounds, uint64_t flags,
                                        VPIImage *imgView);

/**
 * Redefines the image view position inside a parent image.
 *
 * This operation is efficient and does not allocate memory. The view memory will be
 * accessible to the same backends specified during view creation.  The parent image
 * may be the original parent of the view or a new parent.
 *
 * @param[in] view Handle to image view.
 *                 + It must have been created by \ref vpiImageCreateView.
 *
 * @param[in] parent Handle to a potentially new input parent image.
 *                   + The parent image format must match the view's.
 *                   + Mandatory, it can't be NULL.
 *                   + On Tegra devices: parent image must be either wrapping CPU or CUDA buffer,
 *                     or have only CPU or CUDA backends enabled.
 *                   + It must not be destroyed while there are image views associated with it.
 *
 * @param[in] clipBounds Rectangle defining the clip bounds of the redefined image view.
 *                       + The rectangle must be inside chosen parent image.
 *                       + The width and height of the rectangle must be the same as the image view.
 *
 * @retval #VPI_ERROR_INVALID_ARGUMENT  Input \p view is NULL.
 * @retval #VPI_ERROR_INVALID_ARGUMENT  Input \p parent is NULL.
 * @retval #VPI_ERROR_INVALID_ARGUMENT  \p clipBounds is NULL.
 * @retval #VPI_ERROR_INVALID_ARGUMENT  \p clipBounds is outside valid range.
 * @retval #VPI_ERROR_INVALID_ARGUMENT  \p clipBounds has different size than image view.
 * @retval #VPI_ERROR_INVALID_ARGUMENT  \p parent image format does not match \p view image format.
 * @retval #VPI_ERROR_INVALID_ARGUMENT  \p parent has no backends.
 * @retval #VPI_ERROR_INVALID_OPERATION \p view is not created using \ref vpiImageCreateView.
 * @retval #VPI_ERROR_INVALID_OPERATION \p view cannot be redefined with the given \p parent.
 * @retval #VPI_SUCCESS                 Operation executed successfully.
 */
VPI_PUBLIC VPIStatus vpiImageSetView(VPIImage view, VPIImage parent, const VPIRectangleI *clipBounds);

/**
 * Create an image object by wrapping an existing memory block.
 *  
 * The underlying image object does not own/claim the memory block.
 *
 * @param[in] data Pointer to structure with memory to be wrapped.
 *                     + Mandatory, it can't be NULL.
 *                     + The following buffer types are supported:
 *                       - \ref VPI_IMAGE_BUFFER_HOST_PITCH_LINEAR
 *                       - \ref VPI_IMAGE_BUFFER_CUDA_PITCH_LINEAR
 *                       - \ref VPI_IMAGE_BUFFER_EGLIMAGE (on Tegra platforms only)
 *                       - \ref VPI_IMAGE_BUFFER_NVBUFFER (on Tegra platforms only)
 *
 * @param[in] params If not NULL, use the parameters to modify how \p data is wrapped.
 *                   Otherwise, it'll use defaults given by \ref vpiInitImageWrapperParams.
 * 
 * @param[in] flags Bit field specifying the desired characteristics of the image.
 *                  Depending on some buffer types, the following flags will be added automatically:
 *                  | Buffer type                             | Added flag             |
 *                  |-----------------------------------------|------------------------|
 *                  | \ref VPI_IMAGE_BUFFER_HOST_PITCH_LINEAR | \ref VPI_BACKEND_CPU   | 
 *                  | \ref VPI_IMAGE_BUFFER_CUDA_PITCH_LINEAR | \ref VPI_BACKEND_CUDA  |
 *
 *                  + The field must be a combination of zero or more of the following flags:
 *                    - \ref VPIBackend flags.
 *                      This image can be used in algorithms running in these backends.
 *                      If no backend flags are given and \ref VPI_REQUIRE_BACKENDS is not set,
 *                      it'll consider all backends supported by the active \ref VPIContext,
 *                      but disable the backends that are incompatible with the given image parameters.
 *                    - \ref VPI_RESTRICT_MEM_USAGE
 *                      For block-linear formats, this flag will avoid an internal pitch-linear buffer alocation.
 *                      The downside is that \ref vpiImageLockData will fail for these formats.
 *                      Pass this flag if system is under memory restrictions, and no image locking is required.
 *                    - \ref common_flags "Common object flags".
 *                  + If backends are given and \ref VPI_REQUIRE_BACKENDS is
 *                    set, they all must enabled in current context.
 *                  + If backends are automatically added, they must be enabled
 *                    in current context.
 * 
 * @param[out] img Pointer to memory that will receive the created image handle.
 *
 * @retval #VPI_ERROR_INVALID_ARGUMENT  \p img is NULL.
 * @retval #VPI_ERROR_INVALID_ARGUMENT  \p data is NULL or contains invalid/unsupported values.
 * @retval #VPI_ERROR_INVALID_ARGUMENT  Buffer type in \p data isn't supported.
 * @retval #VPI_ERROR_INVALID_ARGUMENT  EGLImage handle is NULL or invalid (e.g. EGL_NO_IMAGE).
 * @retval #VPI_ERROR_INVALID_ARGUMENT  NvBuffer file descriptor is invalid.
 * @retval #VPI_ERROR_INVALID_ARGUMENT  No backend were given and \ref VPI_REQUIRE_BACKENDS is set.
 * @retval #VPI_ERROR_OUT_OF_MEMORY     Not enough resources to create image.
 * @retval #VPI_ERROR_INTERNAL          Can't retrieve default EGLDisplay when wrapping EGLImage, or some unspecified internal error.
 * @retval #VPI_ERROR_INVALID_CONTEXT   Current context is destroyed.
 * @retval #VPI_ERROR_INVALID_OPERATION Requested backend isn't enabled in current context.
 * @retval #VPI_ERROR_INVALID_OPERATION A requested backend can't be created with given image parameters.
 * @retval #VPI_SUCCESS                 Operation executed successfully.
 */
VPI_PUBLIC VPIStatus vpiImageCreateWrapper(const VPIImageData *data, const VPIImageWrapperParams *params,
                                           uint64_t flags, VPIImage *img);

/**
 * Redefines the wrapped memory in an existing \ref VPIImage wrapper.
 *
 * This operation is efficient and does not allocate memory. The wrapped memory will be
 * accessible to the same backends specified during wrapper creation.
 *
 * The wrapped memory must not be deallocated while it's still being wrapped.
 * 
 * @param[in] img Handle to image.
 *                + It must have been created by \ref vpiImageCreateWrapper
 *                + Image must not be locked.
 * 
 * @param[in] data Pointer to structure with memory buffer to be wrapped.
 *                     + Mandatory, it can't be NULL.
 *                     + The existing wrapped image and the new one must have same dimensions and format.
 *                     + The old and new buffer types must match.
 *                     + The wrapped memory must point to a buffer that corresponds to the given buffer type.
 *
 * @retval #VPI_ERROR_INVALID_ARGUMENT  \p data is NULL.
 * @retval #VPI_ERROR_INVALID_ARGUMENT  New and old buffer types don't match.
 * @retval #VPI_ERROR_INVALID_ARGUMENT  \p data dimensions and/or format don't match \p img.
 * @retval #VPI_ERROR_INVALID_ARGUMENT  Wrapped EGLImage is invalid (e.g. EGL_NO_IMAGE).
 * @retval #VPI_ERROR_INTERNAL          Cannot retrieve EGLDisplay.
 * @retval #VPI_ERROR_INVALID_OPERATION \p img is not created using \ref vpiImageCreateWrapper.
 * @retval #VPI_ERROR_INVALID_OPERATION \p img is locked.
 * @retval #VPI_ERROR_INVALID_OPERATION EGL/NvBuffer wrapping not supported on this platform.
 * @retval #VPI_SUCCESS                 Operation executed successfully.
 */
VPI_PUBLIC VPIStatus vpiImageSetWrapper(VPIImage img, const VPIImageData *data);

/**
 * Destroy an image instance.
 *
 * This function deallocates all resources allocated by the image creation function.
 * When destroying an VPIImage wrapper, the wrapped memory itself isn't deallocated.
 *
 * @param[in] img \p img to be destroyed. 
 *                Passing NULL is allowed, to which the function simply does nothing.
 *                + Image must not be in use by any stream, or else undefined behavior might ensue.
 */
VPI_PUBLIC void vpiImageDestroy(VPIImage img);

/**
 * Get the image dimensions in pixels.
 *
 * @param[in] img Image to be queried.
 *                + Mandatory, it can't be NULL.
 * 
 * @param[out] width, height Pointers to buffers where the image width and height (respectively) will be written to.
 *
 * @retval #VPI_ERROR_INVALID_ARGUMENT \p img is NULL or doesn't represent a \ref VPIImage instance.
 * @retval #VPI_ERROR_INVALID_ARGUMENT Output \p width or \p height pointers are NULL.
 * @retval #VPI_SUCCESS                Operation executed successfully.
 */
VPI_PUBLIC VPIStatus vpiImageGetSize(VPIImage img, int32_t *width, int32_t *height);

/**
 * Get the image format.
 *
 * @param[in] img Image to be queried.
 *                + Mandatory, it can't be NULL.
 * 
 * @param[out] format A pointer to where the mage format will be written to.
 *                    + Mandatory, it can't be NULL.
 *
 * @retval #VPI_ERROR_INVALID_ARGUMENT \p img is NULL or doesn't represent a \ref VPIImage instance.
 * @retval #VPI_ERROR_INVALID_ARGUMENT \p format pointer is NULL.
 * @retval #VPI_SUCCESS                Operation executed successfully
 */
VPI_PUBLIC VPIStatus vpiImageGetFormat(VPIImage img, VPIImageFormat *format);

/**
 * Get the image flags.
 *
 * @param[in] img Image to be queried.
 *                + Mandatory, it can't be NULL.
 * 
 * @param[out] flags A pointer to where the flags will be written to.
 *                   + Mandatory, it can't be NULL.
 *
 * @retval #VPI_ERROR_INVALID_ARGUMENT \p flags pointer is NULL.
 * @retval #VPI_ERROR_INVALID_ARGUMENT \p img is NULL or doesn't represent a \ref VPIImage instance.
 * @retval #VPI_SUCCESS                Operation executed successfully.
 */
VPI_PUBLIC VPIStatus vpiImageGetFlags(VPIImage img, uint64_t *flags);

/**
 * Acquires the lock on an image object.
 *
 * Image locking is required when the image object wraps externally-accessible buffers,
 * and these buffers will be accessed outside VPI. As long as the lock is held, any
 * attempt of VPI to access the image in a mode not compatible with the lock mode will
 * result in asynchronous stream errors, \ref VPI_ERROR_BUFFER_LOCKED.
 *
 * The image can be locked multiple times. Each lock operation increments a
 * counter and must be matched by a corresponding \ref vpiImageUnlock
 * call.
 *
 * @param[in] img Image to be locked.
 *                + Mandatory, it can't be NULL.
 *                + Image must not be locked in a mode that is incompatible with given \p mode.
 * 
 * @param[in] mode Lock mode, depending on whether the memory will be written to and/or read from.
 *                 + Valid values: 
 *                   - \ref VPI_LOCK_READ
 *                   - \ref VPI_LOCK_WRITE
 *                   - \ref VPI_LOCK_READ_WRITE
 *
 * @retval #VPI_ERROR_INVALID_ARGUMENT  \p img is NULL or doesn't represent a \ref VPIImage instance.
 * @retval #VPI_ERROR_BUFFER_LOCKED     Image is already locked by either a stream or the user.
 * @retval #VPI_SUCCESS                 Operation executed successfully.
 */
VPI_PUBLIC VPIStatus vpiImageLock(VPIImage img, VPILockMode mode);

/**
 * Acquires the lock on an image object and returns the image contents.
 *
 * Depending on the internal image representation, as well as the actual location in memory, this
 * function might have a significant performance overhead due to format conversion, layout conversion,
 * device-to-host memory copy, etc.
 *
 * The image can be locked multiple times. Each lock operation increments a
 * counter and must be matched by a corresponding \ref vpiImageUnlock
 * call.
 *
 * @param[in] img Image to be locked.
 *                + Mandatory, it can't be NULL.
 *                + Image must not be locked in a mode that is incompatible with given \p mode.
 *                + For some buffer types, the image must have the following backend enabled:
 *                  | Buffer type                             | Required backend flags |
 *                  |-----------------------------------------|------------------------|
 *                  | \ref VPI_IMAGE_BUFFER_HOST_PITCH_LINEAR | \ref VPI_BACKEND_CPU   |
 *                  | \ref VPI_IMAGE_BUFFER_CUDA_PITCH_LINEAR | \ref VPI_BACKEND_CUDA  |
 * 
 * @param[in] mode Lock mode, depending on whether the memory will be written to and/or read from.
 *                 + Valid values: 
 *                   - \ref VPI_LOCK_READ
 *                   - \ref VPI_LOCK_WRITE
 *                   - \ref VPI_LOCK_READ_WRITE
 *
 * @param[in] bufType The type of buffer returned in \p data.
 *                    It defines how the image contents can be accessed by the caller.
 *                    Valid types are:
 *                    - \ref VPI_IMAGE_BUFFER_HOST_PITCH_LINEAR
 *                    - \ref VPI_IMAGE_BUFFER_CUDA_PITCH_LINEAR
 * 
 * @param[out] data A pointer to a structure that will be filled with image memory contents information.
 *                  + Must not be NULL.
 *                  + The buffers it points to are valid until the image is unlocked.
 *
 * @retval #VPI_ERROR_INVALID_ARGUMENT  \p img is NULL or doesn't represent a \ref VPIImage instance.
 * @retval #VPI_ERROR_INVALID_ARGUMENT  \p data must not be NULL.
 * @retval #VPI_ERROR_INVALID_ARGUMENT  \p bufType isn't supported.
 * @retval #VPI_ERROR_INVALID_OPERATION \p img doesn't have required backends enabled.
 * @retval #VPI_ERROR_BUFFER_LOCKED     Image is already locked by either a stream or the user.
 * @retval #VPI_SUCCESS                 Operation executed successfully.
 */
VPI_PUBLIC VPIStatus vpiImageLockData(VPIImage img, VPILockMode mode, VPIImageBufferType bufType, VPIImageData *data);

/**
 * Releases the lock on an image object.
 *
 * The image is effectively unlocked when the internal lock counter reaches 0.
 *
 * @param[in] img Image to be unlocked.
 *                + Mandatory, it can't be NULL.
 *                + Image must have CPU backend enabled.
 *
 * @retval #VPI_ERROR_INVALID_ARGUMENT  \p img is NULL or doesn't represent a \ref VPIImage instance.
 * @retval #VPI_ERROR_INVALID_OPERATION \p img isn't locked.
 * @retval #VPI_SUCCESS                 Operation executed successfully.
 */
VPI_PUBLIC VPIStatus vpiImageUnlock(VPIImage img);

#ifdef __cplusplus
}
#endif

/** @} end of VPI_Image */

#endif /* NV_VPI_IMAGE_H */
// End content from: Image.h

// Begin content from: ArrayType.h
/*
 * Copyright 2020-2023 NVIDIA Corporation. All rights reserved.
 *
 * NOTICE TO LICENSEE:
 *
 * This source code and/or documentation ("Licensed Deliverables") are
 * subject to NVIDIA intellectual property rights under U.S. and
 * international Copyright laws.
 *
 * These Licensed Deliverables contained herein is PROPRIETARY and
 * CONFIDENTIAL to NVIDIA and is being provided under the terms and
 * conditions of a form of NVIDIA software license agreement by and
 * between NVIDIA and Licensee ("License Agreement") or electronically
 * accepted by Licensee. Notwithstanding any terms or conditions to
 * the contrary in the License Agreement, reproduction or disclosure
 * of the Licensed Deliverables to any third party without the express
 * written consent of NVIDIA is prohibited.
 *
 * NOTWITHSTANDING ANY TERMS OR CONDITIONS TO THE CONTRARY IN THE
 * LICENSE AGREEMENT, NVIDIA MAKES NO REPRESENTATION ABOUT THE
 * SUITABILITY OF THESE LICENSED DELIVERABLES FOR ANY PURPOSE. IT IS
 * PROVIDED "AS IS" WITHOUT EXPRESS OR IMPLIED WARRANTY OF ANY KIND.
 * NVIDIA DISCLAIMS ALL WARRANTIES WITH REGARD TO THESE LICENSED
 * DELIVERABLES, INCLUDING ALL IMPLIED WARRANTIES OF MERCHANTABILITY,
 * NONINFRINGEMENT, AND FITNESS FOR A PARTICULAR PURPOSE.
 * NOTWITHSTANDING ANY TERMS OR CONDITIONS TO THE CONTRARY IN THE
 * LICENSE AGREEMENT, IN NO EVENT SHALL NVIDIA BE LIABLE FOR ANY
 * SPECIAL, INDIRECT, INCIDENTAL, OR CONSEQUENTIAL DAMAGES, OR ANY
 * DAMAGES WHATSOEVER RESULTING FROM LOSS OF USE, DATA OR PROFITS,
 * WHETHER IN AN ACTION OF CONTRACT, NEGLIGENCE OR OTHER TORTIOUS
 * ACTION, ARISING OUT OF OR IN CONNECTION WITH THE USE OR PERFORMANCE
 * OF THESE LICENSED DELIVERABLES.
 *
 * U.S. Government End Users. These Licensed Deliverables are a
 * "commercial item" as that term is defined at 48 C.F.R. 2.101 (OCT
 * 1995), consisting of "commercial computer software" and "commercial
 * computer software documentation" as such terms are used in 48
 * C.F.R. 12.212 (SEPT 1995) and is provided to the U.S. Government
 * only as a commercial end item. Consistent with 48 C.F.R.12.212 and
 * 48 C.F.R. 227.7202-1 through 227.7202-4 (JUNE 1995), all
 * U.S. Government End Users acquire the Licensed Deliverables with
 * only those rights set forth herein.
 *
 * Any use of the Licensed Deliverables in individual and commercial
 * software must include, in the user documentation and internal
 * comments to the code, the above Disclaimer and U.S. Government End
 * Users Notice.
 */

/**
 * @file ArrayType.h
 *
 * Defines array types.
 */

#ifndef NV_VPI_ARRAY_TYPE_H
#define NV_VPI_ARRAY_TYPE_H

// #include "Export.h"
// #include "Version.h"

#ifdef __cplusplus
extern "C" {
#endif

/** Array element formats.
 * @ingroup VPI_Array
 **/
typedef enum
{
    VPI_ARRAY_TYPE_INVALID = 0,              /**< Signal type conversion errors. */
    VPI_ARRAY_TYPE_S8,                       /**< Signed 8-bit. */
    VPI_ARRAY_TYPE_U8,                       /**< Unsigned 8-bit. */
    VPI_ARRAY_TYPE_S16,                      /**< Signed 16-bit. */
    VPI_ARRAY_TYPE_U16,                      /**< Unsigned 16-bit. */
    VPI_ARRAY_TYPE_U32,                      /**< Unsigned 32-bit. */
    VPI_ARRAY_TYPE_KEYPOINT_F32,             /**< \ref VPIKeypointF32 element. */
    VPI_ARRAY_TYPE_HOMOGRAPHY_TRANSFORM_2D,  /**< \ref VPIHomographyTransform2D element. */
    VPI_ARRAY_TYPE_KLT_TRACKED_BOUNDING_BOX, /**< \ref VPIKLTTrackedBoundingBox element. */
    VPI_ARRAY_TYPE_F32,                      /**< Floating point 32-bit. */
    VPI_ARRAY_TYPE_KEYPOINT_U32,             /**< \ref VPIKeypointU32 element in U32 format. */
    VPI_ARRAY_TYPE_KEYPOINT_UQ1616,          /**< \ref VPIKeypointU32 element in UQ1616 fixed-point format. */
    VPI_ARRAY_TYPE_STATISTICS,               /**< \ref VPIStats element. */
    VPI_ARRAY_TYPE_BRIEF_DESCRIPTOR,         /**< \ref VPIBriefDescriptor element. */
    VPI_ARRAY_TYPE_MATCHES,                  /**< \ref VPIMatches element. */

#if NV_VPI_VERSION_API_AT_MOST(2, 0)
    VPI_ARRAY_TYPE_KEYPOINT = VPI_ARRAY_TYPE_KEYPOINT_F32, /**< Alias to \ref VPI_ARRAY_TYPE_KEYPOINT_F32. */
#endif
} VPIArrayType;

/** Returns a string representation of the array type.
 *
 * @param[in] type Array type whose name is to be returned.
 *
 * @returns The string representation of the image type.
 *          Returned string is valid until next call of this function from the same calling thread.
 *          Returned pointer must not be freed.
 */
VPI_PUBLIC const char *vpiArrayTypeGetName(VPIArrayType type);

/** Returns the size in bytes of each array element with the given type.
 *
 * @param[in] type The array type to be queried.
 *                 + The array type must be valid.
 *
 * @returns The size in bytes of the array type.
 * @retval 0 An invalid array \p type was given.
 */
VPI_PUBLIC int vpiArrayTypeGetSize(VPIArrayType type);

#ifdef __cplusplus
}
#endif

#endif /* NV_VPI_ARRAY_TYPE_H */
// End content from: ArrayType.h

// Begin content from: AlgoFlags.h
/*
 * Copyright 2020-2021 NVIDIA Corporation. All rights reserved.
 *
 * NOTICE TO LICENSEE:
 *
 * This source code and/or documentation ("Licensed Deliverables") are
 * subject to NVIDIA intellectual property rights under U.S. and
 * international Copyright laws.
 *
 * These Licensed Deliverables contained herein is PROPRIETARY and
 * CONFIDENTIAL to NVIDIA and is being provided under the terms and
 * conditions of a form of NVIDIA software license agreement by and
 * between NVIDIA and Licensee ("License Agreement") or electronically
 * accepted by Licensee. Notwithstanding any terms or conditions to
 * the contrary in the License Agreement, reproduction or disclosure
 * of the Licensed Deliverables to any third party without the express
 * written consent of NVIDIA is prohibited.
 *
 * NOTWITHSTANDING ANY TERMS OR CONDITIONS TO THE CONTRARY IN THE
 * LICENSE AGREEMENT, NVIDIA MAKES NO REPRESENTATION ABOUT THE
 * SUITABILITY OF THESE LICENSED DELIVERABLES FOR ANY PURPOSE. IT IS
 * PROVIDED "AS IS" WITHOUT EXPRESS OR IMPLIED WARRANTY OF ANY KIND.
 * NVIDIA DISCLAIMS ALL WARRANTIES WITH REGARD TO THESE LICENSED
 * DELIVERABLES, INCLUDING ALL IMPLIED WARRANTIES OF MERCHANTABILITY,
 * NONINFRINGEMENT, AND FITNESS FOR A PARTICULAR PURPOSE.
 * NOTWITHSTANDING ANY TERMS OR CONDITIONS TO THE CONTRARY IN THE
 * LICENSE AGREEMENT, IN NO EVENT SHALL NVIDIA BE LIABLE FOR ANY
 * SPECIAL, INDIRECT, INCIDENTAL, OR CONSEQUENTIAL DAMAGES, OR ANY
 * DAMAGES WHATSOEVER RESULTING FROM LOSS OF USE, DATA OR PROFITS,
 * WHETHER IN AN ACTION OF CONTRACT, NEGLIGENCE OR OTHER TORTIOUS
 * ACTION, ARISING OUT OF OR IN CONNECTION WITH THE USE OR PERFORMANCE
 * OF THESE LICENSED DELIVERABLES.
 *
 * U.S. Government End Users. These Licensed Deliverables are a
 * "commercial item" as that term is defined at 48 C.F.R. 2.101 (OCT
 * 1995), consisting of "commercial computer software" and "commercial
 * computer software documentation" as such terms are used in 48
 * C.F.R. 12.212 (SEPT 1995) and is provided to the U.S. Government
 * only as a commercial end item. Consistent with 48 C.F.R.12.212 and
 * 48 C.F.R. 227.7202-1 through 227.7202-4 (JUNE 1995), all
 * U.S. Government End Users acquire the Licensed Deliverables with
 * only those rights set forth herein.
 *
 * Any use of the Licensed Deliverables in individual and commercial
 * software must include, in the user documentation and internal
 * comments to the code, the above Disclaimer and U.S. Government End
 * Users Notice.
 */

/**
 * @file AlgoFlags.h
 *
 * Functions and structures for dealing with VPI images.
 */

#ifndef NV_VPI_ALGOFLAGS_H
#define NV_VPI_ALGOFLAGS_H

// #include "Export.h"
// #include "ImageFormat.h"
// #include "PixelType.h"
// #include "Status.h"
// #include "Types.h"

#include <stdint.h>

/**
 * @ingroup VPI_Algorithms
 * @{
 */

/** 
 * Informs that the matrix used in warp/map operations is already inverted.
 *
 * If user has the transform matrix already inverted, setting this flag allows
 * the warp operation to use it directly instead of inverting it itself prior
 * processing. This is particularly useful if matrix inversion would result
 * in large numerical errors, such as when its determinant is close to zero.
 */
#define VPI_WARP_INVERSE (1u << 0)

/** Informs that the algorithm will choose a precise implementation.
 * By default algorithms will choose an implementation that might trade
 * speed over precision.
 */
#define VPI_PRECISE (1u << 1)

/** Leave output denormalized.
 *
 * Flag currently used in \ref algo_ifft, where it signals that
 * output is to be left denormalized. This leads to faster execution as
 * normalization isn't usually needed.  Absense of this flag will scale the
 * output, dividing it by the total pixel count. This makes the output the
 * exact inverse of direct Fast Fourier Transform.
 */
#define VPI_DENORMALIZED_OUTPUT (1u << 2)

/** Defines whether cross check is enabled
 * 
 * When cross check is enabled, only those pairs of query and reference descriptors
 * are selected which are closest to each other both ways. Meaning if A's(query descriptor)
 * closest reference descriptor is B and if B's closest query descriptor is A only then the pair is selected.
 */
#define VPI_ENABLE_CROSS_CHECK (1U << 0)
/**@}*/

/** Accumulate the counting in the output. 
 *
 * Once it is set, the output will not be cleared at the beginning.
 */
#define VPI_ACCUMULATE_OUTPUT (1u << 3)

#endif /* NV_VPI_ALGOFLAGS_H */
// End content from: AlgoFlags.h

// Begin content from: WarpMap.h
/*
 * Copyright 2020-2021 NVIDIA Corporation. All rights reserved.
 *
 * NOTICE TO LICENSEE:
 *
 * This source code and/or documentation ("Licensed Deliverables") are
 * subject to NVIDIA intellectual property rights under U.S. and
 * international Copyright laws.
 *
 * These Licensed Deliverables contained herein is PROPRIETARY and
 * CONFIDENTIAL to NVIDIA and is being provided under the terms and
 * conditions of a form of NVIDIA software license agreement by and
 * between NVIDIA and Licensee ("License Agreement") or electronically
 * accepted by Licensee. Notwithstanding any terms or conditions to
 * the contrary in the License Agreement, reproduction or disclosure
 * of the Licensed Deliverables to any third party without the express
 * written consent of NVIDIA is prohibited.
 *
 * NOTWITHSTANDING ANY TERMS OR CONDITIONS TO THE CONTRARY IN THE
 * LICENSE AGREEMENT, NVIDIA MAKES NO REPRESENTATION ABOUT THE
 * SUITABILITY OF THESE LICENSED DELIVERABLES FOR ANY PURPOSE. IT IS
 * PROVIDED "AS IS" WITHOUT EXPRESS OR IMPLIED WARRANTY OF ANY KIND.
 * NVIDIA DISCLAIMS ALL WARRANTIES WITH REGARD TO THESE LICENSED
 * DELIVERABLES, INCLUDING ALL IMPLIED WARRANTIES OF MERCHANTABILITY,
 * NONINFRINGEMENT, AND FITNESS FOR A PARTICULAR PURPOSE.
 * NOTWITHSTANDING ANY TERMS OR CONDITIONS TO THE CONTRARY IN THE
 * LICENSE AGREEMENT, IN NO EVENT SHALL NVIDIA BE LIABLE FOR ANY
 * SPECIAL, INDIRECT, INCIDENTAL, OR CONSEQUENTIAL DAMAGES, OR ANY
 * DAMAGES WHATSOEVER RESULTING FROM LOSS OF USE, DATA OR PROFITS,
 * WHETHER IN AN ACTION OF CONTRACT, NEGLIGENCE OR OTHER TORTIOUS
 * ACTION, ARISING OUT OF OR IN CONNECTION WITH THE USE OR PERFORMANCE
 * OF THESE LICENSED DELIVERABLES.
 *
 * U.S. Government End Users. These Licensed Deliverables are a
 * "commercial item" as that term is defined at 48 C.F.R. 2.101 (OCT
 * 1995), consisting of "commercial computer software" and "commercial
 * computer software documentation" as such terms are used in 48
 * C.F.R. 12.212 (SEPT 1995) and is provided to the U.S. Government
 * only as a commercial end item. Consistent with 48 C.F.R.12.212 and
 * 48 C.F.R. 227.7202-1 through 227.7202-4 (JUNE 1995), all
 * U.S. Government End Users acquire the Licensed Deliverables with
 * only those rights set forth herein.
 *
 * Any use of the Licensed Deliverables in individual and commercial
 * software must include, in the user documentation and internal
 * comments to the code, the above Disclaimer and U.S. Government End
 * Users Notice.
 */

/**
 * @file WarpMap.h
 *
 * Declares functions that implement the WarpMap structure and related functions.
 */

#ifndef NV_VPI_WARPMAP_H
#define NV_VPI_WARPMAP_H

// #include "Export.h"
// #include "Status.h"
// #include "Types.h"
// #include "WarpGrid.h"

#include <stdint.h>

/**
 * Defines the \ref VPIWarpMap object and related functions.
 *
 * Warp map holds the mapping from output to input images, used in \ref
 * algo_remap algorithm. It allows both dense and sparse mapping.
 *
 * @defgroup VPI_WarpMap WarpMap
 * @ingroup VPI_API_Core
 * @{
 */

#ifdef __cplusplus
extern "C" {
#endif

/** Defines the mapping between input and output images' pixels.
 *
 * This structure is used as input to \ref algo_remap. It defines the
 * control point positions in the input image. The corresponding positions in
 * the output image is implicitly defined by the warp grid definition.
 */
typedef struct
{
    /** Warp grid control point structure definition.
     *  It implicitly defines the control point positions in the output image. */
    VPIWarpGrid grid;

    /** Number of points horizontally.
     *  + Must match the number of points defined by the grid. This is calculated by \ref vpiWarpMapAllocData. */
    int16_t numHorizPoints;

    /** Number of points vertically. 
     *  + Must match the number of points defined by the grid. This is calculated by \ref vpiWarpMapAllocData. */
    int16_t numVertPoints;

    /** Number of bytes between one control point and the one immediately below.
     *  + Must be at least `sizeof(VPIKeypointF32)*numHorizPoints`. */
    int32_t pitchBytes;

    /** Pointer to an array with control point positions in the input image
     * corresponding to those in the output image.
     * Coordinates are absolute, (0,0) is the top/left corner of output image.
     */
    VPIKeypointF32 *keypoints;
} VPIWarpMap;

/** Allocates the warp map's control point array for a given warp grid.
 *
 * This function will read the warp grid structure and allocated an appropriately sized control point array,
 * filling the numHorizPoints, numVertPoints, strideBytes and keypoints attributes of \ref VPIWarpMap.
 * The warp map must be deallocated by \ref vpiWarpMapFreeData when no longer needed.
 *
 * @param[in,out] warpMap The warp map whose keypoint array will be allocated. 
 *                        + The warp grid attribute must be already filled out with the grid structure.
 *                        + Keypoints must be NULL. 
 *                        + All attributes other then grid and keypoints will be overwriten.
 * 
 * @retval #VPI_ERROR_INVALID_ARGUMENT \p warpMap is NULL.
 * @retval #VPI_ERROR_INVALID_ARGUMENT Parameters to generate \p warpMap are invalid.
 * @retval #VPI_SUCCESS                Operation executed successfully.
 */
VPI_PUBLIC VPIStatus vpiWarpMapAllocData(VPIWarpMap *warpMap);

/** Deallocates the warp map control points allocated by \ref vpiWarpMapAllocData.
 * This function does nothing if control points array is NULL. It sets `numHorizPoints`,
 * `numVertPoints` and `strideBytes` to zero, and `keypoints` to NULL.
 *
 * @param[in,out] warpMap Warp map whose control points array needs to be deallocated.
 * 
 * @retval #VPI_ERROR_INVALID_ARGUMENT \p warpMap is NULL.
 */
VPI_PUBLIC void vpiWarpMapFreeData(VPIWarpMap *warpMap);

/** Fills the given warp map with an identity mapping.
 * This function is useful if the user wants to specify their own mapping. It
 * sets the control points coordinates to the destination coordinates as
 * defined implicitly by the warp grid. The user then can iterate through these
 * points and apply a custom mapping function to each one.
 *
 * @param[in,out] warpMap Warp map with allocated control point array to be filled with identity mapping.
 *                        + WarpMap must be allocated before generating identity.
 * 
 * @retval #VPI_ERROR_INVALID_ARGUMENT \p warpMap is NULL.
 * @retval #VPI_ERROR_INVALID_ARGUMENT \p warpMap is not allocated.
 * @retval #VPI_SUCCESS                Operation executed successfully.
 */
VPI_PUBLIC VPIStatus vpiWarpMapGenerateIdentity(VPIWarpMap *warpMap);

#ifdef __cplusplus
}
#endif

/** @} */

#endif /* NV_VPI_WARPMAP_H */
// End content from: WarpMap.h

// Begin content from: algo/FASTCorners.h
/*
 * Copyright 2022 NVIDIA Corporation. All rights reserved.
 *
 * NOTICE TO LICENSEE:
 *
 * This source code and/or documentation ("Licensed Deliverables") are
 * subject to NVIDIA intellectual property rights under U.S. and
 * international Copyright laws.
 *
 * These Licensed Deliverables contained herein is PROPRIETARY and
 * CONFIDENTIAL to NVIDIA and is being provided under the terms and
 * conditions of a form of NVIDIA software license agreement by and
 * between NVIDIA and Licensee ("License Agreement") or electronically
 * accepted by Licensee. Notwithstanding any terms or conditions to
 * the contrary in the License Agreement, reproduction or disclosure
 * of the Licensed Deliverables to any third party without the express
 * written consent of NVIDIA is prohibited.
 *
 * NOTWITHSTANDING ANY TERMS OR CONDITIONS TO THE CONTRARY IN THE
 * LICENSE AGREEMENT, NVIDIA MAKES NO REPRESENTATION ABOUT THE
 * SUITABILITY OF THESE LICENSED DELIVERABLES FOR ANY PURPOSE. IT IS
 * PROVIDED "AS IS" WITHOUT EXPRESS OR IMPLIED WARRANTY OF ANY KIND.
 * NVIDIA DISCLAIMS ALL WARRANTIES WITH REGARD TO THESE LICENSED
 * DELIVERABLES, INCLUDING ALL IMPLIED WARRANTIES OF MERCHANTABILITY,
 * NONINFRINGEMENT, AND FITNESS FOR A PARTICULAR PURPOSE.
 * NOTWITHSTANDING ANY TERMS OR CONDITIONS TO THE CONTRARY IN THE
 * LICENSE AGREEMENT, IN NO EVENT SHALL NVIDIA BE LIABLE FOR ANY
 * SPECIAL, INDIRECT, INCIDENTAL, OR CONSEQUENTIAL DAMAGES, OR ANY
 * DAMAGES WHATSOEVER RESULTING FROM LOSS OF USE, DATA OR PROFITS,
 * WHETHER IN AN ACTION OF CONTRACT, NEGLIGENCE OR OTHER TORTIOUS
 * ACTION, ARISING OUT OF OR IN CONNECTION WITH THE USE OR PERFORMANCE
 * OF THESE LICENSED DELIVERABLES.
 *
 * U.S. Government End Users. These Licensed Deliverables are a
 * "commercial item" as that term is defined at 48 C.F.R. 2.101 (OCT
 * 1995), consisting of "commercial computer software" and "commercial
 * computer software documentation" as such terms are used in 48
 * C.F.R. 12.212 (SEPT 1995) and is provided to the U.S. Government
 * only as a commercial end item. Consistent with 48 C.F.R.12.212 and
 * 48 C.F.R. 227.7202-1 through 227.7202-4 (JUNE 1995), all
 * U.S. Government End Users acquire the Licensed Deliverables with
 * only those rights set forth herein.
 *
 * Any use of the Licensed Deliverables in individual and commercial
 * software must include, in the user documentation and internal
 * comments to the code, the above Disclaimer and U.S. Government End
 * Users Notice.
 */

/**
 * @file FASTCorners.h
 *
 * Declares functions that implement support for FAST Corners.
 */

#ifndef NV_VPI_ALGORITHMS_FAST_CORNERS_H
#define NV_VPI_ALGORITHMS_FAST_CORNERS_H

// #include "../Export.h"
// #include "../Status.h"
// #include "../Types.h"

#include <stdint.h>

#ifdef __cplusplus
extern "C" {
#endif

/**
 * @defgroup VPI_FASTCorners FAST Corners
 * @ingroup VPI_API_Algorithms
 * @{
 *
 * Detect FAST corners in an image, usually used in keypoint tracking.
 * Refer to \ref algo_fast_corners_detector for more details and usage examples.
 */

/**
 * Structure that defines the parameters for \ref vpiSubmitFASTCornerDetector
 */
typedef struct
{
    /** Circle radius around a pixel to check if it is a corner.
     *  The following circle radii are supported, correlating each radius with the
     *  number of pixels in the circle:
     *  | Circle radius | Number of pixels in the circle |
     *  |:-------------:|:------------------------------:|
     *  |       1       |      8                         |
     *  |       2       |     12                         |
     *  |       3       |     16                         |
     *  + Must be 1, 2 or 3. */
    int32_t circleRadius;

    /** Arc length in pixels over the circle to check central pixel is a corner.
     *  Arc length is the minimum number of contiguous pixels in the circle that are either
     *  brighter (have higher intensity values) or darker (have lower intensity values) than
     *  the central pixel, plus or minus a threshold, respectively, to mark it as a corner.
     *  + For VPI_BACKEND_CPU, it must be in the valid range from 1 to the number of pixels in the circle.
     *  + For VPI_BACKEND_CUDA, it must be either 5, 7 or 9 according to the circle radius as:
     *  | Circle radius | Arc length |
     *  |:-------------:|:----------:|
     *  |       1       |      5     |
     *  |       2       |      7     |
     *  |       3       |      9     |
     */
    int32_t arcLength;

    /** Threshold to select a pixel as being part of the arc in circle around a keypoint candidate.
     *  Intensity threshold is used to check if a pixel in the circle is either brighter
     *  (has higher intensity value) or darker (has lower intensity value) than the central pixel.
     *  This check is used in the arc calculation to determine if a pixel is in the arc or not. */
    float intensityThreshold;

    /** Whether to apply non-maximum suppression to remove corners too close together.
     *  If not '0', it activates non-maximum suppression (NMS) for the FAST corner detector algorithm.
     *  The NMS for FAST suppresses pixels in a 1-ring neighborhood by increasing the intensity
     *  threshold value and removing corner pixels that fail the arc length calculation,
     *  keeping the single pixel in the neighborhood that survives.
     *  If '0', it deactivates the non-maximum suppression. */
    int8_t nonMaxSuppression;
} VPIFASTCornerDetectorParams;

/** Initializes \ref VPIFASTCornerDetectorParams with default values.
 *
 * Default values are:
 * - circleRadius:        3
 * - arcLength:           9
 * - intensityThreshold: 10
 * - nonMaxSuppression:   1
 * 
 * @retval #VPI_ERROR_INVALID_ARGUMENT \p params is NULL.
 * @retval #VPI_SUCCESS Operation executed successfully.
 */
VPI_PUBLIC VPIStatus vpiInitFASTCornerDetectorParams(VPIFASTCornerDetectorParams *params);

/**
 * Submits a \ref algo_fast_corners_detector "FAST Corner Detector" operation to the stream.
 *
 * @param[in] stream The stream where the operation will be queued in.
 *                   + Must not be NULL.
 *                   + Stream must have enabled the backends that will execute the algorithm.
 *
 * @param[in] backend Backend that will execute the algorithm.
 *                    + Valid values: 
 *                      - \ref VPI_BACKEND_CPU
 *                      - \ref VPI_BACKEND_CUDA
 *
 * @param[in] input Input image from where the FAST corners will be extracted.
 *                  + Must not be NULL.
 *                  + Image must have enabled the backends that will execute the algorithm.
 *                  + The accepted image formats are:
 *                    - \ref VPI_IMAGE_FORMAT_Y8
 *                    - \ref VPI_IMAGE_FORMAT_Y16
 *                    - \ref VPI_IMAGE_FORMAT_Y8_ER
 *                    - \ref VPI_IMAGE_FORMAT_Y16_ER
 *                    - \ref VPI_IMAGE_FORMAT_U8
 *                    - \ref VPI_IMAGE_FORMAT_S8
 *                    - \ref VPI_IMAGE_FORMAT_U16
 *                    - \ref VPI_IMAGE_FORMAT_S16
 *
 * @param[out] outCorners Array that will receive the detected corners.
 *                        Array size is updated with the number of corners found.
 *                        + Must not be NULL.
 *                        + It must have type \ref VPI_ARRAY_TYPE_KEYPOINT_F32.
 *                        + Array must have enabled the backends that will execute the algorithm.
 *
 * @param[in] params Pointer to a \ref VPIFASTCornerDetectorParams.
 *                   It defines the parameters for this algorithm invocation.
 *                   These parameters can vary in every call and will be copied internally.
 *                   Thus there is no need to keep the parameters object around.
 *                   - If NULL, use the defaults given by \ref vpiInitFASTCornerDetectorParams.
 *
 * @param[in] border How to handle pixels outside image boundaries.
 *                   + The accepted border extensions are:
 *                     - \ref VPI_BORDER_ZERO
 *                     - \ref VPI_BORDER_CLAMP
 *                     - \ref VPI_BORDER_REFLECT
 *                     - \ref VPI_BORDER_MIRROR
 *                     - \ref VPI_BORDER_LIMITED (ignore pixels with circle going outside image boundaries)
 *  
 * @retval #VPI_ERROR_INVALID_ARGUMENT     \p stream is NULL.
 * @retval #VPI_ERROR_INVALID_ARGUMENT     \p input or \p outCorners are NULL.
 * @retval #VPI_ERROR_INVALID_ARGUMENT     Circle radius in \p params outside valid range.
 * @retval #VPI_ERROR_INVALID_ARGUMENT     Arc length in \p params outside valid range.
 * @retval #VPI_ERROR_INVALID_ARGUMENT     Intensity threshold in \p params outside valid range.
 * @retval #VPI_ERROR_INVALID_ARRAY_TYPE   Invalid \p outCorners array type.
 * @retval #VPI_ERROR_INVALID_IMAGE_FORMAT Unsupported input format.
 * @retval #VPI_ERROR_INVALID_OPERATION    The needed backends aren't enabled in \p stream, \p input or \p outCorners.
 * @retval #VPI_SUCCESS                    Operation executed successfully.
 */
#if NV_VPI_VERSION_API_AT_MOST(2, 2)
__asm__(".symver vpiSubmitFASTCornerDetector,vpiSubmitFASTCornerDetector@VPI_2.1");
#endif
VPI_PUBLIC VPIStatus vpiSubmitFASTCornerDetector(VPIStream stream, uint64_t backend, VPIImage input,
                                                 VPIArray outCorners, const VPIFASTCornerDetectorParams *params,
                                                 VPIBorderExtension border);

/** @} end of VPI_FASTCorners */

#ifdef __cplusplus
}
#endif

#endif /* NV_VPI_ALGORITHMS_FAST_CORNERS_H */
// End content from: algo/FASTCorners.h

// Begin content from: Pyramid.h
/*
 * Copyright 2019-2021 NVIDIA Corporation. All rights reserved.
 *
 * NOTICE TO LICENSEE:
 *
 * This source code and/or documentation ("Licensed Deliverables") are
 * subject to NVIDIA intellectual property rights under U.S. and
 * international Copyright laws.
 *
 * These Licensed Deliverables contained herein is PROPRIETARY and
 * CONFIDENTIAL to NVIDIA and is being provided under the terms and
 * conditions of a form of NVIDIA software license agreement by and
 * between NVIDIA and Licensee ("License Agreement") or electronically
 * accepted by Licensee. Notwithstanding any terms or conditions to
 * the contrary in the License Agreement, reproduction or disclosure
 * of the Licensed Deliverables to any third party without the express
 * written consent of NVIDIA is prohibited.
 *
 * NOTWITHSTANDING ANY TERMS OR CONDITIONS TO THE CONTRARY IN THE
 * LICENSE AGREEMENT, NVIDIA MAKES NO REPRESENTATION ABOUT THE
 * SUITABILITY OF THESE LICENSED DELIVERABLES FOR ANY PURPOSE. IT IS
 * PROVIDED "AS IS" WITHOUT EXPRESS OR IMPLIED WARRANTY OF ANY KIND.
 * NVIDIA DISCLAIMS ALL WARRANTIES WITH REGARD TO THESE LICENSED
 * DELIVERABLES, INCLUDING ALL IMPLIED WARRANTIES OF MERCHANTABILITY,
 * NONINFRINGEMENT, AND FITNESS FOR A PARTICULAR PURPOSE.
 * NOTWITHSTANDING ANY TERMS OR CONDITIONS TO THE CONTRARY IN THE
 * LICENSE AGREEMENT, IN NO EVENT SHALL NVIDIA BE LIABLE FOR ANY
 * SPECIAL, INDIRECT, INCIDENTAL, OR CONSEQUENTIAL DAMAGES, OR ANY
 * DAMAGES WHATSOEVER RESULTING FROM LOSS OF USE, DATA OR PROFITS,
 * WHETHER IN AN ACTION OF CONTRACT, NEGLIGENCE OR OTHER TORTIOUS
 * ACTION, ARISING OUT OF OR IN CONNECTION WITH THE USE OR PERFORMANCE
 * OF THESE LICENSED DELIVERABLES.
 *
 * U.S. Government End Users. These Licensed Deliverables are a
 * "commercial item" as that term is defined at 48 C.F.R. 2.101 (OCT
 * 1995), consisting of "commercial computer software" and "commercial
 * computer software documentation" as such terms are used in 48
 * C.F.R. 12.212 (SEPT 1995) and is provided to the U.S. Government
 * only as a commercial end item. Consistent with 48 C.F.R.12.212 and
 * 48 C.F.R. 227.7202-1 through 227.7202-4 (JUNE 1995), all
 * U.S. Government End Users acquire the Licensed Deliverables with
 * only those rights set forth herein.
 *
 * Any use of the Licensed Deliverables in individual and commercial
 * software must include, in the user documentation and internal
 * comments to the code, the above Disclaimer and U.S. Government End
 * Users Notice.
 */

/**
 * @file Pyramid.h
 *
 * Functions and structures for dealing with VPI pyramids.
 */

#ifndef NV_VPI_PYRAMID_H
#define NV_VPI_PYRAMID_H

// #include "Export.h"
// #include "Image.h"
// #include "Status.h"
// #include "Types.h"
// #include "Version.h"

#include <stdint.h>

/**
 * An abstract representation of a 2D image pyramid.
 *
 * 2D image pyramid containers are created by calling \ref vpiPyramidCreate to
 * allocate and initialize an empty (zeroed) \ref VPIPyramid object. The memory
 * for the image pyramid data is allocated and managed by VPI.
 *
 * Image formats match the ones supported by image container. The pyramid is
 * not necessarily dyadic. The scale between levels is defined in the
 * constructor.
 *
 * Parameters such as levels, scale, width, height and image format are
 * immutable and specified at the construction time. The internal memory layout
 * is also backend-specific. More importantly, efficient exchange of image
 * pyramid data between different hardware blocks might force the
 * implementation to allocate the memory in multiple memory pools (e.g. dGPU
 * and system DRAM). In some scenarios (to optimize performance and memory
 * use), it might be beneficial to constrain the internal allocation policy to
 * support only a particular set of backends. 
 *
 * The set of \ref vpiPyramidLockData / \ref vpiPyramidUnlock calls allows the user
 * to read from/write to the image data from the host. These functions are
 * non-blocking and oblivious to the device command queue, so it's up to the
 * user to make sure that all pending operations using this image pyramid as
 * input or output are finished. Also, depending on the enabled backends
 * lock/unlock operation might be time-consuming and, for example, involve
 * copying data over PCIe bus for dGPUs.
 *
 * @defgroup VPI_Pyramid Pyramid
 * @ingroup VPI_API_Core
 * @{
 */

#ifdef __cplusplus
extern "C" {
#endif

/** Maximum number of pyramid levels */
#define VPI_MAX_PYRAMID_LEVEL_COUNT (10)

/** Stores the pyramid contents.
 * Each level is represented by an entire \ref VPIImageData. There are `numLevels` levels, and
 * they can be accessed from `levels[0]` to `levels[numLevels-1]`.
 */
typedef struct VPIPyramidDataRec
{
    /** Number of levels (i.e. height) of the pyramid. */
    int32_t numLevels;

    /** Scale factor of resolution between two adjecent levels. */
    float scale;

    /** Contents of every pyramid level.
     *  Only the first numLevels levels has valid data. */
    VPIImageData levels[VPI_MAX_PYRAMID_LEVEL_COUNT];

} VPIPyramidData;

/**
 * Create an empty image pyramid instance with the specified flags. Pyramid data is zeroed.
 *
 * @param[in] width, height Dimensions of the finest pyramid level.
 *                          + Width and height must be > 0.
 * 
 * @param[in] numLevels Number of levels.
 *                      + Must be >= 1 and <= \ref VPI_MAX_PYRAMID_LEVEL_COUNT.
 * 
 * @param[in] scale Scale factor from one level and the next.
 *                  + Must be > 0 and <= 1.
 * 
 * @param[in] fmt Image format of each level.
 *                + Accepts non-YUV or YUV 4:4:4 formats (no chroma subsampling allowed)
 *                + CPU and CUDA backends only support pitch-linear formats.
 *                + Can't be \ref VPI_IMAGE_FORMAT_INVALID.
 * 
 * @param[in] flags Bit field specifying the desired characteristics of the pyramid.
 *                  + The field must be a combination of zero or more of the following flags:
 *                    - \ref VPIBackend flags.
 *                      This pyramid can be used in algorithms running in these backends.
 *                      If no backend flags are given and \ref VPI_REQUIRE_BACKENDS is not set,
 *                      it'll consider all backends supported by the active \ref VPIContext,
 *                      but disable the backends that are incompatible with the given image parameters.
 *                    - \ref common_flags "Common object flags"
 *                  + If flag \ref VPI_REQUIRE_BACKENDS is given, user must pass at least one valid backend that is 
 *                    enabled in current context *AND* is compatible with the given image parameters.
 * 
 * @param[out] pyr Pointer to memory that will receive the created pyramid handle.
 *
 * @retval #VPI_ERROR_INVALID_ARGUMENT     Output \p pyr is NULL.
 * @retval #VPI_ERROR_INVALID_ARGUMENT     \p numLevels outside valid range.
 * @retval #VPI_ERROR_INVALID_ARGUMENT     \p width or \p height outside valid range.
 * @retval #VPI_ERROR_INVALID_ARGUMENT     \p scale outside valid range.
 * @retval #VPI_ERROR_INVALID_ARGUMENT     No backend were given and \ref VPI_REQUIRE_BACKENDS is set.
 * @retval #VPI_ERROR_INVALID_IMAGE_FORMAT \p fmt is not accepted.
 * @retval #VPI_ERROR_INVALID_ARGUMENT     Invalid \p flags.
 * @retval #VPI_ERROR_OUT_OF_MEMORY        Not enough resources to create image.
 * @retval #VPI_ERROR_INVALID_CONTEXT      Current context it destroyed.
 * @retval #VPI_ERROR_INVALID_OPERATION    Requested backend isn't enabled in current context.
 * @retval #VPI_SUCCESS                    Operation executed successfully.
 */
VPI_PUBLIC VPIStatus vpiPyramidCreate(int32_t width, int32_t height, VPIImageFormat fmt, int32_t numLevels, float scale,
                                      uint64_t flags, VPIPyramid *pyr);

/**
 * Destroy an image pyramid instance as well as all resources it owns.
 *
 * @param[in] pyr Pyramid handle. 
 *                Passing NULL is allowed, to which the function simply does nothing.
 *                + Pyramid must not be in use by any stream, or else undefined behavior will ensue.
 */
VPI_PUBLIC void vpiPyramidDestroy(VPIPyramid pyr);

/**
 * Returns the flags associated with the pyramid.
 *
 * @param[in] pyr Pyramid handle.
 *                + Mandatory, it can't be NULL.
 * 
 * @param[out] flags Pointer to where the flags will be written.
 *                   + Mandatory, it can't be NULL.
 *
 * @retval #VPI_ERROR_INVALID_ARGUMENT Output \p flags pointer is NULL.
 * @retval #VPI_ERROR_INVALID_ARGUMENT \p pyr is NULL or doesn't represent a \ref VPIPyramid instance.
 * @retval #VPI_SUCCESS                Operation executed successfully.
 */
VPI_PUBLIC VPIStatus vpiPyramidGetFlags(VPIPyramid pyr, uint64_t *flags);

/**
 * Returns the image format of the pyramid levels.
 *
 * @param[in] pyr Pyramid handle.
 *                + Mandatory, it can't be NULL.
 * 
 * @param[out] fmt Pointer to where the image format will be written.
 *                 + Mandatory, it can't be NULL.
 *
 * @retval #VPI_ERROR_INVALID_ARGUMENT Output \p fmt is NULL.
 * @retval #VPI_ERROR_INVALID_ARGUMENT \p pyr is NULL or doesn't represent a \ref VPIPyramid instance.
 * @retval #VPI_SUCCESS                Operation executed successfully.
 */
VPI_PUBLIC VPIStatus vpiPyramidGetFormat(VPIPyramid pyr, VPIImageFormat *fmt);

/**
 * Get the image pyramid level count.
 *
 * @param[in] pyr Pyramid handle.
 *                + Mandatory, it can't be NULL.
 * 
 * @param[out] numLevels A pointer to a variable which will be set to the number of levels of the image pyramid.
 *                       + Mandatory, it can't be NULL.
 *
 * @retval #VPI_ERROR_INVALID_ARGUMENT Output \p numLevels pointer is NULL.
 * @retval #VPI_ERROR_INVALID_ARGUMENT \p pyr is NULL or doesn't represent a \ref VPIPyramid instance.
 * @retval #VPI_SUCCESS                Operation executed successfully.
 */
VPI_PUBLIC VPIStatus vpiPyramidGetNumLevels(VPIPyramid pyr, int32_t *numLevels);

/**
 * Get the image width and height in pixels (*for all levels at once*).
 *
 * @param[in] pyr Pyramid handle.
 *                + Mandatory, it can't be NULL.
 * 
 * @param[in] outSize Size of the output arrays, in elements.
 *                    + Must be >= 1.
 * 
 * @param[out] outWidth, outHeight Pointers to an array which will be filled
 *                                 with widths and heights (respectively) of all image pyramid levels.
 *                                 If any of them is NULL, the corresponding data isn't returned.
 *
 * @retval #VPI_ERROR_INVALID_ARGUMENT \p outSize outside valid range.
 * @retval #VPI_ERROR_INVALID_ARGUMENT \p pyr is NULL or doesn't represent a \ref VPIPyramid instance.
 * @retval #VPI_ERROR_INVALID_ARGUMENT \p outWidth and \p outHeight can't be NULL.
 * @retval #VPI_SUCCESS                Operation executed successfully.
 */
VPI_PUBLIC VPIStatus vpiPyramidGetSize(VPIPyramid pyr, int32_t outSize, int32_t *outWidth, int32_t *outHeight);

/**
 * Returns the scale factor of the pyramid levels.
 *
 * @param[in] pyr Pyramid handle.
 *                + Mandatory, it can't be NULL.
 * 
 * @param[out] scale Pointer to where the scale will be written.
 *                + Mandatory, it can't be NULL.
 *
 * @retval #VPI_ERROR_INVALID_ARGUMENT Output \p scale pointer is NULL.
 * @retval #VPI_ERROR_INVALID_ARGUMENT \p pyr is NULL or doesn't represent a \ref VPIPyramid instance.
 * @retval #VPI_SUCCESS                Operation executed successfully.
 */
VPI_PUBLIC VPIStatus vpiPyramidGetScale(VPIPyramid pyr, float *scale);

/**
 * Acquires the lock on an pyramid object.
 *
 * As long as the lock is held, any attempt of VPI to access the image in a
 * mode not compatible with the lock mode will result in asynchronous stream
 * errors, \ref VPI_ERROR_BUFFER_LOCKED.
 *
 * @param[in] pyr Pyramid handle.
 *                + Mandatory, it can't be NULL.
 *                + Pyramid must not be locked in a mode that is incompatible with given \p mode.
 * 
 * @param[in] lock Lock mode.
 *                 + Valid values are: 
 *                   - \ref VPI_LOCK_READ
 *                   - \ref VPI_LOCK_WRITE
 *                   - \ref VPI_LOCK_READ_WRITE
 *
 * @retval #VPI_ERROR_INVALID_ARGUMENT  \p pyr is NULL or doesn't represent a \ref VPIPyramid instance.
 * @retval #VPI_ERROR_BUFFER_LOCKED     Pyramid is already locked by either a stream or the user.
 * @retval #VPI_ERROR_INVALID_ARGUMENT  \p out is NULL.
 * @retval #VPI_SUCCESS                 Operation executed successfully
 */
VPI_PUBLIC VPIStatus vpiPyramidLock(VPIPyramid pyr, VPILockMode lock);

/**
 * Acquires the lock on a pyramid object and returns host-accessible pointers to each level of the pyramid.
 * Depending on the internal image representation, as well as the actual location in memory, this
 * function might have a significant performance overhead (format conversion, layout conversion,
 * device-to-host memory copy).
 *
 * @param[in] pyr Pyramid handle.
 *                + Mandatory, it can't be NULL.
 *                + Pyramid must not be locked in a mode that is incompatible with given \p mode.
 *                + For some buffer types, the pyramid must have the following backend enabled:
 *                  | Buffer type                             | Required backend flags |
 *                  |-----------------------------------------|------------------------|
 *                  | \ref VPI_IMAGE_BUFFER_HOST_PITCH_LINEAR | \ref VPI_BACKEND_CPU   |
 *                  | \ref VPI_IMAGE_BUFFER_CUDA_PITCH_LINEAR | \ref VPI_BACKEND_CUDA  |
 * 
 * @param[in] lock Lock mode.
 *                 + Valid values are: 
 *                   - \ref VPI_LOCK_READ
 *                   - \ref VPI_LOCK_WRITE
 *                   - \ref VPI_LOCK_READ_WRITE
 *
 * @param[in] bufType The type of buffer returned in \p data.
 *                    It defines how the image contents can be accessed by the caller.
 *                    Valid types are:
 *                    - \ref VPI_IMAGE_BUFFER_HOST_PITCH_LINEAR
 * 
 * @param[out] out A pointer to a structure that will receive the pyramid data to be accessed from host.
 *                 Pass NULL if you're only interested in making sure that the wrapped image is
 *                 updated with the most recent contents from VPI. The image will still be locked.
 *                 + The buffers it points to are valid until the pyramid is unlocked.
 *
 * @retval #VPI_ERROR_INVALID_ARGUMENT  \p pyr is NULL or doesn't represent a \ref VPIPyramid instance.
 * @retval #VPI_ERROR_INVALID_OPERATION \p img doesn't have required backends enabled.
 * @retval #VPI_ERROR_INVALID_ARGUMENT  \p out is NULL.
 * @retval #VPI_ERROR_BUFFER_LOCKED     Pyramid is already locked by either a stream or the user.
 * @retval #VPI_SUCCESS                 Operation executed successfully
 */
VPI_PUBLIC VPIStatus vpiPyramidLockData(VPIPyramid pyr, VPILockMode lock, VPIImageBufferType bufType,
                                        VPIPyramidData *out);

/**
 * Releases the lock on a image pyramid object.
 * This function might have a significant performance overhead (format conversion, layout
 * conversion, host-to-device memory copy).
 *
 * @param[in] pyr Pyramid handle.
 *                + Mandatory, it can't be NULL.
 *
 * @retval #VPI_ERROR_INVALID_ARGUMENT  \p pyr is NULL or doesn't represent a \ref VPIPyramid instance.
 * @retval #VPI_ERROR_INVALID_OPERATION \p pyr doesn't have CPU backend enabled.
 * @retval #VPI_ERROR_INVALID_OPERATION \p pyr isn't locked.
 * @retval #VPI_SUCCESS                 Operation executed successfully.
 */
VPI_PUBLIC VPIStatus vpiPyramidUnlock(VPIPyramid pyr);

/**
 * Creates an image that wraps one pyramid level.
 *
 * The created image doesn't own its contents. Destroying the pyramid while there
 * are images wrapping its levels leads to undefined behavior. If image wraps the
 * base pyramid level, locking the pyramid will also lock the image. Once the image
 * isn't needed anymore, call \ref vpiImageDestroy to free resources.
 *
 * The created image inherits the flags of the wrapped pyramid, including the
 * enabled backends.
 *
 * @param[in] pyr The pyramid whose level will be wrapped.
 *                + Mandatory, it can't be NULL.
 * 
 * @param[in] level Pyramid level to wrap.
 *                  + Must be >= 0.
 * 
 * @param[out] img Pointer to an image handle that will hold the created image.
 *                 + Mandatory, it can't be NULL.
 * 
 * @retval #VPI_ERROR_INVALID_ARGUMENT  Output \p img is NULL.
 * @retval #VPI_ERROR_INVALID_ARGUMENT  \p pyr is NULL.
 * @retval #VPI_ERROR_INVALID_ARGUMENT  \p level outside valid range.
 * @retval #VPI_ERROR_INVALID_ARGUMENT  \p pyr is NULL or doesn't represent a \ref VPIPyramid instance.
 * @retval #VPI_ERROR_INVALID_OPERATION Wrapped image is not created in current context.
 * @retval #VPI_ERROR_INVALID_CONTEXT   Current context was destroyed.
 * @retval #VPI_ERROR_OUT_OF_MEMORY     Not enough resources to create image.
 * @retval #VPI_SUCCESS                 Operation executed successfully.
 */
VPI_PUBLIC VPIStatus vpiImageCreateWrapperPyramidLevel(VPIPyramid pyr, int32_t level, VPIImage *img);

#ifdef __cplusplus
}
#endif

/** @} end of VPI_Pyramid */

#endif /* NV_VPI_PYRAMID_H */
// End content from: Pyramid.h

// Begin content from: Stream.h
/*
 * Copyright 2019-2021 NVIDIA Corporation. All rights reserved.
 *
 * NOTICE TO LICENSEE:
 *
 * This source code and/or documentation ("Licensed Deliverables") are
 * subject to NVIDIA intellectual property rights under U.S. and
 * international Copyright laws.
 *
 * These Licensed Deliverables contained herein is PROPRIETARY and
 * CONFIDENTIAL to NVIDIA and is being provided under the terms and
 * conditions of a form of NVIDIA software license agreement by and
 * between NVIDIA and Licensee ("License Agreement") or electronically
 * accepted by Licensee. Notwithstanding any terms or conditions to
 * the contrary in the License Agreement, reproduction or disclosure
 * of the Licensed Deliverables to any third party without the express
 * written consent of NVIDIA is prohibited.
 *
 * NOTWITHSTANDING ANY TERMS OR CONDITIONS TO THE CONTRARY IN THE
 * LICENSE AGREEMENT, NVIDIA MAKES NO REPRESENTATION ABOUT THE
 * SUITABILITY OF THESE LICENSED DELIVERABLES FOR ANY PURPOSE. IT IS
 * PROVIDED "AS IS" WITHOUT EXPRESS OR IMPLIED WARRANTY OF ANY KIND.
 * NVIDIA DISCLAIMS ALL WARRANTIES WITH REGARD TO THESE LICENSED
 * DELIVERABLES, INCLUDING ALL IMPLIED WARRANTIES OF MERCHANTABILITY,
 * NONINFRINGEMENT, AND FITNESS FOR A PARTICULAR PURPOSE.
 * NOTWITHSTANDING ANY TERMS OR CONDITIONS TO THE CONTRARY IN THE
 * LICENSE AGREEMENT, IN NO EVENT SHALL NVIDIA BE LIABLE FOR ANY
 * SPECIAL, INDIRECT, INCIDENTAL, OR CONSEQUENTIAL DAMAGES, OR ANY
 * DAMAGES WHATSOEVER RESULTING FROM LOSS OF USE, DATA OR PROFITS,
 * WHETHER IN AN ACTION OF CONTRACT, NEGLIGENCE OR OTHER TORTIOUS
 * ACTION, ARISING OUT OF OR IN CONNECTION WITH THE USE OR PERFORMANCE
 * OF THESE LICENSED DELIVERABLES.
 *
 * U.S. Government End Users. These Licensed Deliverables are a
 * "commercial item" as that term is defined at 48 C.F.R. 2.101 (OCT
 * 1995), consisting of "commercial computer software" and "commercial
 * computer software documentation" as such terms are used in 48
 * C.F.R. 12.212 (SEPT 1995) and is provided to the U.S. Government
 * only as a commercial end item. Consistent with 48 C.F.R.12.212 and
 * 48 C.F.R. 227.7202-1 through 227.7202-4 (JUNE 1995), all
 * U.S. Government End Users acquire the Licensed Deliverables with
 * only those rights set forth herein.
 *
 * Any use of the Licensed Deliverables in individual and commercial
 * software must include, in the user documentation and internal
 * comments to the code, the above Disclaimer and U.S. Government End
 * Users Notice.
 */

/**
 * @file Stream.h
 *
 * Declares functions dealing with VPI streams.
 */

#ifndef NV_VPI_STREAM_H
#define NV_VPI_STREAM_H

// #include "Export.h"
// #include "Status.h"
// #include "Types.h"
// #include "Version.h"

/**
 * The main entry-point to the API is the \ref VPIStream object.
 *
 * This object represents a command queue (FIFO) storing a list of
 * commands to execute. Commands might comprise running a particular CV
 * algorithm or signaling an event in a particular backend. This allows the API
 * functions to be executed asynchronously with respect to the calling thread.
 * Invoking any CV function simply pushes a corresponding command to the
 * command queue in the \ref VPIStream instance and immediately returns. The
 * queued commands then get consumed and dispatched to the associated backend
 * device.
 *
 * @defgroup VPI_Stream Stream
 * @ingroup VPI_API_Core
 * @{
 */

#ifdef __cplusplus
extern "C" {
#endif

/** @anchor stream_flags @name Stream-specific flags. */
/**@{*/
#define VPI_STREAM_GREEDY (1ULL << 63) /**< Flushes operations to the backend at every submission. */
/**@}*/

/**
 * Create a stream instance.
 *
 * @param[in] flags Bit field specifying the desired characteristics of the stream.
 *                  + The field must be a combination of zero or more of the following flags:
 *                    - \ref VPIBackend flags.
 *                      Allows algorithms to be submitted to these backends.
 *                      If no backend flags are given and \ref VPI_REQUIRE_BACKENDS is not set,
 *                      it'll consider all backends supported by the active \ref VPIContext.
 *                    - \ref stream_flags "Stream-specific flags".
 *                    - \ref common_flags "Common object flags".
 *                  + If flag \ref VPI_REQUIRE_BACKENDS is given, user must
 *                    pass at least one valid backend that is enabled in current
 *                    context.
 * 
 * @param[out] stream Pointer to memory that will receive the created stream handle.
 *
 * @retval #VPI_ERROR_INVALID_ARGUMENT  Output \p stream handle is NULL.
 * @retval #VPI_ERROR_INVALID_ARGUMENT  \p flags is invalid.
 * @retval #VPI_ERROR_INVALID_ARGUMENT  No backend were given and \ref VPI_REQUIRE_BACKENDS is set.
 * @retval #VPI_ERROR_OUT_OF_MEMORY     Not enough resources to allocate image.
 * @retval #VPI_ERROR_INVALID_CONTEXT   Current context is destroyed.
 * @retval #VPI_ERROR_INVALID_OPERATION Requested backend isn't enabled in current context.
 * @retval #VPI_SUCCESS                 Operation executed successfully.
 */
#if NV_VPI_VERSION_API_AT_MOST(2, 2)
__asm__(".symver vpiStreamCreate,vpiStreamCreate@VPI_2.0");
#endif
VPI_PUBLIC VPIStatus vpiStreamCreate(uint64_t flags, VPIStream *stream);

/**
 * Destroy a stream instance and deallocate all HW resources.
 *
 * This operation will implicitly synchronize the stream to guarantee that all operations
 * submitted to it are completed.
 *
 * @param[in] stream Stream handle to be destroyed.
 *                   Passing NULL is allowed, to which the function simply does nothing.
 */
VPI_PUBLIC void vpiStreamDestroy(VPIStream stream);

/**
 * Submits all pending operations for execution.
 *
 * @param[in] stream Stream handle.
 *                   + Mandatory, it can't be NULL.
 *
 * @retval #VPI_ERROR_INVALID_ARGUMENT \p stream is NULL or doesn't represent a \ref VPIStream instance.
 * @retval #VPI_SUCCESS Operation executed successfully
 */
VPI_PUBLIC VPIStatus vpiStreamFlush(VPIStream stream);

/**
 * Blocks the calling thread until all submitted commands in this stream queue
 * are done (queue is empty). This function call is equivalent to atomically
 * calling \ref vpiEventRecord followed by \ref vpiStreamWaitEvent.
 *
 * The operation will implicitly flush the stream.
 *
 * @param[in] stream Stream handle.
 *                   + Mandatory, it can't be NULL.
 *
 * @retval #VPI_ERROR_INVALID_ARGUMENT \p stream is NULL or doesn't represent a \ref VPIStream instance.
 * @retval #VPI_SUCCESS Operation executed successfully
 */
VPI_PUBLIC VPIStatus vpiStreamSync(VPIStream stream);

/**
 * Pushes a command that blocks the processing of all future commands submitted to the stream until the
 * event is signaled.
 *
 * @param[in] stream Stream handle.
 *                   + Mandatory, it can't be NULL.
 * 
 * @param[in] event Event handle.
 *
 * @retval #VPI_ERROR_INVALID_ARGUMENT Output \p event is invalid.
 * @retval #VPI_ERROR_INVALID_ARGUMENT \p stream is NULL or doesn't represent a \ref VPIStream instance.
 * @retval #VPI_SUCCESS Operation executed successfully
 */
VPI_PUBLIC VPIStatus vpiStreamWaitEvent(VPIStream stream, VPIEvent event);

/**
 * Returns OS-specific handle of the background stream processing thread.
 * 
 * @param[in] stream Stream handle.
 *                   + Mandatory, it can't be NULL.
 * 
 * @param[out] handle Stream processing thread handle.
 * 
 * @retval #VPI_ERROR_INVALID_ARGUMENT \p stream is NULL or doesn't represent a \ref VPIStream instance.
 * @retval #VPI_ERROR_INVALID_ARGUMENT Output \p handle pointer is NULL.
 * @retval #VPI_SUCCESS                Operation executed successfully.
 */
VPI_PUBLIC VPIStatus vpiStreamGetThreadHandle(VPIStream stream, VPINativeThreadHandle *handle);

/** Gets the VPIStream flags passed during its creation.
 *
 * @param[in] stream Stream handle.
 *                   + Mandatory, it can't be NULL.
 * 
 * @param[out] flags Pointer to variable where the flags will be stored into.
 *
 * @retval #VPI_ERROR_INVALID_ARGUMENT \p stream is NULL or doesn't represent a \ref VPIStream instance.
 * @retval #VPI_ERROR_INVALID_ARGUMENT Output \p flags pointer is NULL.
 * @retval #VPI_SUCCESS                Operation executed successfully.
 */
VPI_PUBLIC VPIStatus vpiStreamGetFlags(VPIStream stream, uint64_t *flags);

/**
 * Returns the flags associated with a payload.
 *
 * @ingroup VPI_Payload
 *
 * @param[in] payload Payload to be queried.
 * 
 * @param[out] flags The flags associated with a payload.
 * 
 * @retval #VPI_ERROR_INVALID_ARGUMENT Output \p flags pointer is NULL.
 * @retval #VPI_SUCCESS                Operation executed successfully.
 *
 */
VPI_PUBLIC VPIStatus vpiPayloadGetFlags(VPIPayload payload, uint64_t *flags);

/**
 * Deallocates the payload object and all associated resources.
 *
 * @ingroup VPI_Payload
 *
 * @param[in] payload Payload handle.
 *                    Passing NULL is allowed, to which the function simply does nothing.
 *
 */
VPI_PUBLIC void vpiPayloadDestroy(VPIPayload payload);

#ifdef __cplusplus
}
#endif

/** @} end of VPI_Stream */

#endif /* NV_VPI_STREAM_H */
// End content from: Stream.h

// Begin content from: Event.h
/*
 * Copyright 2019-2021 NVIDIA Corporation. All rights reserved.
 *
 * NOTICE TO LICENSEE:
 *
 * This source code and/or documentation ("Licensed Deliverables") are
 * subject to NVIDIA intellectual property rights under U.S. and
 * international Copyright laws.
 *
 * These Licensed Deliverables contained herein is PROPRIETARY and
 * CONFIDENTIAL to NVIDIA and is being provided under the terms and
 * conditions of a form of NVIDIA software license agreement by and
 * between NVIDIA and Licensee ("License Agreement") or electronically
 * accepted by Licensee. Notwithstanding any terms or conditions to
 * the contrary in the License Agreement, reproduction or disclosure
 * of the Licensed Deliverables to any third party without the express
 * written consent of NVIDIA is prohibited.
 *
 * NOTWITHSTANDING ANY TERMS OR CONDITIONS TO THE CONTRARY IN THE
 * LICENSE AGREEMENT, NVIDIA MAKES NO REPRESENTATION ABOUT THE
 * SUITABILITY OF THESE LICENSED DELIVERABLES FOR ANY PURPOSE. IT IS
 * PROVIDED "AS IS" WITHOUT EXPRESS OR IMPLIED WARRANTY OF ANY KIND.
 * NVIDIA DISCLAIMS ALL WARRANTIES WITH REGARD TO THESE LICENSED
 * DELIVERABLES, INCLUDING ALL IMPLIED WARRANTIES OF MERCHANTABILITY,
 * NONINFRINGEMENT, AND FITNESS FOR A PARTICULAR PURPOSE.
 * NOTWITHSTANDING ANY TERMS OR CONDITIONS TO THE CONTRARY IN THE
 * LICENSE AGREEMENT, IN NO EVENT SHALL NVIDIA BE LIABLE FOR ANY
 * SPECIAL, INDIRECT, INCIDENTAL, OR CONSEQUENTIAL DAMAGES, OR ANY
 * DAMAGES WHATSOEVER RESULTING FROM LOSS OF USE, DATA OR PROFITS,
 * WHETHER IN AN ACTION OF CONTRACT, NEGLIGENCE OR OTHER TORTIOUS
 * ACTION, ARISING OUT OF OR IN CONNECTION WITH THE USE OR PERFORMANCE
 * OF THESE LICENSED DELIVERABLES.
 *
 * U.S. Government End Users. These Licensed Deliverables are a
 * "commercial item" as that term is defined at 48 C.F.R. 2.101 (OCT
 * 1995), consisting of "commercial computer software" and "commercial
 * computer software documentation" as such terms are used in 48
 * C.F.R. 12.212 (SEPT 1995) and is provided to the U.S. Government
 * only as a commercial end item. Consistent with 48 C.F.R.12.212 and
 * 48 C.F.R. 227.7202-1 through 227.7202-4 (JUNE 1995), all
 * U.S. Government End Users acquire the Licensed Deliverables with
 * only those rights set forth herein.
 *
 * Any use of the Licensed Deliverables in individual and commercial
 * software must include, in the user documentation and internal
 * comments to the code, the above Disclaimer and U.S. Government End
 * Users Notice.
 */

/**
 * @file Event.h
 *
 * Functions and structures for dealing with VPI events.
 */

#ifndef NV_VPI_EVENT_H
#define NV_VPI_EVENT_H

// #include "Export.h"
// #include "Status.h"
// #include "Types.h"

#include <stdint.h>

/**
 * A representation of events used in stream synchronization and timing.
 *
 * Each compute function in the API is executed asynchronously with respect to the calling thread,
 * i.e., returns immediately without waiting for the completion. There are two ways of
 * synchronizing with the backend. One is to wait until all the commands in the \ref VPIStream queue
 * are finished using the \ref vpiStreamSync call. This approach, while simple, doesn't allow for
 * fine-grained ("wait for until function X is completed") or inter-device ("before running
 * function A in device B, wait until function C in device D finishes") synchronization. That's
 * where \ref VPIEvent objects come in. Conceptually, they correspond to binary semaphores and are
 * designed to closely mimic events in CUDA API:
 *
 * - Users can capture all commands submitted to a \ref VPIStream instance in an event instance (see
 *   \ref vpiEventRecord). The event is considered completed when all captured commands have been
 *   processed and removed from \ref VPIStream command queue.
 * - Inter-device synchronization is possible with \ref vpiStreamWaitEvent call that pushes a command
 *   to \ref VPIStream queue that blocks processing of future queued commands until given event is
 *   completed.
 * - Host threads can query the event's state with \ref vpiEventQuery
 * - Host threads can block until event is completed with \ref vpiEventSync.
 * - Events can be time-stamped when completed.
 * - Users can compute time-stamp difference between completed events in the same device as well as
 *   between different devices. This implies that internally, the API has to have a notion of
 *   unified time source.
 *
 * @defgroup VPI_Event Event
 * @ingroup VPI_API_Core
 * @{
 *
 */

#ifdef __cplusplus
extern "C" {
#endif

/** @anchor event_flags @name Event-specific flags. */
/**@{*/

/** Disable time-stamping of event signaling.
 * It allows for better performance in operations involving events. */
#define VPI_EVENT_DISABLE_TIMESTAMP (1ULL << 63)
/**@}*/

/**
 * Create an event instance.
 *
 * @param[in] flags Bit field specifying the desired characteristics of the event.
 *                  + The field must be a combination of zero or more of the following flags:
 *                    - \ref VPIBackend flags.
 *                      This even can be used in streams that have these backends enabled.
 *                      If no backend flags are passed and \ref VPI_REQUIRE_BACKENDS flag isn't present,
 *                      it'll consider all backends supported by the active context.
 *                    - \ref event_flags "Event-specific flags".
 *                    - \ref common_flags "Common object flags".
 *                  + If flag \ref VPI_REQUIRE_BACKENDS is given, user must pass at least one valid backend, and
 *                    they all must be enabled in current context.
 * 
 * @param[out] event Pointer to memory that will receive the created event handle.
 *                   + Mandatory parameter, can't be NULL.
 *
 * @retval #VPI_ERROR_INVALID_ARGUMENT  Output \p event handle is NULL.
 * @retval #VPI_ERROR_INVALID_ARGUMENT  \p flags is invalid.
 * @retval #VPI_ERROR_INVALID_ARGUMENT  No backend were given and \ref VPI_REQUIRE_BACKENDS is set.
 * @retval #VPI_ERROR_OUT_OF_MEMORY     Not enough resources to allocate event.
 * @retval #VPI_ERROR_INVALID_CONTEXT   Current context is invalid.
 * @retval #VPI_ERROR_INVALID_OPERATION Requested backend isn't enabled in current context.
 * @retval #VPI_SUCCESS                 Operation executed successfully.
 */
VPI_PUBLIC VPIStatus vpiEventCreate(uint64_t flags, VPIEvent *event);

/**
 * Destroy an event instance as well as all resources it owns.
 *
 * @param[in] event Event handle to be destroyed.
 *                  It can be NULL. In this case, the function doesn't do anything.
 *                  + All streams referencing the event must be idle, or else undefined behavior will ensue.
 */
VPI_PUBLIC void vpiEventDestroy(VPIEvent event);

/**
 * Captures in the event the contents of the stream command queue at the time of this call.
 *
 * When all tasks recorded are finished, the event will be signaled and calls that are waiting
 * for it will be unblocked.
 *
 * This function can be called multiple times on the same event, however existing
 * \ref vpiEventSync / \ref vpiStreamWaitEvent calls are not affected by later calls to \ref vpiEventRecord.
 * This means they will wait for the event completion of the command queue tasks described by the
 * event at the time of the previous \ref vpiEventSync / \ref vpiStreamWaitEvent call.
 *
 * The operation will implicitly flush the stream.
 *
 * @param[in] event An event handle.
 *                  + Mandatory, it can't be NULL.
 * 
 * @param[in] stream A stream handle whose command queue with tasks yet to be
 *                   executed will be recorded in the event.
 *                   + Mandatory, it can't be NULL.
 *
 * @retval #VPI_ERROR_INVALID_ARGUMENT \p event is NULL or doesn't represent an \ref VPIEvent instance.
 * @retval #VPI_ERROR_INVALID_ARGUMENT \p stream is NULL or not valid or doesn't represent \ref VPIStream instance.
 * @retval #VPI_ERROR_INVALID_ARGUMENT Event doesn't have the backend required by the stream enabled.
 * @retval #VPI_ERROR_INTERNAL         Event doesn't have any backends enabled for recording.
 * @retval #VPI_ERROR_INVALID_CONTEXT  Current context is invalid.
 * @retval #VPI_SUCCESS                Operation executed successfully.
 */
VPI_PUBLIC VPIStatus vpiEventRecord(VPIEvent event, VPIStream stream);

/**
 * Blocks the calling thread until the event is signaled.
 *
 * The event is considered signaled when all the tasks captured by
 * \ref vpiEventRecord are completed or when no tasks were captured.
 *
 * @param[in] event An event handle.
 *                  + Mandatory, it can't be NULL.
 *
 * @retval #VPI_ERROR_INVALID_ARGUMENT \p event is NULL or doesn't represent an \ref VPIEvent instance.
 * @retval #VPI_SUCCESS                Operation executed successfully.
 */
VPI_PUBLIC VPIStatus vpiEventSync(VPIEvent event);

/**
 * Queries the status of all work currently captured by the event.
 *
 * @param[in] event An event handle.
 *                  + Mandatory, it can't be NULL.
 * 
 * @param[out] state Pointer to memory that will receive the event state.
 *                   The returned state is only valid when the status returned is \ref VPI_SUCCESS.
 * 
 * @retval #VPI_ERROR_INVALID_ARGUMENT Output \p state pointer is NULL.
 * @retval #VPI_SUCCESS                Operation executed successfully.
 */
VPI_PUBLIC VPIStatus vpiEventQuery(VPIEvent event, VPIEventState *state);

/**
 * Computes the elapsed time in milliseconds between two completed events.
 *
 * @param[in] start An event handle marking the start of the time interval.
   *                + Mandatory, cannot be NULL.
 *                  + Must have been completed/signaled.
 *                  + Must not have been created with \ref VPI_EVENT_DISABLE_TIMESTAMP flag.
 * 
 * @param[in] end An event handle marking the end of the time interval
 *                + Mandatory, cannot be NULL.
 *                + Must have been completed/signaled.
 *                + Must not have been created with \ref VPI_EVENT_DISABLE_TIMESTAMP flag.
 * 
 * @param[out] msec A pointer to a variable which will be set to the time difference between the
 *                  events signaling.
 *                  + Mandatory, cannot be NULL.
 *
 * @retval #VPI_ERROR_INVALID_ARGUMENT  \p start or \p end is NULL or don't represent an \ref VPIEvent instance.
 * @retval #VPI_ERROR_INVALID_ARGUMENT  Output \p msec pointer is NULL.
 * @retval #VPI_ERROR_INVALID_OPERATION At least one event was created with timestamps disabled.
 * @retval #VPI_ERROR_NOT_READY         At least one event is not completed/signaled.
 * @retval #VPI_SUCCESS                 Operation executed successfully.
 */
VPI_PUBLIC VPIStatus vpiEventElapsedTimeMillis(VPIEvent start, VPIEvent end, float *msec);

/**
 * Returns the event flags passed during event creation.
 *
 * @param[in] event An event handle.
 *                  + Mandatory, cannot be NULL.
 * 
 * @param[out] flags Pointer to memory that will hold the event flags.
 *                   + It can't be NULL.
 *
 * @retval #VPI_ERROR_INVALID_ARGUMENT \p event is NULL or doesn't represent an \ref VPIEvent instance.
 * @retval #VPI_ERROR_INVALID_ARGUMENT \p flags is NULL.
 * @retval #VPI_SUCCESS                Operation executed successfully.
 */
VPI_PUBLIC VPIStatus vpiEventGetFlags(VPIEvent event, uint64_t *flags);

#ifdef __cplusplus
}
#endif

/** @} end of VPI_Event */

#endif /* NV_VPI_EVENT_H */
// End content from: Event.h

// Begin content from: Context.h
/*
 * Copyright 2019-2021 NVIDIA Corporation. All rights reserved.
 *
 * NOTICE TO LICENSEE:
 *
 * This source code and/or documentation ("Licensed Deliverables") are
 * subject to NVIDIA intellectual property rights under U.S. and
 * international Copyright laws.
 *
 * These Licensed Deliverables contained herein is PROPRIETARY and
 * CONFIDENTIAL to NVIDIA and is being provided under the terms and
 * conditions of a form of NVIDIA software license agreement by and
 * between NVIDIA and Licensee ("License Agreement") or electronically
 * accepted by Licensee. Notwithstanding any terms or conditions to
 * the contrary in the License Agreement, reproduction or disclosure
 * of the Licensed Deliverables to any third party without the express
 * written consent of NVIDIA is prohibited.
 *
 * NOTWITHSTANDING ANY TERMS OR CONDITIONS TO THE CONTRARY IN THE
 * LICENSE AGREEMENT, NVIDIA MAKES NO REPRESENTATION ABOUT THE
 * SUITABILITY OF THESE LICENSED DELIVERABLES FOR ANY PURPOSE. IT IS
 * PROVIDED "AS IS" WITHOUT EXPRESS OR IMPLIED WARRANTY OF ANY KIND.
 * NVIDIA DISCLAIMS ALL WARRANTIES WITH REGARD TO THESE LICENSED
 * DELIVERABLES, INCLUDING ALL IMPLIED WARRANTIES OF MERCHANTABILITY,
 * NONINFRINGEMENT, AND FITNESS FOR A PARTICULAR PURPOSE.
 * NOTWITHSTANDING ANY TERMS OR CONDITIONS TO THE CONTRARY IN THE
 * LICENSE AGREEMENT, IN NO EVENT SHALL NVIDIA BE LIABLE FOR ANY
 * SPECIAL, INDIRECT, INCIDENTAL, OR CONSEQUENTIAL DAMAGES, OR ANY
 * DAMAGES WHATSOEVER RESULTING FROM LOSS OF USE, DATA OR PROFITS,
 * WHETHER IN AN ACTION OF CONTRACT, NEGLIGENCE OR OTHER TORTIOUS
 * ACTION, ARISING OUT OF OR IN CONNECTION WITH THE USE OR PERFORMANCE
 * OF THESE LICENSED DELIVERABLES.
 *
 * U.S. Government End Users. These Licensed Deliverables are a
 * "commercial item" as that term is defined at 48 C.F.R. 2.101 (OCT
 * 1995), consisting of "commercial computer software" and "commercial
 * computer software documentation" as such terms are used in 48
 * C.F.R. 12.212 (SEPT 1995) and is provided to the U.S. Government
 * only as a commercial end item. Consistent with 48 C.F.R.12.212 and
 * 48 C.F.R. 227.7202-1 through 227.7202-4 (JUNE 1995), all
 * U.S. Government End Users acquire the Licensed Deliverables with
 * only those rights set forth herein.
 *
 * Any use of the Licensed Deliverables in individual and commercial
 * software must include, in the user documentation and internal
 * comments to the code, the above Disclaimer and U.S. Government End
 * Users Notice.
 */

/**
 * @file Context.h
 *
 * Functions and structures for dealing with VPI contexts.
 */

#ifndef NV_VPI_CONTEXT_H
#define NV_VPI_CONTEXT_H

// #include "Export.h"
// #include "Status.h"
// #include "Types.h"
// #include "Version.h"

#include <stdint.h>

/**
 * Context is the implicit owner of objects created when it's active and their properties.
 *
 * This is a top-level class that manages the lifetime and properties of all
 * other API objects.
 * Specifically, it has the following properties:
 * - Thread-specific - every thread within an application has one current \ref VPIContext instance set.
 *   If no instance has been explicitly set for a particular thread, all API calls from this thread
 *   will use a process-specific default context instance instead.
 * - Configurable - the user can specify during construction which kinds of backends are enabled
 *   for this context. This effectively allows to mask support for a particular hardware. For
 *   example, creating a \ref VPIStream instance for a CUDA backend will fail
 *   if the current context doesn't have the \ref VPI_BACKEND_CUDA flag set.
 *   When no backends are passed to context creation, all backends supported by
 *   the running platform are enabled in it. For example, when passing '0' as
 *   context flags (no backends) and only CPU and CUDA backends are available,
 *   \ref vpiContextGetFlags will return `\ref VPI_BACKEND_CUDA|\ref VPI_BACKEND_CPU` flags.
 * - Allows for association with a specific CUDA driver API `CUcontext` instance - this should permit
 *   multi-GPU processing.
 * - Sharing buffers between different contexts is not permitted.
 *
 * @defgroup VPI_Context Context
 * @ingroup VPI_API_Core
 * @{
 */

#ifdef __cplusplus
extern "C" {
#endif

/**
 * @private
 * Forward declaration of CUDA context handle
 */
typedef struct CUctx_st *CUcontext;

/** @anchor context_flags @name Special contexts */
/**@{*/
#define VPI_GLOBAL_CONTEXT ((VPIContext)0x610BA1C1D) /**< Global context identifier */
/**@}*/

/**
 * Represents a context was destroyed or is invalid for some other reason.
 */
#define VPI_INVALID_CONTEXT ((VPIContext)-1)

/**
 * Create a context instance.
 *
 * The context owns the following objects that are created when it is active:
 * - \ref VPIImage
 * - \ref VPIArray
 * - \ref VPIPyramid
 * - \ref VPIStream
 * - \ref VPIEvent
 * - \ref VPIPayload
 *
 * The backends enabled in the context restrict the allowed backends that can be
 * enabled when creating the objects when context is active.
 *
 * The context is created and internal resources are allocated. It isn't
 * assigned to the calling thread, though. For that, use either
 * \ref vpiContextSetCurrent or \ref vpiContextPush.
 *
 * @param[in] flags Bit field specifying the desired characteristics of the context.
 *                  + The field must be a combination of zero or more of the following flags:
 *                    - \ref VPIBackend flags.
 *                      Defines the set of backends that can be enabled during object
 *                      creation when this context is active.
 *                      If no backend flags are given, VPI will enable all
 *                      backends supported by the running platform.
 *                    - \ref context_flags "Context-specific flags".
 *                    - \ref common_flags "Common object flags".
 *                  + If backends are given, their corresponding hardware must be available.
 * 
 * @param[out] ctx Pointer to memory that will receive the new context handle.
 *
 * @retval #VPI_ERROR_INVALID_ARGUMENT  Output \p ctx is NULL.
 * @retval #VPI_ERROR_INVALID_ARGUMENT  \p flags is invalid.
 * @retval #VPI_ERROR_INVALID_ARGUMENT  No backend were given and \ref VPI_REQUIRE_BACKENDS is set.
 * @retval #VPI_ERROR_INVALID_OPERATION Requested backend isn't available in current system.
 * @retval #VPI_SUCCESS                 Operation executed successfully.
 */
VPI_PUBLIC VPIStatus vpiContextCreate(uint64_t flags, VPIContext *ctx);

/**
 * Create a context instance that wraps a CUDA context.
 *
 * CUDA operations will all under the wrapped context whenever the created
 * context is active.
 *
 * \note Currently VPI doesn't do anything with the CUDA context, so currently the
 *       call performs exactly like \ref vpiContextCreate.
 *
 * Behavior regarding objects created when this context is active is same as
 * \ref vpiContextCreate.
 *
 * @param[in] flags Bit field specifying the desired characteristics of the context.
 *                  + The field must be a combination of zero or more of the following flags:
 *                    - \ref VPIBackend flags.
 *                      Defines the set of backends that can be enabled during object
 *                      creation when this context is active.
 *                      If no backend flags are given, VPI will enable all
 *                      backends supported by the running platform.
 *                    - \ref context_flags "Context-specific flags".
 *                    - \ref common_flags "Common object flags".
 *                  + If backends are given, their corresponding hardware must be available.
 * 
 * @param[in] cudaCtx CUDA context handle to be wrapped.
 *                    + Mandatory, it can't be NULL.
 *                    + It must be a valid CUDA context.
 * 
 * @param[out] ctx Pointer to memory that will receive the created context handle.
 *
 * @retval #VPI_ERROR_INVALID_ARGUMENT  Output \p ctx is NULL.
 * @retval #VPI_ERROR_INVALID_ARGUMENT  \p flags is invalid.
 * @retval #VPI_ERROR_INVALID_ARGUMENT  \p cudaCtx is NULL or doesn't represent a valid CUDA context.
 * @retval #VPI_ERROR_OUT_OF_MEMORY     Not enough resources to create context.
 * @retval #VPI_ERROR_INVALID_OPERATION Requested backend isn't available in current system.
 * @retval #VPI_SUCCESS                 Operation executed successfully.
 */
VPI_PUBLIC VPIStatus vpiContextCreateWrapperCUDA(uint64_t flags, CUcontext cudaCtx, VPIContext *ctx);

/**
 * Destroy a context instance as well as all resources it owns.
 *
 * The context will be destroyed regardless of how many threads it is active in. It is the
 * responsibility of the calling function to ensure that no API call issues using ctx while
 * \ref vpiContextDestroy is executing.
 *
 * Upon context destruction, all streams associated with it will be synced, then all objects
 * associated with it will be destroyed.
 *
 * If context is current to the calling thread, then it will also be popped from the current thread's
 * context stack as though \ref vpiContextPop was called. If the context is current to other threads, then
 * it'll will remain current to those threads, and attempting to access it from those threads will
 * result in the error \ref VPI_ERROR_INVALID_CONTEXT.
 *
 * @param[in] ctx Context handle.
 *                Passing NULL is allowed, to which the function simply does nothing.
 *                Passing \ref VPI_GLOBAL_CONTEXT also makes it do nothing as it's
 *                impossible to destroy the global context.
 */
VPI_PUBLIC void vpiContextDestroy(VPIContext ctx);

/**
 * Controls low-level task parallelism of CPU devices owned by the context.
 *
 * This function allows the user to overload the parallel_for implementation
 * used by the CPU backend. Changing this parallel_for implementation on a context
 * that is performing CPU processing is undefined and might lead to application
 * crashes.
 *
 * When a context is created, the parallel_for implementation used is the default.
 * It allows for each CPU task to equaly use all cores available.
 *
 * @param[in] ctx Context handle.
 *                + Mandatory, it can't be NULL or invalid.
 * 
 * @param[in] config A pointer to parallel_for configuration.
 *                   Passing NULL will make the context to fallback to its default
 *                   internal implementation.
 *
 * @retval #VPI_ERROR_INVALID_ARGUMENT \p ctx is NULL or invalid.
 * @retval #VPI_SUCCESS                Operation executed successfully .
 */
VPI_PUBLIC VPIStatus vpiContextSetParallelFor(VPIContext ctx, const VPIParallelForConfig *config);

/**
 * Returns parameters set by \ref vpiContextSetParallelFor.
 *
 * @param[in] ctx Context handle.
 *                + Mandatory, it can't be NULL or invalid.
 * 
 * @param[out] config A pointer to parallel_for configuration.
 *                    + Mandatory, it can't be NULL.
 *
 * @retval #VPI_ERROR_INVALID_ARGUMENT Output \p config pointer is NULL.
 * @retval #VPI_ERROR_INVALID_ARGUMENT \p ctx is NULL or invalid.
 * @retval #VPI_SUCCESS                Operation executed successfully.
 */
#if NV_VPI_VERSION_API_AT_MOST(2, 2)
__asm__(".symver vpiContextGetParallelFor,vpiContextGetParallelFor@VPI_2.0");
#endif
VPI_PUBLIC VPIStatus vpiContextGetParallelFor(VPIContext ctx, VPIParallelForConfig *config);

/**
 * Gets the context for the calling thread.
 *
 * @param[out] ctx Pointer to a context handle.
 *                 + Mandatory, it can't be NULL or invalid.
 *
 * @retval #VPI_ERROR_INVALID_ARGUMENT Output \p ctx is NULL.
 * @retval #VPI_ERROR_INVALID_CONTEXT  Current context is destroyed.
 * @retval #VPI_SUCCESS                Operation executed successfully
 */
VPI_PUBLIC VPIStatus vpiContextGetCurrent(VPIContext *ctx);

/**
 * Sets the context for the calling thread.
 *
 * If the context stack isn't empty, this function will replace the top of the stack (current context)
 * of thread.
 *
 * @param[in] ctx Context handle.
 *                + Mandatory, it can't be NULL or invalid;
 *
 * @retval #VPI_ERROR_INVALID_ARGUMENT \p ctx is NULL or invalid value.
 * @retval #VPI_SUCCESS                Operation executed successfully.
 */
VPI_PUBLIC VPIStatus vpiContextSetCurrent(VPIContext ctx);

/**
 * Pushes the context to a per-thread context stack and sets this context as the current context
 * for the calling thread.
 * 
 * + At most 8 contexts can be pushed to the stack.
 *
 * @param[in] ctx Context handle.
 *                + Mandatory, it can't be NULL.
 *                + It must be a valid context.
 *
 * @retval #VPI_ERROR_INVALID_CONTEXT   \p ctx is invalid.
 * @retval #VPI_ERROR_INVALID_ARGUMENT  \p ctx is NULL.
 * @retval #VPI_ERROR_INVALID_OPERATION Stack size outside valid range.
 * @retval #VPI_ERROR_INVALID_CONTEXT   Current context is destroyed.
 * @retval #VPI_SUCCESS                 Operation executed successfully
 */
VPI_PUBLIC VPIStatus vpiContextPush(VPIContext ctx);

/**
 * Pops a context from a per-thread context stack and saves it to the ctx variable.
 *
 * After the pop operation, the context on top of context stack is current (active) for the calling thread.
 *
 * + The context stack cannot be empty.
 * 
 * @param[out] ctx Pointer to a context handle that receives the popped context.
 *                 If NULL, it'll still pop the context, but won't return it.
 *
 * @retval #VPI_ERROR_INVALID_OPERATION Cannot pop from empty stack.
 * @retval #VPI_SUCCESS                 Operation executed successfully.
 */
VPI_PUBLIC VPIStatus vpiContextPop(VPIContext *ctx);

/**
 * Get the current context flags.
 *
 * This function can be used to verify underlying backend support of current context.
 *
 * @param[in] ctx Context handle.
 *                + Mandatory, it can't be NULL or invalid;
 * 
 * @param[out] flags Pointer to a variable which will be set to the current context flags.
 *                   + Mandatory, it can't be NULL.
 *
 * @retval #VPI_ERROR_INVALID_ARGUMENT  Output \p flags is NULL.
 * @retval #VPI_ERROR_INVALID_ARGUMENT  \p ctx is NULL.
 * @retval #VPI_ERROR_INVALID_CONTEXT   \p ctx is invalid.
 * @retval #VPI_ERROR_INVALID_CONTEXT   Current context is destroyed.
 * @retval #VPI_SUCCESS                 Operation executed successfully.
 */
VPI_PUBLIC VPIStatus vpiContextGetFlags(VPIContext ctx, uint64_t *flags);

#ifdef __cplusplus
}
#endif

/** @} end of VPI_Context */

#endif /* NV_VPI_CONTEXT_H */
// End content from: Context.h

// Begin content from: Array.h
/*
 * Copyright 2019-2021 NVIDIA Corporation. All rights reserved.
 *
 * NOTICE TO LICENSEE:
 *
 * This source code and/or documentation ("Licensed Deliverables") are
 * subject to NVIDIA intellectual property rights under U.S. and
 * international Copyright laws.
 *
 * These Licensed Deliverables contained herein is PROPRIETARY and
 * CONFIDENTIAL to NVIDIA and is being provided under the terms and
 * conditions of a form of NVIDIA software license agreement by and
 * between NVIDIA and Licensee ("License Agreement") or electronically
 * accepted by Licensee. Notwithstanding any terms or conditions to
 * the contrary in the License Agreement, reproduction or disclosure
 * of the Licensed Deliverables to any third party without the express
 * written consent of NVIDIA is prohibited.
 *
 * NOTWITHSTANDING ANY TERMS OR CONDITIONS TO THE CONTRARY IN THE
 * LICENSE AGREEMENT, NVIDIA MAKES NO REPRESENTATION ABOUT THE
 * SUITABILITY OF THESE LICENSED DELIVERABLES FOR ANY PURPOSE. IT IS
 * PROVIDED "AS IS" WITHOUT EXPRESS OR IMPLIED WARRANTY OF ANY KIND.
 * NVIDIA DISCLAIMS ALL WARRANTIES WITH REGARD TO THESE LICENSED
 * DELIVERABLES, INCLUDING ALL IMPLIED WARRANTIES OF MERCHANTABILITY,
 * NONINFRINGEMENT, AND FITNESS FOR A PARTICULAR PURPOSE.
 * NOTWITHSTANDING ANY TERMS OR CONDITIONS TO THE CONTRARY IN THE
 * LICENSE AGREEMENT, IN NO EVENT SHALL NVIDIA BE LIABLE FOR ANY
 * SPECIAL, INDIRECT, INCIDENTAL, OR CONSEQUENTIAL DAMAGES, OR ANY
 * DAMAGES WHATSOEVER RESULTING FROM LOSS OF USE, DATA OR PROFITS,
 * WHETHER IN AN ACTION OF CONTRACT, NEGLIGENCE OR OTHER TORTIOUS
 * ACTION, ARISING OUT OF OR IN CONNECTION WITH THE USE OR PERFORMANCE
 * OF THESE LICENSED DELIVERABLES.
 *
 * U.S. Government End Users. These Licensed Deliverables are a
 * "commercial item" as that term is defined at 48 C.F.R. 2.101 (OCT
 * 1995), consisting of "commercial computer software" and "commercial
 * computer software documentation" as such terms are used in 48
 * C.F.R. 12.212 (SEPT 1995) and is provided to the U.S. Government
 * only as a commercial end item. Consistent with 48 C.F.R.12.212 and
 * 48 C.F.R. 227.7202-1 through 227.7202-4 (JUNE 1995), all
 * U.S. Government End Users acquire the Licensed Deliverables with
 * only those rights set forth herein.
 *
 * Any use of the Licensed Deliverables in individual and commercial
 * software must include, in the user documentation and internal
 * comments to the code, the above Disclaimer and U.S. Government End
 * Users Notice.
 */

/**
 * @file Array.h
 *
 * Functions and structures for dealing with VPI arrays.
 */

#ifndef NV_VPI_ARRAY_H
#define NV_VPI_ARRAY_H

// #include "Export.h"
// #include "Status.h"
// #include "Types.h"

#include <stdint.h>

/**
 * An abstract representation of a generic 1D array.
 *
 * There are two ways of creating 1D array containers with the API. The most
 * basic one is to use \ref vpiArrayCreate to allocate and initialize an empty
 * (zeroed) \ref VPIArray object. The memory for the array data is allocated
 * and managed by the backend implementation. Parameters such as capacity and
 * type are immutable and specified at the construction time. The internal
 * memory layout is also backend-specific. More importantly, efficient exchange
 * of array data between different hardware blocks might force the
 * implementation to allocate the memory in multiple memory pools (e.g. dGPU
 * and system DRAM). In some scenarios (to optimize performance and memory use)
 * it might be beneficial to constrain the internal allocation policy to
 * support only a particular set of backends.
 *
 * To enable interop with existing host- or gpu-side code, the user can also
 * create an array object that wraps a user-allocated (and managed) array
 * data. Similarly to \ref vpiArrayCreate, array parameters passed to
 * \ref vpiArrayCreateWrapper are fixed.
 *
 * The wrapped memory can be redefined by calling \ref vpiArraySetWrapper
 * as long as the new wrapped memory has the same buffer type, capacity, type
 * as the one originally wrapped. It's more efficient to create the \ref VPIArray
 * wrapper once and reuse it later then creating and destroying it all the
 * time.
 *
 * The set of \ref vpiArrayLockData / \ref vpiArrayUnlock allows to read from/write
 * to the array data from host. These functions are non-blocking and oblivious
 * to the stream command queue so it's up to the user to make sure that all
 * pending operations using this array as input or output are finished. Also,
 * depending on which device the memory is allocated, lock/unlock operation
 * might be time-consuming and, for example, involve copying data over PCIe bus
 * for dGPUs.
 *
 * @defgroup VPI_Array Array
 * @ingroup VPI_API_Core
 * @{
 *
 */

// #include "ArrayType.h"

#ifdef __cplusplus
extern "C" {
#endif

/** Stores information about array characteristics and content.
 */

/** Represents array information as an array of structures (AOS). */
typedef struct VPIArrayBufferAOS
{
    /** Type of each array element. */
    VPIArrayType type;

    /** Points to the number of elements in the array.
     *  + Must be >= 0. */
    int32_t *sizePointer;

    /** Maximum number of elements that the array can hold.
     *  + Must be >= 0. */
    int32_t capacity;

    /** Size in bytes of each array element.
     *  + Must be >= 0. 
     *  + Must be at least as large as the element size.
     *  + Must be a multiple of the element size. */
    int32_t strideBytes;

    /** Points to the first element of the array. */
    void *data;
} VPIArrayBufferAOS;

/** Represents how the array data is stored. */
typedef enum
{
    /** Invalid buffer type.
     *  This is commonly used to inform that no buffer type was selected. */
    VPI_ARRAY_BUFFER_INVALID,

    /** Host-accessible array-of-structures. */
    VPI_ARRAY_BUFFER_HOST_AOS,

    /** CUDA-accessible array-of-structures. */
    VPI_ARRAY_BUFFER_CUDA_AOS,

} VPIArrayBufferType;

/** Represents the availablemethods to access array contents.
 * The correct method depends on \ref VPIArrayData::bufferType . */
typedef struct VPIArrayBufferRec
{
    /** Array stored in array-of-structures layout.
     * To be used when \ref VPIArrayData::bufferType is:
     * - \ref VPI_ARRAY_BUFFER_HOST_AOS
     * - \ref VPI_ARRAY_BUFFER_CUDA_AOS
     */
    VPIArrayBufferAOS aos;

} VPIArrayBuffer;

/** Stores information about array characteristics and contents. */
typedef struct VPIArrayDataRec
{
    /** Type of array buffer.
     *  It defines which member of the \ref VPIArrayBuffer tagged union that
     *  must be used to access the array contents. */
    VPIArrayBufferType bufferType;

    /** Stores the array contents. */
    VPIArrayBuffer buffer;

} VPIArrayData;

/**
 * Create an empty array instance.
 *
 * Array data is zeroed. Maximum capacity of the array is fixed and defined at the
 * construction-time. Array size is set to zero. 
 * The VPIArray object owns the allocated memory.
 *
 * @param[in] capacity Array capacity in elements. 
 *                     + Must be >= 0.
 * 
 * @param[in] type Type of each array element.
 *                 + Can't be \ref VPI_ARRAY_TYPE_INVALID.
 * 
 * @param[in] flags Bit field specifying the desired characteristics of the array.
 *                  + The field must be a combination of zero or more of the following flags:
 *                    - \ref VPIBackend flags.
 *                      This array can be used in algorithms running in these backends.
 *                      If no backend flags are passed and \ref VPI_REQUIRE_BACKENDS flag isn't present,
 *                      it'll consider all backends supported by the active context.
 *                    - \ref common_flags "Common object flags".
 *                  + If flag \ref VPI_REQUIRE_BACKENDS is given, user must pass at least one valid backend, and
 *                    they all must be enabled in current context.
 * 
 * @param[out] array Pointer to memory that will receive the created array handle.
 *
 * @retval #VPI_ERROR_INVALID_ARRAY_TYPE Invalid \p type.
 * @retval #VPI_ERROR_INVALID_ARGUMENT   Invalid \p flags.
 * @retval #VPI_ERROR_INVALID_ARGUMENT   \p capacity outside valid range.
 * @retval #VPI_ERROR_INVALID_ARGUMENT   \p array is NULL or doesn't represent a \ref VPIArray instance.
 * @retval #VPI_ERROR_INVALID_ARGUMENT   No backend were given and \ref VPI_REQUIRE_BACKENDS is set.
 * @retval #VPI_ERROR_OUT_OF_MEMORY      Not enough resources to allocate array.
 * @retval #VPI_ERROR_INVALID_CONTEXT    Current context is destroyed.
 * @retval #VPI_ERROR_INVALID_OPERATION  Requested backend isn't enabled in current context.
 * @retval #VPI_SUCCESS                  Operation executed successfully.
 */
VPI_PUBLIC VPIStatus vpiArrayCreate(int32_t capacity, VPIArrayType type, uint64_t flags, VPIArray *array);

/**
 * Create an array object by wrapping an existing host memory block.
 *
 * The returned handle must be destroyed when not being used anymore by calling \ref vpiArrayDestroy.
 *
 * The object doesn't own the wrapped memory. The user is still responsible for wrapped memory lifetime, which
 * must be valid until the array object is destroyed.
 *
 * @param[in] data Pointer to structure with memory buffer to be wrapped.
 *                      + Mandatory, it can't be NULL.
 * 
 * @param[in] flags Bit field specifying the desired characteristics of the array.
 *                  Depending on some buffer types, the following flags will be added automatically:
 *                  | Buffer type                    | Added flag             |
 *                  |--------------------------------|------------------------|
 *                  | \ref VPI_ARRAY_BUFFER_HOST_AOS | \ref VPI_BACKEND_CPU   | 
 *                  | \ref VPI_ARRAY_BUFFER_CUDA_AOS | \ref VPI_BACKEND_CUDA  |
 *
 *                  + The field must be a combination of zero or more of the following flags:
 *                    - \ref VPIBackend flags.
 *                      This array can be used in algorithms running in these backends.
 *                      If no backend flags are passed and \ref VPI_REQUIRE_BACKENDS flag isn't present,
 *                      it'll consider all backends supported by the active context.
 *                    - \ref common_flags "Common object flags".
 *                  + If backends are given and \ref VPI_REQUIRE_BACKENDS is
 *                    set, they all must enabled in current context.
 *                  + If backends are automatically added, they must be enabled
 *                    in current context.
 * 
 * @param[out] array Pointer to memory that will receive the created array handle.
 *
 * @retval #VPI_ERROR_INVALID_ARGUMENT  \p array is NULL.
 * @retval #VPI_ERROR_INVALID_ARGUMENT  \p data is NULL or contains invalid/unsupported values.
 * @retval #VPI_ERROR_INVALID_ARGUMENT  Buffer type in \p data isn't supported.
 * @retval #VPI_ERROR_INVALID_ARGUMENT  No backend were given and \ref VPI_REQUIRE_BACKENDS is set.
 * @retval #VPI_ERROR_OUT_OF_MEMORY     Not enough resources to create array.
 * @retval #VPI_ERROR_INVALID_CONTEXT   Current context is destroyed.
 * @retval #VPI_ERROR_INVALID_OPERATION Requested backend isn't enabled in current context.
 * @retval #VPI_ERROR_INVALID_OPERATION Automatically added backend flags aren't enabled in current context.
 * @retval #VPI_SUCCESS                 Operation executed successfully.
 */
VPI_PUBLIC VPIStatus vpiArrayCreateWrapper(const VPIArrayData *data, uint64_t flags, VPIArray *array);

/**
 * Redefines the wrapped memory buffer in an existing \ref VPIArray wrapper.
 *
 * This operation is efficient and does not allocate memory. The wrapped memory will be
 * accessible to the same backends specified during wrapper creation.
 *
 * The wrapped memory must not be deallocated while it's still being wrapped.
 *
 * @param[in] array Handle to array.
 *                  + It must have been created by \ref vpiArrayCreateWrapper.
 *                  + Array must not be locked.
 * 
 * @param[in] data Pointer to structure with host memory to be wrapped.
 *                 + Mandatory, it can't be NULL.
 *                 + The existing wrapped array and the new one must have same capacity and element type.
 *                 + The old and new buffer types must match.
 *                 + The wrapped memory must point to a buffer that corresponds to the given buffer type.
 *
 * @retval #VPI_ERROR_INVALID_ARGUMENT  \p data is NULL.
 * @retval #VPI_ERROR_INVALID_ARGUMENT  \p data has an unsupported buffer type.
 * @retval #VPI_ERROR_INVALID_ARGUMENT  New and old buffer types don't match.
 * @retval #VPI_ERROR_INVALID_OPERATION \p array is not created suing vpiArrayCreateWrapper.
 * @retval #VPI_ERROR_INVALID_OPERATION \p data capacity and/or format don't match \p array.
 * @retval #VPI_ERROR_INVALID_OPERATION \p array is locked.
 * @retval #VPI_SUCCESS                 Operation executed successfully.
 */
VPI_PUBLIC VPIStatus vpiArraySetWrapper(VPIArray array, const VPIArrayData *data);

/**
 * Destroy an array instance.
 *
 * This function deallocates all resources allocated by the array creation function.
 * When destroying an VPIArray wrapper, the wrapped memory itself isn't deallocated.
 *
 * @param[in] array Array handle to be destroyed.
 *                  Passing NULL is allowed, to which the function simply does nothing.
 *                  + Array must not be in use by any stream, or else undefined behavior will ensue.
 */
VPI_PUBLIC void vpiArrayDestroy(VPIArray array);

/**
 * Returns the array size in elements.
 *
 * @param[in] array A valid array handle.
 *                  + Mandatory, it can't be NULL.
 * 
 * @param[out] size A pointer to a variable which will be set to the size of the array.
 *                  + Mandatory, it can't be NULL.
 *
 * @retval #VPI_ERROR_INVALID_ARGUMENT \p array is NULL or doesn't represent a \ref VPIArray instance.
 * @retval #VPI_ERROR_INVALID_ARGUMENT Output \p size pointer is NULL.
 * @retval #VPI_SUCCESS                Operation executed successfully.
 */
VPI_PUBLIC VPIStatus vpiArrayGetSize(VPIArray array, int32_t *size);

/**
 * Set the array size in elements.
 *
 * @param[in] array A valid array handle.
 *                  + Mandatory, it can't be NULL.
 * 
 * @param[in] size The new size of the array. 
 *                 + Must be less than or equal to array's capacity.
 *                 + Must be >= 0.
 *
 * @retval #VPI_ERROR_INVALID_ARGUMENT \p array is NULL or doesn't represent a \ref VPIArray instance.
 * @retval #VPI_ERROR_INVALID_ARGUMENT Input \p size outside valid range.
 * @retval #VPI_SUCCESS                Operation executed successfully.
 */
VPI_PUBLIC VPIStatus vpiArraySetSize(VPIArray array, int32_t size);

/**
 * Returns the array capacity in elements.
 *
 * @param[in] array A valid array handle.
 *                  + Mandatory, it can't be NULL.
 * 
 * @param[out] capacity A pointer to a variable which will be set to the capacity of the array.
 *                      + Mandatory, it can't be NULL.
 *
 * @retval #VPI_ERROR_INVALID_ARGUMENT \p array is NULL or doesn't represent a \ref VPIArray instance.
 * @retval #VPI_ERROR_INVALID_ARGUMENT Output \p capacity pointer is NULL.
 * @retval #VPI_SUCCESS                Operation executed successfully
 */
VPI_PUBLIC VPIStatus vpiArrayGetCapacity(VPIArray array, int32_t *capacity);

/**
 * Returns the array stride (distance between two consecutive elements) in bytes.
 *
 * @param[in] array A valid array handle.
 *                  + Mandatory, it can't be NULL.
 * 
 * @param[out] strideBytes A pointer to a variable which will be set to the stride of the array element, in bytes.
 *                         + Mandatory, it can't be NULL.
 *
 * @retval #VPI_ERROR_INVALID_ARGUMENT \p array is NULL or doesn't represent a \ref VPIArray instance.
 * @retval #VPI_ERROR_INVALID_ARGUMENT Output \p strideBytes pointer is NULL.
 * @retval #VPI_SUCCESS                Operation executed successfully.
 */
VPI_PUBLIC VPIStatus vpiArrayGetStrideBytes(VPIArray array, int32_t *strideBytes);

/**
 * Returns the array flags.
 *
 * @param[in] array A valid array handle.
 *                  + Mandatory, it can't be NULL.
 * 
 * @param[out] flags A pointer where the flags will be written to.
 *                   + Mandatory, it can't be NULL.
 *
 * @retval #VPI_ERROR_INVALID_ARGUMENT \p array is NULL or doesn't represent a \ref VPIArray instance.
 * @retval #VPI_ERROR_INVALID_ARGUMENT Output \p flags pointer is NULL.
 * @retval #VPI_SUCCESS                Operation executed successfully.
 */
VPI_PUBLIC VPIStatus vpiArrayGetFlags(VPIArray array, uint64_t *flags);

/**
 * Returns the array type.
 *
 * @param[in] array A valid array handle.
 *                  + Mandatory, it can't be NULL.
 * 
 * @param[out] type A pointer where the array type will be written to.
 *                  + Mandatory, it can't be NULL.
 *
 * @retval #VPI_ERROR_INVALID_ARGUMENT \p array is NULL or doesn't represent a \ref VPIArray instance.
 * @retval #VPI_ERROR_INVALID_ARGUMENT Output \p type pointer is NULL.
 * @retval #VPI_SUCCESS                Operation executed successfully.
 */
VPI_PUBLIC VPIStatus vpiArrayGetType(VPIArray array, VPIArrayType *type);

/**
 * Acquires the lock on an array object.
 *
 * Array locking is required when the array object wraps externally-accessible buffers,
 * and these buffers will be accessed outside VPI. As long as the lock is held, any
 * attempt of VPI to access the array in a mode not compatible with the lock mode will
 * result in asynchronous stream errors, \ref VPI_ERROR_BUFFER_LOCKED.
 *
 * The array can be locked multiple times. Each lock operation increments a
 * counter and must be matched by a corresponding \ref vpiArrayUnlock
 * call. Lock will fail if the array is being used by a stream.
 *
 * @param[in] array Array to be locked.
 *                  + Mandatory, it can't be NULL.
 *                  + Array must not be locked in a mode that is incompatible with given \p mode.
 * 
 * @param[in] mode Lock mode, depending on whether the memory will be written to and/or read from.
 *                 + Valid values are: 
 *                   - \ref VPI_LOCK_READ
 *                   - \ref VPI_LOCK_WRITE
 *                   - \ref VPI_LOCK_READ_WRITE
 * 
 * @retval #VPI_ERROR_INVALID_ARGUMENT  \p array is NULL or doesn't represent a \ref VPIArray instance.
 * @retval #VPI_ERROR_BUFFER_LOCKED     Array is already locked by either a stream or the user.
 * @retval #VPI_SUCCESS                 Operation executed successfully
 */
VPI_PUBLIC VPIStatus vpiArrayLock(VPIArray array, VPILockMode mode);

/**
 * Acquires the lock on an array object and returns the array contents.
 *
 * Depending on the internal array representation, as well as the actual location in memory, this
 * function might have a significant performance overhead due to type conversion, memory copies, etc.
 *
 * The array can be locked multiple times. Each lock operation increments a
 * counter and must be matched by a corresponding \ref vpiArrayUnlock
 * call. Lock will fail if the array is being used by a stream.
 *
 * @param[in] array Array to be locked.
 *                  + Mandatory, it can't be NULL.
 *                  + Array must not be locked in a mode that is incompatible with given \p mode.
 *                  + For some buffer types, the image must have the following backend enabled:
 *                  | Buffer type                    | Required backend flags |
 *                  |--------------------------------|------------------------|
 *                  | \ref VPI_ARRAY_BUFFER_HOST_AOS | \ref VPI_BACKEND_CPU   | 
 *                  | \ref VPI_ARRAY_BUFFER_CUDA_AOS | \ref VPI_BACKEND_CUDA  |
 * 
 * @param[in] bufType The type of buffer returned in \p data.
 *                    It defines how the array contents can be accessed by the caller.
 *                    Valid types are:
 *                    - \ref VPI_ARRAY_BUFFER_HOST_AOS
 * 
 * @param[in] mode Lock mode, depending on whether the memory will be written to and/or read from.
 *                 + Valid values are: 
 *                   - \ref VPI_LOCK_READ
 *                   - \ref VPI_LOCK_WRITE
 *                   - \ref VPI_LOCK_READ_WRITE
 * 
 * @param[out] data A pointer to a structure that will be filled with array memory information..
 *                  + The buffer it points to are valid until the array is unlocked.
 *
 * @retval #VPI_ERROR_INVALID_ARGUMENT  \p array is NULL or doesn't represent a \ref VPIArray instance.
 * @retval #VPI_ERROR_INVALID_ARGUMENT  \p data is NULL.
 * @retval #VPI_ERROR_INVALID_ARGUMENT  \p bufType isn't supported.
 * @retval #VPI_ERROR_INVALID_OPERATION \p array doesn't have required backends enabled.
 * @retval #VPI_ERROR_BUFFER_LOCKED     Array is already locked by either a stream or the user.
 * @retval #VPI_SUCCESS                 Operation executed successfully
 */
VPI_PUBLIC VPIStatus vpiArrayLockData(VPIArray array, VPILockMode mode, VPIArrayBufferType bufType, VPIArrayData *data);

/**
 * Releases the lock on array object.
 *
 * This function might have a significant performance overhead (type conversion, layout
 * conversion, host-to-device memory copy).
 *
 * The array is effectively unlocked when the internal lock counter reaches 0.
 *
 * @param[in] array A valid array handle.
 *                  + Mandatory, it can't be NULL.
 *
 * @retval #VPI_ERROR_INVALID_ARGUMENT  \p array is NULL or doesn't represent a \ref VPIArray instance.
 * @retval #VPI_ERROR_INVALID_OPERATION \p array isn't locked.
 * @retval #VPI_SUCCESS                 Operation executed successfully
 */
VPI_PUBLIC VPIStatus vpiArrayUnlock(VPIArray array);

#ifdef __cplusplus
}
#endif

/** @} end of VPI_Array */

#endif /* NV_VPI_ARRAY_H */
// End content from: Array.h

// Begin content from: algo/Rescale.h
/*
 * Copyright 2019-2021 NVIDIA Corporation. All rights reserved.
 *
 * NOTICE TO LICENSEE:
 *
 * This source code and/or documentation ("Licensed Deliverables") are
 * subject to NVIDIA intellectual property rights under U.S. and
 * international Copyright laws.
 *
 * These Licensed Deliverables contained herein is PROPRIETARY and
 * CONFIDENTIAL to NVIDIA and is being provided under the terms and
 * conditions of a form of NVIDIA software license agreement by and
 * between NVIDIA and Licensee ("License Agreement") or electronically
 * accepted by Licensee. Notwithstanding any terms or conditions to
 * the contrary in the License Agreement, reproduction or disclosure
 * of the Licensed Deliverables to any third party without the express
 * written consent of NVIDIA is prohibited.
 *
 * NOTWITHSTANDING ANY TERMS OR CONDITIONS TO THE CONTRARY IN THE
 * LICENSE AGREEMENT, NVIDIA MAKES NO REPRESENTATION ABOUT THE
 * SUITABILITY OF THESE LICENSED DELIVERABLES FOR ANY PURPOSE. IT IS
 * PROVIDED "AS IS" WITHOUT EXPRESS OR IMPLIED WARRANTY OF ANY KIND.
 * NVIDIA DISCLAIMS ALL WARRANTIES WITH REGARD TO THESE LICENSED
 * DELIVERABLES, INCLUDING ALL IMPLIED WARRANTIES OF MERCHANTABILITY,
 * NONINFRINGEMENT, AND FITNESS FOR A PARTICULAR PURPOSE.
 * NOTWITHSTANDING ANY TERMS OR CONDITIONS TO THE CONTRARY IN THE
 * LICENSE AGREEMENT, IN NO EVENT SHALL NVIDIA BE LIABLE FOR ANY
 * SPECIAL, INDIRECT, INCIDENTAL, OR CONSEQUENTIAL DAMAGES, OR ANY
 * DAMAGES WHATSOEVER RESULTING FROM LOSS OF USE, DATA OR PROFITS,
 * WHETHER IN AN ACTION OF CONTRACT, NEGLIGENCE OR OTHER TORTIOUS
 * ACTION, ARISING OUT OF OR IN CONNECTION WITH THE USE OR PERFORMANCE
 * OF THESE LICENSED DELIVERABLES.
 *
 * U.S. Government End Users. These Licensed Deliverables are a
 * "commercial item" as that term is defined at 48 C.F.R. 2.101 (OCT
 * 1995), consisting of "commercial computer software" and "commercial
 * computer software documentation" as such terms are used in 48
 * C.F.R. 12.212 (SEPT 1995) and is provided to the U.S. Government
 * only as a commercial end item. Consistent with 48 C.F.R.12.212 and
 * 48 C.F.R. 227.7202-1 through 227.7202-4 (JUNE 1995), all
 * U.S. Government End Users acquire the Licensed Deliverables with
 * only those rights set forth herein.
 *
 * Any use of the Licensed Deliverables in individual and commercial
 * software must include, in the user documentation and internal
 * comments to the code, the above Disclaimer and U.S. Government End
 * Users Notice.
 */

/**
 * @file Rescale.h
 *
 * Declares functions that implement the Rescale algorithm.
 */

#ifndef NV_VPI_ALGORITHMS_RESCALE_H
#define NV_VPI_ALGORITHMS_RESCALE_H

// #include "../AlgoFlags.h"
// #include "../Export.h"
// #include "../Status.h"
// #include "../Types.h"

#include <stdint.h>

#ifdef __cplusplus
extern "C" {
#endif

/**
 * @defgroup VPI_Rescale Rescale
 * @ingroup VPI_API_Algorithms
 * @{
 *
 * Changes the dimensions of the input image while stretching/squeezing it.
 * Refer to \ref algo_rescale for more details and usage examples.
 */

/**
 * Changes the size and scale of a 2D image.
 *
 * @param[in] stream The stream where the operation will be queued in.
 *                   + Must not be NULL.
 *                   + Stream must have enabled the backends that will execute the algorithm.
 *
 * @param[in] backend VPI backend that will execute the algorithm.
 *                    + Valid values:
 *                      - \ref VPI_BACKEND_CPU
 *                      - \ref VPI_BACKEND_CUDA
 *                      - \ref VPI_BACKEND_VIC
 *
 * @param[in] input Input image to be rescaled.
 *                  + Must not be NULL.
 *                  + Image must have enabled the backends that will execute the algorithm.
 *                  + Dimensions must be >= 1x1. On VIC, valid range is >= 16x16 and <= 16384x16384.
 *                  + On VIC, when using YUV formats with chroma-subsampling of 4:2:0, 4:2:2 or 4:2:2R,
 *                    the image dimensions must be even.
 *                  + Supported image formats are:
 *                    | Format                           | CPU | CUDA | VIC |
 *                    |----------------------------------|:---:|:----:|:---:|
 *                    | \ref VPI_IMAGE_FORMAT_U8         |  *  |   *  |     |
 *                    | \ref VPI_IMAGE_FORMAT_U16        |  *  |   *  |     |
 *                    | \ref VPI_IMAGE_FORMAT_S8         |  *  |   *  |     |
 *                    | \ref VPI_IMAGE_FORMAT_S16        |  *  |   *  |     |
 *                    | \ref VPI_IMAGE_FORMAT_F32        |  *  |   *  |     |
 *                    | \ref VPI_IMAGE_FORMAT_Y8         |  *  |   *  |  *  |
 *                    | \ref VPI_IMAGE_FORMAT_Y8_ER      |  *  |   *  |  *  |
 *                    | \ref VPI_IMAGE_FORMAT_Y8_BL      |     |      |  *  |
 *                    | \ref VPI_IMAGE_FORMAT_Y8_ER_BL   |     |      |  *  |
 *                    | \ref VPI_IMAGE_FORMAT_Y16        |  *  |   *  |  *  |
 *                    | \ref VPI_IMAGE_FORMAT_Y16_ER     |  *  |   *  |  *  |
 *                    | \ref VPI_IMAGE_FORMAT_Y16_BL     |     |      |  *  |
 *                    | \ref VPI_IMAGE_FORMAT_Y16_ER_BL  |     |      |  *  |
 *                    | \ref VPI_IMAGE_FORMAT_RGB8       |  *  |      |     |
 *                    | \ref VPI_IMAGE_FORMAT_BGR8       |  *  |      |     |
 *                    | \ref VPI_IMAGE_FORMAT_RGBA8      |  *  |   *  |  *  |
 *                    | \ref VPI_IMAGE_FORMAT_BGRA8      |  *  |   *  |  *  |
 *                    | \ref VPI_IMAGE_FORMAT_RGB8p      |  *  |   *  |     |
 *                    | \ref VPI_IMAGE_FORMAT_BGR8p      |  *  |   *  |     |
 *                    | \ref VPI_IMAGE_FORMAT_RGBA8p     |  *  |   *  |     |
 *                    | \ref VPI_IMAGE_FORMAT_BGRA8p     |  *  |   *  |     |
 *                    | \ref VPI_IMAGE_FORMAT_NV12       |  *  |   *  |  *  |
 *                    | \ref VPI_IMAGE_FORMAT_NV12_ER    |  *  |   *  |  *  |
 *                    | \ref VPI_IMAGE_FORMAT_NV12_BL    |     |      |  *  |
 *                    | \ref VPI_IMAGE_FORMAT_NV12_ER_BL |     |      |  *  |
 *                    | \ref VPI_IMAGE_FORMAT_NV24       |  *  |   *  |  *  |
 *                    | \ref VPI_IMAGE_FORMAT_NV24_ER    |  *  |   *  |  *  |
 *                    | \ref VPI_IMAGE_FORMAT_NV24_BL    |     |      |  *  |
 *                    | \ref VPI_IMAGE_FORMAT_NV24_ER_BL |     |      |  *  |
 *                    | \ref VPI_IMAGE_FORMAT_UYVY       |     |      |  *  |
 *                    | \ref VPI_IMAGE_FORMAT_UYVY_ER    |     |      |  *  |
 *                    | \ref VPI_IMAGE_FORMAT_UYVY_BL    |     |      |  *  |
 *                    | \ref VPI_IMAGE_FORMAT_UYVY_ER_BL |     |      |  *  |
 *                    | \ref VPI_IMAGE_FORMAT_YUYV       |     |      |  *  |
 *                    | \ref VPI_IMAGE_FORMAT_YUYV_ER    |     |      |  *  |
 *                    | \ref VPI_IMAGE_FORMAT_YUYV_BL    |     |      |  *  |
 *                    | \ref VPI_IMAGE_FORMAT_YUYV_ER_BL |     |      |  *  |
 *
 * @param[out] output Output image with the desired resulting dimensions.
 *                    + Must not be NULL.
 *                    + Image must have enabled the backends that will execute the algorithm.
 *                    + Dimensions must be >= 1x1. On VIC, valid range is >= 16x16 and <= 16384x16384.
 *                    + On VIC, when using YUV formats with chroma-subsampling of 4:2:0, 4:2:2 or 4:2:2R,
 *                      the image dimensions must be even.
 *                    + On VIC, scale factor (output/input) must be between 1/16.0f and 16.0f.
 *                    + On VIC, input and output formats can be different. Accepted formats are
 *                      the same as \p input, provided that the following constraints are met:
 *                      - No bit depth conversion is allowed, i.e., Y8 to Y16, Y16 to NV12, etc.
 *                      - No conversion from/to Y16_ER, except when only changing layout.
 *                        Example: Y16_ER_BL to Y16_ER is allowed, but Y16_ER_BL to Y16 or Y16_BL isn't.
 *                    + On other backends, input and output formats must be the same.
 *
 * @param[in] interpolationType Interpolation method to be used.
 *                              + Valid values:
 *                                - \ref VPI_INTERP_NEAREST
 *                                - \ref VPI_INTERP_LINEAR (VIC only supports this one)
 *                                - \ref VPI_INTERP_CATMULL_ROM
 *
 * @param[in] border Border extension to be used when sampling pixels outside the image border.
 *                   + The accepted border extensions are:
 *                     - \ref VPI_BORDER_ZERO
 *                     - \ref VPI_BORDER_CLAMP (VIC only supports this one)
 *
 * @param[in] flags Control flags.
 *                  + Valid values are a combination of one or more of the following flags:
 *                    - 0: default, negation of all other flags.
 *                    - \ref VPI_PRECISE : precise, but potentially slower implementation.
 *
 * @retval #VPI_ERROR_INVALID_ARGUMENT     \p stream is NULL.
 * @retval #VPI_ERROR_INVALID_ARGUMENT     \p input or \p output are NULL.
 * @retval #VPI_ERROR_INVALID_ARGUMENT     \p input or \p output dimensions are outside valid range.
 * @retval #VPI_ERROR_INVALID_ARGUMENT     \p flags has some unsupported flag(s).
 * @retval #VPI_ERROR_INVALID_ARGUMENT     \p border not supported.
 * @retval #VPI_ERROR_INVALID_ARGUMENT     \p interpolationType not supported.
 * @retval #VPI_ERROR_INVALID_ARGUMENT     \p backend is invalid or unknown.
 * @retval #VPI_ERROR_INVALID_ARGUMENT     \p input and \p output formats are not compatible.
 * @retval #VPI_ERROR_INVALID_IMAGE_FORMAT \p input or \p output format not supported.
 * @retval #VPI_ERROR_NOT_IMPLEMENTED      Rescale algorithm is not supported by given backend.
 * @retval #VPI_ERROR_INVALID_OPERATION    Backend hardware not available.
 * @retval #VPI_ERROR_INVALID_OPERATION    The needed backends aren't enabled in \p stream, \p input or \p output.
 * @retval #VPI_SUCCESS                    Operation executed successfully.
 */
VPI_PUBLIC VPIStatus vpiSubmitRescale(VPIStream stream, uint64_t backend, VPIImage input, VPIImage output,
                                      VPIInterpolationType interpolationType, VPIBorderExtension border,
                                      uint64_t flags);

/** @} end of VPI_Rescale */

#ifdef __cplusplus
}
#endif

#endif /* NV_VPI_ALGORITHMS_RESCALE_H */
// End content from: algo/Rescale.h

// Begin content from: algo/HarrisCorners.h
/*
 * Copyright 2019-2021 NVIDIA Corporation. All rights reserved.
 *
 * NOTICE TO LICENSEE:
 *
 * This source code and/or documentation ("Licensed Deliverables") are
 * subject to NVIDIA intellectual property rights under U.S. and
 * international Copyright laws.
 *
 * These Licensed Deliverables contained herein is PROPRIETARY and
 * CONFIDENTIAL to NVIDIA and is being provided under the terms and
 * conditions of a form of NVIDIA software license agreement by and
 * between NVIDIA and Licensee ("License Agreement") or electronically
 * accepted by Licensee. Notwithstanding any terms or conditions to
 * the contrary in the License Agreement, reproduction or disclosure
 * of the Licensed Deliverables to any third party without the express
 * written consent of NVIDIA is prohibited.
 *
 * NOTWITHSTANDING ANY TERMS OR CONDITIONS TO THE CONTRARY IN THE
 * LICENSE AGREEMENT, NVIDIA MAKES NO REPRESENTATION ABOUT THE
 * SUITABILITY OF THESE LICENSED DELIVERABLES FOR ANY PURPOSE. IT IS
 * PROVIDED "AS IS" WITHOUT EXPRESS OR IMPLIED WARRANTY OF ANY KIND.
 * NVIDIA DISCLAIMS ALL WARRANTIES WITH REGARD TO THESE LICENSED
 * DELIVERABLES, INCLUDING ALL IMPLIED WARRANTIES OF MERCHANTABILITY,
 * NONINFRINGEMENT, AND FITNESS FOR A PARTICULAR PURPOSE.
 * NOTWITHSTANDING ANY TERMS OR CONDITIONS TO THE CONTRARY IN THE
 * LICENSE AGREEMENT, IN NO EVENT SHALL NVIDIA BE LIABLE FOR ANY
 * SPECIAL, INDIRECT, INCIDENTAL, OR CONSEQUENTIAL DAMAGES, OR ANY
 * DAMAGES WHATSOEVER RESULTING FROM LOSS OF USE, DATA OR PROFITS,
 * WHETHER IN AN ACTION OF CONTRACT, NEGLIGENCE OR OTHER TORTIOUS
 * ACTION, ARISING OUT OF OR IN CONNECTION WITH THE USE OR PERFORMANCE
 * OF THESE LICENSED DELIVERABLES.
 *
 * U.S. Government End Users. These Licensed Deliverables are a
 * "commercial item" as that term is defined at 48 C.F.R. 2.101 (OCT
 * 1995), consisting of "commercial computer software" and "commercial
 * computer software documentation" as such terms are used in 48
 * C.F.R. 12.212 (SEPT 1995) and is provided to the U.S. Government
 * only as a commercial end item. Consistent with 48 C.F.R.12.212 and
 * 48 C.F.R. 227.7202-1 through 227.7202-4 (JUNE 1995), all
 * U.S. Government End Users acquire the Licensed Deliverables with
 * only those rights set forth herein.
 *
 * Any use of the Licensed Deliverables in individual and commercial
 * software must include, in the user documentation and internal
 * comments to the code, the above Disclaimer and U.S. Government End
 * Users Notice.
 */

/**
 * @file HarrisCorners.h
 *
 * Declares functions that implement the Harris Corner Detector algorithm.
 */

#ifndef NV_VPI_ALGORITHMS_HARRIS_CORNERS_H
#define NV_VPI_ALGORITHMS_HARRIS_CORNERS_H

// #include "../Export.h"
// #include "../Status.h"
// #include "../Types.h"

#include <stdint.h>

#ifdef __cplusplus
extern "C" {
#endif

/**
 * @defgroup VPI_HarrisCorners Harris Corners
 * @ingroup VPI_API_Algorithms
 * @{
 *
 * Detect Harris keypoints in an image, usually used in keypoint tracking.
 * Refer to \ref algo_harris_corners for more details and usage examples.
 */

/**
 * Structure that defines the parameters for \ref vpiSubmitHarrisCornerDetector
 */
typedef struct
{
    /** Gradient window size.
     *  + Must be 3, 5 or 7. */
    int32_t gradientSize;

    /** Block window size used to compute the Harris Corner score.
     *  + Must be 3, 5 or 7. */
    int32_t blockSize;

    /** Specifies the minimum threshold with which to eliminate Harris Corner scores.
     *  + Must be >= 0. */
    float strengthThresh;

    /** Specifies sensitivity threshold from the Harris-Stephens equation. */
    float sensitivity;

    /** Non-maximum suppression radius, set to 0 to disable it.
     *  + On PVA backend, this must be set to 8. */
    float minNMSDistance;
} VPIHarrisCornerDetectorParams;

/** Initializes \ref VPIHarrisCornerDetectorParams with default values.
 *
 * Default values are:
 * - gradientSize:   3
 * - blockSize:      3
 * - strengthThresh: 20
 * - sensitivity:    0.0625
 * - minNMSDistance: 8
 * 
 * @retval #VPI_ERROR_INVALID_ARGUMENT \p params is NULL.
 * @retval #VPI_SUCCESS Operation executed successfully.
 */
VPI_PUBLIC VPIStatus vpiInitHarrisCornerDetectorParams(VPIHarrisCornerDetectorParams *params);

/**
 * Creates a \ref algo_harris_corners "Harris Corner Detector" payload.
 * This function allocates all temporary memory needed by the algorithm.
 *
 * @param[in] backends VPI backends that are eligible to execute the algorithm.
 *                     + Valid values:
 *                       - \ref VPI_BACKEND_CPU
 *                       - \ref VPI_BACKEND_CUDA
 *                     + Backend must be enabled in current context.
 *
 * @param[in] inputWidth, inputHeight Dimensions of the input image that will be used with this payload.
 *                                    + On PVA dimensions limited to minimum of 160x120, maximum of 3264x2448.
 *                                    + Must be >= 0 (other backends).
 *
 * @param[out] payload Pointer to the payload variable that receives the created handle.
 * 
 * @retval #VPI_ERROR_INVALID_ARGUMENT  \p payload is NULL.
 * @retval #VPI_ERROR_INVALID_ARGUMENT  \p inputWidth or \p inputHeight outside valid range.
 * @retval #VPI_ERROR_INVALID_ARGUMENT  \p backends refers to an invalid backend.
 * @retval #VPI_ERROR_INVALID_OPERATION Backend hardware not available.
 * @retval #VPI_ERROR_NOT_IMPLEMENTED   Harris Corner Detector algorithm is not supported by given backend.
 * @retval #VPI_ERROR_INVALID_CONTEXT   Current context is destroyed.
 * @retval #VPI_ERROR_OUT_OF_MEMORY     Cannot allocate required resources.
 * @retval #VPI_ERROR_INVALID_OPERATION Backend isn't enabled in current context.
 * @retval #VPI_SUCCESS                 Operation executed successfully.
 */
VPI_PUBLIC VPIStatus vpiCreateHarrisCornerDetector(uint64_t backends, int32_t inputWidth, int32_t inputHeight,
                                                   VPIPayload *payload);

/**
 * Submits a \ref algo_harris_corners "Harris Corner Detector" operation to the stream.
 *
 * @param[in] stream The stream where the operation will be queued in.
 *                   + Must not be NULL.
 *                   + Stream must have enabled the backends that will execute the algorithm.
 *
 * @param[in] backend Backend that will execute the algorithm.
 *                    + Must be the backend specified during payload creation or 0 as a shorthand to use this backend.
 *
 * @param[in] payload Payload to be submitted along the other parameters.
 *
 * @param[in] input Input image from where the Harris corners will be extracted.
 *                  + Must not be NULL.
 *                  + Image must have enabled the backends that will execute the algorithm.
 *                  + The accepted image formats are:
 *                    - \ref VPI_IMAGE_FORMAT_U8
 *                    - \ref VPI_IMAGE_FORMAT_S8
 *                    - \ref VPI_IMAGE_FORMAT_U16
 *                    - \ref VPI_IMAGE_FORMAT_S16 (PVA backend only supports this format)
 *
 * @param[out] outFeatures Array that will receive the detected corners.
 *                         Array size is updated with the number of corners found.
 *                         + Must not be NULL.
 *                         + It must have type \ref VPI_ARRAY_TYPE_KEYPOINT_F32.
 *                         + Array must have enabled the backends that will execute the algorithm.
 *                         + On PVA, the array capacity must be 8192.
 *
 * @param[out] outScores Array that will receive the corners' scores.
 *                       Array size matches outFeatures array' size.
 *                       + Must not be NULL.
 *                       + It must have type \ref VPI_ARRAY_TYPE_U32.
 *                       + Array must have enabled the backends that will execute the algorithm.
 *                       + Must have same capacity as outFeatures.
 *
 * @param[in] params Pointer to a \ref VPIHarrisCornerDetectorParams with parameters for this algorithm invocation.
 *                   These parameters can vary in every call and will be copied internally, no need to keep the object around.
 *  
 * @retval #VPI_ERROR_INVALID_ARGUMENT     \p stream is NULL.
 * @retval #VPI_ERROR_INVALID_ARGUMENT     \p input, \p outFeatures or \p outScores are NULL.
 * @retval #VPI_ERROR_INVALID_ARGUMENT     \p payload is not created by vpiCreateHarrisCornerDetector.
 * @retval #VPI_ERROR_INVALID_ARGUMENT     Strength threshold in \p params outside valid range.
 * @retval #VPI_ERROR_INVALID_ARGUMENT     Output arrays must have same capacity.
 * @retval #VPI_ERROR_INVALID_ARGUMENT     Unsupported \p outFeatures or \p outScores type.
 * @retval #VPI_ERROR_INVALID_ARGUMENT     Invalid \p input dimensions.
 * @retval #VPI_ERROR_INVALID_PAYLOAD_TYPE \p payload is invalid.
 * @retval #VPI_ERROR_INVALID_IMAGE_FORMAT Unsupported input format.
 * @retval #VPI_ERROR_INVALID_OPERATION    The needed backends aren't enabled in \p stream, \p outFeatures or \p outScores.
 * @retval #VPI_SUCCESS                    Operation executed successfully.
 */
VPI_PUBLIC VPIStatus vpiSubmitHarrisCornerDetector(VPIStream stream, uint64_t backend, VPIPayload payload,
                                                   VPIImage input, VPIArray outFeatures, VPIArray outScores,
                                                   const VPIHarrisCornerDetectorParams *params);

/** @} end of VPI_HarrisCorners */

#ifdef __cplusplus
}
#endif

#endif /* NV_VPI_ALGORITHMS_HARRIS_CORNERS_H */
// End content from: algo/HarrisCorners.h

// Begin content from: algo/KLTFeatureTracker.h
/*
 * Copyright 2019-2021 NVIDIA Corporation. All rights reserved.
 *
 * NOTICE TO LICENSEE:
 *
 * This source code and/or documentation ("Licensed Deliverables") are
 * subject to NVIDIA intellectual property rights under U.S. and
 * international Copyright laws.
 *
 * These Licensed Deliverables contained herein is PROPRIETARY and
 * CONFIDENTIAL to NVIDIA and is being provided under the terms and
 * conditions of a form of NVIDIA software license agreement by and
 * between NVIDIA and Licensee ("License Agreement") or electronically
 * accepted by Licensee. Notwithstanding any terms or conditions to
 * the contrary in the License Agreement, reproduction or disclosure
 * of the Licensed Deliverables to any third party without the express
 * written consent of NVIDIA is prohibited.
 *
 * NOTWITHSTANDING ANY TERMS OR CONDITIONS TO THE CONTRARY IN THE
 * LICENSE AGREEMENT, NVIDIA MAKES NO REPRESENTATION ABOUT THE
 * SUITABILITY OF THESE LICENSED DELIVERABLES FOR ANY PURPOSE. IT IS
 * PROVIDED "AS IS" WITHOUT EXPRESS OR IMPLIED WARRANTY OF ANY KIND.
 * NVIDIA DISCLAIMS ALL WARRANTIES WITH REGARD TO THESE LICENSED
 * DELIVERABLES, INCLUDING ALL IMPLIED WARRANTIES OF MERCHANTABILITY,
 * NONINFRINGEMENT, AND FITNESS FOR A PARTICULAR PURPOSE.
 * NOTWITHSTANDING ANY TERMS OR CONDITIONS TO THE CONTRARY IN THE
 * LICENSE AGREEMENT, IN NO EVENT SHALL NVIDIA BE LIABLE FOR ANY
 * SPECIAL, INDIRECT, INCIDENTAL, OR CONSEQUENTIAL DAMAGES, OR ANY
 * DAMAGES WHATSOEVER RESULTING FROM LOSS OF USE, DATA OR PROFITS,
 * WHETHER IN AN ACTION OF CONTRACT, NEGLIGENCE OR OTHER TORTIOUS
 * ACTION, ARISING OUT OF OR IN CONNECTION WITH THE USE OR PERFORMANCE
 * OF THESE LICENSED DELIVERABLES.
 *
 * U.S. Government End Users. These Licensed Deliverables are a
 * "commercial item" as that term is defined at 48 C.F.R. 2.101 (OCT
 * 1995), consisting of "commercial computer software" and "commercial
 * computer software documentation" as such terms are used in 48
 * C.F.R. 12.212 (SEPT 1995) and is provided to the U.S. Government
 * only as a commercial end item. Consistent with 48 C.F.R.12.212 and
 * 48 C.F.R. 227.7202-1 through 227.7202-4 (JUNE 1995), all
 * U.S. Government End Users acquire the Licensed Deliverables with
 * only those rights set forth herein.
 *
 * Any use of the Licensed Deliverables in individual and commercial
 * software must include, in the user documentation and internal
 * comments to the code, the above Disclaimer and U.S. Government End
 * Users Notice.
 */

/**
 * @file KLTFeatureTracker.h
 *
 * Declares functions that implement the KLT Feature Tracker algorithm.
 */

#ifndef NV_VPI_ALGORITHMS_KLT_BOUNDING_BOX_TRACKER_H
#define NV_VPI_ALGORITHMS_KLT_BOUNDING_BOX_TRACKER_H

/**
 * @defgroup VPI_KLTFeatureTracker KLT Feature Tracker
 * @ingroup VPI_API_Algorithms
 * @{
 *
 * Runs KLT Feature tracking on a sequence of frames.
 * Refer to \ref algo_klt_tracker for more details and usage examples.
 */

// #include "../Export.h"
// #include "../ImageFormat.h"
// #include "../Status.h"
// #include "../Types.h"

#include <stdint.h>

#ifdef __cplusplus
extern "C" {
#endif

/** Creation parameters of KLT Feature Tracker. */
typedef struct
{
    /** Maximum number of templates to be tracked.
     *  + Must be >= 1 and <= 128. */
    int32_t maxTemplateCount;

    /** Maximum width of each tracked template.
     *  + It must be >= 4 and <= 128 (on PVA, <= 64). */
    int32_t maxTemplateWidth;

    /** Maximum height of each tracked templates.
     *  + It must be >= 4 and <= 128 (on PVA, <= 64). */
    int32_t maxTemplateHeight;

} VPIKLTFeatureTrackerCreationParams;

/** Initialize \ref VPIKLTFeatureTrackerCreationParams with default values.
 *
 * Default values:
 *   - maxTemplateCount:  128
 *   - maxTemplateWidth:  64
 *   - maxTemplateHeight: 64
 *
 * @param[out] params Structure to be filled with default values.
 *
 * @retval #VPI_ERROR_INVALID_ARGUMENT \p params is NULL.
 * @retval #VPI_SUCCESS Operation executed successfully.
 */
#if NV_VPI_VERSION_API_AT_MOST(2, 0)
__asm__(".symver vpiInitKLTFeatureTrackerCreationParams,vpiInitKLTFeatureTrackerCreationParams@VPI_2.0");
VPI_PUBLIC VPIStatus vpiInitKLTFeatureTrackerCreationParams(VPIKLTFeatureTrackerCreationParams *params);
#else
VPI_PUBLIC VPIStatus vpiInitKLTFeatureTrackerCreationParams(VPIKLTFeatureTrackerCreationParams *params);
#endif

/**
 * Creates payload for \ref vpiSubmitKLTFeatureTracker
 *
 * @param[in] backends VPI backends that are eligible to execute the algorithm.
 *                     + Valid values:
 *                       - \ref VPI_BACKEND_CPU
 *                       - \ref VPI_BACKEND_CUDA
 *                     + Backend must be enabled in current context.
 *
 * @param[in] imageWidth, imageHeight Input image dimensions.
 *                                    + On PVA, dimensions must be between 65x65 and 3264x2448.
 *                                    + Must be >= 0 (other backends).
 *
 * @param[in] imageFormat Input image format.
 *                        + The accepted image formats are:
 *                          - \ref VPI_IMAGE_FORMAT_U8
 *                          - \ref VPI_IMAGE_FORMAT_S8
 *                          - \ref VPI_IMAGE_FORMAT_U16 (PVA only supports this format, pixel values' range must be between 0 and 255)
 *                          - \ref VPI_IMAGE_FORMAT_S16
 *
 * @param[in] params params 
 *
 * @param[out] payload Pointer to the payload variable that receives the created handle.
 *
 * @retval #VPI_ERROR_INVALID_ARGUMENT  \p payload is NULL.
 * @retval #VPI_ERROR_INVALID_ARGUMENT  \p imageWidth and \p imageHeight outside valid range.
 * @retval #VPI_ERROR_INVALID_ARGUMENT  \p maxTemplateWidth and \p maxTemplateHeight in \p params outside valid range.
 * @retval #VPI_ERROR_INVALID_ARGUMENT  \p maxTemplateCount in \p params outside valid range.
 * @retval #VPI_ERROR_INVALID_ARGUMENT  \p backends refers to an invalid backend.
 * @retval #VPI_IMAGE_FORMAT_INVALID    \p imageFormat is not supported.
 * @retval #VPI_ERROR_INVALID_OPERATION PVA hardware is not available.
 * @retval #VPI_ERROR_INVALID_OPERATION Backend isn't enabled in current context.
 * @retval #VPI_ERROR_NOT_IMPLEMENTED   KLT Feature Tracker algorithm is not supported by given backend.
 * @retval #VPI_ERROR_INVALID_CONTEXT   Current context is destroyed.
 * @retval #VPI_ERROR_OUT_OF_MEMORY     Cannot allocate required resources.
 * @retval #VPI_SUCCESS                 Operation executed successfully.
 */

#if NV_VPI_VERSION_API_AT_MOST(2, 0)
__asm__(".symver vpiCreateKLTFeatureTracker,vpiCreateKLTFeatureTracker@VPI_2.0");
VPI_PUBLIC VPIStatus vpiCreateKLTFeatureTracker(uint64_t backends, int32_t imageWidth, int32_t imageHeight,
                                                VPIImageFormat imageFormat,
                                                const VPIKLTFeatureTrackerCreationParams *params, VPIPayload *payload);
#else
VPI_PUBLIC VPIStatus vpiCreateKLTFeatureTracker(uint64_t backends, int32_t imageWidth, int32_t imageHeight,
                                                VPIImageFormat imageFormat,
                                                const VPIKLTFeatureTrackerCreationParams *params, VPIPayload *payload);
#endif

/**
 * KLT Feature Tracker algorithm type.
 */
typedef enum
{
    /** Inverse compositional algorithm for KLT tracker.
        The inverse compositional algorithm is a reformulation of the classic
        Lucas-Kanade algorithm to make the steepest-descent images and Hessian
        constant.<br>
        <table border=0px margin=0px>
        <tr><td valign=top>Ref:</td><td>Simon Baker, Iain Matthew, <a href="http://www.ncorr.com/download/publications/bakerunify.pdf">"Lucas-Kanade 20 Years On: A Unified Framework"</a>.<br>
             International Journal of Computer Vision, February 2004, Volume 56, issue 3, pp. 228-231.</td></tr>
        </table>
    */
    VPI_KLT_INVERSE_COMPOSITIONAL
} VPIKLTFeatureTrackerType;

/**
 * Structure that defines the parameters for \ref vpiCreateKLTFeatureTracker
 */
typedef struct
{
    /** Number of Inverse compositional iterations of scale estimations.
     * + On PVA the maximum allowed is 20. */
    int32_t numberOfIterationsScaling;

    /** Threshold for requiring template update.
     *  + Must be a value between 0 and 1.
     *  + Must be greater than nccThresholdKill. */
    float nccThresholdUpdate;

    /** Threshold to consider template tracking was lost.
     *  + Must be a value between 0 and 1. */
    float nccThresholdKill;

    /** Threshold to early stop iteration.
     *  + Must be a value between 0 and 1.
        + Must be greater than nccThresholdUpdate. */
    float nccThresholdStop;

    /** Maximum relative scale change.
     *  Scale changes larger than this will make KLT consider that tracking was lost.
     *  + Must be >= 0.
     *  + On PVA, maximum scale change is 0.2. */
    float maxScaleChange;

    /** Maximum relative translation change.
     *  + Must be less >= 0.
     *  + Translation changes larger than this will make KLT consider that tracking was lost. */
    float maxTranslationChange;

    /** Type of KLT tracking that will be performed. */
    VPIKLTFeatureTrackerType trackingType;
} VPIKLTFeatureTrackerParams;

/** Initialize \ref VPIKLTFeatureTrackerParams with default values.
 *
 * Default values:
 *   - numberOfIterationsScaling: 20
 *   - nccThresholdUpdate: 0.8
 *   - nccThresholdKill: 0.6
 *   - nccThresholdStop: 1.0
 *   - maxScaleChange: 0.2
 *   - maxTranslationChange: 1.5
 *   - trackingType: VPI_KLT_INVERSE_COMPOSITIONAL
 *
 * @param[out] params Structure to be filled with default values.
 *
 * @returns an error code on failure else \ref VPI_SUCCESS.
 */
VPI_PUBLIC VPIStatus vpiInitKLTFeatureTrackerParams(VPIKLTFeatureTrackerParams *params);

/**
 * Runs KLT Feature Tracker on two frames. Outputs tracked bounding boxes and estimated transform array.
 *
 * @param[in] stream The stream where the operation will be queued in.
 *                   + Must not be NULL.
 *                   + Stream must have enabled the backends that will execute the algorithm.
 *
 * @param[in] backend Backend that will execute the algorithm.
 *                    + Must be the backend specified during payload creation or 0 as a shorthand to use this backend.
 *
 * @param[in] payload Payload created by \ref vpiCreateKLTFeatureTracker.
 *
 * @param[in] referenceImage Reference image.
 *                           + Must not be NULL.
 *                           + Must have same dimensions and format as template image. 
 *                           + Image must have enabled the backends that will execute the algorithm.
 *
 * @param[in] inputBoxList Input bounding box array.
 *                         + Must not be NULL.
 *                         + Must have type \ref VPI_ARRAY_TYPE_KLT_TRACKED_BOUNDING_BOX.
 *                         + Array must have enabled the backends that will execute the algorithm.
 *                         + On PVA, array capacity must be >= 128.
 *
 * @param[in] inputPredictionList Input predicted transform array.
 *                                + Must not be NULL.
 *                                + Must have type \ref VPI_ARRAY_TYPE_HOMOGRAPHY_TRANSFORM_2D.
 *                                + Array must have enabled the backends that will execute the algorithm.
 *                                + On PVA, array capacity must be >= 128.
 *
 * @param[in] templateImage Template image.
 *                          + Must not be NULL.
 *                          + Must have same dimensions and format as \p referenceImage.
 *                          + Image must have enabled the backends that will execute the algorithm.
 *
 * @param[out] outputBoxList Output Bounding box array.
 *                           + Must not be NULL.
 *                           + Must have type \ref VPI_ARRAY_TYPE_KLT_TRACKED_BOUNDING_BOX.
 *                           + Array must have enabled the backends that will execute the algorithm.
 *                           + On PVA, array capacity must be >= 128.
 *
 * @param[out] outputEstimationList Estimated transform array.
 *                                  + Must not be NULL.
 *                                  + Must have type \ref VPI_ARRAY_TYPE_HOMOGRAPHY_TRANSFORM_2D.
 *                                  + Array must have enabled the backends that will execute the algorithm.
 *                                  + On PVA, array capacity must be >= 128.
 *
 * @param[in] params Control parameters of the KLT feature tracker algorithm.
 * 
 * @retval #VPI_ERROR_INVALID_ARGUMENT     \p stream is NULL.
 * @retval #VPI_ERROR_INVALID_ARGUMENT     \p referenceImage, \p templateImage, \p inputBoxList, \p inputPredictionList,
 *                                         \p outputBoxList or \p outputEstimationList are NULL.
 * @retval #VPI_ERROR_INVALID_ARGUMENT     \p params is NULL.
 * @retval #VPI_ERROR_INVALID_ARGUMENT     \p payload not created by vpiCreateKLTFeatureTracker.
 * @retval #VPI_ERROR_INVALID_ARGUMENT     \p templateImage and \p referenceImage dimensions and format do not match.
 * @retval #VPI_ERROR_INVALID_ARGUMENT     Input and parameter image dimension do not match.
 * @retval #VPI_ERROR_INVALID_ARGUMENT     Image format and \p payload image format do not match.
 * @retval #VPI_ERROR_INVALID_ARGUMENT     Unsupported array type for \p inputBoxList or \p outputBoxList.
 * @retval #VPI_ERROR_INVALID_ARGUMENT     Unsupported array type for \p inputPredictionList or \p outputEstimationList.
 * @retval #VPI_ERROR_INVALID_ARGUMENT     Parameter(s) in \p params outside valid range.
 * @retval #VPI_ERROR_INVALID_PAYLOAD_TYPE \p payload is invalid.
 * @retval #VPI_ERROR_INVALID_OPERATION    The needed backends aren't enabled in \p stream, \p referenceImage, \p templateImage,
 *                                         \p inputBoxList, \p inputPredictionList, \p outputBoxList or \p outputEstimationList.
 * @retval #VPI_SUCCESS                    Operation executed successfully.
 */
VPI_PUBLIC VPIStatus vpiSubmitKLTFeatureTracker(VPIStream stream, uint64_t backend, VPIPayload payload,
                                                VPIImage templateImage, VPIArray inputBoxList,
                                                VPIArray inputPredictionList, VPIImage referenceImage,
                                                VPIArray outputBoxList, VPIArray outputEstimationList,
                                                const VPIKLTFeatureTrackerParams *params);
/** @} end of VPI_KLTFeatureTracker */

#ifdef __cplusplus
}
#endif

#endif /* NV_VPI_ALGORITHMS_KLT_BOUNDING_BOX_TRACKER_H */
// End content from: algo/KLTFeatureTracker.h

// Begin content from: algo/MinMaxLoc.h
/*
 * Copyright 2021 NVIDIA Corporation. All rights reserved.
 *
 * NOTICE TO LICENSEE:
 *
 * This source code and/or documentation ("Licensed Deliverables") are
 * subject to NVIDIA intellectual property rights under U.S. and
 * international Copyright laws.
 *
 * These Licensed Deliverables contained herein is PROPRIETARY and
 * CONFIDENTIAL to NVIDIA and is being provided under the terms and
 * conditions of a form of NVIDIA software license agreement by and
 * between NVIDIA and Licensee ("License Agreement") or electronically
 * accepted by Licensee. Notwithstanding any terms or conditions to
 * the contrary in the License Agreement, reproduction or disclosure
 * of the Licensed Deliverables to any third party without the express
 * written consent of NVIDIA is prohibited.
 *
 * NOTWITHSTANDING ANY TERMS OR CONDITIONS TO THE CONTRARY IN THE
 * LICENSE AGREEMENT, NVIDIA MAKES NO REPRESENTATION ABOUT THE
 * SUITABILITY OF THESE LICENSED DELIVERABLES FOR ANY PURPOSE. IT IS
 * PROVIDED "AS IS" WITHOUT EXPRESS OR IMPLIED WARRANTY OF ANY KIND.
 * NVIDIA DISCLAIMS ALL WARRANTIES WITH REGARD TO THESE LICENSED
 * DELIVERABLES, INCLUDING ALL IMPLIED WARRANTIES OF MERCHANTABILITY,
 * NONINFRINGEMENT, AND FITNESS FOR A PARTICULAR PURPOSE.
 * NOTWITHSTANDING ANY TERMS OR CONDITIONS TO THE CONTRARY IN THE
 * LICENSE AGREEMENT, IN NO EVENT SHALL NVIDIA BE LIABLE FOR ANY
 * SPECIAL, INDIRECT, INCIDENTAL, OR CONSEQUENTIAL DAMAGES, OR ANY
 * DAMAGES WHATSOEVER RESULTING FROM LOSS OF USE, DATA OR PROFITS,
 * WHETHER IN AN ACTION OF CONTRACT, NEGLIGENCE OR OTHER TORTIOUS
 * ACTION, ARISING OUT OF OR IN CONNECTION WITH THE USE OR PERFORMANCE
 * OF THESE LICENSED DELIVERABLES.
 *
 * U.S. Government End Users. These Licensed Deliverables are a
 * "commercial item" as that term is defined at 48 C.F.R. 2.101 (OCT
 * 1995), consisting of "commercial computer software" and "commercial
 * computer software documentation" as such terms are used in 48
 * C.F.R. 12.212 (SEPT 1995) and is provided to the U.S. Government
 * only as a commercial end item. Consistent with 48 C.F.R.12.212 and
 * 48 C.F.R. 227.7202-1 through 227.7202-4 (JUNE 1995), all
 * U.S. Government End Users acquire the Licensed Deliverables with
 * only those rights set forth herein.
 *
 * Any use of the Licensed Deliverables in individual and commercial
 * software must include, in the user documentation and internal
 * comments to the code, the above Disclaimer and U.S. Government End
 * Users Notice.
 */

/**
 * @file MinMaxLoc.h
 *
 * Declares functions to perform minimum and maximum location finding in images.
 *
 */

#ifndef NV_VPI_ALGORITHMS_MINMAXLOC_H
#define NV_VPI_ALGORITHMS_MINMAXLOC_H

// #include "../Export.h"
// #include "../Status.h"
// #include "../Types.h"

#include <stdint.h>

#ifdef __cplusplus
extern "C" {
#endif

/**
 * @defgroup VPI_MinMaxLoc MinMaxLoc
 * @ingroup VPI_API_Algorithms
 * @{
 *
 * Find in an image the minimum and maximum value locations.
 * The function \ref vpiCreateMinMaxLoc is used to create the payload for the algorithm.
 * The function \ref vpiSubmitMinMaxLoc is used to find minimum and maximum locations in an image.
 *
 */

/**
 * Creates payload for \ref vpiSubmitMinMaxLoc
 *
 * @param[in] backends VPI backend that will execute the algorithm.
 *                     + Valid values:
 *                       - \ref VPI_BACKEND_CPU
 *                       - \ref VPI_BACKEND_CUDA 
 *                     + Backend must be enabled in current context.
 *
 * @param[in] imageWidth, imageHeight Input image dimensions.
 *                                    + Must be >= 1x1.
 *
 * @param[in] imageFormat Input image format.
 *                        + Supported formats:
 *                          - \ref VPI_IMAGE_FORMAT_U8
 *                          - \ref VPI_IMAGE_FORMAT_S8
 *                          - \ref VPI_IMAGE_FORMAT_U16
 *                          - \ref VPI_IMAGE_FORMAT_S16
 *                          - \ref VPI_IMAGE_FORMAT_U32
 *                          - \ref VPI_IMAGE_FORMAT_S32
 *                          - \ref VPI_IMAGE_FORMAT_F32
 *                          - \ref VPI_IMAGE_FORMAT_F64
 *
 * @param[out] payload Pointer to the payload variable that receives the created handle.
 *
 * @retval #VPI_ERROR_INVALID_ARGUMENT  \p payload is NULL.
 * @retval #VPI_ERROR_INVALID_ARGUMENT  \p imageWidth or \p imageHeight outside valid range.
 * @retval #VPI_ERROR_INVALID_ARGUMENT  \p backend refers to an invalid backend.
 * @retval #VPI_ERROR_NOT_IMPLEMENTED   MinMaxLoc algorithm is not supported by given backend.
 * @retval #VPI_ERROR_INVALID_CONTEXT   Current context is destroyed.
 * @retval #VPI_IMAGE_FORMAT_INVALID    \p imageFormat is not supported.
 * @retval #VPI_ERROR_OUT_OF_MEMORY     Cannot allocate required resources.
 * @retval #VPI_ERROR_INVALID_OPERATION Backend isn't enabled in current context.
 * @retval #VPI_SUCCESS                 Operation executed successfully.
 */
VPI_PUBLIC VPIStatus vpiCreateMinMaxLoc(uint64_t backends, int32_t imageWidth, int32_t imageHeight,
                                        VPIImageFormat imageFormat, VPIPayload *payload);

/**
 * Finds minimum and maximum value locations in an image.
 *
 * @note The MinMaxLoc algorithm does not guarantee deterministic output.
 *       Each array capacity (**minCoords** and **maxCoords** in
 *       \ref vpiSubmitMinMaxLoc) limit the number of locations found by the
 *       algorithm, that is the total number may be greater than this
 *       limitation and the set of locations returned might differ from one
 *       backend to another and in different runs on the same backend.
 *       Additionally, there is no strict ordering imposed to each array of
 *       locations and might also differ on different backends and runs.
 *
 * @param[in] stream The stream handle where the operation will be queued in.
 *                   + Must not be NULL.
 *                   + Stream must have enabled the backends that will execute the algorithm.
 *
 * @param[in] backend Backend that will execute the algorithm.
 *                    + Must be the backend specified during payload creation or 0 as a shorthand to use this backend.
 *
 * @param[in] payload Payload as created by \ref vpiCreateMinMaxLoc.
 *
 * @param[in] input Input image where minimum and/or maximum are to be found.
 *                  + Must not be NULL.
 *                  + Input image size and format must match the ones defined in \ref vpiCreateMinMaxLoc.
 *                  + Input image pitch must be a multiple of its pixels if using \ref VPI_BACKEND_CUDA.
 *                  + Image must have enabled the backends that will execute the algorithm.
 *
 * @param[out] minCoords Output array that stores pixel coordinates with minimum value.
 *                       If not needed, pass NULL. Number of coordinates returned is limited by array capacity.
 *                       + Array type must be \ref VPI_ARRAY_TYPE_KEYPOINT_F32.
 *                       + Array must have enabled the backends that will execute the algorithm.
 *
 * @param[out] maxCoords Output array that stores pixel coordinates with maximum value.
 *                       If not needed, pass NULL. Number of coordinates returned is limited by array capacity.
 *                       + Array type must be \ref VPI_ARRAY_TYPE_KEYPOINT_F32.
 *                       + Array must have enabled the backends that will execute the algorithm.
 *
 * @retval #VPI_ERROR_INVALID_ARGUMENT     \p stream is NULL.
 * @retval #VPI_ERROR_INVALID_ARGUMENT     \p input is NULL.
 * @retval #VPI_ERROR_INVALID_ARGUMENT     \p payload is not created using vpiCreateMinMaxLoc.
 * @retval #VPI_ERROR_INVALID_ARGUMENT     \p input image dimension and format does not match the ones associated with \p payload.
 * @retval #VPI_ERROR_INVALID_ARRAY_TYPE   \p minCoords or \p maxCoords array type not accepted.
 * @retval #VPI_ERROR_INVALID_PAYLOAD_TYPE \p payload is invalid.
 * @retval #VPI_ERROR_INVALID_OPERATION    The given backend isn't enabled in \p stream.
 * @retval #VPI_ERROR_INVALID_OPERATION    The needed backends aren't enabled in \p stream, \p input, \p minCoords or \p maxCoords.
 * @retval #VPI_SUCCESS                    Operation executed successfully.
 */
VPI_PUBLIC VPIStatus vpiSubmitMinMaxLoc(VPIStream stream, uint64_t backend, VPIPayload payload, VPIImage input,
                                        VPIArray minCoords, VPIArray maxCoords);

/** @} */

#ifdef __cplusplus
}
#endif

#endif /* NV_VPI_ALGORITHMS_MINMAXLOC_H */
// End content from: algo/MinMaxLoc.h

// Begin content from: algo/Histogram.h
/*
 * Copyright 2021 NVIDIA Corporation. All rights reserved.
 *
 * NOTICE TO LICENSEE:
 *
 * This source code and/or documentation ("Licensed Deliverables") are
 * subject to NVIDIA intellectual property rights under U.S. and
 * international Copyright laws.
 *
 * These Licensed Deliverables contained herein is PROPRIETARY and
 * CONFIDENTIAL to NVIDIA and is being provided under the terms and
 * conditions of a form of NVIDIA software license agreement by and
 * between NVIDIA and Licensee ("License Agreement") or electronically
 * accepted by Licensee. Notwithstanding any terms or conditions to
 * the contrary in the License Agreement, reproduction or disclosure
 * of the Licensed Deliverables to any third party without the express
 * written consent of NVIDIA is prohibited.
 *
 * NOTWITHSTANDING ANY TERMS OR CONDITIONS TO THE CONTRARY IN THE
 * LICENSE AGREEMENT, NVIDIA MAKES NO REPRESENTATION ABOUT THE
 * SUITABILITY OF THESE LICENSED DELIVERABLES FOR ANY PURPOSE. IT IS
 * PROVIDED "AS IS" WITHOUT EXPRESS OR IMPLIED WARRANTY OF ANY KIND.
 * NVIDIA DISCLAIMS ALL WARRANTIES WITH REGARD TO THESE LICENSED
 * DELIVERABLES, INCLUDING ALL IMPLIED WARRANTIES OF MERCHANTABILITY,
 * NONINFRINGEMENT, AND FITNESS FOR A PARTICULAR PURPOSE.
 * NOTWITHSTANDING ANY TERMS OR CONDITIONS TO THE CONTRARY IN THE
 * LICENSE AGREEMENT, IN NO EVENT SHALL NVIDIA BE LIABLE FOR ANY
 * SPECIAL, INDIRECT, INCIDENTAL, OR CONSEQUENTIAL DAMAGES, OR ANY
 * DAMAGES WHATSOEVER RESULTING FROM LOSS OF USE, DATA OR PROFITS,
 * WHETHER IN AN ACTION OF CONTRACT, NEGLIGENCE OR OTHER TORTIOUS
 * ACTION, ARISING OUT OF OR IN CONNECTION WITH THE USE OR PERFORMANCE
 * OF THESE LICENSED DELIVERABLES.
 *
 * U.S. Government End Users. These Licensed Deliverables are a
 * "commercial item" as that term is defined at 48 C.F.R. 2.101 (OCT
 * 1995), consisting of "commercial computer software" and "commercial
 * computer software documentation" as such terms are used in 48
 * C.F.R. 12.212 (SEPT 1995) and is provided to the U.S. Government
 * only as a commercial end item. Consistent with 48 C.F.R.12.212 and
 * 48 C.F.R. 227.7202-1 through 227.7202-4 (JUNE 1995), all
 * U.S. Government End Users acquire the Licensed Deliverables with
 * only those rights set forth herein.
 *
 * Any use of the Licensed Deliverables in individual and commercial
 * software must include, in the user documentation and internal
 * comments to the code, the above Disclaimer and U.S. Government End
 * Users Notice.
 */

/**
 * @file Histogram.h
 *
 * Declares functions that compute image histogram.
 */

#ifndef NV_VPI_ALGORITHMS_HISTOGRAM_H
#define NV_VPI_ALGORITHMS_HISTOGRAM_H

// #include "../AlgoFlags.h"
// #include "../Export.h"
// #include "../Status.h"
// #include "../Types.h"

#ifdef __cplusplus
extern "C" {
#endif

/**
 * @defgroup VPI_Histogram Image Histogram
 * @ingroup VPI_API_Algorithms
 * @{
 *
 * Computes image histogram from the input image.
 * Refer to \ref algo_histogram for more details and usage examples.
 */

/**
 * Creates payload for Image Histogram Even algorithm.
 * It calculates the image histogram assuming uniform (even) bins.
 *
 * @param[in] backends VPI backends that are eligible to execute the algorithm.
 *                     + Valid values: 
 *                       - \ref VPI_BACKEND_CPU
 *                       - \ref VPI_BACKEND_CUDA
 *                     + Backend must be enabled in current context.
 *
 * @param[in] fmt Format of input image.
 *                + The accepted image formats are:
 *                  - \ref VPI_IMAGE_FORMAT_U8
 *                  - \ref VPI_IMAGE_FORMAT_U16
 *
 * @param[in] start Specifies the low end of the histogram range (inclusive).
 *                  + Must be <= \p end.
 *
 * @param[in] end Specifies the high end of the histogram range (exclusive).
 *                + Must be >= \p start.
 *
 * @param[in] numBins Specifies the number of bins in the output array.
 *                    + Maximum number of bins depends on input image format:
 *                      - \ref VPI_IMAGE_FORMAT_U8  : 256
 *                      - \ref VPI_IMAGE_FORMAT_U16 : 65536
 *
 * @param[out] payload Pointer to the payload variable that receives the created handle.
 *
 * @retval #VPI_ERROR_INVALID_ARGUMENT  \p payload is NULL.
 * @retval #VPI_ERROR_INVALID_ARGUMENT  Maximum allowed \p numBins for given \p fmt outside valid range.
 * @retval #VPI_ERROR_INVALID_ARGUMENT  Invalid \p start and \p end values.
 * @retval #VPI_ERROR_INVALID_ARGUMENT  \p backends refers to an invalid backend.
 * @retval #VPI_ERROR_NOT_IMPLEMENTED   Histogram Even algorithm is not supported by given backends.
 * @retval #VPI_ERROR_INVALID_CONTEXT   Current context was destroyed.
 * @retval #VPI_IMAGE_FORMAT_INVALID    \p fmt is not supported.
 * @retval #VPI_ERROR_OUT_OF_MEMORY     Cannot allocate required resources.
 * @retval #VPI_ERROR_INVALID_OPERATION Backend isn't enabled in current context.
 * @retval #VPI_SUCCESS                 Operation executed successfully.
 */
VPI_PUBLIC VPIStatus vpiCreateHistogramEven(uint64_t backends, VPIImageFormat fmt, float start, float end,
                                            int32_t numBins, VPIPayload *payload);

/**
 * Computes the image histogram.
 *
 * @param[in] stream The stream where the operation will be queued in.
 *                   + Must not be NULL.
 *                   + Stream must have enabled the backends that will execute the algorithm.
 *
 * @param[in] backend Backend that will execute the algorithm.
 *                    + Must be the backend specified during payload creation or 0 as a shorthand to use this backend.
 *
 * @param[in] payload Payload created by \ref vpiCreateHistogramEven.
 *
 * @param[in] input Input image.
 *                  + Must not be NULL.
 *                  + Must have same format as the one specified during payload creation.
 *                  + Image must have enabled the backends that will execute the algorithm.
 *
 * @param[out] output Where the resulting image histogram will be written to.
 *                    + Must not be NULL.
 *                    + Array's capacity must be greater or equal than the number of bins configured in the payload.
 *                    + Array must have enabled the backends that will execute the algorithm.
 *
 * @param[in] flags Control flags.
 *                  + Valid values are a combination of one or more of the following flags:
 *                    - 0: Output will be zeroed out first.
 *                    - \ref VPI_ACCUMULATE_OUTPUT : accumulate on existing output values.
 * 
 * @retval #VPI_ERROR_INVALID_ARGUMENT     \p stream is NULL.
 * @retval #VPI_ERROR_INVALID_ARGUMENT     \p input or \p output are NULL.
 * @retval #VPI_ERROR_INVALID_ARGUMENT     \p payload not created by vpiCreateHistogramEven.
 * @retval #VPI_ERROR_INVALID_ARGUMENT     \p output array's capacity outside valid range.
 * @retval #VPI_ERROR_INVALID_ARRAY_TYPE   \p output array type not supported.
 * @retval #VPI_ERROR_INVALID_IMAGE_FORMAT \p input image format does not match with one associated with \p payload.
 * @retval #VPI_ERROR_INVALID_PAYLOAD_TYPE \p payload is invalid.
 * @retval #VPI_ERROR_INVALID_OPERATION    The needed backends aren't enabled in \p stream, \p input or \p output.
 * @retval #VPI_SUCCESS                    Operation executed successfully.
 */
VPI_PUBLIC VPIStatus vpiSubmitHistogram(VPIStream stream, uint64_t backend, VPIPayload payload, VPIImage input,
                                        VPIArray output, uint64_t flags);

#ifdef __cplusplus
}
#endif

/** @} */

#endif /* NV_VPI_ALGORITHMS_HISTOGRAM_H */
// End content from: algo/Histogram.h

// Begin content from: algo/GaussianFilter.h
/*
 * Copyright 2019-2021 NVIDIA Corporation. All rights reserved.
 *
 * NOTICE TO LICENSEE:
 *
 * This source code and/or documentation ("Licensed Deliverables") are
 * subject to NVIDIA intellectual property rights under U.S. and
 * international Copyright laws.
 *
 * These Licensed Deliverables contained herein is PROPRIETARY and
 * CONFIDENTIAL to NVIDIA and is being provided under the terms and
 * conditions of a form of NVIDIA software license agreement by and
 * between NVIDIA and Licensee ("License Agreement") or electronically
 * accepted by Licensee. Notwithstanding any terms or conditions to
 * the contrary in the License Agreement, reproduction or disclosure
 * of the Licensed Deliverables to any third party without the express
 * written consent of NVIDIA is prohibited.
 *
 * NOTWITHSTANDING ANY TERMS OR CONDITIONS TO THE CONTRARY IN THE
 * LICENSE AGREEMENT, NVIDIA MAKES NO REPRESENTATION ABOUT THE
 * SUITABILITY OF THESE LICENSED DELIVERABLES FOR ANY PURPOSE. IT IS
 * PROVIDED "AS IS" WITHOUT EXPRESS OR IMPLIED WARRANTY OF ANY KIND.
 * NVIDIA DISCLAIMS ALL WARRANTIES WITH REGARD TO THESE LICENSED
 * DELIVERABLES, INCLUDING ALL IMPLIED WARRANTIES OF MERCHANTABILITY,
 * NONINFRINGEMENT, AND FITNESS FOR A PARTICULAR PURPOSE.
 * NOTWITHSTANDING ANY TERMS OR CONDITIONS TO THE CONTRARY IN THE
 * LICENSE AGREEMENT, IN NO EVENT SHALL NVIDIA BE LIABLE FOR ANY
 * SPECIAL, INDIRECT, INCIDENTAL, OR CONSEQUENTIAL DAMAGES, OR ANY
 * DAMAGES WHATSOEVER RESULTING FROM LOSS OF USE, DATA OR PROFITS,
 * WHETHER IN AN ACTION OF CONTRACT, NEGLIGENCE OR OTHER TORTIOUS
 * ACTION, ARISING OUT OF OR IN CONNECTION WITH THE USE OR PERFORMANCE
 * OF THESE LICENSED DELIVERABLES.
 *
 * U.S. Government End Users. These Licensed Deliverables are a
 * "commercial item" as that term is defined at 48 C.F.R. 2.101 (OCT
 * 1995), consisting of "commercial computer software" and "commercial
 * computer software documentation" as such terms are used in 48
 * C.F.R. 12.212 (SEPT 1995) and is provided to the U.S. Government
 * only as a commercial end item. Consistent with 48 C.F.R.12.212 and
 * 48 C.F.R. 227.7202-1 through 227.7202-4 (JUNE 1995), all
 * U.S. Government End Users acquire the Licensed Deliverables with
 * only those rights set forth herein.
 *
 * Any use of the Licensed Deliverables in individual and commercial
 * software must include, in the user documentation and internal
 * comments to the code, the above Disclaimer and U.S. Government End
 * Users Notice.
 */

/**
 * @file GaussianFilter.h
 *
 * Declares functions that implement the Gaussian Filter algorithm.
 */

#ifndef NV_VPI_ALGORITHMS_GAUSSIAN_FILTER_H
#define NV_VPI_ALGORITHMS_GAUSSIAN_FILTER_H

// #include "vpi/Export.h"
// #include "vpi/Status.h"
// #include "vpi/Types.h"

#include <stdint.h>

#ifdef __cplusplus
extern "C" {
#endif

/**
 * @defgroup VPI_GaussianFilter Gaussian Filter
 * @ingroup VPI_API_Algorithms
 * @{
 *
 * Runs a generic 2D Gaussian filter over the input image.
 * Refer to \ref algo_gaussian_filter for more details and usage examples.
 */

/**
 * Runs a 2D Gaussian filter over an image.
 *
 * @param[in] stream The stream where the operation will be queued in.
 *                   + Must not be NULL.
 *                   + Stream must have enabled the backends that will execute the algorithm.
 *
 * @param[in] backend Backend that will execute the algorithm.
 *                    + Accepted values:
 *                      - \ref VPI_BACKEND_CPU
 *                      - \ref VPI_BACKEND_CUDA
 *                      - \ref VPI_BACKEND_PVA
 *
 * @param[in] input Input image to be filtered.
 *                  + Must not be NULL.
 *                  + Image must have enabled the backends that will execute the algorithm.
 *                  + On PVA, image dimensions must be between 64x32 and 3264x2448.
 *                  + The accepted image formats are:
 *                    | Formats                      | CPU | CUDA | PVA |
 *                    |------------------------------|:---:|:----:|:---:|
 *                    | \ref VPI_IMAGE_FORMAT_U8     |  *  |   *  |  *  |
 *                    | \ref VPI_IMAGE_FORMAT_S8     |  *  |   *  |  *  |
 *                    | \ref VPI_IMAGE_FORMAT_U16    |  *  |   *  |  *  |
 *                    | \ref VPI_IMAGE_FORMAT_S16    |  *  |   *  |  *  |
 *                    | \ref VPI_IMAGE_FORMAT_Y8     |  *  |   1  |  *  |
 *                    | \ref VPI_IMAGE_FORMAT_Y8_ER  |  *  |   1  |  *  |
 *                    | \ref VPI_IMAGE_FORMAT_Y16    |  *  |   1  |  *  |
 *                    | \ref VPI_IMAGE_FORMAT_Y16_ER |  *  |   1  |  *  |
 *                    | \ref VPI_IMAGE_FORMAT_F32    |  *  |   *  |     |
 *                    | \ref VPI_IMAGE_FORMAT_RGB8p  |  2  |      |     |
 *                    | \ref VPI_IMAGE_FORMAT_RGBA8p |  2  |      |     |
 *                    | \ref VPI_IMAGE_FORMAT_BGR8p  |  2  |      |     |
 *                    | \ref VPI_IMAGE_FORMAT_BGRA8p |  2  |      |     |
 *                    (1) only for kernel dimensions <= 3x3
 *                    (2) only for kernel dimensions >= 3x3
 *
 * @param[out] output Image where the result will be written to.
 *                    + Must not be NULL.
 *                    + Image must have enabled the backends that will execute the algorithm.
 *                    + Must have same dimensions as input image.
 *
 * @param[in] kernelSizeX, kernelSizeY Gaussian kernel size in X and Y directions respectively.
 *                                     If 0, it'll be `2*ceil(3*sigma)` rounded to the next odd size.
 *                                     + Limited between 1 and 11.
 *                                     + Must be odd.
 *
 * @param[in] sigmaX, sigmaY Standard deviation of the Gaussian kernel in the X and Y directions respectively.
 *                           + It must be a positive value.
 *                           + If `kernelSize==0`, sigma is limited to 2.
 *
 * @param[in] border How to handle pixels outside image boundaries.
 *                   + The accepted border extensions are:
 *                     - \ref VPI_BORDER_ZERO
 *                     - \ref VPI_BORDER_CLAMP
 *
 * @retval #VPI_ERROR_INVALID_ARGUMENT     \p stream is NULL.
 * @retval #VPI_ERROR_INVALID_ARGUMENT     \p input or \p output are NULL.
 * @retval #VPI_ERROR_INVALID_ARGUMENT     \p kernelSizeX or \p kernelSizeY outside valid range.
 * @retval #VPI_ERROR_INVALID_ARGUMENT     \p sigmaX or \p sigmaY outside valid range.
 * @retval #VPI_ERROR_INVALID_ARGUMENT     \p input or \p output image dimensions outside valid range.
 * @retval #VPI_ERROR_INVALID_ARGUMENT     \p input and \p output image dimensions and format must be the same.
 * @retval #VPI_ERROR_INVALID_ARGUMENT     \p border not supported.
 * @retval #VPI_ERROR_INVALID_ARGUMENT     \p backend is invalid or unknown.
 * @retval #VPI_ERROR_INVALID_IMAGE_FORMAT \p input or \p output image format not supported.
 * @retval #VPI_ERROR_NOT_IMPLEMENTED      Gaussian Filter algorithm is not supported by given backend.
 * @retval #VPI_ERROR_INVALID_OPERATION    Backend hardware not available.
 * @retval #VPI_ERROR_INVALID_OPERATION    The needed backends aren't enabled in \p stream, \p input or \p output.
 * @retval #VPI_SUCCESS                    Operation executed successfully.
 */
VPI_PUBLIC VPIStatus vpiSubmitGaussianFilter(VPIStream stream, uint64_t backend, VPIImage input, VPIImage output,
                                             int32_t kernelSizeX, int32_t kernelSizeY, float sigmaX, float sigmaY,
                                             VPIBorderExtension border);

#ifdef __cplusplus
}
#endif

/** @} end of VPI_GaussianFilter */

#endif /* NV_VPI_ALGORITHMS_GAUSSIAN_FILTER_H */
// End content from: algo/GaussianFilter.h

// Begin content from: algo/MixChannels.h
/*
 * Copyright 2022 NVIDIA Corporation. All rights reserved.
 *
 * NOTICE TO LICENSEE:
 *
 * This source code and/or documentation ("Licensed Deliverables") are
 * subject to NVIDIA intellectual property rights under U.S. and
 * international Copyright laws.
 *
 * These Licensed Deliverables contained herein is PROPRIETARY and
 * CONFIDENTIAL to NVIDIA and is being provided under the terms and
 * conditions of a form of NVIDIA software license agreement by and
 * between NVIDIA and Licensee ("License Agreement") or electronically
 * accepted by Licensee. Notwithstanding any terms or conditions to
 * the contrary in the License Agreement, reproduction or disclosure
 * of the Licensed Deliverables to any third party without the express
 * written consent of NVIDIA is prohibited.
 *
 * NOTWITHSTANDING ANY TERMS OR CONDITIONS TO THE CONTRARY IN THE
 * LICENSE AGREEMENT, NVIDIA MAKES NO REPRESENTATION ABOUT THE
 * SUITABILITY OF THESE LICENSED DELIVERABLES FOR ANY PURPOSE. IT IS
 * PROVIDED "AS IS" WITHOUT EXPRESS OR IMPLIED WARRANTY OF ANY KIND.
 * NVIDIA DISCLAIMS ALL WARRANTIES WITH REGARD TO THESE LICENSED
 * DELIVERABLES, INCLUDING ALL IMPLIED WARRANTIES OF MERCHANTABILITY,
 * NONINFRINGEMENT, AND FITNESS FOR A PARTICULAR PURPOSE.
 * NOTWITHSTANDING ANY TERMS OR CONDITIONS TO THE CONTRARY IN THE
 * LICENSE AGREEMENT, IN NO EVENT SHALL NVIDIA BE LIABLE FOR ANY
 * SPECIAL, INDIRECT, INCIDENTAL, OR CONSEQUENTIAL DAMAGES, OR ANY
 * DAMAGES WHATSOEVER RESULTING FROM LOSS OF USE, DATA OR PROFITS,
 * WHETHER IN AN ACTION OF CONTRACT, NEGLIGENCE OR OTHER TORTIOUS
 * ACTION, ARISING OUT OF OR IN CONNECTION WITH THE USE OR PERFORMANCE
 * OF THESE LICENSED DELIVERABLES.
 *
 * U.S. Government End Users. These Licensed Deliverables are a
 * "commercial item" as that term is defined at 48 C.F.R. 2.101 (OCT
 * 1995), consisting of "commercial computer software" and "commercial
 * computer software documentation" as such terms are used in 48
 * C.F.R. 12.212 (SEPT 1995) and is provided to the U.S. Government
 * only as a commercial end item. Consistent with 48 C.F.R.12.212 and
 * 48 C.F.R. 227.7202-1 through 227.7202-4 (JUNE 1995), all
 * U.S. Government End Users acquire the Licensed Deliverables with
 * only those rights set forth herein.
 *
 * Any use of the Licensed Deliverables in individual and commercial
 * software must include, in the user documentation and internal
 * comments to the code, the above Disclaimer and U.S. Government End
 * Users Notice.
 */

/**
 * @file MixChannels.h
 *
 * Declares functions that implement support for Mix Channels.
 */

#ifndef NV_VPI_ALGORITHMS_MIX_CHANNELS_H
#define NV_VPI_ALGORITHMS_MIX_CHANNELS_H

// #include "../Export.h"
// #include "../Status.h"
// #include "../Types.h"

#include <stdint.h>

#ifdef __cplusplus
extern "C" {
#endif

/**
 * @defgroup VPI_MixChannels Mix Channels
 * @ingroup VPI_API_Algorithms
 * @{
 *
 * Mix channels from one or more input image channels to one or more output image channels.
 * The operation is a copy operation without increasing or decreasing resolution, the input
 * and output sizes must match, and without any color conversion.
 * Refer to \ref algo_mix_channels for more details and usage examples.
 */

/** Maximum number of images that can be passed to \ref algo_mix_channels as either input or output.
 */
#define VPI_MIX_CHANNELS_MAX_IMAGES 4

/**
 * Submits a \ref algo_mix_channels "Mix Channels" operation to the stream.
 *
 * @param[in] stream The stream where the operation will be queued in.
 *                   + Must not be NULL.
 *                   + Stream must have enabled the backends that will execute the algorithm.
 *
 * @param[in] backend Backend that will execute the algorithm.
 *                    + Valid values: 
 *                      - \ref VPI_BACKEND_CPU
 *                      - \ref VPI_BACKEND_CUDA
 *
 * @param[in] inputs One or more input images from where to draw channels from.
 *                   + Must not be NULL.
 *                   + All input images must be already allocated.
 *                   + Each input image plane size must match the mapped output image plane size.
 *                   + Images must have enabled the backends that will execute the algorithm.
 *                   + The accepted image formats are:
 *                     - \ref VPI_IMAGE_FORMAT_U8
 *                     - \ref VPI_IMAGE_FORMAT_S8
 *                     - \ref VPI_IMAGE_FORMAT_U16
 *                     - \ref VPI_IMAGE_FORMAT_U32
 *                     - \ref VPI_IMAGE_FORMAT_S32
 *                     - \ref VPI_IMAGE_FORMAT_S16
 *                     - \ref VPI_IMAGE_FORMAT_2S16
 *                     - \ref VPI_IMAGE_FORMAT_F32
 *                     - \ref VPI_IMAGE_FORMAT_F64
 *                     - \ref VPI_IMAGE_FORMAT_2F32
 *                     - \ref VPI_IMAGE_FORMAT_Y8
 *                     - \ref VPI_IMAGE_FORMAT_Y8_ER
 *                     - \ref VPI_IMAGE_FORMAT_Y16
 *                     - \ref VPI_IMAGE_FORMAT_Y16_ER
 *                     - \ref VPI_IMAGE_FORMAT_NV12
 *                     - \ref VPI_IMAGE_FORMAT_NV12_ER
 *                     - \ref VPI_IMAGE_FORMAT_NV24
 *                     - \ref VPI_IMAGE_FORMAT_NV24_ER
 *                     - \ref VPI_IMAGE_FORMAT_RGB8
 *                     - \ref VPI_IMAGE_FORMAT_BGR8
 *                     - \ref VPI_IMAGE_FORMAT_RGBA8
 *                     - \ref VPI_IMAGE_FORMAT_BGRA8
 *                     - \ref VPI_IMAGE_FORMAT_RGB8p
 *                     - \ref VPI_IMAGE_FORMAT_BGR8p
 *                     - \ref VPI_IMAGE_FORMAT_RGBA8p
 *                     - \ref VPI_IMAGE_FORMAT_BGRA8p
 *
 * @param[in] numInputs Number of inputs in the array of inputs pointer argument.
 *                      + Must be between 1 and \ref VPI_MIX_CHANNELS_MAX_IMAGES .
 *
 * @param[out] outputs One or more output images from where to insert channels to.
 *                     + Must not be NULL.
 *                     + All output images must be already allocated.
 *                     + Each output image plane size must match the mapped input image plane size.
 *                     + Images must have enabled the backends that will execute the algorithm.
 *                     + The accepted image formats are the same as in \p inputs.
 *
 * @param[in] numOutputs Number of outputs in the array of outputs pointer argument.
  *                      + Must be between 1 and \ref VPI_MIX_CHANNELS_MAX_IMAGES .
 *
 * @param[in] inMapping Array with indices to channels of input images
 *                    The channels are considered linearized throughout images, that is each input is
 *                    viewed as a sequence of channels and all inputs are concatenated in its array order.
 *                    The index of an input channel gives the position on the whole inputs
 *                    channels concatenated sequence.
 *                    + Must contain existing input channel indices.
 *                    + Array size must be equal to \p numMapping.
 *
 * @param[in] outMapping Array with indices to channels of output images
 *                    The channels are considered linearized throughout images, that is each output is
 *                    viewed as a sequence of channels and all outputs are concatenated in its array order.
 *                    The index of an output channel gives the position on the whole outputs
 *                    channels concatenated sequence.
 *                    + Must contain existing output channel indices.
 *                    + Array size must be equal to \p numMapping.
 *
 * @param[in] numMapping Number of mappings in the mapping array pointer argument.
 *                       + Must be >= 1 and <= \ref VPI_MIX_CHANNELS_MAX_IMAGES * \ref VPI_MAX_PLANE_COUNT.
 *  
 * @retval #VPI_ERROR_INVALID_ARGUMENT     \p stream or \p inputs or \p outputs or \p mappings are NULL.
 * @retval #VPI_ERROR_INVALID_ARGUMENT     \p numInputs or \p numOutputs or \p numMapping are outside valid range.
 * @retval #VPI_ERROR_INVALID_IMAGE_FORMAT Unsupported input or output format.
 * @retval #VPI_ERROR_INVALID_OPERATION    The needed backends aren't enabled in \p stream, \p inputs or \p outputs.
 * @retval #VPI_SUCCESS                    Operation executed successfully.
 */
VPI_PUBLIC VPIStatus vpiSubmitMixChannels(VPIStream stream, uint64_t backend, VPIImage *inputs, int numInputs,
                                          VPIImage *outputs, int numOutputs, const int *inMapping,
                                          const int *outMapping, int numMapping);

/** @} end of VPI_MixChannels */

#ifdef __cplusplus
}
#endif

#endif /* NV_VPI_ALGORITHMS_MIX_CHANNELS_H */
// End content from: algo/MixChannels.h

// Begin content from: algo/BoxFilter.h
/*
 * Copyright 2019-2021 NVIDIA Corporation. All rights reserved.
 *
 * NOTICE TO LICENSEE:
 *
 * This source code and/or documentation ("Licensed Deliverables") are
 * subject to NVIDIA intellectual property rights under U.S. and
 * international Copyright laws.
 *
 * These Licensed Deliverables contained herein is PROPRIETARY and
 * CONFIDENTIAL to NVIDIA and is being provided under the terms and
 * conditions of a form of NVIDIA software license agreement by and
 * between NVIDIA and Licensee ("License Agreement") or electronically
 * accepted by Licensee. Notwithstanding any terms or conditions to
 * the contrary in the License Agreement, reproduction or disclosure
 * of the Licensed Deliverables to any third party without the express
 * written consent of NVIDIA is prohibited.
 *
 * NOTWITHSTANDING ANY TERMS OR CONDITIONS TO THE CONTRARY IN THE
 * LICENSE AGREEMENT, NVIDIA MAKES NO REPRESENTATION ABOUT THE
 * SUITABILITY OF THESE LICENSED DELIVERABLES FOR ANY PURPOSE. IT IS
 * PROVIDED "AS IS" WITHOUT EXPRESS OR IMPLIED WARRANTY OF ANY KIND.
 * NVIDIA DISCLAIMS ALL WARRANTIES WITH REGARD TO THESE LICENSED
 * DELIVERABLES, INCLUDING ALL IMPLIED WARRANTIES OF MERCHANTABILITY,
 * NONINFRINGEMENT, AND FITNESS FOR A PARTICULAR PURPOSE.
 * NOTWITHSTANDING ANY TERMS OR CONDITIONS TO THE CONTRARY IN THE
 * LICENSE AGREEMENT, IN NO EVENT SHALL NVIDIA BE LIABLE FOR ANY
 * SPECIAL, INDIRECT, INCIDENTAL, OR CONSEQUENTIAL DAMAGES, OR ANY
 * DAMAGES WHATSOEVER RESULTING FROM LOSS OF USE, DATA OR PROFITS,
 * WHETHER IN AN ACTION OF CONTRACT, NEGLIGENCE OR OTHER TORTIOUS
 * ACTION, ARISING OUT OF OR IN CONNECTION WITH THE USE OR PERFORMANCE
 * OF THESE LICENSED DELIVERABLES.
 *
 * U.S. Government End Users. These Licensed Deliverables are a
 * "commercial item" as that term is defined at 48 C.F.R. 2.101 (OCT
 * 1995), consisting of "commercial computer software" and "commercial
 * computer software documentation" as such terms are used in 48
 * C.F.R. 12.212 (SEPT 1995) and is provided to the U.S. Government
 * only as a commercial end item. Consistent with 48 C.F.R.12.212 and
 * 48 C.F.R. 227.7202-1 through 227.7202-4 (JUNE 1995), all
 * U.S. Government End Users acquire the Licensed Deliverables with
 * only those rights set forth herein.
 *
 * Any use of the Licensed Deliverables in individual and commercial
 * software must include, in the user documentation and internal
 * comments to the code, the above Disclaimer and U.S. Government End
 * Users Notice.
 */

/**
 * @file BoxFilter.h
 *
 * Declares functions that implement the Box Filter algorithm.
 */

#ifndef NV_VPI_ALGORITHMS_BOX_FILTER_H
#define NV_VPI_ALGORITHMS_BOX_FILTER_H

/**
 * @defgroup VPI_BoxFilter Box Filter
 * @ingroup VPI_API_Algorithms
 * @{
 *
 * Runs a generic 2D box filter over the input image.
 * Refer to \ref algo_box_filter for more details and usage examples.
 */

// #include "../Export.h"
// #include "../Status.h"
// #include "../Types.h"

#include <stdint.h>

#ifdef __cplusplus
extern "C" {
#endif

/**
 * Runs a 2D box filter over an image.
 *
 * @param[in] stream A stream handle where the operation will be queued into.
 *                   + Must not be NULL.
 *                   + Stream must have enabled the backends that will execute the algorithm.
 *
 * @param[in] backend Backend that will execute the algorithm.
 *                    + Valid values:
 *                      - \ref VPI_BACKEND_CPU
 *                      - \ref VPI_BACKEND_CUDA
 *                      - \ref VPI_BACKEND_PVA
 *
 * @param[in] input Input image to be filtered.
 *                  + Must not be NULL.
 *                  + Image must have enabled the backends that will execute the algorithm.
 *                  + On PVA, image dimensions must be between 65x33 and 3264x2448.
 *                  + The accepted image formats are:
 *                    | Formats                      | CPU | CUDA | PVA |
 *                    |------------------------------|:---:|:----:|:---:|
 *                    | \ref VPI_IMAGE_FORMAT_U8     |  *  |   *  |  *  |
 *                    | \ref VPI_IMAGE_FORMAT_S8     |  *  |   *  |  *  |
 *                    | \ref VPI_IMAGE_FORMAT_U16    |  *  |   *  |  *  |
 *                    | \ref VPI_IMAGE_FORMAT_S16    |  *  |   *  |  *  |
 *                    | \ref VPI_IMAGE_FORMAT_Y8     |  *  |   1  |     |
 *                    | \ref VPI_IMAGE_FORMAT_Y8_ER  |  *  |   1  |     |
 *                    | \ref VPI_IMAGE_FORMAT_Y16    |  *  |   1  |     |
 *                    | \ref VPI_IMAGE_FORMAT_Y16_ER |  *  |   1  |     |
 *                    | \ref VPI_IMAGE_FORMAT_F32    |  *  |   *  |     |
 *                    | \ref VPI_IMAGE_FORMAT_RGB8p  |  2  |      |     |
 *                    | \ref VPI_IMAGE_FORMAT_RGBA8p |  2  |      |     |
 *                    | \ref VPI_IMAGE_FORMAT_BGR8p  |  2  |      |     |
 *                    | \ref VPI_IMAGE_FORMAT_BGRA8p |  2  |      |     |
 *                    (1) only for kernel dimensions <= 3x3
 *                    (2) only for kernel dimensions >= 3x3
 *
 * @param[out] output Output image where the result is written to.
 *                    + Must not be NULL.
 *                    + It must have same dimensions and format as input.
 *                    + Image must have enabled the backends that will execute the algorithm.
 *
 * @param[in] kernelWidth, kernelHeight Box kernel dimensions.
 *                                      Can be non-square.
 *                                      + Both must be between 1x1 and 11x11, and odd.
 *
 * @param[in] border How to handle pixels outside image boundaries.
 *                   + The accepted border extensions are:
 *                     - \ref VPI_BORDER_ZERO
 *                     - \ref VPI_BORDER_CLAMP
 *
 * @retval #VPI_ERROR_INVALID_ARGUMENT     \p stream is NULL.
 * @retval #VPI_ERROR_INVALID_ARGUMENT     \p input or \p output are NULL.
 * @retval #VPI_ERROR_INVALID_ARGUMENT     \p kernelWidth or \p kernelHeight outside valid range.
 * @retval #VPI_ERROR_INVALID_ARGUMENT     \p input or \p output image dimensions ouside valid range.
 * @retval #VPI_ERROR_INVALID_ARGUMENT     \p input and \p output image dimensions or format do not match.
 * @retval #VPI_ERROR_INVALID_ARGUMENT     \p border not supported.
 * @retval #VPI_ERROR_INVALID_ARGUMENT     \p backend is invalid or unknown.
 * @retval #VPI_ERROR_INVALID_IMAGE_FORMAT \p input or \p output image format not supported.
 * @retval #VPI_ERROR_INVALID_OPERATION    Backend hardware is not available.
 * @retval #VPI_ERROR_INVALID_OPERATION    The needed backends aren't enabled in \p stream, \p input or \p output.
 * @retval #VPI_ERROR_NOT_IMPLEMENTED      Box Filter algorithm is not supported by given backend.
 * @retval #VPI_SUCCESS                    Operation executed successfully.
 */
VPI_PUBLIC VPIStatus vpiSubmitBoxFilter(VPIStream stream, uint64_t backend, VPIImage input, VPIImage output,
                                        int32_t kernelWidth, int32_t kernelHeight, VPIBorderExtension border);

#ifdef __cplusplus
}
#endif

/** @} end of VPI_BoxFilter */

#endif /* NV_VPI_ALGORITHMS_BOX_FILTER_H */
// End content from: algo/BoxFilter.h

// Begin content from: algo/StereoDisparity.h
/*
 * Copyright 2019-2023 NVIDIA Corporation. All rights reserved.
 *
 * NOTICE TO LICENSEE:
 *
 * This source code and/or documentation ("Licensed Deliverables") are
 * subject to NVIDIA intellectual property rights under U.S. and
 * international Copyright laws.
 *
 * These Licensed Deliverables contained herein is PROPRIETARY and
 * CONFIDENTIAL to NVIDIA and is being provided under the terms and
 * conditions of a form of NVIDIA software license agreement by and
 * between NVIDIA and Licensee ("License Agreement") or electronically
 * accepted by Licensee. Notwithstanding any terms or conditions to
 * the contrary in the License Agreement, reproduction or disclosure
 * of the Licensed Deliverables to any third party without the express
 * written consent of NVIDIA is prohibited.
 *
 * NOTWITHSTANDING ANY TERMS OR CONDITIONS TO THE CONTRARY IN THE
 * LICENSE AGREEMENT, NVIDIA MAKES NO REPRESENTATION ABOUT THE
 * SUITABILITY OF THESE LICENSED DELIVERABLES FOR ANY PURPOSE. IT IS
 * PROVIDED "AS IS" WITHOUT EXPRESS OR IMPLIED WARRANTY OF ANY KIND.
 * NVIDIA DISCLAIMS ALL WARRANTIES WITH REGARD TO THESE LICENSED
 * DELIVERABLES, INCLUDING ALL IMPLIED WARRANTIES OF MERCHANTABILITY,
 * NONINFRINGEMENT, AND FITNESS FOR A PARTICULAR PURPOSE.
 * NOTWITHSTANDING ANY TERMS OR CONDITIONS TO THE CONTRARY IN THE
 * LICENSE AGREEMENT, IN NO EVENT SHALL NVIDIA BE LIABLE FOR ANY
 * SPECIAL, INDIRECT, INCIDENTAL, OR CONSEQUENTIAL DAMAGES, OR ANY
 * DAMAGES WHATSOEVER RESULTING FROM LOSS OF USE, DATA OR PROFITS,
 * WHETHER IN AN ACTION OF CONTRACT, NEGLIGENCE OR OTHER TORTIOUS
 * ACTION, ARISING OUT OF OR IN CONNECTION WITH THE USE OR PERFORMANCE
 * OF THESE LICENSED DELIVERABLES.
 *
 * U.S. Government End Users. These Licensed Deliverables are a
 * "commercial item" as that term is defined at 48 C.F.R. 2.101 (OCT
 * 1995), consisting of "commercial computer software" and "commercial
 * computer software documentation" as such terms are used in 48
 * C.F.R. 12.212 (SEPT 1995) and is provided to the U.S. Government
 * only as a commercial end item. Consistent with 48 C.F.R.12.212 and
 * 48 C.F.R. 227.7202-1 through 227.7202-4 (JUNE 1995), all
 * U.S. Government End Users acquire the Licensed Deliverables with
 * only those rights set forth herein.
 *
 * Any use of the Licensed Deliverables in individual and commercial
 * software must include, in the user documentation and internal
 * comments to the code, the above Disclaimer and U.S. Government End
 * Users Notice.
 */

#ifndef NV_VPI_ALGORITHMS_STEREO_DISPARITY_H
#define NV_VPI_ALGORITHMS_STEREO_DISPARITY_H

/**
 * @file StereoDisparity.h
 *
 * Declares functions that implement stereo disparity estimation algorithms.
 */

// #include "../Export.h"
// #include "../ImageFormat.h"
// #include "../Status.h"
// #include "../Types.h"

#include <stdint.h>

#ifdef __cplusplus
extern "C" {
#endif

/**
 * @defgroup VPI_StereoDisparityEstimator Stereo Disparity Estimator
 * @ingroup VPI_API_Algorithms
 * @{
 *
 * Estimates disparity from a stereo pair.
 * Refer to \ref algo_stereo_disparity for more details and usage examples.
 */

/**
 * Structure that defines the parameters for \ref vpiCreateStereoDisparityEstimator
 */
typedef struct
{
    /** Maximum disparity for matching search.
     *  + Must be positive.
     *  + On CPU backend, maxDisparity must be <= 64.
     *  + On PVA backend, maxDisparity must be == 64.
     *  + On OFA or OFA+PVA+VIC backend, maxDisparity must be 128 or 256.
     *  + On CUDA backends, maxDisparity must be >= 0 and <= 256.
     *  + On PVA+NVENC+VIC backends, range from >= 0 and <= 256 is accepted, but
     *    internally this value is ignored and 256 is used instead.
     */
    int32_t maxDisparity;

    /** Output's downscale factor with respect to the input's resolution.
     *  + For PVA+NVENC+VIC backend, only 4 is supported.
     *    Setting it to 4 leads to faster execution speeds as NVENC engine internal output has 1/4th resolution.
     *  + For OFA and OFA+PVA+VIC backend, the allowed values are 1, 2, 4 or 8.
     *  + For other backends, only 1 is supported, i.e. output dimension equals input's. */
    int32_t downscaleFactor;

    /** Include diagonals or oblique paths in semi-global matching (SGM) computation.
     * Including diagonal paths makes the stereo disparity estimator slower, but increases the result quality.
     * Including diagonal paths also increases memory usage in the CUDA backend.
     * If zero means not to include diagonal paths, i.e. horizontal and vertical paths only.
     * If not zero means to include diagonal paths, i.e. horizontal, vertical and oblique paths.
     * It's only applicable when using CUDA and OFA backends. */
    int8_t includeDiagonals;

} VPIStereoDisparityEstimatorCreationParams;

/**
 * Initializes \ref VPIStereoDisparityEstimatorCreationParams with default values.
 *
 * Defaults:
 * - maxDisparity     = 64
 * - downscaleFactor  = 1
 * - includeDiagonals = 1
 *
 * @param[in] params Structure to be filled with default values.
 *
 * @retval #VPI_ERROR_INVALID_ARGUMENT \p params is NULL.
 * @retval #VPI_SUCCESS Operation executed successfully.
 */
#if NV_VPI_VERSION_API_AT_MOST(2, 2)
__asm__(".symver vpiInitStereoDisparityEstimatorCreationParams,vpiInitStereoDisparityEstimatorCreationParams@VPI_2.0");
VPI_PUBLIC VPIStatus vpiInitStereoDisparityEstimatorCreationParams(VPIStereoDisparityEstimatorCreationParams *params);
#else
VPI_PUBLIC VPIStatus vpiInitStereoDisparityEstimatorCreationParams(VPIStereoDisparityEstimatorCreationParams *params);
#endif

/**
 * Creates payload for \ref vpiSubmitStereoDisparityEstimator
 *
 * @param[in] backends VPI backends that are eligible to execute the algorithm.
 *                     + Valid values:
 *                       - \ref VPI_BACKEND_CPU
 *                       - \ref VPI_BACKEND_CUDA
 *                       - \ref VPI_BACKEND_OFA
 *                       - \ref VPI_BACKEND_PVA
 *                       - \ref VPI_BACKEND_PVA | \ref VPI_BACKEND_OFA   | \ref VPI_BACKEND_VIC
 *                       - \ref VPI_BACKEND_PVA | \ref VPI_BACKEND_NVENC | \ref VPI_BACKEND_VIC
 *                     + Backends must be enabled in current context.
 *
 * @param[in] imageWidth, imageHeight Input image dimensions.
 *                                    + Must be >= 0.
 *                                    + On PVA, input dimensions must be 480x270.
 *                                    + On PVA+NVENC+VIC, input dimensions must be 1920x1080.
 *                                    + On OFA, input width and height must be between 16 and 16384 after applying downscaleFactor.
 *                                    + On OFA+PVA+VIC, input width must be at least max(64, maxDisparity/downscaleFactor) * downscaleFactor.
 *
 * @param[in] inputFormat Input image format.
 *                        + Supported image formats are:
 *                          | Formats                          | CUDA | CPU | PVA | OFA | OFA+PVA+VIC | PVA+NVENC+VIC |
 *                          |----------------------------------|:----:|:---:|:---:|:---:|:-----------:|:-------------:|
 *                          | \ref VPI_IMAGE_FORMAT_U8         |   *  |  *  |     |     |             |               |
 *                          | \ref VPI_IMAGE_FORMAT_U16        |   *  |  *  |  *  |     |             |               |
 *                          | \ref VPI_IMAGE_FORMAT_Y8         |   *  |  *  |     |     |             |               |
 *                          | \ref VPI_IMAGE_FORMAT_Y8_BL      |      |     |     |  *  |      *      |               |
 *                          | \ref VPI_IMAGE_FORMAT_Y8_ER      |   *  |  *  |     |     |             |               |
 *                          | \ref VPI_IMAGE_FORMAT_Y8_ER_BL   |      |     |     |  *  |      *      |               |
 *                          | \ref VPI_IMAGE_FORMAT_Y16        |   *  |  *  |     |     |             |               |
 *                          | \ref VPI_IMAGE_FORMAT_Y16_BL     |      |     |     |  *  |      *      |               |
 *                          | \ref VPI_IMAGE_FORMAT_Y16_ER     |   *  |  *  |  *  |     |             |               |
 *                          | \ref VPI_IMAGE_FORMAT_Y16_ER_BL  |      |     |     |  *  |      *      |       *       |
 *                          | \ref VPI_IMAGE_FORMAT_NV12       |   *  |  *  |     |     |             |               |
 *                          | \ref VPI_IMAGE_FORMAT_NV12_BL    |      |     |     |  *  |      *      |               |
 *                          | \ref VPI_IMAGE_FORMAT_NV12_ER    |   *  |  *  |     |     |             |               |
 *                          | \ref VPI_IMAGE_FORMAT_NV12_ER_BL |      |     |     |  *  |      *      |               |
 *                          | \ref VPI_IMAGE_FORMAT_NV24       |   *  |  *  |     |     |             |               |
 *                          | \ref VPI_IMAGE_FORMAT_NV24_BL    |      |     |     |  *  |      *      |               |
 *                          | \ref VPI_IMAGE_FORMAT_NV24_ER    |   *  |  *  |     |     |             |               |
 *                          | \ref VPI_IMAGE_FORMAT_NV24_ER_BL |      |     |     |  *  |      *      |               |
 *
 * @param[in] params Creation parameters.
 *                   Pass NULL to use defaults given by \ref vpiInitStereoDisparityEstimatorCreationParams.
 *
 * @param[out] payload Pointer to the payload variable that receives the created handle.
 *
 * @retval #VPI_ERROR_INVALID_IMAGE_FORMAT \p inputFormat is not supported.
 * @retval #VPI_ERROR_INVALID_ARGUMENT     \p payload is NULL.
 * @retval #VPI_ERROR_INVALID_ARGUMENT     \p imageWidth or \p imageHeight outside valid range.
 * @retval #VPI_ERROR_INVALID_ARGUMENT     \p backends refers to an invalid backend.
 * @retval #VPI_ERROR_INVALID_ARGUMENT     Maximum disparity in \p params outside valid range.
 * @retval #VPI_ERROR_NOT_IMPLEMENTED      Stereo Disparity Estimator algorithm is not supported by given backends.
 * @retval #VPI_ERROR_INVALID_OPERATION    Backend hardware not available.
 * @retval #VPI_ERROR_INVALID_CONTEXT      Current context is destroyed.
 * @retval #VPI_ERROR_OUT_OF_MEMORY        Cannot allocate required resources.
 * @retval #VPI_ERROR_INVALID_OPERATION    Backend isn't enabled in current context.
 * @retval #VPI_SUCCESS                    Operation executed successfully.
 */
VPI_PUBLIC VPIStatus vpiCreateStereoDisparityEstimator(uint64_t backends, int32_t imageWidth, int32_t imageHeight,
                                                       VPIImageFormat inputFormat,
                                                       const VPIStereoDisparityEstimatorCreationParams *params,
                                                       VPIPayload *payload);

/** Defines the way the confidence values are computed.
 *
 *  This computation needs the disparity difference from left to right (D_lr) and from right to left (D_rl), and
 *  potentially the maximum disparity (MAX_DISP).  Lower confidence values (than the given confidence threshold
 *  parameter) make the output disparity invalid.
 */
typedef enum
{
    /** The U16 confidence value of a pixel is given by:
     *  [ 1 - abs(D_lr - D_rl) / MAX_DISP ] * 0xFFFF
     */
    VPI_STEREO_CONFIDENCE_ABSOLUTE = 0,

    /** The U16 confidence value of a pixel is given by:
     *  [ 1 - abs(D_lr - D_rl) / D_lr ] * 0xFFFF
     */
    VPI_STEREO_CONFIDENCE_RELATIVE = 1

} VPIStereoDisparityConfidenceType;

/**
 * Structure that defines the parameters for \ref vpiSubmitStereoDisparityEstimator
 */
typedef struct
{
    /** Represents the median filter size (on PVA+NVENC+VIC or OFA+PVA+VIC backend)
        or census transform window size (other backends) used in the algorithm.
     *  + On PVA backend, it must be 5.
     *  + On CPU backend, it must be >= 1.
     *  + On CUDA backend this is ignored. A 9x7 window is used instead.
     *  + On OFA backend it is ignored.
     *  + On OFA+PVA+VIC backend, valid values are 1, 3, 5 or 7.
     *  + On PVA+NVENC+VIC backend, valid values are 1, 3, 5 or 7. */
    int32_t windowSize;

    /** Maximum disparity for matching search.
     *  + Maximum disparity must be 0 (use from payload), or positive and less or equal to what's configured in payload.
     *  + For CUDA, it must be equal to the configured in the payload (or 0) */
    int32_t maxDisparity;

    /** Confidence threshold above which disparity values are considered valid.
     * Only used in CUDA, PVA+NVENC+VIC, and OFA+PVA+VIC backends.
     * + Must be a value in U16 ranges, i.e. from 0 to 65535. */
    int32_t confidenceThreshold;

    /** Quality of disparity output.
     * It's only applicable when using PVA+NVENC+VIC backend.
     * The higher the value, better the quality and possibly slower perf.
     * + Must be a value between 1 and 8. */
    int32_t quality;

    /** Computation type to produce the confidence output.
     * + Use \ref VPI_STEREO_CONFIDENCE_ABSOLUTE for absolute difference between disparities computation.
     * + Use \ref VPI_STEREO_CONFIDENCE_RELATIVE for relative difference between disparities computation. */
    VPIStereoDisparityConfidenceType confidenceType;

    /** Minimum possible disparity value.
     * It's only applicable when using CUDA backend.
     * Normally it is zero, but it may be adjusted depending on input images.
     * + Must be between 0 and maximum disparity. */
    int32_t minDisparity;

    /** Penalty on disparity changes of +/- 1 between neighbor pixels.
     * It is normally a small value, in (min, max) disparity range, used to penalize small changes in disparity, i.e. one.
     * Using a lower P1 penalty allows for an adaptation to slanted or curver surfaces.
     * (Please refer to \ref paper_sgm on how penalties affect disparity values.)
     * It's only applicable when using CUDA and OFA backends.
     * + Must be a positive value.
     * + Must be smaller than or equal to P2. */
    int32_t p1;

    /** Penalty on disparity changes of more than 1 between neighbor pixels.
     * It is normally a large value, in (min, max) disparity range, used to penalize large changes in disparity.
     * Using a higher P2 penalty avoids abrupt disparity changes, i.e. discontinuities.
     * (Please refer to \ref paper_sgm on how penalties affect disparity values.)
     * It's only applicable when using CUDA and OFA backends.
     * + Must be a positive value.
     * + Must be equal to or greater than P1.
     * + in CUDA backend, must be less than 256.
     * + In OFA backends, must be less than or equal to 217 - P1. */
    int32_t p2;

    /** Alpha is used to enable adaptive large penalty (adaptive P2) feature.
     * It's used to better preserve object boundaries and thin objects.
     * Higher alpha indicates lower adaptation of P2 in accordance to pixel intensities.
     * It's the alpha value in: P2' = - (1 / alpha) * abs(I_cur - I_prev) + P2;
     * where P2' is the adaptive version of the given P2 penalty.
     * The abs(I_cur - I_prev) is the absolute difference in intensity between the current and previous pixel
     * location along the direction of path cost evaluation.  The intuition behind this adaptation is that large
     * disparity differences should be penalized less if they coincide with large intensity changes.
     * The alpha value can be 0, 1, 2, 4 or 8.  Using an alpha value of 0 disables the adaptive P2 feature.
     * It's only applicable when using OFA backend.
     * + Must be 0, 1, 2, 4 or 8. */
    int32_t p2Alpha;

    /** Uniqueness ratio, in [0, 1] range, is a margin by which best cost value should win over the second best.
     * A value of 1 means less pixels are marked invalid, as the full cost is considered when comparing against the current best cost.
     * Values less than 1 mean only a ratio of the cost is considered for the best cost.
     * A value of 0 means more pixels are marked invalid, as only disparity changes of +/- 1 pixels are considered.
     * Use it to improve certainty of computed disparity.
     * Use value outside [0, 1], such as -1, to disregard the uniqueness computation.
     * It's only applicable when using CUDA backend. */
    float uniqueness;

    /** Number of passes in memory-efficient semi-global matching (eSGM) computation.
     * A value of 1 or 2 means to do one forward or one forward and one backward passes per direction.
     * A value of 3 means to do another forward pass after forward and backward passes.
     * Setting number of passes to 3 makes the stereo disparity estimator slower, but increases the result quality.
     * It's only applicable when using OFA backends.
     * + Must be 1, 2 or 3. */
    int8_t numPasses;

} VPIStereoDisparityEstimatorParams;

/**
 * Initializes \ref VPIStereoDisparityEstimatorParams with default values.
 *
 * Defaults:
 * - windowSize          = 5
 * - maxDisparity        = 0 (uses disparity set during payload construction)
 * - confidenceThreshold = 32767
 * - quality             = 6
 * - confidenceType      = \ref VPI_STEREO_CONFIDENCE_ABSOLUTE
 * - minDisparity        = 0
 * - p1                  = 3
 * - p2                  = 48
 * - p2Alpha             = 0
 * - uniqueness          = -1
 * - numPasses           = 3
 *
 * @param[in] params Structure to be filled with default values.
 *
 * @retval #VPI_ERROR_INVALID_ARGUMENT \p params is NULL.
 * @retval #VPI_SUCCESS Operation executed successfully.
 */
#if NV_VPI_VERSION_API_AT_MOST(2, 2)
__asm__(".symver vpiInitStereoDisparityEstimatorParams,vpiInitStereoDisparityEstimatorParams@VPI_2.0");
VPI_PUBLIC VPIStatus vpiInitStereoDisparityEstimatorParams(VPIStereoDisparityEstimatorParams *params);
#else
VPI_PUBLIC VPIStatus vpiInitStereoDisparityEstimatorParams(VPIStereoDisparityEstimatorParams *params);
#endif

/**
 * Runs stereo processing on a pair of images and outputs a disparity map.
 *
 * @param[in] stream The stream where the operation will be queued in.
 *                   + Must not be NULL.
 *                   + Stream must have enabled the backends that will execute the algorithm.
 *
 * @param[in] backend Backend that will execute the algorithm.
 *                    + Must be the backend specified during payload creation or 0 as a shorthand to use this backend.
 *
 * @param[in] payload Payload to be submitted along the other parameters.
 *
 * @param[in] left Left stereo input image.
 *                 + Must not be NULL.
 *                 + Must have same format and dimensions as the one specified during payload creation.
 *                 + Image must have enabled the backends that will execute the algorithm.
 *
 * @param[in] right Right stereo input image.
 *                  + Must not be NULL.
 *                  + Must have same format and dimensions as \p left.
 *                  + Image must have enabled the backends that will execute the algorithm.
 *
 * @param[out] disparity Image where the disparity values will be written to.
 *                       Returned values are in Q10.5 format, i.e., signed fixed point with 5 fractional bits.
 *                       Divide it by 32.0f to convert it to floating point.
 *                       + Must not be NULL.
 *                       + On OFA backend, image format must be \ref VPI_IMAGE_FORMAT_S16_BL
 *                       + On other backends, image format must be \ref VPI_IMAGE_FORMAT_S16.
 *                       + On PVA+NVENC+VIC backend, image format can be \ref VPI_IMAGE_FORMAT_U16.
 *                       + On OFA+PVA+VIC backend, and if windowSize==1, confidenceMap==NULL and confidenceThreshold==0,
 *                         the image format can be either \ref VPI_IMAGE_FORMAT_S16 or \ref VPI_IMAGE_FORMAT_S16_BL.
 *                       + Dimensions must be equal to \p input,
 *                         but downscaled by \ref VPIStereoDisparityEstimatorCreationParams::downscaleFactor
 *                         passed in \p params.
 *                       + Image must have enabled the backends that will execute the algorithm.
 *
 * @param[out] confidenceMap Image containing a confidence score telling how accurate the disparity is.
 *                           Pass NULL if it isn't needed.
 *                           Returned confidence range from 0 to 65535.
 *                           The higher the confidence, more accurate is the corresponding disparity.
 *                           + CPU, PVA and OFA backends don't support confidence map output, it must be NULL.
 *                           + If NULL on PVA+NVENC+VIC backend, the confidenceThreshold parameter will be ignored.
 *                           + Image format must be \ref VPI_IMAGE_FORMAT_U16
 *                           + Must be same dimensions as \p disparity.
 *                           + Image must have enabled the backends that will execute the algorithm.
 *
 * @param[in] params Pointer to algorithm control parameters. If NULL, it'll use the
 *                   defaults given by \ref vpiInitStereoDisparityEstimatorParams.
 *
 * @retval #VPI_ERROR_INVALID_ARGUMENT     \p stream is NULL.
 * @retval #VPI_ERROR_INVALID_ARGUMENT     \p left, \p right or \p disparity are NULL.
 * @retval #VPI_ERROR_INVALID_ARGUMENT     Maximum disparity in \p params outside valid range.
 * @retval #VPI_ERROR_INVALID_ARGUMENT     Window size in \p params outside valid range.
 * @retval #VPI_ERROR_INVALID_ARGUMENT     \p left and \p right images must have the same dimensions.
 * @retval #VPI_ERROR_INVALID_ARGUMENT     Input image dimensions must be equal to what's configured in \p payload.
 * @retval #VPI_ERROR_INVALID_ARGUMENT     \p confidenceMap and \p disparity must have same dimensions.
 * @retval #VPI_ERROR_INVALID_ARGUMENT     Backend doesn't output confidence map.
 * @retval #VPI_ERROR_INVALID_IMAGE_FORMAT \p left and \p right format don't match payload image format.
 * @retval #VPI_ERROR_INVALID_IMAGE_FORMAT \p disparity format is invalid.
 * @retval #VPI_ERROR_INVALID_PAYLOAD_TYPE \p payload is invalid.
 * @retval #VPI_ERROR_INVALID_OPERATION    The needed backends aren't enabled in \p stream, \p left, \p right,
 *                                         \p disparity or \p confidenceMap.
 * @retval #VPI_SUCCESS                    Operation executed successfully.
 */
#if NV_VPI_VERSION_API_AT_MOST(2, 2)
__asm__(".symver vpiSubmitStereoDisparityEstimator,vpiSubmitStereoDisparityEstimator@VPI_2.0");
VPI_PUBLIC VPIStatus vpiSubmitStereoDisparityEstimator(VPIStream stream, uint64_t backend, VPIPayload payload,
                                                       VPIImage left, VPIImage right, VPIImage disparity,
                                                       VPIImage confidenceMap,
                                                       const VPIStereoDisparityEstimatorParams *params);
#else
VPI_PUBLIC VPIStatus vpiSubmitStereoDisparityEstimator(VPIStream stream, uint64_t backend, VPIPayload payload,
                                                       VPIImage left, VPIImage right, VPIImage disparity,
                                                       VPIImage confidenceMap,
                                                       const VPIStereoDisparityEstimatorParams *params);
#endif

/** @} end of VPI_StereoDisparityEstimator */

#ifdef __cplusplus
}
#endif

#endif /* NV_VPI_ALGORITHMS_STEREO_DISPARITY_H */
// End content from: algo/StereoDisparity.h

// Begin content from: algo/PerspectiveWarp.h
/*
 * Copyright 2020-2022 NVIDIA Corporation. All rights reserved.
 *
 * NOTICE TO LICENSEE:
 *
 * This source code and/or documentation ("Licensed Deliverables") are
 * subject to NVIDIA intellectual property rights under U.S. and
 * international Copyright laws.
 *
 * These Licensed Deliverables contained herein is PROPRIETARY and
 * CONFIDENTIAL to NVIDIA and is being provided under the terms and
 * conditions of a form of NVIDIA software license agreement by and
 * between NVIDIA and Licensee ("License Agreement") or electronically
 * accepted by Licensee. Notwithstanding any terms or conditions to
 * the contrary in the License Agreement, reproduction or disclosure
 * of the Licensed Deliverables to any third party without the express
 * written consent of NVIDIA is prohibited.
 *
 * NOTWITHSTANDING ANY TERMS OR CONDITIONS TO THE CONTRARY IN THE
 * LICENSE AGREEMENT, NVIDIA MAKES NO REPRESENTATION ABOUT THE
 * SUITABILITY OF THESE LICENSED DELIVERABLES FOR ANY PURPOSE. IT IS
 * PROVIDED "AS IS" WITHOUT EXPRESS OR IMPLIED WARRANTY OF ANY KIND.
 * NVIDIA DISCLAIMS ALL WARRANTIES WITH REGARD TO THESE LICENSED
 * DELIVERABLES, INCLUDING ALL IMPLIED WARRANTIES OF MERCHANTABILITY,
 * NONINFRINGEMENT, AND FITNESS FOR A PARTICULAR PURPOSE.
 * NOTWITHSTANDING ANY TERMS OR CONDITIONS TO THE CONTRARY IN THE
 * LICENSE AGREEMENT, IN NO EVENT SHALL NVIDIA BE LIABLE FOR ANY
 * SPECIAL, INDIRECT, INCIDENTAL, OR CONSEQUENTIAL DAMAGES, OR ANY
 * DAMAGES WHATSOEVER RESULTING FROM LOSS OF USE, DATA OR PROFITS,
 * WHETHER IN AN ACTION OF CONTRACT, NEGLIGENCE OR OTHER TORTIOUS
 * ACTION, ARISING OUT OF OR IN CONNECTION WITH THE USE OR PERFORMANCE
 * OF THESE LICENSED DELIVERABLES.
 *
 * U.S. Government End Users. These Licensed Deliverables are a
 * "commercial item" as that term is defined at 48 C.F.R. 2.101 (OCT
 * 1995), consisting of "commercial computer software" and "commercial
 * computer software documentation" as such terms are used in 48
 * C.F.R. 12.212 (SEPT 1995) and is provided to the U.S. Government
 * only as a commercial end item. Consistent with 48 C.F.R.12.212 and
 * 48 C.F.R. 227.7202-1 through 227.7202-4 (JUNE 1995), all
 * U.S. Government End Users acquire the Licensed Deliverables with
 * only those rights set forth herein.
 *
 * Any use of the Licensed Deliverables in individual and commercial
 * software must include, in the user documentation and internal
 * comments to the code, the above Disclaimer and U.S. Government End
 * Users Notice.
 */

/**
 * @file PerspectiveWarp.h
 *
 * Declares functions that implement the Perspective Warp algorithm.
 */

#ifndef NV_VPI_ALGORITHMS_PERSPECTIVE_WARP_H
#define NV_VPI_ALGORITHMS_PERSPECTIVE_WARP_H

// #include "../AlgoFlags.h"
// #include "../Export.h"
// #include "../Status.h"
// #include "../Types.h"
// #include "../WarpMap.h"

#include <stdint.h>

#ifdef __cplusplus
extern "C" {
#endif

/**
 * @defgroup VPI_PerspectiveWarp Perspective Warp
 * @ingroup VPI_API_Algorithms
 * @{
 *
 * Applies a perspective warp on an image.
 * Refer to \ref algo_persp_warp for more details and usage examples.
 */

/**
 * Submits a \ref algo_persp_warp "Perspective Warp" operation to the stream.
 *
 * @param[in] stream The stream where the operation will be queued in.
 *                   + Must not be NULL.
 *                   + Stream must have enabled the backends that will execute the algorithm.
 *
 * @param[in] backend VPI backends that are eligible to execute the algorithm.
 *                     + Valid values:
 *                       - \ref VPI_BACKEND_CPU
 *                       - \ref VPI_BACKEND_CUDA
 *                       - \ref VPI_BACKEND_VIC
 *
 * @param[in] input Input image to be warped.
 *                  + Must not be NULL.
 *                  + Image must have enabled the backends that will execute the algorithm.
 *                  + On VIC, minimum input dimensions is 64x16 and even.
 *                  + The accepted image formats are:
 *                    | Formats                          | CPU | CUDA | VIC |
 *                    |----------------------------------|:---:|:----:|:---:|
 *                    | \ref VPI_IMAGE_FORMAT_U8         |  *  |   *  |  *  |
 *                    | \ref VPI_IMAGE_FORMAT_U8_BL      |  *  |   *  |  *  |
 *                    | \ref VPI_IMAGE_FORMAT_S8         |  *  |   *  |     |
 *                    | \ref VPI_IMAGE_FORMAT_U16        |  *  |   *  |     |
 *                    | \ref VPI_IMAGE_FORMAT_S16        |  *  |   *  |     |
 *                    | \ref VPI_IMAGE_FORMAT_F32        |  *  |   *  |     |
 *                    | \ref VPI_IMAGE_FORMAT_Y8_ER      |  *  |   *  |  *  |
 *                    | \ref VPI_IMAGE_FORMAT_Y8_ER_BL   |     |      |  *  |
 *                    | \ref VPI_IMAGE_FORMAT_Y16_ER     |  *  |   *  |     |
 *                    | \ref VPI_IMAGE_FORMAT_RGB8       |  *  |   *  |     |
 *                    | \ref VPI_IMAGE_FORMAT_BGR8       |  *  |   *  |     |
 *                    | \ref VPI_IMAGE_FORMAT_RGBA8      |  *  |   *  |     |
 *                    | \ref VPI_IMAGE_FORMAT_BGRA8      |  *  |   *  |     |
 *                    | \ref VPI_IMAGE_FORMAT_NV12       |     |      |  *  |
 *                    | \ref VPI_IMAGE_FORMAT_NV12_ER    |  *  |   *  |  *  |
 *                    | \ref VPI_IMAGE_FORMAT_NV12_BL    |     |      |  *  |
 *                    | \ref VPI_IMAGE_FORMAT_NV12_ER_BL |     |      |  *  |
 *                    | \ref VPI_IMAGE_FORMAT_NV24       |     |      |  *  |
 *                    | \ref VPI_IMAGE_FORMAT_NV24_ER    |     |      |  *  |
 *
 * @param[in] xform Transform to be applied.
 *
 * @param[out] output Output image where warped image is written to.
 *                    Dimensions may be different from \p input.
 *                    + Must not be NULL.
 *                    + Image must have enabled the backends that will execute the algorithm.
 *                    + Must have same format as input image.
 *                    + Dimensions must be even.
 *
 * @param[in] grid Grid on the output to establish performance/quality trade-offs.
 *                 A dense grid will result in best quality, albeit slower performance.
 *                 Grid must be set depending on the perf/quality criteria needed.
 *                 Pass NULL as a shortcut for using a dense grid.
 *                 + CPU and CUDA only accept dense grids.
 *                 + Grid dimensions must match \p output dimensions.
 *
 * @param[in] interp Interpolation mode to be used when source coordinate doesn't fall exactly on pixel center.
 *                   + Valid values:
 *                     - \ref VPI_INTERP_NEAREST
 *                     - \ref VPI_INTERP_LINEAR
 *                     - \ref VPI_INTERP_CATMULL_ROM
 *
 * @param[in] border Border extension to use for samples that fall outsize input's bounds.
 *                   + The accepted border extensions are:
 *                     - \ref VPI_BORDER_ZERO
 *
 * @param[in] flags Flags to modify algorithm behavior.
 *                  + Can be a combination of one or more of the following values:
 *                    - 0 : default, transform maps the input into the output
 *                    - \ref VPI_WARP_INVERSE : transform maps the output back into the input.
 *                    - \ref VPI_PRECISE      : precise, but potentially slower implementation.
 *
 * @retval #VPI_ERROR_INVALID_ARGUMENT      \p stream is NULL.
 * @retval #VPI_ERROR_INVALID_ARGUMENT      \p input or \p output are NULL.
 * @retval #VPI_ERROR_INVALID_ARGUMENT      \p xform is NULL.
 * @retval #VPI_ERROR_INVALID_ARGUMENT      Invalid \p flags.
 * @retval #VPI_ERROR_INVALID_ARGUMENT      \p input and \p output must have the same format.
 * @retval #VPI_ERROR_INVALID_ARGUMENT      \p border not supported.
 * @retval #VPI_ERROR_INVALID_ARGUMENT      \p backend is invalid or unknown.
 * @retval #VPI_ERROR_INVALID_ARGUMENT      \p input and/or \p output dimensions not supported.
 * @retval #VPI_ERROR_INVALID_ARGUMENT      \p grid configuration not supported by backend.
 * @retval #VPI_ERROR_INVALID_ARGUMENT      \p grid dimensions don't match output image's.
 * @retval #VPI_ERROR_INVALID_IMAGE_FORMAT  Image format not supported.
 * @retval #VPI_ERROR_NOT_IMPLEMENTED       Perspective Warp algorithm is not supported by given backend.
 * @retval #VPI_ERROR_INVALID_OPERATION     Backend hardware not available.
 * @retval #VPI_ERROR_INVALID_OPERATION     The needed backends aren't enabled in \p stream, \p input or \p output.
 * @retval #VPI_SUCCESS                     Operation executed successfully.
 */
VPI_PUBLIC VPIStatus vpiSubmitPerspectiveWarp(VPIStream stream, uint64_t backend, VPIImage input,
                                              const VPIPerspectiveTransform xform, VPIImage output,
                                              const VPIWarpGrid *grid, VPIInterpolationType interp,
                                              VPIBorderExtension border, uint64_t flags);

/** @} end of VPI_PerspectiveWarp */

#ifdef __cplusplus
}
#endif

#endif /* NV_VPI_ALGORITHMS_PERSPECTIVE_WARP_H */
// End content from: algo/PerspectiveWarp.h

// Begin content from: algo/ORB.h
/*
 * Copyright 2022-2023 NVIDIA Corporation. All rights reserved.
 *
 * NOTICE TO LICENSEE:
 *
 * This source code and/or documentation ("Licensed Deliverables") are
 * subject to NVIDIA intellectual property rights under U.S. and
 * international Copyright laws.
 *
 * These Licensed Deliverables contained herein is PROPRIETARY and
 * CONFIDENTIAL to NVIDIA and is being provided under the terms and
 * conditions of a form of NVIDIA software license agreement by and
 * between NVIDIA and Licensee ("License Agreement") or electronically
 * accepted by Licensee. Notwithstanding any terms or conditions to
 * the contrary in the License Agreement, reproduction or disclosure
 * of the Licensed Deliverables to any third party without the express
 * written consent of NVIDIA is prohibited.
 *
 * NOTWITHSTANDING ANY TERMS OR CONDITIONS TO THE CONTRARY IN THE
 * LICENSE AGREEMENT, NVIDIA MAKES NO REPRESENTATION ABOUT THE
 * SUITABILITY OF THESE LICENSED DELIVERABLES FOR ANY PURPOSE. IT IS
 * PROVIDED "AS IS" WITHOUT EXPRESS OR IMPLIED WARRANTY OF ANY KIND.
 * NVIDIA DISCLAIMS ALL WARRANTIES WITH REGARD TO THESE LICENSED
 * DELIVERABLES, INCLUDING ALL IMPLIED WARRANTIES OF MERCHANTABILITY,
 * NONINFRINGEMENT, AND FITNESS FOR A PARTICULAR PURPOSE.
 * NOTWITHSTANDING ANY TERMS OR CONDITIONS TO THE CONTRARY IN THE
 * LICENSE AGREEMENT, IN NO EVENT SHALL NVIDIA BE LIABLE FOR ANY
 * SPECIAL, INDIRECT, INCIDENTAL, OR CONSEQUENTIAL DAMAGES, OR ANY
 * DAMAGES WHATSOEVER RESULTING FROM LOSS OF USE, DATA OR PROFITS,
 * WHETHER IN AN ACTION OF CONTRACT, NEGLIGENCE OR OTHER TORTIOUS
 * ACTION, ARISING OUT OF OR IN CONNECTION WITH THE USE OR PERFORMANCE
 * OF THESE LICENSED DELIVERABLES.
 *
 * U.S. Government End Users. These Licensed Deliverables are a
 * "commercial item" as that term is defined at 48 C.F.R. 2.101 (OCT
 * 1995), consisting of "commercial computer software" and "commercial
 * computer software documentation" as such terms are used in 48
 * C.F.R. 12.212 (SEPT 1995) and is provided to the U.S. Government
 * only as a commercial end item. Consistent with 48 C.F.R.12.212 and
 * 48 C.F.R. 227.7202-1 through 227.7202-4 (JUNE 1995), all
 * U.S. Government End Users acquire the Licensed Deliverables with
 * only those rights set forth herein.
 *
 * Any use of the Licensed Deliverables in individual and commercial
 * software must include, in the user documentation and internal
 * comments to the code, the above Disclaimer and U.S. Government End
 * Users Notice.
 */

/**
 * @file ORB.h
 *
 * Declares functions that implement support for ORB.
 */

#ifndef NV_VPI_ALGORITHMS_ORB_H
#define NV_VPI_ALGORITHMS_ORB_H

// #include "../Export.h"
// #include "../Status.h"
// #include "../Types.h"
// #include "FASTCorners.h"

#include <stddef.h>
#include <stdint.h>

#ifdef __cplusplus
extern "C" {
#endif

/**
 * @defgroup VPI_OrbFeatureDetector ORB features
 * @ingroup VPI_API_Algorithms
 * @{
 *
 * Runs the ORB algorithm over the input image to detect features and extract descriptors.
 * Refer to \ref algo_orb_feature_detector for more details and usage examples.
 */

/**
 * Use non-rotationally-invariant BRIEF in ORB.
 */
#define VPI_DISABLE_RBRIEF (0x01)

/**
 * Structure that defines the parameters for \ref vpiSubmitORBFeatureDetector.
 */
typedef struct
{
    /**
     * Parameters for the FAST corner detector, see \ref algo_fast_corners_detector for more details.
     * The FAST algorithm is used by ORB to detect corners or features per level of the input pyramid.
     */
    VPIFASTCornerDetectorParams fastParams;

    /**
     * The maximum number N of features per level of the input pyramid to be used by ORB.
     * The FAST algorithm may find a large number C of corners per level prior to filtering the N top corners.
     * The number C is the capacity input argument for the create ORB payload function:
     * \ref vpiCreateORBFeatureDetector.
     * The maximum number of features for all levels is defined by the capacity of the output arrays passed as
     * arguments to the submit ORB function: \ref vpiSubmitORBFeatureDetector.
     * The filtering is done depending on the \ref VPIORBParams.scoreType parameter.
     * + The number N (i.e. this parameter) must be lower or equal to the capacity C (see above definitions).
     */
#if NV_VPI_VERSION_API_AT_MOST(2, 2)
    int32_t maxFeatures;
#else
    int32_t maxFeaturesPerLevel;
#endif

    /**
     * Maximum number of levels in the input pyramid to utilize.
     */
#if NV_VPI_VERSION_API_AT_MOST(2, 2)
    int32_t pyramidLevels;
#else
    int32_t maxPyramidLevels;
#endif

    /**
     * The score type allows to define how scores are assigned to corners.
     * The cornerness score is used to sort all corners detected by FAST from highest to lowest score value.
     * After score assignment, ORB filters the top N corners, where N is determined by the parameter:
     * \ref VPIORBParams.maxFeaturesPerLevel.
     * Use \ref VPI_CORNER_SCORE_HARRIS to assign cornerness scores based on Harris response score.
     * Use \ref VPI_CORNER_SCORE_FAST to skip cornerness score assignment and sorting.
     * By using FAST score type the performance of ORB is improved but the quality of output features is reduced.
     */
    VPICornerScore scoreType;

#if NV_VPI_VERSION_API_AT_MOST(2, 2)
    /**
     * Whether or not to enable rBRIEF (rotationally invariant BRIEF).
     * Disabling this makes it non-rotationally invariant but calculates faster.
     */
    uint8_t enableRBRIEF;
#else
    /**
     * Control flags.
     * + Valid values are a combination of one or more of the following flags:
     *   -  0: default, negation of all other flags.
     *   - \ref VPI_DISABLE_RBRIEF : Disable rotationally-invariant BRIEF.
     */
    uint32_t flags;
#endif
} VPIORBParams;

/** Initializes \ref VPIORBParams with default values.
 *
 * Default values are:
 *  - params.fastParams                      See \ref vpiInitFASTCornerDetectorParams
 *  - params.maxFeaturesPerLevel:            100
 *  - params.maxPyramidLevels:               4
 *  - params.scoreType:                      VPI_CORNER_SCORE_HARRIS;
 *  - params.flags:                          0
 * 
 * @retval #VPI_ERROR_INVALID_ARGUMENT \p params is NULL.
 * @retval #VPI_SUCCESS Operation executed successfully.
 */
VPI_PUBLIC VPIStatus vpiInitORBParams(VPIORBParams *params);

/**
 * Creates an \ref algo_orb_feature_detector "ORB feature detector" payload.
 * This function allocates all temporary memory needed by the algorithm.
 *
 * @param[in] backends VPI backends that are eligible to execute the algorithm.
 *                     + Valid values:
 *                       - \ref VPI_BACKEND_CPU
 *                       - \ref VPI_BACKEND_CUDA
 *                     + Backend must be enabled in current context.
 * 
 * @param[in] capacity Capacity of internal buffers used to store FAST corners and scores per input pyramid level.
 *                     It determines the maximum number of features per level detected by FAST prior to ORB filtering.
 *                     The ORB algorithm assigns scores to these features, cf. \ref VPIORBParams.scoreType, and
 *                     sort them to filter the top N best features in accordance to these scores, where N is the
 *                     \ref VPIORBParams.maxFeaturesPerLevel parameter.
 *
 * @param[out] payload Pointer to the payload variable that receives the created handle.
 * 
 * @retval #VPI_ERROR_INVALID_ARGUMENT  \p payload is NULL.
 * @retval #VPI_ERROR_INVALID_ARGUMENT  \p backends refers to an invalid backend.
 * @retval #VPI_ERROR_INVALID_OPERATION Backend hardware not available.
 * @retval #VPI_ERROR_NOT_IMPLEMENTED   ORB algorithm is not supported by given backend.
 * @retval #VPI_ERROR_INVALID_CONTEXT   Current context is destroyed.
 * @retval #VPI_ERROR_OUT_OF_MEMORY     Cannot allocate required resources.
 * @retval #VPI_ERROR_INVALID_OPERATION Backend isn't enabled in current context.
 * @retval #VPI_SUCCESS                 Operation executed successfully.
 */
#if NV_VPI_VERSION_API_AT_MOST(2, 2)
__asm__(".symver vpiCreateORBFeatureDetector,vpiCreateORBFeatureDetector@VPI_2.2");
VPI_PUBLIC VPIStatus vpiCreateORBFeatureDetector(uint64_t backends, size_t capacity, VPIPayload *payload);
#else
VPI_PUBLIC VPIStatus vpiCreateORBFeatureDetector(uint64_t backends, int32_t capacity, VPIPayload *payload);
#endif

/**
 * Submits an \ref algo_orb_feature_detector "ORB feature detector" operation to the stream.
 *
 * @note This operation detects features and extracts descriptors at the same time.  In case only the feature
 * detection is necessary, use this operation passing NULL to the descriptor output array for it to be ignored.
 *
 * @param[in] stream The stream where the operation will be queued in.
 *                   + Must not be NULL.
 *                   + Stream must have enabled the backends that will execute the algorithm.
 *
 * @param[in] backend Backend that will execute the algorithm.
 *                    + Valid values: 
 *                      - \ref VPI_BACKEND_CPU
 *                      - \ref VPI_BACKEND_CUDA
 *
 * @param[in] payload Payload to be submitted along the other parameters.
 * 
 * @param[in] input Input Input pyramid on which ORB will be executed.
 *                  + Must not be NULL.
 *                  + Pyramid must have enabled the backends that will execute the algorithm.
 *                  + The accepted image formats are:
 *                    - \ref VPI_IMAGE_FORMAT_Y8
 *                    - \ref VPI_IMAGE_FORMAT_Y16
 *                    - \ref VPI_IMAGE_FORMAT_Y8_ER
 *                    - \ref VPI_IMAGE_FORMAT_Y16_ER
 *                    - \ref VPI_IMAGE_FORMAT_U8
 *                    - \ref VPI_IMAGE_FORMAT_S8
 *                    - \ref VPI_IMAGE_FORMAT_U16
 *                    - \ref VPI_IMAGE_FORMAT_S16
 *
 * @param[out] outCorners Array that will receive the detected corners.
 *                        Array size is updated with the number of corners found.
 *                        Array capacity defines the maximum number of corners to be found for all levels.
 *                        The maximum possible number of features in all levels F is defined as the
 *                        \p VPIORBParams.maxFeaturesPerLevel times the number of levels.
 *                        + Must not be NULL.
 *                        + It must have type \ref VPI_ARRAY_TYPE_KEYPOINT_F32.
 *                        + It must have the same capacity as outDescriptors if less than F (see above).
 *                        + Array must have enabled the backends that will execute the algorithm.
 * 
 * @param[out] outDescriptors Array that will receive the descriptors for the corners
 *                            Array size is updated with the number of corners found.
 *                            Array capacity defines the maximum number of descriptors to be found for all levels.
 *                            The maximum possible number of features in all levels F is defined as the
 *                            \p VPIORBParams.maxFeaturesPerLevel times the number of levels.
 *                            + It may be NULL to do feature detection only.
 *                            + It must have type \ref VPI_ARRAY_TYPE_BRIEF_DESCRIPTOR.
 *                            + It must have the same capacity as outCorners if less than F (see above).
 *                            + Array must have enabled the backends that will execute the algorithm.
 *
 * @param[in] params Pointer to a VPIORBParams.
 *                   It defines the parameters for this algorithm invocation.
 *                   These parameters can vary in every call and will be copied internally.
 *                   Thus there is no need to keep the parameters object around.
 *                   - If NULL, use the defaults given by \ref vpiInitORBParams.
 *
 * @param[in] border How to handle pixels outside image boundaries.
 *                   It affects FAST corner detection per level, rf. \ref algo_fast_corners_detector.
 *                   + The accepted border extensions are:
 *                     - \ref VPI_BORDER_ZERO
 *                     - \ref VPI_BORDER_CLAMP
 *                     - \ref VPI_BORDER_REFLECT
 *                     - \ref VPI_BORDER_MIRROR
 *                     - \ref VPI_BORDER_LIMITED (ignore pixels with circle going outside image boundaries)
 *  
 * @retval #VPI_ERROR_INVALID_ARGUMENT     \p stream is NULL.
 * @retval #VPI_ERROR_INVALID_ARGUMENT     \p input or \p outCorners or \p outDescriptors are NULL.
 * @retval #VPI_ERROR_INVALID_ARGUMENT     \p backend is invalid or unknown.
 * @retval #VPI_ERROR_INVALID_ARGUMENT     A parameter in \p params is outside valid range.
 * @retval #VPI_ERROR_INVALID_ARRAY_TYPE   Invalid \p outCorners or \p outDescriptors array type.
 * @retval #VPI_ERROR_INVALID_IMAGE_FORMAT Unsupported input format.
 * @retval #VPI_ERROR_INVALID_OPERATION    The needed backends aren't enabled in \p stream or \p input.
 * @retval #VPI_ERROR_INVALID_OPERATION    The needed backends aren't enabled in \p outCorners or \p outDescriptors.
 * @retval #VPI_SUCCESS                    Operation executed successfully.
 */
#if NV_VPI_VERSION_API_AT_MOST(2, 2)
__asm__(".symver vpiSubmitORBFeatureDetector,vpiSubmitORBFeatureDetector@VPI_2.2");
#endif
VPI_PUBLIC VPIStatus vpiSubmitORBFeatureDetector(VPIStream stream, uint64_t backend, VPIPayload payload,
                                                 VPIPyramid input, VPIArray outCorners, VPIArray outDescriptors,
                                                 const VPIORBParams *params, VPIBorderExtension border);

/**
 * Creates an \ref algo_orb_feature_detector "ORB descriptor extractor" payload.
 * This function allocates all temporary memory needed by the algorithm.
 *
 * @param[in] backends VPI backends that are eligible to execute the algorithm.
 *                     + Valid values:
 *                       - \ref VPI_BACKEND_CPU
 *                       - \ref VPI_BACKEND_CUDA
 *                     + Backend must be enabled in current context.
 *
 * @param[out] payload Pointer to the payload variable that receives the created handle.
 *
 * @retval #VPI_ERROR_INVALID_ARGUMENT  \p payload is NULL.
 * @retval #VPI_ERROR_INVALID_ARGUMENT  \p backends refers to an invalid backend.
 * @retval #VPI_ERROR_INVALID_OPERATION Backend hardware not available.
 * @retval #VPI_ERROR_NOT_IMPLEMENTED   ORB algorithm is not supported by given backend.
 * @retval #VPI_ERROR_INVALID_CONTEXT   Current context is destroyed.
 * @retval #VPI_ERROR_OUT_OF_MEMORY     Cannot allocate required resources.
 * @retval #VPI_ERROR_INVALID_OPERATION Backend isn't enabled in current context.
 * @retval #VPI_SUCCESS                 Operation executed successfully.
 */
VPI_PUBLIC VPIStatus vpiCreateORBDescriptorExtractor(uint64_t backends, VPIPayload *payload);

/**
 * Submits an \ref algo_orb_feature_detector "ORB descriptor extractor" operation to the stream.
 *
 * @note This operation is only useful in a scenario where decoupled ORB feature detection and extraction is
 * necessary.  For cases where both detection and extraction is executed at the same time, use \ref
 * vpiSubmitORBFeatureDetector instead.
 *
 * @param[in] stream The stream where the operation will be queued in.
 *                   + Must not be NULL.
 *                   + Stream must have enabled the backends that will execute the algorithm.
 *
 * @param[in] backend Backend that will execute the algorithm.
 *                    + Valid values:
 *                      - \ref VPI_BACKEND_CPU
 *                      - \ref VPI_BACKEND_CUDA
 *
 * @param[in] payload Payload reserved for future use.  It may be NULL.
 *
 * @param[in] input Input image on which ORB descriptor extractor will be executed.
 *                  + Must not be NULL.
 *                  + Image must have enabled the backends that will execute the algorithm.
 *                  + The accepted image formats are:
 *                    - \ref VPI_IMAGE_FORMAT_Y8
 *                    - \ref VPI_IMAGE_FORMAT_Y16
 *                    - \ref VPI_IMAGE_FORMAT_Y8_ER
 *                    - \ref VPI_IMAGE_FORMAT_Y16_ER
 *                    - \ref VPI_IMAGE_FORMAT_U8
 *                    - \ref VPI_IMAGE_FORMAT_S8
 *                    - \ref VPI_IMAGE_FORMAT_U16
 *                    - \ref VPI_IMAGE_FORMAT_S16
 *
 * @param[in] inCorners Array with corners to compute descriptors from.
 *                      Each item in this array, i.e. a corner, is used to compute one item in the output array,
 *                      i.e. a descriptor for the corresponding corner.
 *                      The size of this input array determines the number of corners to extract descriptors from.
 *                      + Must not be NULL.
 *                      + It must have type \ref VPI_ARRAY_TYPE_KEYPOINT_F32.
 *                      + Array must have enabled the backends that will execute the algorithm.
 *
 * @param[out] outDescriptors Array that will receive the descriptors for the corners.
 *                            Each position in this output array corresponds to the corner descriptor for the same
 *                            position in the input array.
 *                            The output array capacity defines the maximum number of descriptors to be extracted.
 *                            The output array capacity must be bigger than the size of the input array to extract
 *                            descriptors for all corners.
 *                            + Must not be NULL.
 *                            + It must have type \ref VPI_ARRAY_TYPE_BRIEF_DESCRIPTOR.
 *                            + Array must have enabled the backends that will execute the algorithm.
 *
 * @param[in] flags Control flags.
 *                  + Valid values are a combination of one or more of the following flags:
 *                    -  0: default, negation of all other flags.
 *                    - \ref VPI_DISABLE_RBRIEF : Enable rotationally-invariant BRIEF.
 *
 * @retval #VPI_ERROR_INVALID_ARGUMENT     Either \p stream or \p input or \p inCorners or \p outDescriptors is NULL.
 * @retval #VPI_ERROR_INVALID_ARGUMENT     The \p backend is invalid or unknown.
 * @retval #VPI_ERROR_INVALID_ARRAY_TYPE   Invalid \p inCorners or \p outDescriptors array type.
 * @retval #VPI_ERROR_INVALID_IMAGE_FORMAT Unsupported input format.
 * @retval #VPI_ERROR_INVALID_OPERATION    The needed backends aren't enabled in \p stream or \p input.
 * @retval #VPI_ERROR_INVALID_OPERATION    The needed backends aren't enabled in \p inCorners or \p outDescriptors.
 * @retval #VPI_SUCCESS                    Operation executed successfully.
 */
#if NV_VPI_VERSION_API_AT_MOST(2, 3)
__asm__(".symver vpiSubmitORBDescriptorExtractor,vpiSubmitORBDescriptorExtractor@VPI_2.3");
#endif
VPI_PUBLIC VPIStatus vpiSubmitORBDescriptorExtractor(VPIStream stream, uint64_t backend, VPIPayload payload,
                                                     VPIImage input, VPIArray inCorners, VPIArray outDescriptors,
                                                     uint32_t flags);

#ifdef __cplusplus
}
#endif

/** @} */ // end of VPI_OrbFeatureDetector

#endif /* NV_VPI_ALGORITHMS_ORB_H */
// End content from: algo/ORB.h

// Begin content from: algo/OpticalFlowPyrLK.h
/*
 * Copyright 2020-2021 NVIDIA Corporation. All rights reserved.
 *
 * NOTICE TO LICENSEE:
 *
 * This source code and/or documentation ("Licensed Deliverables") are
 * subject to NVIDIA intellectual property rights under U.S. and
 * international Copyright laws.
 *
 * These Licensed Deliverables contained herein is PROPRIETARY and
 * CONFIDENTIAL to NVIDIA and is being provided under the terms and
 * conditions of a form of NVIDIA software license agreement by and
 * between NVIDIA and Licensee ("License Agreement") or electronically
 * accepted by Licensee. Notwithstanding any terms or conditions to
 * the contrary in the License Agreement, reproduction or disclosure
 * of the Licensed Deliverables to any third party without the express
 * written consent of NVIDIA is prohibited.
 *
 * NOTWITHSTANDING ANY TERMS OR CONDITIONS TO THE CONTRARY IN THE
 * LICENSE AGREEMENT, NVIDIA MAKES NO REPRESENTATION ABOUT THE
 * SUITABILITY OF THESE LICENSED DELIVERABLES FOR ANY PURPOSE. IT IS
 * PROVIDED "AS IS" WITHOUT EXPRESS OR IMPLIED WARRANTY OF ANY KIND.
 * NVIDIA DISCLAIMS ALL WARRANTIES WITH REGARD TO THESE LICENSED
 * DELIVERABLES, INCLUDING ALL IMPLIED WARRANTIES OF MERCHANTABILITY,
 * NONINFRINGEMENT, AND FITNESS FOR A PARTICULAR PURPOSE.
 * NOTWITHSTANDING ANY TERMS OR CONDITIONS TO THE CONTRARY IN THE
 * LICENSE AGREEMENT, IN NO EVENT SHALL NVIDIA BE LIABLE FOR ANY
 * SPECIAL, INDIRECT, INCIDENTAL, OR CONSEQUENTIAL DAMAGES, OR ANY
 * DAMAGES WHATSOEVER RESULTING FROM LOSS OF USE, DATA OR PROFITS,
 * WHETHER IN AN ACTION OF CONTRACT, NEGLIGENCE OR OTHER TORTIOUS
 * ACTION, ARISING OUT OF OR IN CONNECTION WITH THE USE OR PERFORMANCE
 * OF THESE LICENSED DELIVERABLES.
 *
 * U.S. Government End Users. These Licensed Deliverables are a
 * "commercial item" as that term is defined at 48 C.F.R. 2.101 (OCT
 * 1995), consisting of "commercial computer software" and "commercial
 * computer software documentation" as such terms are used in 48
 * C.F.R. 12.212 (SEPT 1995) and is provided to the U.S. Government
 * only as a commercial end item. Consistent with 48 C.F.R.12.212 and
 * 48 C.F.R. 227.7202-1 through 227.7202-4 (JUNE 1995), all
 * U.S. Government End Users acquire the Licensed Deliverables with
 * only those rights set forth herein.
 *
 * Any use of the Licensed Deliverables in individual and commercial
 * software must include, in the user documentation and internal
 * comments to the code, the above Disclaimer and U.S. Government End
 * Users Notice.
 */

/**
 * @file OpticalFlowPyrLK.h
 *
 * Declares functions that implement the Pyramidal LK Optical Flow algorithm.
 */

#ifndef NV_VPI_ALGORITHMS_OPTICALFLOWPYRLK_H
#define NV_VPI_ALGORITHMS_OPTICALFLOWPYRLK_H

/**
 * @defgroup VPI_OpticalFlowPyrLK Pyramidal LK Optical Flow
 * @ingroup VPI_API_Algorithms
 * @{
 *
 * Algorithm used to track points from one frame to the next.
 * Refer to \ref algo_optflow_lk for more details and usage examples.
 */

// #include "../Export.h"
// #include "../ImageFormat.h"
// #include "../Status.h"
// #include "../Types.h"

#include <stdbool.h>
#include <stdint.h>

#ifdef __cplusplus
extern "C" {
#endif

/**
 * Defines the error measurement types
 */
typedef enum
{
    /** L1 distance between previous feature and a next feature. */
    VPI_LK_ERROR_L1
} VPIEpsilonType;

/**
 * Structure that defines the parameters for \ref vpiSubmitOpticalFlowPyrLK.
 */
typedef struct
{
    /** Uses initial estimations stored in current frame keypoints array when this flag is not 0,
     *  otherwise previous frame keypoints are copied to current frame keypoints array and is considered the initial estimate.
     */
    uint32_t useInitialFlow;

    /** Specifies the termination criteria.
     *  + It must be bitwise combination of one or more of the following values:
     *    - \ref VPI_TERMINATION_CRITERIA_ITERATIONS
     *    - \ref VPI_TERMINATION_CRITERIA_EPSILON
     */
    uint32_t termination;

    /** Specifies the tracking error type. */
    VPIEpsilonType epsilonType;

    /** Specifies minimum error threshold for terminating the algorithm.
     *  Only applicable if termination flags includes \ref VPI_TERMINATION_CRITERIA_ITERATIONS. */
    float epsilon;

    /** Specifies the maximum number of iterations.
     *  Only applicable if termination flags includes \ref VPI_TERMINATION_CRITERIA_ITERATIONS.
     *  + Must be >= 1 and <= 32. */
    int32_t numIterations;

    /** Specifies the size of the window on which to perform the algorithm.
     *  + Must be >= 6 and <= 32. */
    int32_t windowDimension;

} VPIOpticalFlowPyrLKParams;

/**
 * Initializes \ref VPIOpticalFlowPyrLKParams with default values.
 *
 * Defaults:
 * - useInitialFlow  = 0
 * - termination     = VPI_TERMINATION_CRITERIA_ITERATIONS | VPI_TERMINATION_CRITERIA_EPSILON
 * - epsilonType     = VPI_LK_ERROR_L1
 * - epsilon         = 0
 * - windowDimension = 15
 * - numIterations   = 6
 *
 * @param[in] params Structure to be filled with default values.
 *
 * @retval #VPI_ERROR_INVALID_ARGUMENT \p params is NULL.
 * @retval #VPI_SUCCESS Operation executed successfully.
 */
VPI_PUBLIC VPIStatus vpiInitOpticalFlowPyrLKParams(VPIOpticalFlowPyrLKParams *params);

/**
 * Creates payload for \ref vpiSubmitOpticalFlowPyrLK
 *
 * @param[in] backends VPI backends that are eligible to execute the algorithm.
 *                     + Valid values: 
 *                       - \ref VPI_BACKEND_CPU
 *                       - \ref VPI_BACKEND_CUDA
 *                     + Backend must be enabled in current context.
 *
 * @param[in] fmt Specifies the format for the pyramid.
 *                + The accepted image formats are:
 *                  - \ref VPI_IMAGE_FORMAT_U8
 *                  - \ref VPI_IMAGE_FORMAT_U16
 *
 * @param[in] width, height Specifies the dimensions of the pyramid on the finest resolution.
 *                          + Must be >= 0.
 *
 * @param[in] levels Number of levels of the pyramid to be used.
 *
 * @param[in] scale Scale of the pyramid to be used.
 *
 * @param[out] payload Pointer to the payload variable that receives the created handle.
 *
 * @retval #VPI_IMAGE_FORMAT_INVALID    \p fmt is not supported.
 * @retval #VPI_ERROR_INVALID_ARGUMENT  \p payload is NULL.
 * @retval #VPI_ERROR_INVALID_ARGUMENT  \p width or \p height outside valid range.
 * @retval #VPI_ERROR_INVALID_ARGUMENT  \p fmt is not supported.
 * @retval #VPI_ERROR_INVALID_ARGUMENT  \p backends refers to an invalid backend.
 * @retval #VPI_ERROR_NOT_IMPLEMENTED   Pyramidal LK Optical Flow algorithm is not supported by given backend.
 * @retval #VPI_ERROR_INVALID_CONTEXT   Current context is destroyed.
 * @retval #VPI_ERROR_OUT_OF_MEMORY     Cannot allocate required resources.
 * @retval #VPI_ERROR_INVALID_OPERATION Backend isn't enabled in current context.
 * @retval #VPI_SUCCESS                 Operation executed successfully.
 */
VPI_PUBLIC VPIStatus vpiCreateOpticalFlowPyrLK(uint64_t backends, int32_t width, int32_t height, VPIImageFormat fmt,
                                               int32_t levels, float scale, VPIPayload *payload);

/**
 * Runs Pyramidal LK Optical Flow on two frames.
 * Outputs estimated feature points and tracking status.
 *
 * @param[in] stream The stream where the operation will be queued in.
 *                   + Must not be NULL.
 *                   + Stream must have enabled the backends that will execute the algorithm.
 *
 * @param[in] backend Backend that will execute the algorithm.
 *                    + Must be the backend specified during payload creation or 0 as a shorthand to use this backend.
 *
 * @param[in] payload Payload created with \ref vpiCreateOpticalFlowPyrLK.
 *
 * @param[in] prevPyr Previous frame, represented as a gaussian pyramid.
 *                    + Must not be NULL.
 *                    + Must have same format, scale and number of levels as the ones specified during payload creation.
 *                    + Pyramid must have enabled the backends that will execute the algorithm.
 *
 * @param[in] curPyr  Current frame, represented as a gaussian pyramid.
 *                    + Must not be NULL.
 *                    + Must have same number of levels, size, scale and format as \p prevPyr.
 *                    + Pyramid must have enabled the backends that will execute the algorithm.
 *
 * @param[in] prevPts Array of keypoints in the \p prevPyr high resolution pyramid.
 *                    + Must not be NULL.
 *                    + The type of array must be \ref VPI_ARRAY_TYPE_KEYPOINT_F32.
 *                    + If useInitialFlow in \p params is not zero, \p prevPts must have same size as \p curPts.
 *                    + Array must have enabled the backends that will execute the algorithm.
 *
 * @param[in,out] curPts Array of keypoints in first level of \p curPyr.
 *                       It is used as starting search point in curPyr if useInitialFlow in \p params is not 0.
 *                       + Must not be NULL.
 *                       + The type of array must be \ref VPI_ARRAY_TYPE_KEYPOINT_F32.
 *                       + If useInitialFlow in \p params is not zero, \p curPts must have same size as \p prevPts.
 *                       + Array capacity must be greater or equal than \p prevPts array size.
 *                       + Array must have enabled the backends that will execute the algorithm.
 *
 * @param[in,out] trackingStatus Status array for tracking status for each input in prevPts.
 *                               If element is 0, the corresponding keypoint is being tracked, otherwide, tracking is lost.
 *                               + Must not be NULL.
 *                               + The type of the array must be \ref VPI_ARRAY_TYPE_U8.
 *                               + Array capacity must be greater or equal than \p prevPts array size.
 *                               + Array must have enabled the backends that will execute the algorithm.
 *
 * @param[in] params Parameters for the LK tracker.
 *                   If NULL, it uses default parameters are returned by \ref vpiInitOpticalFlowPyrLKParams.
 * 
 * @retval #VPI_ERROR_INVALID_ARGUMENT     \p stream is NULL.
 * @retval #VPI_ERROR_INVALID_ARGUMENT     \p prevPyr, \p curPyr, \p prevPts, \p curPts or \p trackingStatus are NULL.
 * @retval #VPI_ERROR_INVALID_ARGUMENT     \p payload is not generated using vpiCreateKLTFeatureTracker.
 * @retval #VPI_ERROR_INVALID_ARGUMENT     \p prevPyr and \p curPyr should have same number of levels, size, scale and format.
 * @retval #VPI_ERROR_INVALID_ARGUMENT     \p prevPyr and \p curPyr format should match with format specified in the \p payload creation.
 * @retval #VPI_ERROR_INVALID_ARGUMENT     Invalid termination criteria provided in \p params.
 * @retval #VPI_ERROR_INVALID_ARGUMENT     Number of iterations in \p params outside valid range.
 * @retval #VPI_ERROR_INVALID_ARGUMENT     Tracking window dimension in \p params is invalid.
 * @retval #VPI_ERROR_INVALID_ARGUMENT     \p prevPts or \p curPts have unsupported array type.
 * @retval #VPI_ERROR_INVALID_ARGUMENT     \p prevPts or \p curPts's size outside valid range.
 * @retval #VPI_ERROR_INVALID_ARGUMENT     \p prevPts or \p trackingStatus's capacity outside valid range.
 * @retval #VPI_ERROR_INVALID_ARGUMENT     \p trackingStatus has unsupported array type.
 * @retval #VPI_ERROR_INVALID_PAYLOAD_TYPE \p payload is invalid.
 * @retval #VPI_ERROR_INVALID_OPERATION    The needed backends aren't enabled in \p stream, \p prevPyr, \p curPyr,
 *                                         \p prevPts, \p curPts or \p trackingStatus.
 * @retval #VPI_SUCCESS                    Operation executed successfully.
 */
VPI_PUBLIC VPIStatus vpiSubmitOpticalFlowPyrLK(VPIStream stream, uint64_t backend, VPIPayload payload,
                                               VPIPyramid prevPyr, VPIPyramid curPyr, VPIArray prevPts, VPIArray curPts,
                                               VPIArray trackingStatus, const VPIOpticalFlowPyrLKParams *params);

#ifdef __cplusplus
}
#endif

/** @} */ // end of VPI_OpticalFlowPyrLK

#endif // NV_VPI_ALGORITHMS_OPTICALFLOWPYRLK_H
// End content from: algo/OpticalFlowPyrLK.h

// Begin content from: algo/CannyEdges.h
/*
 * Copyright 2022 NVIDIA Corporation. All rights reserved.
 *
 * NOTICE TO LICENSEE:
 *
 * This source code and/or documentation ("Licensed Deliverables") are
 * subject to NVIDIA intellectual property rights under U.S. and
 * international Copyright laws.
 *
 * These Licensed Deliverables contained herein is PROPRIETARY and
 * CONFIDENTIAL to NVIDIA and is being provided under the terms and
 * conditions of a form of NVIDIA software license agreement by and
 * between NVIDIA and Licensee ("License Agreement") or electronically
 * accepted by Licensee. Notwithstanding any terms or conditions to
 * the contrary in the License Agreement, reproduction or disclosure
 * of the Licensed Deliverables to any third party without the express
 * written consent of NVIDIA is prohibited.
 *
 * NOTWITHSTANDING ANY TERMS OR CONDITIONS TO THE CONTRARY IN THE
 * LICENSE AGREEMENT, NVIDIA MAKES NO REPRESENTATION ABOUT THE
 * SUITABILITY OF THESE LICENSED DELIVERABLES FOR ANY PURPOSE. IT IS
 * PROVIDED "AS IS" WITHOUT EXPRESS OR IMPLIED WARRANTY OF ANY KIND.
 * NVIDIA DISCLAIMS ALL WARRANTIES WITH REGARD TO THESE LICENSED
 * DELIVERABLES, INCLUDING ALL IMPLIED WARRANTIES OF MERCHANTABILITY,
 * NONINFRINGEMENT, AND FITNESS FOR A PARTICULAR PURPOSE.
 * NOTWITHSTANDING ANY TERMS OR CONDITIONS TO THE CONTRARY IN THE
 * LICENSE AGREEMENT, IN NO EVENT SHALL NVIDIA BE LIABLE FOR ANY
 * SPECIAL, INDIRECT, INCIDENTAL, OR CONSEQUENTIAL DAMAGES, OR ANY
 * DAMAGES WHATSOEVER RESULTING FROM LOSS OF USE, DATA OR PROFITS,
 * WHETHER IN AN ACTION OF CONTRACT, NEGLIGENCE OR OTHER TORTIOUS
 * ACTION, ARISING OUT OF OR IN CONNECTION WITH THE USE OR PERFORMANCE
 * OF THESE LICENSED DELIVERABLES.
 *
 * U.S. Government End Users. These Licensed Deliverables are a
 * "commercial item" as that term is defined at 48 C.F.R. 2.101 (OCT
 * 1995), consisting of "commercial computer software" and "commercial
 * computer software documentation" as such terms are used in 48
 * C.F.R. 12.212 (SEPT 1995) and is provided to the U.S. Government
 * only as a commercial end item. Consistent with 48 C.F.R.12.212 and
 * 48 C.F.R. 227.7202-1 through 227.7202-4 (JUNE 1995), all
 * U.S. Government End Users acquire the Licensed Deliverables with
 * only those rights set forth herein.
 *
 * Any use of the Licensed Deliverables in individual and commercial
 * software must include, in the user documentation and internal
 * comments to the code, the above Disclaimer and U.S. Government End
 * Users Notice.
 */

/**
 * @file CannyEdges.h
 *
 * Declares functions that implement the canny edge detector algorithm.
 */

#ifndef NV_VPI_ALGORITHMS_CANNY_EDGE_DETECTOR_H
#define NV_VPI_ALGORITHMS_CANNY_EDGE_DETECTOR_H

/**
 * @defgroup VPI_CannyEdgeDetector Canny Edge Detector
 * @ingroup VPI_API_Algorithms
 * @{
 *
 * Runs the canny edge detector algorithm over the input image.
 * Refer to \ref algo_canny_edge_detector for more details and usage examples.
 */

// #include "../Export.h"
// #include "../Status.h"
// #include "../Types.h"

#include <stdint.h>

#ifdef __cplusplus
extern "C" {
#endif

/**
 * Creates payload for \ref vpiSubmitCannyEdgeDetector
 *
 * @param[in] backends VPI backends that are eligible to execute the algorithm.
 *                     + Valid values:
 *                       - \ref VPI_BACKEND_CPU
 *                       - \ref VPI_BACKEND_CUDA
 *                     + Backend must be enabled in current context.
 *
 * @param[in] imageWidth, imageHeight Input image dimensions.
 *                                    + Must be >= 1x1.
 *
 * @param[out] payload Pointer to the payload variable that receives the created handle.
 *
 * @retval #VPI_ERROR_INVALID_ARGUMENT  \p payload is NULL.
 * @retval #VPI_ERROR_INVALID_ARGUMENT  \p imageWidth and \p imageHeight outside valid range.
 * @retval #VPI_ERROR_INVALID_ARGUMENT  \p backends refers to an invalid backend.
 * @retval #VPI_ERROR_INVALID_OPERATION Backend isn't enabled in current context.
 * @retval #VPI_ERROR_NOT_IMPLEMENTED   Canny edge detector algorithm is not supported by given backend.
 * @retval #VPI_ERROR_INVALID_CONTEXT   Current context is destroyed.
 * @retval #VPI_ERROR_OUT_OF_MEMORY     Cannot allocate required resources.
 * @retval #VPI_SUCCESS                 Operation executed successfully.
 */
VPI_PUBLIC VPIStatus vpiCreateCannyEdgeDetector(uint64_t backends, int32_t imageWidth, int32_t imageHeight,
                                                VPIPayload *payload);

/**
 * Structure that defines the parameters for \ref vpiSubmitCannyEdgeDetector
 */
typedef struct
{
    /** Determine the norm to calculate the gradient intensity. */
    VPINormType normType;

    /** Specify the method used to generate gradient from the input image. */
    VPIGradientMethod gradMethod;

    /** Gradient window size.
     *  + Must be 3, 5 or 7. */
    int32_t gradientSize;
} VPICannyEdgeDetectorParams;

/** Initialize \ref vpiInitCannyEdgeDetectorParams with default values.
 *
 * Default values:
 *   - normType: \ref VPI_NORM_L2
 *   - gradMethod: GEN_GRADIENT_SOBEL
 *   - gradientSize: 3
 *
 * @param[out] params Structure to be filled with default values.
 *
 * @returns an error code on failure else \ref VPI_SUCCESS.
 */
VPI_PUBLIC VPIStatus vpiInitCannyEdgeDetectorParams(VPICannyEdgeDetectorParams *params);

/**
 * Runs the canny edge detector algorithm over an image.
 *
 * @param[in] stream A stream handle where the operation will be queued into.
 *                   + Must not be NULL.
 *                   + Stream must have enabled the backends that will execute the algorithm.
 *
 * @param[in] backend Backend that will execute the algorithm.
 *                    + Valid values:
 *                      - \ref VPI_BACKEND_CPU
 *                      - \ref VPI_BACKEND_CUDA
 *
 * @param[in] payload Pointer to the payload variable that receives the created handle.
 *
 * @param[in] input Input image.
 *                  + Must not be NULL.
 *                  + Image must have enabled the backends that will execute the algorithm.
 *                  + The accepted image formats are:
 *                    | Format                           | CPU | CUDA |
 *                    |----------------------------------|:---:|:----:|
 *                    | \ref VPI_IMAGE_FORMAT_U8         |  *  |   *  |
 *                    | \ref VPI_IMAGE_FORMAT_S8         |  *  |   *  |
 *                    | \ref VPI_IMAGE_FORMAT_U16        |  *  |   *  |
 *                    | \ref VPI_IMAGE_FORMAT_S16        |  *  |   *  |
 *                    | \ref VPI_IMAGE_FORMAT_F32        |  *  |   *  |
 *                    | \ref VPI_IMAGE_FORMAT_Y8_ER      |  *  |   *  |
 *                    | \ref VPI_IMAGE_FORMAT_Y8         |  *  |   *  |
 *                    | \ref VPI_IMAGE_FORMAT_Y16_ER     |  *  |   *  |
 *                    | \ref VPI_IMAGE_FORMAT_Y16        |  *  |   *  |
 *
 * @param[out] output Output image where the result is written to.
 *                  + Must not be NULL.
 *                  + It must have same dimensions as input image.
 *                  + Image must have enabled the backends that will execute the algorithm.
 *                  + The accepted formats are the same as \p input
 *
 * @param[in] thresholdStrong Strong threshold for the hysteresis procedure.
 * @param[in] thresholdWeak Weak threshold for the hysteresis procedure.
 * @param[in] edgeValue Value used to mark edge.
 *                  + This value should be different than nonEdgeValue.
 *                  + This value will be clamped if it exceeds the value range of the output image.
 *
 * @param[in] nonEdgeValue Value used to mark non-edge.
 *                  + This value should be different than edgeValue.
 *                  + This value will be clamped if it exceeds the value range of the output image.
 *
 * @param[in] params Control parameters of the canny edge detector algorithm.
 *
 * @retval #VPI_ERROR_INVALID_ARGUMENT     \p stream is NULL.
 * @retval #VPI_ERROR_INVALID_ARGUMENT     \p input or \p output are NULL.
 * @retval #VPI_ERROR_INVALID_ARGUMENT     \p input or \p output image dimensions ouside valid range.
 * @retval #VPI_ERROR_INVALID_ARGUMENT     \p backend is invalid or unknown.
 * @retval #VPI_ERROR_INVALID_IMAGE_FORMAT \p input or \p output image format not supported.
 * @retval #VPI_ERROR_INVALID_OPERATION    Backend hardware is not available.
 * @retval #VPI_ERROR_INVALID_OPERATION    The needed backends aren't enabled in \p stream, \p input or \p output.
 * @retval #VPI_ERROR_NOT_IMPLEMENTED      Canny edge detector algorithm is not supported by given backend.
 * @retval #VPI_SUCCESS                    Operation executed successfully.
 */

VPI_PUBLIC VPIStatus vpiSubmitCannyEdgeDetector(VPIStream stream, uint64_t backend, VPIPayload payload, VPIImage input,
                                                VPIImage output, float thresholdStrong, float thresholdWeak,
                                                float edgeValue, float nonEdgeValue,
                                                const VPICannyEdgeDetectorParams *params);

#ifdef __cplusplus
}
#endif

/** @} end of VPI_CannyEdgeDetector */

#endif /* NV_VPI_ALGORITHMS_CANNY_EDGE_DETECTOR_H */
// End content from: algo/CannyEdges.h

// Begin content from: algo/ConvertImageFormat.h
/*
 * Copyright 2020-2021 NVIDIA Corporation. All rights reserved.
 *
 * NOTICE TO LICENSEE:
 *
 * This source code and/or documentation ("Licensed Deliverables") are
 * subject to NVIDIA intellectual property rights under U.S. and
 * international Copyright laws.
 *
 * These Licensed Deliverables contained herein is PROPRIETARY and
 * CONFIDENTIAL to NVIDIA and is being provided under the terms and
 * conditions of a form of NVIDIA software license agreement by and
 * between NVIDIA and Licensee ("License Agreement") or electronically
 * accepted by Licensee. Notwithstanding any terms or conditions to
 * the contrary in the License Agreement, reproduction or disclosure
 * of the Licensed Deliverables to any third party without the express
 * written consent of NVIDIA is prohibited.
 *
 * NOTWITHSTANDING ANY TERMS OR CONDITIONS TO THE CONTRARY IN THE
 * LICENSE AGREEMENT, NVIDIA MAKES NO REPRESENTATION ABOUT THE
 * SUITABILITY OF THESE LICENSED DELIVERABLES FOR ANY PURPOSE. IT IS
 * PROVIDED "AS IS" WITHOUT EXPRESS OR IMPLIED WARRANTY OF ANY KIND.
 * NVIDIA DISCLAIMS ALL WARRANTIES WITH REGARD TO THESE LICENSED
 * DELIVERABLES, INCLUDING ALL IMPLIED WARRANTIES OF MERCHANTABILITY,
 * NONINFRINGEMENT, AND FITNESS FOR A PARTICULAR PURPOSE.
 * NOTWITHSTANDING ANY TERMS OR CONDITIONS TO THE CONTRARY IN THE
 * LICENSE AGREEMENT, IN NO EVENT SHALL NVIDIA BE LIABLE FOR ANY
 * SPECIAL, INDIRECT, INCIDENTAL, OR CONSEQUENTIAL DAMAGES, OR ANY
 * DAMAGES WHATSOEVER RESULTING FROM LOSS OF USE, DATA OR PROFITS,
 * WHETHER IN AN ACTION OF CONTRACT, NEGLIGENCE OR OTHER TORTIOUS
 * ACTION, ARISING OUT OF OR IN CONNECTION WITH THE USE OR PERFORMANCE
 * OF THESE LICENSED DELIVERABLES.
 *
 * U.S. Government End Users. These Licensed Deliverables are a
 * "commercial item" as that term is defined at 48 C.F.R. 2.101 (OCT
 * 1995), consisting of "commercial computer software" and "commercial
 * computer software documentation" as such terms are used in 48
 * C.F.R. 12.212 (SEPT 1995) and is provided to the U.S. Government
 * only as a commercial end item. Consistent with 48 C.F.R.12.212 and
 * 48 C.F.R. 227.7202-1 through 227.7202-4 (JUNE 1995), all
 * U.S. Government End Users acquire the Licensed Deliverables with
 * only those rights set forth herein.
 *
 * Any use of the Licensed Deliverables in individual and commercial
 * software must include, in the user documentation and internal
 * comments to the code, the above Disclaimer and U.S. Government End
 * Users Notice.
 */

/**
 * @file ConvertImageFormat.h
 *
 * Declares functions that handle image format conversion.
 */

#ifndef NV_VPI_ALGORITHMS_CONVERT_IMAGE_FORMAT_H
#define NV_VPI_ALGORITHMS_CONVERT_IMAGE_FORMAT_H

// #include "../AlgoFlags.h"
// #include "../Export.h"
// #include "../Status.h"
// #include "../Types.h"

#include <stdint.h>

#ifdef __cplusplus
extern "C" {
#endif

/**
 * @defgroup VPI_ConvertImageFormat Convert Image Format
 * @ingroup VPI_API_Algorithms
 * @{
 *
 * Converts the image contents to the desired format, with optional pixel value scaling and offset.
 * Refer to \ref algo_imageconv for more details and usage examples.
 */

/** Parameters for customizing image format conversion.
 * These parameters are used to customize how the conversion will be made.
 * Make sure to call \ref vpiInitConvertImageFormatParams to initialize this
 * structure before updating its attributes. This guarantees that new attributes
 * added in future versions will have a suitable default value assigned.
 */
typedef struct
{
    /** Conversion policy to be used.
     *  + VIC backend only supports \ref VPI_CONVERSION_CLAMP. */
    VPIConversionPolicy policy;

    /** Scaling factor.
     *  Pass 1 for no scaling. 
     *  + VIC backend doesn't support scaling, it must be 1.*/
    float scale;

    /** Offset factor. 
     *  Pass 0 for no offset.
     *  + VIC backend doesn't support offset, it must be 0. */
    float offset;

    /** Control flags.
     *  + Valid values:
     *    - 0: default, negation of all other flags.
     *    - \ref VPI_PRECISE : precise, potentially slower implementation.
     */
    uint64_t flags;

    /** Interpolation to use for chroma upsampling.
     * + Valid values:
     *   | Interpolation type          | CPU | CUDA | VIC |
     *   |-----------------------------|:---:|:----:|:---:|
     *   | \ref VPI_INTERP_NEAREST     |  *  |   *  |  1  |
     *   | \ref VPI_INTERP_LINEAR      |     |      |  *  |
     *   | \ref VPI_INTERP_CATMULL_ROM |     |      |  *  |
     *   (1) Nearest-neighbor interpolation is currently accepted,
     *   but linear is performed instead.
     */
    VPIInterpolationType chromaUpFilter;

    /** Interpolation to use for chroma downsampling.
     * + Valid values:
     *   | Interpolation type          | CPU | CUDA | VIC |
     *   |-----------------------------|:---:|:----:|:---:|
     *   | \ref VPI_INTERP_NEAREST     |  *  |   *  |  *  |
     *   | \ref VPI_INTERP_LINEAR      |     |      |     |
     *   | \ref VPI_INTERP_CATMULL_ROM |     |      |     |
     */
    VPIInterpolationType chromaDownFilter;
} VPIConvertImageFormatParams;

/** Initialize \ref VPIConvertImageFormatParams with default values.
 *
 *  The following parameters are set:
 * - policy: \ref VPI_CONVERSION_CLAMP
 * - scale:  1
 * - offset: 0
 * - flags:  0
 * - chromaUpFilter:   \ref VPI_INTERP_NEAREST
 * - chromaDownFilter: \ref VPI_INTERP_NEAREST
 *
 * @param[out] params Pointer to structure to be filled. Must not be NULL.
 * 
 * @retval #VPI_ERROR_INVALID_ARGUMENT \p params is NULL.
 * @retval #VPI_SUCCESS Operation executed successfully.
 */
VPI_PUBLIC VPIStatus vpiInitConvertImageFormatParams(VPIConvertImageFormatParams *params);

/**
 * Converts the image contents to the desired format, with optional scaling and offset.
 * The input and output formats are inferred from the corresponding images passed as parameters.
 * When scaling and offset are fractional, input is converted to 32-bit floating point prior conversion takes place.
 * The formula that relates input and output pixels is:
 *
 * \f[
 *    out(x,y) = clamp_{[\mathsf{min_{out}},\mathsf{max_{out}}]}(in(x,y)*\alpha + \beta)
 * \f]
 *
 * where:
 * - \f$\mathsf{min_{out}}\f$ and \f$\mathsf{max_{out}}\f$ are the minimum and maximum
 *   representable value by output image format. Exception is for floating point types,
 *   where limits are \f$[-\infty,\infty]\f$, i.e., no clamping is done.
 * - \f$\alpha\f$ is the scaling.
 * - \f$\beta\f$ is the offset.
 *
 * Floating point to integer conversion does returns the nearest integer number, rounding halfway cases away from zero.
 *
 * Supported format conversions.
 *  + Conversion between image format's marked with an '*' aren't implemented.
 *  + On CPU and CUDA, any pitch-linear format can be converted to itself,
 *    provided that scale is 1 and offset is 0.
 *  + Formats within each table below can be converted between themselves.
 *
 *   |          CPU and CUDA          |                VIC               |
 *   |--------------------------------|----------------------------------|
 *   | \ref VPI_IMAGE_FORMAT_U8       | \ref VPI_IMAGE_FORMAT_Y8         |
 *   | \ref VPI_IMAGE_FORMAT_U16      | \ref VPI_IMAGE_FORMAT_Y8_BL      |
 *   | \ref VPI_IMAGE_FORMAT_S8       | \ref VPI_IMAGE_FORMAT_Y8_ER      |
 *   | \ref VPI_IMAGE_FORMAT_S16      | \ref VPI_IMAGE_FORMAT_Y8_ER_BL   |
 *   | \ref VPI_IMAGE_FORMAT_Y8_ER    | \ref VPI_IMAGE_FORMAT_NV12       |   
 *   | \ref VPI_IMAGE_FORMAT_Y16_ER   | \ref VPI_IMAGE_FORMAT_NV12_BL    |
 *   | \ref VPI_IMAGE_FORMAT_NV12_ER* | \ref VPI_IMAGE_FORMAT_NV12_ER    |
 *   | \ref VPI_IMAGE_FORMAT_NV24_ER* | \ref VPI_IMAGE_FORMAT_NV12_ER_BL |
 *   | \ref VPI_IMAGE_FORMAT_RGB8     | \ref VPI_IMAGE_FORMAT_NV24       |
 *   | \ref VPI_IMAGE_FORMAT_BGR8     | \ref VPI_IMAGE_FORMAT_NV24_BL    |
 *   | \ref VPI_IMAGE_FORMAT_RGBA8    | \ref VPI_IMAGE_FORMAT_NV24_ER    |
 *   | \ref VPI_IMAGE_FORMAT_BGRA8    | \ref VPI_IMAGE_FORMAT_NV24_ER_BL |
 *   | \ref VPI_IMAGE_FORMAT_F32      | \ref VPI_IMAGE_FORMAT_YUYV       |
 *   |                                | \ref VPI_IMAGE_FORMAT_YUYV_BL    |
 *   |                                | \ref VPI_IMAGE_FORMAT_YUYV_ER    |
 *   |                                | \ref VPI_IMAGE_FORMAT_YUYV_ER_BL |
 *   |                                | \ref VPI_IMAGE_FORMAT_UYVY       |
 *   |                                | \ref VPI_IMAGE_FORMAT_UYVY_BL    | 
 *   |                                | \ref VPI_IMAGE_FORMAT_UYVY_ER    |
 *   |                                | \ref VPI_IMAGE_FORMAT_UYVY_ER_BL |
 *   |                                | \ref VPI_IMAGE_FORMAT_RGBA8      |
 *   |                                | \ref VPI_IMAGE_FORMAT_BGRA8      |
 *
 *   |          CPU and CUDA          |                VIC               |
 *   |--------------------------------|----------------------------------|
 *   | \ref VPI_IMAGE_FORMAT_2F32     | \ref VPI_IMAGE_FORMAT_Y16        |
 *   |                                | \ref VPI_IMAGE_FORMAT_Y16_BL     |
 *
 *   |                VIC              |
 *   |---------------------------------|
 *   | \ref VPI_IMAGE_FORMAT_Y16_ER    |
 *   | \ref VPI_IMAGE_FORMAT_Y16_ER_BL |
 *
 *   |                VIC              |
 *   |---------------------------------|
 *   | \ref VPI_IMAGE_FORMAT_2S16      |
 *   | \ref VPI_IMAGE_FORMAT_2S16_BL   |
 *
 *  + Conversions from left format to right and vice-versa are supported.
 *   |                           CPU and CUDA                           ||
 *   |--------------------------------|----------------------------------|
 *   | \ref VPI_IMAGE_FORMAT_Y8       | \ref VPI_IMAGE_FORMAT_S8         |
 *   | \ref VPI_IMAGE_FORMAT_Y16      | \ref VPI_IMAGE_FORMAT_S16        |
 *   |                                | \ref VPI_IMAGE_FORMAT_U8         |
 *   |                                | \ref VPI_IMAGE_FORMAT_U16        |
 *   |                                | \ref VPI_IMAGE_FORMAT_F32        |
 *
 * Conversion among format with extended or studio ranges and non-color formats
 * (i.e. U8, F32, S16, ...) will keep range unchanged, except for clamping or
 * casting specified in \ref VPIConvertImageFormatParams::policy.
 *
 * @param[in] stream A stream handle where the operation will be queued into.
 *                   + Must not be NULL.
 *                   + Stream must have enabled the backends that will execute the algorithm.
 *
 * @param[in] backend Backend that will execute the algorithm.
 *                    + Valid values:
 *                      - \ref VPI_BACKEND_CPU
 *                      - \ref VPI_BACKEND_CUDA
 *                      - \ref VPI_BACKEND_VIC
 *
 * @param[in] input Input image to be converted.
 *                   + Must not be NULL.
 *                   + Image must have enabled the backends that will execute the algorithm.
 *                   + On VIC, when converting from format with 4:2:2(R) chroma subsampling to
 *                     a format isn't YUV or chroma-subsampling is not 4:4:4, the image width
 *                     must be even (no restriction on height).
 *
 * @param[out] output Output image where result will be written to, with the desired format.
 *                    + Must not be NULL.
 *                    + Must have same dimensions as input image.
 *                    + Image must have enabled the backends that will execute the algorithm.
 *                    + On VIC, When converting to format with 4:2:0 or 4:2:2(R) chroma subsampling
 *                      (i.e. YUYV or NV12), the image width and height must be even.
 *
 * @param[in] params Parameters to fine tune the conversion.
 *                   Pass NULL to use default values given by \ref vpiInitConvertImageFormatParams. 
 *
 * @retval #VPI_ERROR_INVALID_ARGUMENT     \p stream is NULL.
 * @retval #VPI_ERROR_INVALID_ARGUMENT     \p input or \p output are NULL.
 * @retval #VPI_ERROR_INVALID_ARGUMENT     Invalid flags in \p params.
 * @retval #VPI_ERROR_INVALID_ARGUMENT     Invalid conversion type in \p params.
 * @retval #VPI_ERROR_INVALID_ARGUMENT     \p input and \p output image dimensions do not match.
 * @retval #VPI_ERROR_INVALID_ARGUMENT     \p output format can't be used with given image dimensions.
 * @retval #VPI_ERROR_INVALID_IMAGE_FORMAT Format conversion not supported.
 * @retval #VPI_ERROR_NOT_IMPLEMENTED      Convert Image Format algorithm is not supported by given backend.
 * @retval #VPI_ERROR_INVALID_OPERATION    Hardware backend not available.
 * @retval #VPI_ERROR_INVALID_OPERATION    The needed backends aren't enabled in \p stream, \p input or \p output.
 * @retval #VPI_SUCCESS                    Operation executed successfully.
 */
VPI_PUBLIC VPIStatus vpiSubmitConvertImageFormat(VPIStream stream, uint64_t backend, VPIImage input, VPIImage output,
                                                 const VPIConvertImageFormatParams *params);

/**
 * Converts the pyramid contents to the desired format, with optional scaling and offset.
 * The input and output formats are inferred from the corresponding pyramids passed as parameters.
 * When scaling and offset are fractional, input is converted to 32-bit floating point prior conversion takes place.
 * The formula that relates input and output pixels is:
 *
 * \f[
 *    out(x,y) = clamp_{[\mathsf{min_{out}},\mathsf{max_{out}}]}(in(x,y)*\alpha + \beta)
 * \f]
 *
 * where:
 * - \f$\mathsf{min_{out}}\f$ and \f$\mathsf{max_{out}}\f$ are the minimum and maximum
 *   representable value by output image format. Exception is for floating point types,
 *   where limits are \f$[-\infty,\infty]\f$, i.e., no clamping is done.
 * - \f$\alpha\f$ is the scaling.
 * - \f$\beta\f$ is the offset.
 *
 * Floating point to integer conversion does returns the nearest integer number, rounding halfway cases away from zero.
 *
 * Supported format conversions.
 *  + Conversion between image format's marked with an '*' aren't implemented.
 *  + On CPU and CUDA, any pitch-linear format can be converted to itself,
 *    provided that scale is 1 and offset is 0.
 *  + Formats within each table below can be converted between themselves.
 *
 *   |          CPU and CUDA          |                VIC               |
 *   |--------------------------------|----------------------------------|
 *   | \ref VPI_IMAGE_FORMAT_U8       | \ref VPI_IMAGE_FORMAT_Y8         |
 *   | \ref VPI_IMAGE_FORMAT_U16      | \ref VPI_IMAGE_FORMAT_Y8_BL      |
 *   | \ref VPI_IMAGE_FORMAT_S8       | \ref VPI_IMAGE_FORMAT_Y8_ER      |
 *   | \ref VPI_IMAGE_FORMAT_S16      | \ref VPI_IMAGE_FORMAT_Y8_ER_BL   |
 *   | \ref VPI_IMAGE_FORMAT_Y8_ER    | \ref VPI_IMAGE_FORMAT_NV12       |   
 *   | \ref VPI_IMAGE_FORMAT_Y16_ER   | \ref VPI_IMAGE_FORMAT_NV12_BL    |
 *   | \ref VPI_IMAGE_FORMAT_NV12_ER* | \ref VPI_IMAGE_FORMAT_NV12_ER    |
 *   | \ref VPI_IMAGE_FORMAT_NV24_ER* | \ref VPI_IMAGE_FORMAT_NV12_ER_BL |
 *   | \ref VPI_IMAGE_FORMAT_RGB8     | \ref VPI_IMAGE_FORMAT_NV24       |
 *   | \ref VPI_IMAGE_FORMAT_BGR8     | \ref VPI_IMAGE_FORMAT_NV24_BL    |
 *   | \ref VPI_IMAGE_FORMAT_RGBA8    | \ref VPI_IMAGE_FORMAT_NV24_ER    |
 *   | \ref VPI_IMAGE_FORMAT_BGRA8    | \ref VPI_IMAGE_FORMAT_NV24_ER_BL |
 *   | \ref VPI_IMAGE_FORMAT_F32      | \ref VPI_IMAGE_FORMAT_YUYV       |
 *   |                                | \ref VPI_IMAGE_FORMAT_YUYV_BL    |
 *   |                                | \ref VPI_IMAGE_FORMAT_YUYV_ER    |
 *   |                                | \ref VPI_IMAGE_FORMAT_YUYV_ER_BL |
 *   |                                | \ref VPI_IMAGE_FORMAT_UYVY       |
 *   |                                | \ref VPI_IMAGE_FORMAT_UYVY_BL    | 
 *   |                                | \ref VPI_IMAGE_FORMAT_UYVY_ER    |
 *   |                                | \ref VPI_IMAGE_FORMAT_UYVY_ER_BL |
 *   |                                | \ref VPI_IMAGE_FORMAT_RGBA8      |
 *   |                                | \ref VPI_IMAGE_FORMAT_BGRA8      |
 *
 *   |          CPU and CUDA          |                VIC               |
 *   |--------------------------------|----------------------------------|
 *   | \ref VPI_IMAGE_FORMAT_2F32     | \ref VPI_IMAGE_FORMAT_Y16        |
 *   |                                | \ref VPI_IMAGE_FORMAT_Y16_BL     |
 *
 *   |                VIC              |
 *   |---------------------------------|
 *   | \ref VPI_IMAGE_FORMAT_Y16_ER    |
 *   | \ref VPI_IMAGE_FORMAT_Y16_ER_BL |
 *
 *   |                VIC              |
 *   |---------------------------------|
 *   | \ref VPI_IMAGE_FORMAT_S16       |
 *   | \ref VPI_IMAGE_FORMAT_S16_BL    |
 *
 *
 *  + Conversions from left format to right and vice-versa are supported.
 *   |                           CPU and CUDA                           ||
 *   |--------------------------------|----------------------------------|
 *   | \ref VPI_IMAGE_FORMAT_Y8       | \ref VPI_IMAGE_FORMAT_S8         |
 *   | \ref VPI_IMAGE_FORMAT_Y16      | \ref VPI_IMAGE_FORMAT_S16        |
 *   |                                | \ref VPI_IMAGE_FORMAT_U8         |
 *   |                                | \ref VPI_IMAGE_FORMAT_U16        |
 *   |                                | \ref VPI_IMAGE_FORMAT_F32        |
 *
 * Conversion among format with extended or studio ranges and non-color formats
 * (i.e. U8, F32, S16, ...) will keep range unchanged, except for clamping or
 * casting specified in \ref VPIConvertImageFormatParams::policy.
 *
 * @param[in] stream A stream handle where the operation will be queued into.
 *                   + Must not be NULL.
 *                   + Stream must have enabled the backends that will execute the algorithm.
 *
 * @param[in] backend Backend that will execute the algorithm.
 *                    + Valid values:
 *                      - \ref VPI_BACKEND_CPU
 *                      - \ref VPI_BACKEND_CUDA
 *                      - \ref VPI_BACKEND_VIC
 *
 * @param[in] input Input pyramid to be converted.
 *                   + Must not be NULL.
 *                   + Image must have enabled the backends that will execute the algorithm.
 *                   + On VIC, when converting from format with 4:2:2(R) chroma subsampling to
 *                     a format isn't YUV or chroma-subsampling is not 4:4:4, the pyramid width in all levels
 *                     must be even (no restriction on height).
 *
 * @param[out] output Output pyramid where result will be written to, with the desired format.
 *                    + Must not be NULL.
 *                    + Must have same dimensions as input pyramid.
 *                    + Image must have enabled the backends that will execute the algorithm.
 *                    + On VIC, When converting to format with 4:2:0 or 4:2:2(R) chroma subsampling
 *                      (i.e. YUYV or NV12), the pyramid width and height in all levels must be even.
 *
 * @param[in] params Parameters to fine tune the conversion.
 *                   Pass NULL to use default values given by \ref vpiInitConvertImageFormatParams. 
 *
 * @retval #VPI_ERROR_INVALID_ARGUMENT     \p stream is NULL.
 * @retval #VPI_ERROR_INVALID_ARGUMENT     \p input or \p output are NULL.
 * @retval #VPI_ERROR_INVALID_ARGUMENT     Invalid flags in \p params.
 * @retval #VPI_ERROR_INVALID_ARGUMENT     Invalid conversion type in \p params.
 * @retval #VPI_ERROR_INVALID_ARGUMENT     \p input and \p output pyramid dimensions or number of levels do not match.
 * @retval #VPI_ERROR_INVALID_ARGUMENT     \p output format can't be used with given pyramid dimensions.
 * @retval #VPI_ERROR_INVALID_IMAGE_FORMAT Format conversion not supported.
 * @retval #VPI_ERROR_NOT_IMPLEMENTED      Convert Image Format algorithm is not supported by given backend.
 * @retval #VPI_ERROR_INVALID_OPERATION    Hardware backend not available.
 * @retval #VPI_ERROR_INVALID_OPERATION    The needed backends aren't enabled in \p stream, \p input or \p output.
 * @retval #VPI_SUCCESS                    Operation executed successfully.
 */
VPI_PUBLIC VPIStatus vpiSubmitConvertImageFormatPyramid(VPIStream stream, uint64_t backend, VPIPyramid input,
                                                        VPIPyramid output, const VPIConvertImageFormatParams *params);

/** @} end of VPI_ConvertImageFormat */

#ifdef __cplusplus
}
#endif

#endif /* NV_VPI_ALGORITHMS_CONVERT_IMAGE_FORMAT_H */
// End content from: algo/ConvertImageFormat.h

// Begin content from: algo/ImageStats.h
/*
 * Copyright 2022 NVIDIA Corporation. All rights reserved.
 *
 * NOTICE TO LICENSEE:
 *
 * This source code and/or documentation ("Licensed Deliverables") are
 * subject to NVIDIA intellectual property rights under U.S. and
 * international Copyright laws.
 *
 * These Licensed Deliverables contained herein is PROPRIETARY and
 * CONFIDENTIAL to NVIDIA and is being provided under the terms and
 * conditions of a form of NVIDIA software license agreement by and
 * between NVIDIA and Licensee ("License Agreement") or electronically
 * accepted by Licensee. Notwithstanding any terms or conditions to
 * the contrary in the License Agreement, reproduction or disclosure
 * of the Licensed Deliverables to any third party without the express
 * written consent of NVIDIA is prohibited.
 *
 * NOTWITHSTANDING ANY TERMS OR CONDITIONS TO THE CONTRARY IN THE
 * LICENSE AGREEMENT, NVIDIA MAKES NO REPRESENTATION ABOUT THE
 * SUITABILITY OF THESE LICENSED DELIVERABLES FOR ANY PURPOSE. IT IS
 * PROVIDED "AS IS" WITHOUT EXPRESS OR IMPLIED WARRANTY OF ANY KIND.
 * NVIDIA DISCLAIMS ALL WARRANTIES WITH REGARD TO THESE LICENSED
 * DELIVERABLES, INCLUDING ALL IMPLIED WARRANTIES OF MERCHANTABILITY,
 * NONINFRINGEMENT, AND FITNESS FOR A PARTICULAR PURPOSE.
 * NOTWITHSTANDING ANY TERMS OR CONDITIONS TO THE CONTRARY IN THE
 * LICENSE AGREEMENT, IN NO EVENT SHALL NVIDIA BE LIABLE FOR ANY
 * SPECIAL, INDIRECT, INCIDENTAL, OR CONSEQUENTIAL DAMAGES, OR ANY
 * DAMAGES WHATSOEVER RESULTING FROM LOSS OF USE, DATA OR PROFITS,
 * WHETHER IN AN ACTION OF CONTRACT, NEGLIGENCE OR OTHER TORTIOUS
 * ACTION, ARISING OUT OF OR IN CONNECTION WITH THE USE OR PERFORMANCE
 * OF THESE LICENSED DELIVERABLES.
 *
 * U.S. Government End Users. These Licensed Deliverables are a
 * "commercial item" as that term is defined at 48 C.F.R. 2.101 (OCT
 * 1995), consisting of "commercial computer software" and "commercial
 * computer software documentation" as such terms are used in 48
 * C.F.R. 12.212 (SEPT 1995) and is provided to the U.S. Government
 * only as a commercial end item. Consistent with 48 C.F.R.12.212 and
 * 48 C.F.R. 227.7202-1 through 227.7202-4 (JUNE 1995), all
 * U.S. Government End Users acquire the Licensed Deliverables with
 * only those rights set forth herein.
 *
 * Any use of the Licensed Deliverables in individual and commercial
 * software must include, in the user documentation and internal
 * comments to the code, the above Disclaimer and U.S. Government End
 * Users Notice.
 */

/**
 * @file ImageStats.h
 *
 * Declares functions that implement image statistics algorithms.
 */

#ifndef NV_VPI_ALGORITHMS_IMAGE_STATS_H
#define NV_VPI_ALGORITHMS_IMAGE_STATS_H

// #include "../Export.h"
// #include "../Status.h"
// #include "../Types.h"

#include <stdint.h>

#ifdef __cplusplus
extern "C" {
#endif

/**
 * @defgroup VPI_ImageStats Image Statistics
 * @ingroup VPI_API_Algorithms
 * @{
 *
 * Returns various image statistics of the input image.
 *
 */

/**
 * Returns various image statistics of the input image.
 *
 * @param[in] stream A stream handle where the operation will be queued into.
 *
 * @param[in] backend Backend that will execute the algorithm.
 *                    + Valid values: 
 *                      - \ref VPI_BACKEND_CPU
 *                      - \ref VPI_BACKEND_CUDA
 *
 * @param[in] input Input image.
 *                  + Valid Image formats:
 *                    | Formats                       | CPU | CUDA |
 *                    |-------------------------------|:---:|:----:|
 *                    | \ref VPI_IMAGE_FORMAT_U8      |  *  |   *  |
 *                    | \ref VPI_IMAGE_FORMAT_S8      |  *  |   *  |
 *                    | \ref VPI_IMAGE_FORMAT_U16     |  *  |   *  |
 *                    | \ref VPI_IMAGE_FORMAT_S16     |  *  |   *  |
 *                    | \ref VPI_IMAGE_FORMAT_Y8      |  *  |   *  |
 *                    | \ref VPI_IMAGE_FORMAT_Y8_ER   |  *  |   *  |
 *                    | \ref VPI_IMAGE_FORMAT_Y16     |  *  |   *  |
 *                    | \ref VPI_IMAGE_FORMAT_Y16_ER  |  *  |   *  |
 *                    | \ref VPI_IMAGE_FORMAT_U32     |  *  |   *  |
 *                    | \ref VPI_IMAGE_FORMAT_S32     |  *  |   *  |
 *                    | \ref VPI_IMAGE_FORMAT_RGB8    |  *  |   *  |
 *                    | \ref VPI_IMAGE_FORMAT_RGBA8   |  *  |   *  |
 *                    | \ref VPI_IMAGE_FORMAT_BGR8    |  *  |   *  |
 *                    | \ref VPI_IMAGE_FORMAT_BGRA8   |  *  |   *  |
 *                    | \ref VPI_IMAGE_FORMAT_NV12    |  *  |   *  |
 *                    | \ref VPI_IMAGE_FORMAT_NV12_ER |  *  |   *  |
 *                    | \ref VPI_IMAGE_FORMAT_NV24    |  *  |   *  |
 *                    | \ref VPI_IMAGE_FORMAT_NV24_ER |  *  |   *  |
 *                    | \ref VPI_IMAGE_FORMAT_2S16    |  *  |   *  |
 *                    | \ref VPI_IMAGE_FORMAT_F32     |  *  |   *  |
 *                    | \ref VPI_IMAGE_FORMAT_F64     |  *  |   *  |
 *                    | \ref VPI_IMAGE_FORMAT_2F32    |  *  |   *  |
 *                    | \ref VPI_IMAGE_FORMAT_RGB8p   |  *  |      |
 *                    | \ref VPI_IMAGE_FORMAT_RGBA8p  |  *  |      |
 *                    | \ref VPI_IMAGE_FORMAT_BGR8p   |  *  |      |
 *                    | \ref VPI_IMAGE_FORMAT_BGRA8p  |  *  |      |
 * 
 * @param[out] statistics Output array.
 *                        + Must be of type \ref VPI_ARRAY_TYPE_STATISTICS
 *                        + Must not be NULL.
 * 
 * @param[in] mask Image statistics kernel binary image mask.
 *                 It defines the pixels that will be used for the image statistics calculation.
 *                 The pixel under a non-zero mask element will be used in image statistics calculation.
 *                 Use NULL for all elements in statistics calculation, i.e. all mask pixels considered to be non-zero.
 *                 + If not NULL, it must be of image format \ref VPI_IMAGE_FORMAT_U8 and same size as \p input image.
 *
 * @param[in] flags Statistics calculation flags.
 *                  Flags determine which image statistics will be calculated.
 *                  + The accepted flags are:
 *                    - \ref VPI_STAT_PIXEL_COUNT
 *                    - \ref VPI_STAT_SUM
 *                    - \ref VPI_STAT_MEAN (also triggers the \ref VPI_STAT_PIXEL_COUNT and \ref VPI_STAT_SUM flags)
 *                    - \ref VPI_STAT_VARIANCE (also triggers the \ref VPI_STAT_MEAN flag)
 *                    - \ref VPI_STAT_COVARIANCE (also triggers the \ref VPI_STAT_VARIANCE flag)
 *                  + \p flags can be a combination of the accepted flags.
 * 
 * @retval #VPI_ERROR_INVALID_ARGUMENT     \p stream is NULL.
 * @retval #VPI_ERROR_INVALID_ARGUMENT     \p input or \p statistics are NULL.
 * @retval #VPI_ERROR_INVALID_ARGUMENT     \p input and \p mask image dimensions do not match.
 * @retval #VPI_ERROR_INVALID_ARGUMENT     \p flags not supported.
 * @retval #VPI_ERROR_INVALID_ARGUMENT     \p backend is invalid or unknown.
 * @retval #VPI_ERROR_INVALID_IMAGE_FORMAT \p input and \p mask formats aren't supported
 * @retval #VPI_ERROR_NOT_IMPLEMENTED      Image Stats algorithm is not supported by given backend.
 * @retval #VPI_ERROR_INVALID_OPERATION    Backend hardware not available.
 * @retval #VPI_ERROR_INVALID_OPERATION    The needed backends aren't enabled in \p stream, \p input or \p statistics.
 * @retval #VPI_SUCCESS                    Operation executed successfully.
 */
VPI_PUBLIC VPIStatus vpiSubmitImageStats(VPIStream stream, uint64_t backend, VPIImage input, VPIArray statistics,
                                         VPIImage mask, uint32_t flags);
/** @} */

#ifdef __cplusplus
}
#endif

#endif /* NV_VPI_ALGORITHMS_IMAGE_STATS_H */
// End content from: algo/ImageStats.h

// Begin content from: algo/GaussianPyramid.h
/*
 * Copyright 2019-2021 NVIDIA Corporation. All rights reserved.
 *
 * NOTICE TO LICENSEE:
 *
 * This source code and/or documentation ("Licensed Deliverables") are
 * subject to NVIDIA intellectual property rights under U.S. and
 * international Copyright laws.
 *
 * These Licensed Deliverables contained herein is PROPRIETARY and
 * CONFIDENTIAL to NVIDIA and is being provided under the terms and
 * conditions of a form of NVIDIA software license agreement by and
 * between NVIDIA and Licensee ("License Agreement") or electronically
 * accepted by Licensee. Notwithstanding any terms or conditions to
 * the contrary in the License Agreement, reproduction or disclosure
 * of the Licensed Deliverables to any third party without the express
 * written consent of NVIDIA is prohibited.
 *
 * NOTWITHSTANDING ANY TERMS OR CONDITIONS TO THE CONTRARY IN THE
 * LICENSE AGREEMENT, NVIDIA MAKES NO REPRESENTATION ABOUT THE
 * SUITABILITY OF THESE LICENSED DELIVERABLES FOR ANY PURPOSE. IT IS
 * PROVIDED "AS IS" WITHOUT EXPRESS OR IMPLIED WARRANTY OF ANY KIND.
 * NVIDIA DISCLAIMS ALL WARRANTIES WITH REGARD TO THESE LICENSED
 * DELIVERABLES, INCLUDING ALL IMPLIED WARRANTIES OF MERCHANTABILITY,
 * NONINFRINGEMENT, AND FITNESS FOR A PARTICULAR PURPOSE.
 * NOTWITHSTANDING ANY TERMS OR CONDITIONS TO THE CONTRARY IN THE
 * LICENSE AGREEMENT, IN NO EVENT SHALL NVIDIA BE LIABLE FOR ANY
 * SPECIAL, INDIRECT, INCIDENTAL, OR CONSEQUENTIAL DAMAGES, OR ANY
 * DAMAGES WHATSOEVER RESULTING FROM LOSS OF USE, DATA OR PROFITS,
 * WHETHER IN AN ACTION OF CONTRACT, NEGLIGENCE OR OTHER TORTIOUS
 * ACTION, ARISING OUT OF OR IN CONNECTION WITH THE USE OR PERFORMANCE
 * OF THESE LICENSED DELIVERABLES.
 *
 * U.S. Government End Users. These Licensed Deliverables are a
 * "commercial item" as that term is defined at 48 C.F.R. 2.101 (OCT
 * 1995), consisting of "commercial computer software" and "commercial
 * computer software documentation" as such terms are used in 48
 * C.F.R. 12.212 (SEPT 1995) and is provided to the U.S. Government
 * only as a commercial end item. Consistent with 48 C.F.R.12.212 and
 * 48 C.F.R. 227.7202-1 through 227.7202-4 (JUNE 1995), all
 * U.S. Government End Users acquire the Licensed Deliverables with
 * only those rights set forth herein.
 *
 * Any use of the Licensed Deliverables in individual and commercial
 * software must include, in the user documentation and internal
 * comments to the code, the above Disclaimer and U.S. Government End
 * Users Notice.
 */

/**
 * @file GaussianPyramid.h
 *
 * Declares functions that handle gaussian pyramids.
 */

#ifndef NV_VPI_ALGORITHMS_GAUSSIAN_PYRAMID_H
#define NV_VPI_ALGORITHMS_GAUSSIAN_PYRAMID_H

// #include "../Export.h"
// #include "../Status.h"
// #include "../Types.h"

#ifdef __cplusplus
extern "C" {
#endif

/**
 * @defgroup VPI_GaussianPyramid Gaussian Pyramid Generator
 * @ingroup VPI_API_Algorithms
 * @{
 *
 * Creates a Gaussian pyramid from the input image.
 * Refer to \ref algo_gaussian_pyramid_generator for more details and usage examples.
 */

/**
 * Computes the Gaussian pyramid from the input image.
 *
 * @param[in] stream The stream where the operation will be queued in.
 *                   + Must not be NULL.
 *                   + Stream must have enabled the backends that will execute the algorithm.
 *
 * @param[in] backend VPI backend that will execute the algorithm.
 *                    + Valid values:
 *                      - \ref VPI_BACKEND_CPU
 *                      - \ref VPI_BACKEND_CUDA
 *                      - \ref VPI_BACKEND_PVA
 *
 * @param[in] input Input image that corresponds to the finer level of the pyramid.
 *                  Processing is more efficient if input is wrapping the first level of the output pyramid.
 *                  + Must not be NULL.
 *                  + Image must have enabled the backends that will execute the algorithm.
 *                  + Supported image formats are:
 *                    | Format                           | CPU | CUDA | PVA |
 *                    |----------------------------------|:---:|:----:|:---:|
 *                    | \ref VPI_IMAGE_FORMAT_U8         |  *  |   *  |  *  |
 *                    | \ref VPI_IMAGE_FORMAT_S8         |  *  |   *  |  *  |
 *                    | \ref VPI_IMAGE_FORMAT_U16        |  *  |   *  |  *  |
 *                    | \ref VPI_IMAGE_FORMAT_S16        |  *  |   *  |  *  |
 *                    | \ref VPI_IMAGE_FORMAT_F32        |  *  |   *  |     |
 *                    | \ref VPI_IMAGE_FORMAT_Y8_ER      |  *  |   *  |  *  |
 *                    | \ref VPI_IMAGE_FORMAT_Y8         |  *  |   *  |  *  |
 *                    | \ref VPI_IMAGE_FORMAT_Y16_ER     |  *  |   *  |  *  |
 *                    | \ref VPI_IMAGE_FORMAT_Y16        |  *  |   *  |  *  |
 *                    | \ref VPI_IMAGE_FORMAT_RGB8p      |  *  |   *  |     |
 *                    | \ref VPI_IMAGE_FORMAT_BGR8p      |  *  |   *  |     |
 *                    | \ref VPI_IMAGE_FORMAT_RGBA8p     |  *  |   *  |     |
 *                    | \ref VPI_IMAGE_FORMAT_BGRA8p     |  *  |   *  |     |
 *
 * @param[out] output Where the resulting gaussian pyramid will be written to.
 *                    It must have been created with the desired scale and number of levels.
 *                    + Must not be NULL.
 *                    + Must have scale == 0.5.
 *                    + Must have been created with the desired scale and number of levels.
 *                    + First level dimensions must match input image's.
 *                    + Pyramid format must match input's.
 *                    + Pyramid must have enabled the backends that will execute the algorithm.
 *                    + On PVA backend, every pyramid level's dimension must be at least 16x16 big and have at most 10 levels.
 *                    
 * @param[in] border Border extension.
 *                   + Valid values:
 *                    | Border                  | CPU | CUDA | PVA |
 *                    |-------------------------|:---:|:----:|:---:|
 *                    | \ref VPI_BORDER_ZERO    |  *  |   *  |  *  |
 *                    | \ref VPI_BORDER_CLAMP   |  *  |   *  |  *  |
 *                    | \ref VPI_BORDER_REFLECT |     |   *  |     |
 *                    | \ref VPI_BORDER_MIRROR  |     |   *  |     |
 *
 * @retval #VPI_ERROR_INVALID_ARGUMENT     \p stream is NULL.
 * @retval #VPI_ERROR_INVALID_ARGUMENT     \p input or \p output are NULL.
 * @retval #VPI_ERROR_INVALID_ARGUMENT     \p output pyramid's scale or dimensions outside valid range.
 * @retval #VPI_ERROR_INVALID_ARGUMENT     \p input image and \p output pyramid's first level dimensions do not match.
 * @retval #VPI_ERROR_INVALID_ARGUMENT     \p border not supported.
 * @retval #VPI_ERROR_INVALID_ARGUMENT     \p backend is invalid or unknown.
 * @retval #VPI_ERROR_INVALID_ARGUMENT     \p input and \p output formats do not match.
 * @retval #VPI_ERROR_INVALID_IMAGE_FORMAT \p input and \p output formats aren't not supported.
 * @retval #VPI_ERROR_NOT_IMPLEMENTED      Gaussian Pyramid Generator algorithm is not supported by given backend.
 * @retval #VPI_ERROR_INVALID_OPERATION    Backend hardware not available.
 * @retval #VPI_ERROR_INVALID_OPERATION    The needed backends aren't enabled in \p stream, \p input or \p output.
 * @retval #VPI_SUCCESS                    Operation executed successfully.
 */

#if NV_VPI_VERSION_API_AT_MOST(2, 0)
__asm__(".symver vpiSubmitGaussianPyramidGenerator,vpiSubmitGaussianPyramidGenerator@VPI_2.0");
VPI_PUBLIC VPIStatus vpiSubmitGaussianPyramidGenerator(VPIStream stream, uint64_t backend, VPIImage input,
                                                       VPIPyramid output, VPIBorderExtension border);
#elif NV_VPI_VERSION_API_AT_MOST(2, 3)
__asm__(".symver vpiSubmitGaussianPyramidGenerator,vpiSubmitGaussianPyramidGenerator@VPI_2.1");
VPI_PUBLIC VPIStatus vpiSubmitGaussianPyramidGenerator(VPIStream stream, uint64_t backend, VPIImage input,
                                                       VPIPyramid output, VPIBorderExtension border);
#else
VPI_PUBLIC VPIStatus vpiSubmitGaussianPyramidGenerator(VPIStream stream, uint64_t backend, VPIImage input,
                                                       VPIPyramid output, VPIBorderExtension border);
#endif

#ifdef __cplusplus
}
#endif

/** @} */

#endif /* NV_VPI_ALGORITHMS_GAUSSIAN_PYRAMID_H */
// End content from: algo/GaussianPyramid.h

// Begin content from: algo/BruteForceMatcher.h
/*
 * Copyright 2023 NVIDIA Corporation. All rights reserved.
 *
 * NOTICE TO LICENSEE:
 *
 * This source code and/or documentation ("Licensed Deliverables") are
 * subject to NVIDIA intellectual property rights under U.S. and
 * international Copyright laws.
 *
 * These Licensed Deliverables contained herein is PROPRIETARY and
 * CONFIDENTIAL to NVIDIA and is being provided under the terms and
 * conditions of a form of NVIDIA software license agreement by and
 * between NVIDIA and Licensee ("License Agreement") or electronically
 * accepted by Licensee. Notwithstanding any terms or conditions to
 * the contrary in the License Agreement, reproduction or disclosure
 * of the Licensed Deliverables to any third party without the express
 * written consent of NVIDIA is prohibited.
 *
 * NOTWITHSTANDING ANY TERMS OR CONDITIONS TO THE CONTRARY IN THE
 * LICENSE AGREEMENT, NVIDIA MAKES NO REPRESENTATION ABOUT THE
 * SUITABILITY OF THESE LICENSED DELIVERABLES FOR ANY PURPOSE. IT IS
 * PROVIDED "AS IS" WITHOUT EXPRESS OR IMPLIED WARRANTY OF ANY KIND.
 * NVIDIA DISCLAIMS ALL WARRANTIES WITH REGARD TO THESE LICENSED
 * DELIVERABLES, INCLUDING ALL IMPLIED WARRANTIES OF MERCHANTABILITY,
 * NONINFRINGEMENT, AND FITNESS FOR A PARTICULAR PURPOSE.
 * NOTWITHSTANDING ANY TERMS OR CONDITIONS TO THE CONTRARY IN THE
 * LICENSE AGREEMENT, IN NO EVENT SHALL NVIDIA BE LIABLE FOR ANY
 * SPECIAL, INDIRECT, INCIDENTAL, OR CONSEQUENTIAL DAMAGES, OR ANY
 * DAMAGES WHATSOEVER RESULTING FROM LOSS OF USE, DATA OR PROFITS,
 * WHETHER IN AN ACTION OF CONTRACT, NEGLIGENCE OR OTHER TORTIOUS
 * ACTION, ARISING OUT OF OR IN CONNECTION WITH THE USE OR PERFORMANCE
 * OF THESE LICENSED DELIVERABLES.
 *
 * U.S. Government End Users. These Licensed Deliverables are a
 * "commercial item" as that term is defined at 48 C.F.R. 2.101 (OCT
 * 1995), consisting of "commercial computer software" and "commercial
 * computer software documentation" as such terms are used in 48
 * C.F.R. 12.212 (SEPT 1995) and is provided to the U.S. Government
 * only as a commercial end item. Consistent with 48 C.F.R.12.212 and
 * 48 C.F.R. 227.7202-1 through 227.7202-4 (JUNE 1995), all
 * U.S. Government End Users acquire the Licensed Deliverables with
 * only those rights set forth herein.
 *
 * Any use of the Licensed Deliverables in individual and commercial
 * software must include, in the user documentation and internal
 * comments to the code, the above Disclaimer and U.S. Government End
 * Users Notice.
 */

/**
 * @file BruteForceMatcher.h
 *
 * Declares functions that implement brute force matcher algorithms.
 */

#ifndef NV_VPI_ALGORITHMS_BRUTEFORCE_MATCHER_H
#define NV_VPI_ALGORITHMS_BRUTEFORCE_MATCHER_H

// #include "../AlgoFlags.h"
// #include "../Export.h"
// #include "../Status.h"
// #include "../Types.h"

#include <stdint.h>

#ifdef __cplusplus
extern "C" {
#endif

/**
 * @defgroup VPI_BruteForceMatcher Brute Force Matcher
 * @ingroup VPI_API_Algorithms
 * @{
 *
 * Runs a brute force matcher algorithm on descriptors.
 * 
 * Brute force matcher uses query descriptors and reference descriptors provided by the user
 * and calculates matches for every query descriptor by determining the closest reference descriptors.
 * The distance calculation metric can be chosen by the user and also the number of matches to be 
 * returned per query descriptor.  
 */

/**
 * Runs a brute force matcher algorithm on descriptors.
 *
 * @param[in] stream A stream handle where the operation will be queued into.
 *
 * @param[in] backend Backend that will execute the algorithm.
 *                    + Valid values: 
 *                      - \ref VPI_BACKEND_CPU
 *                      - \ref VPI_BACKEND_CUDA
 *
 * @param[in] queryDescriptor Query descriptor array.
 *                            + Must be of type VPI_ARRAY_TYPE_BRIEF_DESCRIPTOR
 *                            + Must not be NULL.
 * 
 * @param[in] referenceDescriptor Input Descriptor array to be used as refernce for matches.
 *                                + Must be of type VPI_ARRAY_TYPE_BRIEF_DESCRIPTOR
 *                                + Must not be NULL.
 * 
 * @param[in] normType Determines the type of norm calculation.
 *                     + Must be \ref VPI_NORM_HAMMING.
 * 
 * @param[in] maxMatchesPerQuery Maximum number of closest matches per query to be added in the output array.
 *                               + Must be >= 1 and <= \ref VPI_MAX_MATCHES_PER_DESCRIPTOR.
 *                               + If \ref VPI_ENABLE_CROSS_CHECK is passed as flags, maxMatchesPerQuery must be 1.
 *
 * @param[out] matches Output array.
 *                     + Must be of type \ref VPI_ARRAY_TYPE_MATCHES
 *                     + Must not be NULL.
 * 
 * @param[in] algoFlag Matches calculation flags.
 *                     + The accepted flags are:
 *                       - \ref VPI_ENABLE_CROSS_CHECK to enable cross check. 
 * 
 * @retval #VPI_ERROR_INVALID_ARGUMENT     \p stream is NULL.
 * @retval #VPI_ERROR_INVALID_ARGUMENT     \p queryDescriptor , \p referenceDescriptor or \p matches are NULL.
 * @retval #VPI_ERROR_INVALID_ARGUMENT     \p matches capacity >= \p queryDescriptor capacity.
 * @retval #VPI_ERROR_INVALID_ARGUMENT     \p algoFlag not supported.
 * @retval #VPI_ERROR_INVALID_ARGUMENT     \p backend is invalid or unknown.
 * @retval #VPI_ERROR_INVALID_ARGUMENT     \p queryDescriptor and \p referenceDescriptor formats aren't supported.
 * @retval #VPI_ERROR_INVALID_ARGUMENT     \p normType is not supported.
 * @retval #VPI_ERROR_INVALID_ARGUMENT     \p matches formats is not supported.
 * @retval #VPI_ERROR_INVALID_ARGUMENT     \p maxMatchesPerQuery outside valid range.
 * @retval #VPI_ERROR_NOT_IMPLEMENTED      Brute Force Matcher algorithm is not supported by given backend.
 * @retval #VPI_ERROR_INVALID_OPERATION    Backend hardware not available.
 * @retval #VPI_ERROR_INVALID_OPERATION    The needed backends aren't enabled in \p stream, \p queryDescriptor, \p referenceDescriptor or \p matches.
 * @retval #VPI_SUCCESS                    Operation executed successfully.
 */
VPI_PUBLIC VPIStatus vpiSubmitBruteForceMatcher(VPIStream stream, uint64_t backend, VPIArray queryDescriptor,
                                                VPIArray referenceDescriptor, VPINormType normType,
                                                int32_t maxMatchesPerQuery, VPIArray matches, uint32_t algoFlag);
/** @} */

#ifdef __cplusplus
}
#endif

#endif /* NV_VPI_ALGORITHMS_BRUTEFORCE_MATCHER_H */
// End content from: algo/BruteForceMatcher.h

// Begin content from: algo/TransformEstimator.h
/*
 * Copyright 2023 NVIDIA Corporation. All rights reserved.
 *
 * NOTICE TO LICENSEE:
 *
 * This source code and/or documentation ("Licensed Deliverables") are
 * subject to NVIDIA intellectual property rights under U.S. and
 * international Copyright laws.
 *
 * These Licensed Deliverables contained herein is PROPRIETARY and
 * CONFIDENTIAL to NVIDIA and is being provided under the terms and
 * conditions of a form of NVIDIA software license agreement by and
 * between NVIDIA and Licensee ("License Agreement") or electronically
 * accepted by Licensee. Notwithstanding any terms or conditions to
 * the contrary in the License Agreement, reproduction or disclosure
 * of the Licensed Deliverables to any third party without the express
 * written consent of NVIDIA is prohibited.
 *
 * NOTWITHSTANDING ANY TERMS OR CONDITIONS TO THE CONTRARY IN THE
 * LICENSE AGREEMENT, NVIDIA MAKES NO REPRESENTATION ABOUT THE
 * SUITABILITY OF THESE LICENSED DELIVERABLES FOR ANY PURPOSE. IT IS
 * PROVIDED "AS IS" WITHOUT EXPRESS OR IMPLIED WARRANTY OF ANY KIND.
 * NVIDIA DISCLAIMS ALL WARRANTIES WITH REGARD TO THESE LICENSED
 * DELIVERABLES, INCLUDING ALL IMPLIED WARRANTIES OF MERCHANTABILITY,
 * NONINFRINGEMENT, AND FITNESS FOR A PARTICULAR PURPOSE.
 * NOTWITHSTANDING ANY TERMS OR CONDITIONS TO THE CONTRARY IN THE
 * LICENSE AGREEMENT, IN NO EVENT SHALL NVIDIA BE LIABLE FOR ANY
 * SPECIAL, INDIRECT, INCIDENTAL, OR CONSEQUENTIAL DAMAGES, OR ANY
 * DAMAGES WHATSOEVER RESULTING FROM LOSS OF USE, DATA OR PROFITS,
 * WHETHER IN AN ACTION OF CONTRACT, NEGLIGENCE OR OTHER TORTIOUS
 * ACTION, ARISING OUT OF OR IN CONNECTION WITH THE USE OR PERFORMANCE
 * OF THESE LICENSED DELIVERABLES.
 *
 * U.S. Government End Users. These Licensed Deliverables are a
 * "commercial item" as that term is defined at 48 C.F.R. 2.101 (OCT
 * 1995), consisting of "commercial computer software" and "commercial
 * computer software documentation" as such terms are used in 48
 * C.F.R. 12.212 (SEPT 1995) and is provided to the U.S. Government
 * only as a commercial end item. Consistent with 48 C.F.R.12.212 and
 * 48 C.F.R. 227.7202-1 through 227.7202-4 (JUNE 1995), all
 * U.S. Government End Users acquire the Licensed Deliverables with
 * only those rights set forth herein.
 *
 * Any use of the Licensed Deliverables in individual and commercial
 * software must include, in the user documentation and internal
 * comments to the code, the above Disclaimer and U.S. Government End
 * Users Notice.
 */

/**
 * @file TransformEstimator.h
 *
 * Declares functions that implement the Transform Estimator algorithm.
 */

#ifndef NV_VPI_ALGORITHMS_TRANSFORM_ESTIMATOR_H
#define NV_VPI_ALGORITHMS_TRANSFORM_ESTIMATOR_H

// #include "../AlgoFlags.h"
// #include "../Export.h"
// #include "../Status.h"
// #include "../Types.h"

#include <stdint.h>

#ifdef __cplusplus
extern "C" {
#endif

/**
 * @defgroup VPI_TransformEstimator Transform Estimator
 * @ingroup VPI_API_Algorithms
 * @{
 *
 * Estimate the transform between source and target keypoints.
 * Refer to \ref algo_xform_estim for more details and usage examples.
 */

/**
 * Creates payload for \ref vpiSubmitTransformEstimator
 *
 * @param[in] backends VPI backend that will execute the algorithm.
 *                     + Valid values:
 *                       - \ref VPI_BACKEND_CPU
 *                     + Backend must be enabled in current context.
 *
 * @param[in] maxKeypoints Maximum number of keypoints processed.
 *                                    + Must be > 0.
 *
 * @param[out] payload Pointer to the payload variable that receives the created handle.
 *
 * @retval #VPI_ERROR_INVALID_ARGUMENT  \p payload is NULL.
 * @retval #VPI_ERROR_INVALID_ARGUMENT  \p maxKeypints outside valid range.
 * @retval #VPI_ERROR_INVALID_ARGUMENT  \p backend refers to an invalid backend.
 * @retval #VPI_ERROR_NOT_IMPLEMENTED   Transform Estimator algorithm is not supported by given backend.
 * @retval #VPI_ERROR_INVALID_CONTEXT   Current context was destroyed.
 * @retval #VPI_ERROR_INVALID_OPERATION Backend isn't enabled in current context.
 * @retval #VPI_ERROR_OUT_OF_MEMORY     Cannot allocate required resources.
 * @retval #VPI_SUCCESS                 Operation executed successfully.
 */
VPI_PUBLIC VPIStatus vpiCreateTransformEstimator(uint64_t backends, int32_t maxKeypoints, VPIPayload *payload);

/** Holds the configuration of a constrained 2d homography transform. */
typedef struct
{
    /** Valid rotation range, in radians.
     * If min==-FLT_MAX, do not impose restriction on minimum rotation.
     * If max==FLT_MAX, do not impose restriction on maximum rotation.
     * If min==max, no rotation will be estimated, it'll be considered to be min.
     * @{ */
    float minRotation, maxRotation;
    /* @} */

    /** Valid horizontal scale range.
     * If isIsotropicScale is != 0 (true), this range is for the isotropic scale.
     * If 0, don't restrict.
     * If min==max, no horizontal scaling will be estimated, it'll be considered to be min.
     * * If max != 0, min must be <= max.
     * @{ */
    float minXScale, maxXScale;
    /** @} */

    /** Valid vertical scale range.
     * Only used if isIsotropicScale is 0 (false).
     * If 0, don't restrict.
     * If min==max, no vertical scaling will be estimated, it'll be considered to be min.
     * * If max != 0, min must be <= max.
     * @{ */
    float minYScale, maxYScale;
    /** @} */

    /** Valid horizontal translation range.
     * If min==-FLT_MAX, do not impose restriction on minimum horizontal translation.
     * If max==FLT_MAX, do not impose restriction on maximum  horizontal translation.
     * If min==max, no horizontal translation will be estimated, it'll be considered to be min.
     * * min must be <= max.
     * @{ */
    float minXTranslation, maxXTranslation;
    /** @} */

    /** Valid vertical translation range.
     * If min==-FLT_MAX, do not impose restriction on minimum vertical translation.
     * If max==FLT_MAX, do not impose restriction on maximum vertical translation.
     * If min==max, no vertical translation will be estimated, it'll be considered to be min.
     * * min must be <= max.
     * @{ */
    float minYTranslation, maxYTranslation;
    /** @} */

    /** Valid shearing range.
     * If min==-FLT_MAX, do not impose restriction on minimum shear.
     * If max==FLT_MAX, do not impose restriction on maximum shear.
     * If min==max, no shear will be estimated, it'll be considered to be min.
     * * min must be <= max.
     * @{ */
    float minShear, maxShear;
    /** @} */

    /** Whether to restrict to affine transforms.
     * If != 0, restrict transform to affine.
     * If 0, allow perspective transform. */
    int8_t isAffine;

    /** Whether scaling is uniform in all directions (isotropic) or not.
     * If != 0, assume scale is isotropic.
     * If 0, allow different horizontal and vertical scaling. */
    int8_t isIsotropicScale;
} VPIConstrainedHomography2DConfig;

/** Types of transformation supported. */
typedef enum
{
    /** Represents a constrained 2D homography transform. */
    VPI_XFORM_CONSTRAINED_HOMOGRAPHY_2D
} VPITransformType;

/** Transformation parameters. */
typedef union
{
    VPIConstrainedHomography2DConfig constrainedHomography2D;
} VPITransformConfig;

/** Transform estimation method */
typedef enum
{
    /** Use least squares minimization method. */
    VPI_XFORM_ESTIM_METHOD_REGULAR,
    /** Use robust estimation with RANSAC and least squares. */
    VPI_XFORM_ESTIM_METHOD_RANSAC,
} VPITransfomEstimationMethod;

/** Parameters used to tune Transform Estimator algorithm. */
typedef struct
{
    /** Method to use for transform estimation. */
    VPITransfomEstimationMethod method;

    /** Maximum number of iterations the non-linear solver should take. */
    int32_t solverMaxIterations;

    /** Maximum number of RANSAC iterations. */
    int32_t ransacMaxIterations;
    /** Maximum allowed reprojection error for a point to be treated as an inlier. */
    float ransacReprojErrorTolerance;
    /** Maximum allowed reprojection error for a point to be treated as an inlier. */
    float ransacConfidenceLevel;
    /** Random number seed to be used. */
    int32_t ransacSeed;
    /** Maximum number of iterations for model refinement step.
     *  Pass 0 to skip refinement. It's usually needed when transform isn't affine. */
    int32_t maxRefinementIterations;

    /** Type of transform to estimate */
    VPITransformType xftype;
    /** Transform configuration, such as trusted boundaries, etc. */
    VPITransformConfig xfcfg;
} VPITransformEstimatorParams;

/**
 * Initializes the VPITransformEstimatorParams with default values for a given transform type.
 *
 * The default values remove all parameter constraints.
 * It sets the following parameters:
 * - method: \ref VPI_XFORM_ESTIM_METHOD_RANSAC
 * - ransacMaxIterations: 2000
 * - ransacReprojErrorTolerance: 3
 * - ransacConfidenceLevel: 0.95
 * - ransacSeed: 0
 * - solverMaxIterations: 50
 * - solverReprojErrorTolerance: 1e-6
 * - solverParameterTolerance: 1e-8
 * - maxRefinementIterations: 10
 * 
 * - xftype: (type passed)
 * If xftype == VPI_XFORM_CONSTRAINED_HOMOGRAPHY_2D:
 * - xfcfg.constrainedHomography2D.minRotation: -FLT_MAX
 * - xfcfg.constrainedHomography2D.maxRotation: +FLT_MAX
 * - xfcfg.constrainedHomography2D.minXScale: 0
 * - xfcfg.constrainedHomography2D.maxXScale: 0
 * - xfcfg.constrainedHomography2D.minYScale: 0
 * - xfcfg.constrainedHomography2D.maxYScale: 0
 * - xfcfg.constrainedHomography2D.minXTranslation: -FLT_MAX
 * - xfcfg.constrainedHomography2D.maxXTranslation: FLT_MAX
 * - xfcfg.constrainedHomography2D.minYTranslation: -FLT_MAX
 * - xfcfg.constrainedHomography2D.maxYTranslation: FLT_MAX
 * - xfcfg.constrainedHomography2D.isAffine: 0
 * - xfcfg.constrainedHomography2D.isIsotropicScale: 0
 *
 * @param[in] type Type of transform to initialize the structure to.
 *                 * Accepted types:
 *                   - \ref VPI_XFORM_CONSTRAINED_HOMOGRAPHY_2D
 * @param[in,out] params Pointer to structure to be initialized.
 *                       + Must not be NULL.
 *
 * @retval #VPI_ERROR_INVALID_ARGUMENT      \p params is NULL.
 * @retval #VPI_ERROR_INVALID_ARGUMENT      Transform type not accepted.
 * @retval #VPI_SUCCESS                     Operation executed successfully.
 */
VPI_PUBLIC VPIStatus vpiInitTransformEstimatorParams(VPITransformType type, VPITransformEstimatorParams *params);

/**
 * Submits a \ref algo_xform_estim "Transform Estimator" operation to the stream.
 *
 * @param[in] stream The stream where the operation will be queued in.
 *                   + Must not be NULL.
 *                   + Stream must have enabled the backends that will execute the algorithm.
 *
 * @param[in] backend Backend that will execute the algorithm.
 *                    + Must be the backend specified during payload creation or 0 as a shorthand to use this backend.
 *
 * @param[in] payload Payload created with \ref vpiCreateTransformEstimator.
 *                    + Must not be NULL.
 *
 * @param[in] srcKeypoints Source keypoints.
 *                         It defines a set of keypoints to which the estimated
 *                         transform is to be applied to.
 *                         * Must not be NULL.
 *                         * Array type must be \ref VPI_ARRAY_TYPE_KEYPOINT_F32.
 *                         * If \p matches is not NULL, \p srcKeypoints and \p matches must have the same size.
 *
 * @param[in] tgtKeypoints Target keypoints.
 *                         It defines a set of keypoints that are to be the
 *                         result of applying the transform to the source
 *                         keypoints.
 *                         * Must not be NULL.
 *                         * Array type must be \ref VPI_ARRAY_TYPE_KEYPOINT_F32.
 *                         * If \p matches is NULL, \p srcKeypoints and \p tgtKeypoints must have the same size.
 *                         * If \p matches is not NULL, it must be guaranteed that the first element of
 *                           \ref VPIMatches::refIndex exists in \p tgtKeypoints.
 *
 * @param[in] matches Correspondence between source and target keypoints.
 *                    If not NULL, for each i-th element in matches, the correspondence is given by:
 *                    - src = srcKeypoints[i]
 *                    - tgt = tgtKeypoints[matches[i].refIndex[0]]
 *                    If it's NULL, for each i-th element in srcKeypoints, the correspondence is given by:
 *                    - src = srcKeypoints[i]
 *                    - tgt = tgtKeypoints[i]
 *
 *                    * If not NULL, it must have type \ref VPI_ARRAY_TYPE_MATCHES.
 *
 * @param[out] outTransform Where the estimated transformation will be written to.
 *                          Array's type specify what transform is to be estimated.
 *                          * Must not be NULL.
 *                          * Capacity must be >= 1.
 *                          * Array type must be \ref VPI_ARRAY_TYPE_HOMOGRAPHY_TRANSFORM_2D.
 *
 * @param[out] outInliers Indices of the inlier matches.
 *                        Optional, if not needed pass NULL.
 *                        * Capacity must be >= number of keypoints in srcKeypoints.
 *                        * The array type must be \ref VPI_ARRAY_TYPE_U32
 *
 * @param[in] params Parameters specifying the parameters of the transform to be estimated.
 *                   If NULL, will perform an unconstrained estimation for the transform given by the
 *                   output transform array type.
 *                   If not NULL, the following restrictions apply:
 *                   * Transform type must be consistent with output transform array type:
 *                     | Transform Type                           | Output transform array type                 |
 *                     |------------------------------------------|---------------------------------------------|
 *                     | \ref VPI_XFORM_CONSTRAINED_HOMOGRAPHY_2D | \ref VPI_ARRAY_TYPE_HOMOGRAPHY_TRANSFORM_2D |
 *
 * @retval #VPI_ERROR_INVALID_ARGUMENT      \p stream is NULL.
 * @retval #VPI_ERROR_INVALID_ARGUMENT      \p payload is NULL.
 * @retval #VPI_ERROR_INVALID_ARGUMENT      \p srcKeypoints or \p tgtKeypoints are NULL.
 * @retval #VPI_ERROR_INVALID_ARGUMENT      \p outTransform is NULL.
 * @retval #VPI_ERROR_INVALID_ARGUMENT      \p backend is invalid or unknown.
 * @retval #VPI_ERROR_INVALID_ARGUMENT      \p srcKeypoints, \p tgtKeypoints aren't consistent.
 * @retval #VPI_ERROR_INVALID_ARGUMENT      Transform type not consistent with output transform array type.
 * @retval #VPI_ERROR_INVALID_ARRAY_TYPE    Array type of \p srcKeypoints, \p tgtKeypoints,  \p matches or \p outInliers is not correct.
 * @retval #VPI_ERROR_NOT_IMPLEMENTED       Transform Estimator algorithm is not supported by given backend.
 * @retval #VPI_ERROR_INVALID_OPERATION     Backend hardware not available.
 * @retval #VPI_ERROR_INVALID_OPERATION     The needed backends aren't enabled in \p stream, \p srcKeypoints, \p tgtKeypoints or \p matches.
 * @retval #VPI_SUCCESS                     Operation executed successfully.
 */
VPI_PUBLIC VPIStatus vpiSubmitTransformEstimator(VPIStream stream, uint64_t backend, VPIPayload payload,
                                                 VPIArray srcKeypoints, VPIArray tgtKeypoints, VPIArray matches,
                                                 VPIArray outTransform, VPIArray outInliers,
                                                 const VPITransformEstimatorParams *params);

/** @} end of VPI_TransformEstimator */

#ifdef __cplusplus
}
#endif

#endif /* NV_VPI_ALGORITHMS_TRANSFORM_ESTIMATOR_H */
// End content from: algo/TransformEstimator.h

// Begin content from: algo/BackgroundSubtractor.h
/*
 * Copyright 2021 NVIDIA Corporation. All rights reserved.
 *
 * NOTICE TO LICENSEE:
 *
 * This source code and/or documentation ("Licensed Deliverables") are
 * subject to NVIDIA intellectual property rights under U.S. and
 * international Copyright laws.
 *
 * These Licensed Deliverables contained herein is PROPRIETARY and
 * CONFIDENTIAL to NVIDIA and is being provided under the terms and
 * conditions of a form of NVIDIA software license agreement by and
 * between NVIDIA and Licensee ("License Agreement") or electronically
 * accepted by Licensee. Notwithstanding any terms or conditions to
 * the contrary in the License Agreement, reproduction or disclosure
 * of the Licensed Deliverables to any third party without the express
 * written consent of NVIDIA is prohibited.
 *
 * NOTWITHSTANDING ANY TERMS OR CONDITIONS TO THE CONTRARY IN THE
 * LICENSE AGREEMENT, NVIDIA MAKES NO REPRESENTATION ABOUT THE
 * SUITABILITY OF THESE LICENSED DELIVERABLES FOR ANY PURPOSE. IT IS
 * PROVIDED "AS IS" WITHOUT EXPRESS OR IMPLIED WARRANTY OF ANY KIND.
 * NVIDIA DISCLAIMS ALL WARRANTIES WITH REGARD TO THESE LICENSED
 * DELIVERABLES, INCLUDING ALL IMPLIED WARRANTIES OF MERCHANTABILITY,
 * NONINFRINGEMENT, AND FITNESS FOR A PARTICULAR PURPOSE.
 * NOTWITHSTANDING ANY TERMS OR CONDITIONS TO THE CONTRARY IN THE
 * LICENSE AGREEMENT, IN NO EVENT SHALL NVIDIA BE LIABLE FOR ANY
 * SPECIAL, INDIRECT, INCIDENTAL, OR CONSEQUENTIAL DAMAGES, OR ANY
 * DAMAGES WHATSOEVER RESULTING FROM LOSS OF USE, DATA OR PROFITS,
 * WHETHER IN AN ACTION OF CONTRACT, NEGLIGENCE OR OTHER TORTIOUS
 * ACTION, ARISING OUT OF OR IN CONNECTION WITH THE USE OR PERFORMANCE
 * OF THESE LICENSED DELIVERABLES.
 *
 * U.S. Government End Users. These Licensed Deliverables are a
 * "commercial item" as that term is defined at 48 C.F.R. 2.101 (OCT
 * 1995), consisting of "commercial computer software" and "commercial
 * computer software documentation" as such terms are used in 48
 * C.F.R. 12.212 (SEPT 1995) and is provided to the U.S. Government
 * only as a commercial end item. Consistent with 48 C.F.R.12.212 and
 * 48 C.F.R. 227.7202-1 through 227.7202-4 (JUNE 1995), all
 * U.S. Government End Users acquire the Licensed Deliverables with
 * only those rights set forth herein.
 *
 * Any use of the Licensed Deliverables in individual and commercial
 * software must include, in the user documentation and internal
 * comments to the code, the above Disclaimer and U.S. Government End
 * Users Notice.
 */

/**
 * @file BackgroundSubtractor.h
 *
 * Declares functions that implement background subtractor algorithms.
 */

#ifndef NV_VPI_ALGORITHMS_BACKGROUND_SUBTRACTOR_H
#define NV_VPI_ALGORITHMS_BACKGROUND_SUBTRACTOR_H

// #include "../Export.h"
// #include "../Status.h"
// #include "../Types.h"

#include <stdint.h>

#ifdef __cplusplus
extern "C" {
#endif

/**
 * @defgroup VPI_BackgroundSubtractor Background Subtractor
 * @ingroup VPI_API_Algorithms
 * @{
 *
 * Separate foreground and background from video.
 * Refer to \ref algo_background_subtractor for more details and usage examples.
 * 
 */

/**
 * Structure that defines the parameters for \ref vpiCreateBackgroundSubtractor
 */
typedef struct
{
    /** Threshold on the squared Mahalanobis distance between the pixel and the model
      * to decide whether a pixel is well described by the background model.
      * This parameter does not affect the background update. */
    float varThreshold;

    /** The algorithm will detect shadows and mark them if this is set to non-zero value */
    uint8_t detectShadow;

    /** Pixel value representing shadow. */
    uint8_t shadowPixelValue;

    /** Learning rate that indicates how fast the background model is learnt.
     *  + This value must be between 0 and 1.
     *    - Minimum of 0 means that the background model is not updated at all
     *    - Maximum of 1 means that the background model is completely reinitialized from the last frame.
     */

    float learningRate;
} VPIBackgroundSubtractorParams;

/**
 * Initializes \ref VPIBackgroundSubtractorParams with default values.
 *
 * Defaults:
 * - varThreshold: 16
 * - detectShadow: 1
 * - shadowPixelValue: 127
 * - learningRate: 0.001
 *
 * @param[out] params Structure to be filled with default values.
 *
 * @retval #VPI_ERROR_INVALID_ARGUMENT \p params is NULL
 * @retval #VPI_SUCCESS                Operation executed successfully.
 */
VPI_PUBLIC VPIStatus vpiInitBackgroundSubtractorParams(VPIBackgroundSubtractorParams *params);

/**
 * Creates payload for \ref vpiSubmitBackgroundSubtractor
 *
 * @param[in] backends VPI backend that will execute the algorithm.
 *                     + Valid values:
 *                       - \ref VPI_BACKEND_CPU
 *                       - \ref VPI_BACKEND_CUDA
 *                     + Backend must be enabled in current context.
 *
 * @param[in] imageWidth, imageHeight Input image dimensions.
 *                                    + Must be > 0.
 *
 * @param[in] inputFormat Input image format.
 *                        + The accepted image formats are:
 *                          - \ref VPI_IMAGE_FORMAT_U8
 *                          - \ref VPI_IMAGE_FORMAT_U16
 *                          - \ref VPI_IMAGE_FORMAT_NV12
 *                          - \ref VPI_IMAGE_FORMAT_NV12_ER
 *                          - \ref VPI_IMAGE_FORMAT_RGB8
 *                          - \ref VPI_IMAGE_FORMAT_RGBA8
 *
 * @param[out] payload Pointer to the payload variable that receives the created handle.
 *
 * @retval #VPI_ERROR_INVALID_ARGUMENT  \p payload is NULL.
 * @retval #VPI_ERROR_INVALID_ARGUMENT  \p imageWidth or \p imageHeight outside valid range.
 * @retval #VPI_ERROR_INVALID_ARGUMENT  \p backend refers to an invalid backend.
 * @retval #VPI_IMAGE_FORMAT_INVALID    \p inputFormat is not supported.
 * @retval #VPI_ERROR_NOT_IMPLEMENTED   Background Subtractor algorithm is not supported by given backend.
 * @retval #VPI_ERROR_INVALID_CONTEXT   Current context was destroyed.
 * @retval #VPI_ERROR_INVALID_OPERATION Backend isn't enabled in current context.
 * @retval #VPI_ERROR_OUT_OF_MEMORY     Cannot allocate required resources.
 * @retval #VPI_SUCCESS                 Operation executed successfully.
 */
VPI_PUBLIC VPIStatus vpiCreateBackgroundSubtractor(uint64_t backends, int32_t imageWidth, int32_t imageHeight,
                                                   VPIImageFormat inputFormat, VPIPayload *payload);

/**
 * Submits a \ref algo_background_subtractor "Background Subtractor" operation to the stream.
 *
 * Runs background subtractor on the incoming image from the video and outputs an estimate of the foreground mask.
 *
 * @param[in] stream The stream where the operation will be queued in.
 *                   + Must not be NULL.
 *                   + Stream must have enabled the backends that will execute the algorithm.
 *
 * @param[in] backend Backend that will execute the algorithm.
 *                    + Must be the backend specified during payload creation or 0 as a shorthand to use this backend.
 *
 * @param[in] payload Payload to be submitted along the other parameters.
 *
 * @param[in] inFrame Incoming frame from the video.
 *                    + Must not be NULL.
 *                    + Must have same dimensions as the one specified during payload creation.
 *                    + Image must have enabled the backends that will execute the algorithm.
 *
 * @param[out] outFGMask The output foreground mask as an 8-bit binary image.
 *                       + Must not be NULL.
 *                       + Must have same dimensions as input image.
 *                       + The only accepted format is \ref VPI_IMAGE_FORMAT_U8.
 *                       + Image must have enabled the backends that will execute the algorithm.
 *
 * @param[out] outBGImage Background image.
 *                        Pass NULL if not needed.
 *                        + Must have same format and dimensions as input image.
 *                        + Image must have enabled the backends that will execute the algorithm.
 *
 * @param[in] params Algorithm control parameters.
 *                   Pass NULL to use the defaults given by \ref vpiInitBackgroundSubtractorParams.
 *
 * @retval #VPI_ERROR_INVALID_ARGUMENT     \p stream is NULL.
 * @retval #VPI_ERROR_INVALID_ARGUMENT     \p params is NULL.
 * @retval #VPI_ERROR_INVALID_ARGUMENT     \p inFrame or \p outFGMask are NULL.
 * @retval #VPI_ERROR_INVALID_ARGUMENT     \p payload is not created by vpiCreateBackgroundSubtractor.
 * @retval #VPI_ERROR_INVALID_ARGUMENT     \p inFrame image dimension does not match the one associated with \p payload.
 * @retval #VPI_ERROR_INVALID_ARGUMENT     \p outFGMask dimension does not match the one associated with \p payload.
 * @retval #VPI_ERROR_INVALID_ARGUMENT     Learning rate in \p params outside valid range.
 * @retval #VPI_ERROR_INVALID_IMAGE_FORMAT \p inFrame image format does not match the one associated with \p payload.
 * @retval #VPI_ERROR_INVALID_IMAGE_FORMAT \p outFGMask format not supported.
 * @retval #VPI_ERROR_INVALID_IMAGE_FORMAT \p outBGImage format does not match the one associated with \p payload.
 * @retval #VPI_ERROR_INVALID_ARGUMENT     \p payload is invalid.
 * @retval #VPI_ERROR_INVALID_OPERATION    The needed backends aren't enabled in \p stream, \p inFrame, \p outFGMask or \p outBGImage.
 *
 * @retval #VPI_SUCCESS Operation executed successfully.
 */
VPI_PUBLIC VPIStatus vpiSubmitBackgroundSubtractor(VPIStream stream, uint64_t backend, VPIPayload payload,
                                                   VPIImage inFrame, VPIImage outFGMask, VPIImage outBGImage,
                                                   const VPIBackgroundSubtractorParams *params);

/** @} end of VPI_BackgroundSubtractor */

#ifdef __cplusplus
}
#endif

#endif /* NV_VPI_ALGORITHMS_BACKGROUND_SUBTRACTOR_H */
// End content from: algo/BackgroundSubtractor.h

// Begin content from: algo/TemporalNoiseReduction.h
/*
 * Copyright 2020-2021 NVIDIA Corporation. All rights reserved.
 *
 * NOTICE TO LICENSEE:
 *
 * This source code and/or documentation ("Licensed Deliverables") are
 * subject to NVIDIA intellectual property rights under U.S. and
 * international Copyright laws.
 *
 * These Licensed Deliverables contained herein is PROPRIETARY and
 * CONFIDENTIAL to NVIDIA and is being provided under the terms and
 * conditions of a form of NVIDIA software license agreement by and
 * between NVIDIA and Licensee ("License Agreement") or electronically
 * accepted by Licensee. Notwithstanding any terms or conditions to
 * the contrary in the License Agreement, reproduction or disclosure
 * of the Licensed Deliverables to any third party without the express
 * written consent of NVIDIA is prohibited.
 *
 * NOTWITHSTANDING ANY TERMS OR CONDITIONS TO THE CONTRARY IN THE
 * LICENSE AGREEMENT, NVIDIA MAKES NO REPRESENTATION ABOUT THE
 * SUITABILITY OF THESE LICENSED DELIVERABLES FOR ANY PURPOSE. IT IS
 * PROVIDED "AS IS" WITHOUT EXPRESS OR IMPLIED WARRANTY OF ANY KIND.
 * NVIDIA DISCLAIMS ALL WARRANTIES WITH REGARD TO THESE LICENSED
 * DELIVERABLES, INCLUDING ALL IMPLIED WARRANTIES OF MERCHANTABILITY,
 * NONINFRINGEMENT, AND FITNESS FOR A PARTICULAR PURPOSE.
 * NOTWITHSTANDING ANY TERMS OR CONDITIONS TO THE CONTRARY IN THE
 * LICENSE AGREEMENT, IN NO EVENT SHALL NVIDIA BE LIABLE FOR ANY
 * SPECIAL, INDIRECT, INCIDENTAL, OR CONSEQUENTIAL DAMAGES, OR ANY
 * DAMAGES WHATSOEVER RESULTING FROM LOSS OF USE, DATA OR PROFITS,
 * WHETHER IN AN ACTION OF CONTRACT, NEGLIGENCE OR OTHER TORTIOUS
 * ACTION, ARISING OUT OF OR IN CONNECTION WITH THE USE OR PERFORMANCE
 * OF THESE LICENSED DELIVERABLES.
 *
 * U.S. Government End Users. These Licensed Deliverables are a
 * "commercial item" as that term is defined at 48 C.F.R. 2.101 (OCT
 * 1995), consisting of "commercial computer software" and "commercial
 * computer software documentation" as such terms are used in 48
 * C.F.R. 12.212 (SEPT 1995) and is provided to the U.S. Government
 * only as a commercial end item. Consistent with 48 C.F.R.12.212 and
 * 48 C.F.R. 227.7202-1 through 227.7202-4 (JUNE 1995), all
 * U.S. Government End Users acquire the Licensed Deliverables with
 * only those rights set forth herein.
 *
 * Any use of the Licensed Deliverables in individual and commercial
 * software must include, in the user documentation and internal
 * comments to the code, the above Disclaimer and U.S. Government End
 * Users Notice.
 */

/**
 * @file TemporalNoiseReduction.h
 *
 * Declares functions that implement the Temporal Noise Reduction algorithm
 */

#ifndef NV_VPI_ALGORITHMS_TEMPORAL_NOISE_REDUCTION_H
#define NV_VPI_ALGORITHMS_TEMPORAL_NOISE_REDUCTION_H

// #include "../Export.h"
// #include "../ImageFormat.h"
// #include "../Status.h"
// #include "../Types.h"

#include <stdint.h>

#ifdef __cplusplus
extern "C" {
#endif

/**
 * @defgroup VPI_TNR Temporal Noise Reduction
 * @ingroup VPI_API_Algorithms
 * @{
 *
 * Performs temporal noise reduction in a sequence of images.
 * Refer to \ref algo_tnr for more details and usage examples.
 */

/** Defines scene presets for temporal noise reduction.
 * These presets are used by \ref algo_tnr to define its internal parameters suitable
 * for noise reduction of scenes captured with given characteristics.
 */
typedef enum
{
    VPI_TNR_PRESET_DEFAULT,              /**< Default preset, suitable for most scenes. */
    VPI_TNR_PRESET_OUTDOOR_LOW_LIGHT,    /**< Low light outdoor scene. */
    VPI_TNR_PRESET_OUTDOOR_MEDIUM_LIGHT, /**< Medium light outdoor scene. */
    VPI_TNR_PRESET_OUTDOOR_HIGH_LIGHT,   /**< Bright light outdoor scene. */
    VPI_TNR_PRESET_INDOOR_LOW_LIGHT,     /**< Low light indoor scene. */
    VPI_TNR_PRESET_INDOOR_MEDIUM_LIGHT,  /**< Medium light indoor scene. */
    VPI_TNR_PRESET_INDOOR_HIGH_LIGHT     /**< Bright light indoor scene. */
} VPITNRPreset;

/** Defines the version of the \ref algo_tnr algorithm to be used.
 *  Higher version numbers usually achieve better quality.
 */
typedef enum
{
    /** Chooses the version with best quality available in the current device and given backend. */
    VPI_TNR_DEFAULT,

    /** Version 1, without scene control and somewhat poor noise reduction capability specially in dark scenes, but runs fast. */
    VPI_TNR_V1,

    /** Version 2, offers noise reduction strength control with decent processing speed. */
    VPI_TNR_V2,

    /** Version 3, offers quite good quality overall, specially in dark scenes.
     * + CUDA backend only supports this one.
     * + VIC backend supported only on Jetson Xavier. */
    VPI_TNR_V3

} VPITNRVersion;

/**
 * Creates a payload for \ref algo_tnr algorithm.
 * This function allocates all resources needed by the algorithm and ties the
 * returned payload to the given backend.
 *
 * @param[in] backends VPI backends that are eligible to execute the algorithm.
 *                     + Valid values:
 *                       - \ref VPI_BACKEND_CUDA
 *                       - \ref VPI_BACKEND_VIC
 *                     + Backend must be enabled in current context.
 *
 * @param[in] width,height Dimensions of frames to be processed.
 *                         + Must be positive.
 *
 * @param[in] imgFormat Format of the images to be processed. 
 *                      + Supported formats:
 *                          - \ref VPI_IMAGE_FORMAT_NV12_ER (CUDA backend only supports this one)
 *                          - \ref VPI_IMAGE_FORMAT_NV12_ER_BL
 *                          - \ref VPI_IMAGE_FORMAT_YUYV_ER
 *                          - \ref VPI_IMAGE_FORMAT_YUYV_ER_BL
 *                          - \ref VPI_IMAGE_FORMAT_UYVY_ER
 *                          - \ref VPI_IMAGE_FORMAT_UYVY_ER_BL
 *
 * @param[in] version Version of the algorithm to be used.
 *
 * @param[out] payload Pointer to the payload variable that receives the created handle.
 *
 * @retval #VPI_IMAGE_FORMAT_INVALID    \p imgFormat is not supported.
 * @retval #VPI_ERROR_INVALID_ARGUMENT  \p payload is NULL.
 * @retval #VPI_ERROR_INVALID_ARGUMENT  \p width or \p height outside valid range.
 * @retval #VPI_ERROR_INVALID_ARGUMENT  Invalid TNR \p version.
 * @retval #VPI_ERROR_INVALID_ARGUMENT  \p backends refers to an invalid backend.
 * @retval #VPI_ERROR_INVALID_OPERATION No VIC support is available.
 * @retval #VPI_ERROR_INVALID_OPERATION Backend isn't enabled in current context.
 * @retval #VPI_ERROR_NOT_IMPLEMENTED   Temporal Noise Reduction algorithm version is not supported by given backend.
 * @retval #VPI_ERROR_NOT_IMPLEMENTED   VIC Hardware with TNRv3 support is not available.
 * @retval #VPI_ERROR_INVALID_CONTEXT   Current context is destroyed.
 * @retval #VPI_ERROR_OUT_OF_MEMORY     Cannot allocate required resources.
 * @retval #VPI_SUCCESS                 Operation executed successfully.
 */
VPI_PUBLIC VPIStatus vpiCreateTemporalNoiseReduction(uint64_t backends, int32_t width, int32_t height,
                                                     VPIImageFormat imgFormat, VPITNRVersion version,
                                                     VPIPayload *payload);

/**
 * Structure that defines the parameters for \ref vpiSubmitTemporalNoiseReduction
 */
typedef struct
{
    /** Scene preset to be used. */
    VPITNRPreset preset;

    /** Noise reduction strength.
     *  + Must be >= 0 and <=1. */
    float strength;

} VPITNRParams;

/**
 * Initializes \ref vpiSubmitTemporalNoiseReduction with default values.
 *
 * Defaults:
 * - preset: \ref VPI_TNR_PRESET_DEFAULT
 * - strength: 0.5
 *
 * @param[in] params Structure to be filled with default values.
 *
 * @retval #VPI_ERROR_INVALID_ARGUMENT \p params is NULL.
 * @retval #VPI_SUCCESS Operation executed successfully.
 */
VPI_PUBLIC VPIStatus vpiInitTemporalNoiseReductionParams(VPITNRParams *params);

/**
 * Submits a \ref algo_tnr "Temporal Noise Reduction" operation to the stream.
 *
 * @param[in] stream The stream where the operation will be queued in.
 *                   + Must not be NULL.
 *                   + Stream must have enabled the backends that will execute the algorithm.
 *
 * @param[in] backend Backend that will execute the algorithm.
 *                    + Must be the backend specified during payload creation or 0 as a shorthand to use this backend.
 *
 * @param[in] payload Payload to be submitted along the other parameters.
 *
 * @param[in] prevFrame Result of the previous iteration.
 *                      If the frame passed isn't the result image of the previous iteration, TNR will
 *                      consider it to be NULL, i.e, the internal state will be reset and \p curFrame will
 *                      be considered to be the first frame of a new sequence to be denoised.
 *                      + When processing the first frame of a video sequence, this must be NULL.
 *                      + Must have same format and dimensions as the one specified during payload creation.
 *                      + Input must have enabled the backends that will execute the algorithm.
 *
 * @param[in] curFrame Current (noisy) frame to be processed. 
 *                     + Must not be NULL.
 *                     + Must have same format and dimensions as the one specified during payload creation.
 *                     + Input must have enabled the backends that will execute the algorithm.
 *
 * @param[out] outFrame Output frame, where de-noised image will be written to.
 *                      + Must not be NULL.
 *                      + Must have same format and dimensions as the one specified during payload creation.
 *                      + Input must have enabled the backends that will execute the algorithm.
 *
 * @param[in] params Control parameters for temporal noise reduction
 *                   If NULL, it'll use the defaults given by \ref vpiInitTemporalNoiseReductionParams.
 *
 * @retval #VPI_ERROR_INVALID_ARGUMENT     \p stream is NULL.
 * @retval #VPI_ERROR_INVALID_ARGUMENT     \p curFrame or \p outFrame are NULL.
 * @retval #VPI_ERROR_INVALID_ARGUMENT     \p payload is not generated using vpiCreateTemporalNoiseReduction family of functions.
 * @retval #VPI_ERROR_INVALID_ARGUMENT     \p prevFrame, \p curFrame and \p outFrame must have the same format and size
 *                                         configured during \p payload creation.
 * @retval #VPI_ERROR_INVALID_ARGUMENT     Strength in \p params outside valid range.
 * @retval #VPI_ERROR_INVALID_PAYLOAD_TYPE \p payload is invalid.
 * @retval #VPI_ERROR_INVALID_OPERATION    The needed backends aren't enabled in \p stream, \p prevFrame, \p curFrame or \p outFrame.
 * @retval #VPI_SUCCESS                    Operation executed successfully.
 */
VPI_PUBLIC VPIStatus vpiSubmitTemporalNoiseReduction(VPIStream stream, uint64_t backend, VPIPayload payload,
                                                     VPIImage prevFrame, VPIImage curFrame, VPIImage outFrame,
                                                     const VPITNRParams *params);
/** @} end of VPI_TNR */

#ifdef __cplusplus
}
#endif

#endif /* NV_VPI_ALGORITHMS_TEMPORAL_NOISE_REDUCTION_H */
// End content from: algo/TemporalNoiseReduction.h

// Begin content from: algo/BilateralFilter.h
/*
 * Copyright 2019-2021 NVIDIA Corporation. All rights reserved.
 *
 * NOTICE TO LICENSEE:
 *
 * This source code and/or documentation ("Licensed Deliverables") are
 * subject to NVIDIA intellectual property rights under U.S. and
 * international Copyright laws.
 *
 * These Licensed Deliverables contained herein is PROPRIETARY and
 * CONFIDENTIAL to NVIDIA and is being provided under the terms and
 * conditions of a form of NVIDIA software license agreement by and
 * between NVIDIA and Licensee ("License Agreement") or electronically
 * accepted by Licensee. Notwithstanding any terms or conditions to
 * the contrary in the License Agreement, reproduction or disclosure
 * of the Licensed Deliverables to any third party without the express
 * written consent of NVIDIA is prohibited.
 *
 * NOTWITHSTANDING ANY TERMS OR CONDITIONS TO THE CONTRARY IN THE
 * LICENSE AGREEMENT, NVIDIA MAKES NO REPRESENTATION ABOUT THE
 * SUITABILITY OF THESE LICENSED DELIVERABLES FOR ANY PURPOSE. IT IS
 * PROVIDED "AS IS" WITHOUT EXPRESS OR IMPLIED WARRANTY OF ANY KIND.
 * NVIDIA DISCLAIMS ALL WARRANTIES WITH REGARD TO THESE LICENSED
 * DELIVERABLES, INCLUDING ALL IMPLIED WARRANTIES OF MERCHANTABILITY,
 * NONINFRINGEMENT, AND FITNESS FOR A PARTICULAR PURPOSE.
 * NOTWITHSTANDING ANY TERMS OR CONDITIONS TO THE CONTRARY IN THE
 * LICENSE AGREEMENT, IN NO EVENT SHALL NVIDIA BE LIABLE FOR ANY
 * SPECIAL, INDIRECT, INCIDENTAL, OR CONSEQUENTIAL DAMAGES, OR ANY
 * DAMAGES WHATSOEVER RESULTING FROM LOSS OF USE, DATA OR PROFITS,
 * WHETHER IN AN ACTION OF CONTRACT, NEGLIGENCE OR OTHER TORTIOUS
 * ACTION, ARISING OUT OF OR IN CONNECTION WITH THE USE OR PERFORMANCE
 * OF THESE LICENSED DELIVERABLES.
 *
 * U.S. Government End Users. These Licensed Deliverables are a
 * "commercial item" as that term is defined at 48 C.F.R. 2.101 (OCT
 * 1995), consisting of "commercial computer software" and "commercial
 * computer software documentation" as such terms are used in 48
 * C.F.R. 12.212 (SEPT 1995) and is provided to the U.S. Government
 * only as a commercial end item. Consistent with 48 C.F.R.12.212 and
 * 48 C.F.R. 227.7202-1 through 227.7202-4 (JUNE 1995), all
 * U.S. Government End Users acquire the Licensed Deliverables with
 * only those rights set forth herein.
 *
 * Any use of the Licensed Deliverables in individual and commercial
 * software must include, in the user documentation and internal
 * comments to the code, the above Disclaimer and U.S. Government End
 * Users Notice.
 */

/**
 * @file BilateralFilter.h
 *
 * Declares functions that implement the Bilateral Filter algorithm.
 */

#ifndef NV_VPI_ALGORITHMS_BILATERAL_FILTER_H
#define NV_VPI_ALGORITHMS_BILATERAL_FILTER_H

// #include "../Export.h"
// #include "../Status.h"
// #include "../Types.h"

#include <stdint.h>

#ifdef __cplusplus
extern "C" {
#endif

/**
 * @defgroup VPI_BilateralFilter Bilateral Filter
 * @ingroup VPI_API_Algorithms
 * @{
 *
 * Runs a generic 2D bilateral filter over the input image.
 * Refer to \ref algo_bilat_filter for more details and usage examples.
 */

/**
 * Runs a 2D bilateral filter over an image.
 *
 * @param[in] stream A stream handle where the operation will be queued into.
 *                   + Must not be NULL.
 *                   + Stream must have enabled the backends that will execute the algorithm.
 *
 * @param[in] backend Backend that will execute the algorithm.
 *                    + Valid values: 
 *                      - \ref VPI_BACKEND_CPU
 *                      - \ref VPI_BACKEND_CUDA
 *
 * @param[in] input Input image to be filtered.
 *                  + Must not be NULL.
 *                  + Image must have enabled the backends that will execute the algorithm.
 *                  + The accepted image formats are:
 *                    | Formats                       | CPU | CUDA |
 *                    |-------------------------------|:---:|:----:|
 *                    | \ref VPI_IMAGE_FORMAT_U8      |  *  |   *  |
 *                    | \ref VPI_IMAGE_FORMAT_S8      |  *  |   *  |
 *                    | \ref VPI_IMAGE_FORMAT_U16     |  *  |   *  |
 *                    | \ref VPI_IMAGE_FORMAT_S16     |  *  |   *  |
 *                    | \ref VPI_IMAGE_FORMAT_Y8      |  *  |   *  |
 *                    | \ref VPI_IMAGE_FORMAT_Y8_ER   |  *  |   *  |
 *                    | \ref VPI_IMAGE_FORMAT_Y16     |  *  |   *  |
 *                    | \ref VPI_IMAGE_FORMAT_Y16_ER  |  *  |   *  |
 *                    | \ref VPI_IMAGE_FORMAT_F32     |  *  |   *  |
 *                    | \ref VPI_IMAGE_FORMAT_NV12    |     |   *  |
 *                    | \ref VPI_IMAGE_FORMAT_NV12_ER |     |   *  |
 *
 * @param[out] output Output image where the result will be written to.
 *                    + Must not be NULL.
 *                    + It must have the same format and dimensions as input.
 *                    + Image must have enabled the backends that will execute the algorithm.
 *
 * @param[in] kernelSize Kernel support dimensions, in pixels.
 *                       + Must be >= 1 and <= 11.
 *                       + Must be odd.
 *
 * @param[in] sigmaRange Standard deviation in color space.
 *                       + Must be > 0.
 *
 * @param[in] sigmaSpace Standard deviation in the coordinate space.
 *                       + Must be > 0.
 *
 * @param[in] border How to handle pixels outside image boundaries.
 *                   + The accepted border extensions are:
 *                     - \ref VPI_BORDER_ZERO
 *                     - \ref VPI_BORDER_CLAMP
 *
 * @retval #VPI_ERROR_INVALID_ARGUMENT     \p stream is NULL.
 * @retval #VPI_ERROR_INVALID_ARGUMENT     \p input or \p output are NULL.
 * @retval #VPI_ERROR_INVALID_ARGUMENT     \p input and \p output image dimensions or formats don't match.
 * @retval #VPI_ERROR_INVALID_ARGUMENT     \p input or \p output image dimensions outside valid range.
 * @retval #VPI_ERROR_INVALID_ARGUMENT     \p kernelSize outside valid range.
 * @retval #VPI_ERROR_INVALID_ARGUMENT     \p sigmaRange or \p sigmaSpace outside valid range.
 * @retval #VPI_ERROR_INVALID_ARGUMENT     \p backend is invalid or unknown.
 * @retval #VPI_ERROR_INVALID_ARGUMENT     \p border not supported.
 * @retval #VPI_ERROR_INVALID_IMAGE_FORMAT \p input or \p output format is not supported.
 * @retval #VPI_ERROR_NOT_IMPLEMENTED      Bilateral Filter algorithm is not supported by given backend.
 * @retval #VPI_ERROR_INVALID_OPERATION    The needed backends aren't enabled in \p stream, \p input or \p output.
 * @retval #VPI_SUCCESS                    Operation executed successfully.
 */
VPI_PUBLIC VPIStatus vpiSubmitBilateralFilter(VPIStream stream, uint64_t backend, VPIImage input, VPIImage output,
                                              int32_t kernelSize, float sigmaRange, float sigmaSpace,
                                              VPIBorderExtension border);
/** @} */

#ifdef __cplusplus
}
#endif

#endif /* NV_VPI_ALGORITHMS_BILATERAL_FILTER_H */
// End content from: algo/BilateralFilter.h

// Begin content from: algo/OpticalFlowDense.h
/*
 * Copyright 2021 NVIDIA Corporation. All rights reserved.
 *
 * NOTICE TO LICENSEE:
 *
 * This source code and/or documentation ("Licensed Deliverables") are
 * subject to NVIDIA intellectual property rights under U.S. and
 * international Copyright laws.
 *
 * These Licensed Deliverables contained herein is PROPRIETARY and
 * CONFIDENTIAL to NVIDIA and is being provided under the terms and
 * conditions of a form of NVIDIA software license agreement by and
 * between NVIDIA and Licensee ("License Agreement") or electronically
 * accepted by Licensee. Notwithstanding any terms or conditions to
 * the contrary in the License Agreement, reproduction or disclosure
 * of the Licensed Deliverables to any third party without the express
 * written consent of NVIDIA is prohibited.
 *
 * NOTWITHSTANDING ANY TERMS OR CONDITIONS TO THE CONTRARY IN THE
 * LICENSE AGREEMENT, NVIDIA MAKES NO REPRESENTATION ABOUT THE
 * SUITABILITY OF THESE LICENSED DELIVERABLES FOR ANY PURPOSE. IT IS
 * PROVIDED "AS IS" WITHOUT EXPRESS OR IMPLIED WARRANTY OF ANY KIND.
 * NVIDIA DISCLAIMS ALL WARRANTIES WITH REGARD TO THESE LICENSED
 * DELIVERABLES, INCLUDING ALL IMPLIED WARRANTIES OF MERCHANTABILITY,
 * NONINFRINGEMENT, AND FITNESS FOR A PARTICULAR PURPOSE.
 * NOTWITHSTANDING ANY TERMS OR CONDITIONS TO THE CONTRARY IN THE
 * LICENSE AGREEMENT, IN NO EVENT SHALL NVIDIA BE LIABLE FOR ANY
 * SPECIAL, INDIRECT, INCIDENTAL, OR CONSEQUENTIAL DAMAGES, OR ANY
 * DAMAGES WHATSOEVER RESULTING FROM LOSS OF USE, DATA OR PROFITS,
 * WHETHER IN AN ACTION OF CONTRACT, NEGLIGENCE OR OTHER TORTIOUS
 * ACTION, ARISING OUT OF OR IN CONNECTION WITH THE USE OR PERFORMANCE
 * OF THESE LICENSED DELIVERABLES.
 *
 * U.S. Government End Users. These Licensed Deliverables are a
 * "commercial item" as that term is defined at 48 C.F.R. 2.101 (OCT
 * 1995), consisting of "commercial computer software" and "commercial
 * computer software documentation" as such terms are used in 48
 * C.F.R. 12.212 (SEPT 1995) and is provided to the U.S. Government
 * only as a commercial end item. Consistent with 48 C.F.R.12.212 and
 * 48 C.F.R. 227.7202-1 through 227.7202-4 (JUNE 1995), all
 * U.S. Government End Users acquire the Licensed Deliverables with
 * only those rights set forth herein.
 *
 * Any use of the Licensed Deliverables in individual and commercial
 * software must include, in the user documentation and internal
 * comments to the code, the above Disclaimer and U.S. Government End
 * Users Notice.
 */

/**
 * @file OpticalFlowDense.h
 *
 * Declares functions that implement the dense optical flow.
 */

#ifndef NV_VPI_ALGORITHMS_OPTICALFLOWDENSE_H
#define NV_VPI_ALGORITHMS_OPTICALFLOWDENSE_H

/**
 * @defgroup VPI_OpticalFlowDense Dense Optical Flow
 * @ingroup VPI_API_Algorithms
 * @{
 *
 * Algorithm used to estimate the motion vectors from previous image to current image.
 * Refer to \ref algo_optflow_dense for more details and usage examples.
 */

// #include "../Export.h"
// #include "../ImageFormat.h"
// #include "../Pyramid.h"
// #include "../Status.h"
// #include "../Types.h"

#include <stdbool.h>
#include <stdint.h>

#ifdef __cplusplus
extern "C" {
#endif

/**
 * Creates payload for \ref vpiSubmitOpticalFlowDense
 *
 * @param[in] backends VPI backends that are eligible to execute the algorithm.
 *                     + Supported backends:
 *                       - \ref VPI_BACKEND_NVENC
 *                       - \ref VPI_BACKEND_OFA
 *                     + Backend must be enabled in current context.
 *
 * @param[in] width,height Dimensions of current and previous image.
 *                         The output dimensions depend on the \p gridSize
 *                         and the input dimensions.
 *                         + Must be >= 0.
 *
 * @param[in] gridSize Array with grid sizes for each pyramid level.
 *                     If working with input images, not pyramids, \p gridSize
 *                     points to the single grid size used, as if it were for a pyramid with only one level.
 *                     The first value in the array corresponds to the bottom (finer) level, the last
 *                     corresponds to the top (coarse) level.
 *                     Passing 1 allows for a dense grid. With 2 or more, the grid
 *                     will be sparse.
 *                     The output image dimensions depend on the first value in \p gridSize
 *                     and the input dimensions.
 *                     + Valid values:
 *                     | Backend                | Allowed grid sizes per level |
 *                     |------------------------|:----------------------------:|
 *                     | \ref VPI_BACKEND_NVENC |                4             |
 *                     | \ref VPI_BACKEND_OFA   |             1,2,4,8          |
 *
 * @param[in] numLevels Number of pyramid levels to be processed.
 *                      When using pyramids as inputs, this specifies the
 *                      number of levels to be considered. 
 *                      When using images, \p numLevels must be 1.
 *                      + On OFA, the number of levels is limited by the dimensions of the
 *                        smallest pyramid level. It must be >= 32x32.
 *                        Moreover, after dividing this smallest level by \p gridSize, the
 *                        result must be >= 4x4.
 *                      + Valid values:
 *                     | Backend                | minimum | maximum :|
 *                     |------------------------|:-------:|:--------:|
 *                     | \ref VPI_BACKEND_NVENC |    1    |    1     |
 *                     | \ref VPI_BACKEND_OFA   |    1    |    7     |
 *
 * @param[in] inputFmt Format of current and previous image/pyramid.
 *                     + The accepted image formats are:
 *                     | Format                           | NVENC | OFA  |
 *                     |----------------------------------|:-----:|:----:|
 *                     | \ref VPI_IMAGE_FORMAT_NV12_BL    |   *   |  *   |
 *                     | \ref VPI_IMAGE_FORMAT_NV12_ER_BL |   *   |  *   |
 *                     | \ref VPI_IMAGE_FORMAT_U8_BL      |       |  *   |
 *                     | \ref VPI_IMAGE_FORMAT_Y8_BL      |       |  *   |
 *                     | \ref VPI_IMAGE_FORMAT_Y8_ER_BL   |       |  *   |
 *                     | \ref VPI_IMAGE_FORMAT_Y16_BL     |       |  *   |
 *                     | \ref VPI_IMAGE_FORMAT_Y16_ER_BL  |       |  *   |
 *
 * @param[in] quality Quality of the dense optical flow algorithm.
 *
 * @param[out] payload Pointer to the payload variable that receives the created handle.
 *
 * @retval #VPI_IMAGE_FORMAT_INVALID    \p inputFmt is not supported.
 * @retval #VPI_ERROR_INVALID_ARGUMENT  \p payload is NULL.
 * @retval #VPI_ERROR_INVALID_ARGUMENT  \p width, \p height, \p numLevels or \p gridSize outside valid range.
 * @retval #VPI_ERROR_INVALID_ARGUMENT  \p backends refers to an invalid backend.
 * @retval #VPI_ERROR_INVALID_OPERATION Backend hardware not available.
 * @retval #VPI_ERROR_INVALID_OPERATION Backend isn't enabled in current context.
 * @retval #VPI_ERROR_NOT_IMPLEMENTED   Dense Optical Flow algorithm is not supported by given backends.
 * @retval #VPI_ERROR_INVALID_CONTEXT   Current context is destroyed.
 * @retval #VPI_ERROR_OUT_OF_MEMORY     Cannot allocate required resources.
 * @retval #VPI_SUCCESS                 Operation executed successfully.
 */
#if NV_VPI_VERSION_API_AT_MOST(2, 2)
VPI_PUBLIC VPIStatus vpiCreateOpticalFlowDense(uint64_t backends, int32_t width, int32_t height,
                                               VPIImageFormat inputFmt, VPIOpticalFlowQuality quality,
                                               VPIPayload *payload);
#else
VPI_PUBLIC VPIStatus vpiCreateOpticalFlowDense(uint64_t backends, int32_t width, int32_t height,
                                               VPIImageFormat inputFmt, const int32_t *gridSize, int32_t numLevels,
                                               VPIOpticalFlowQuality quality, VPIPayload *payload);
#endif

/**
 * Runs dense Optical Flow on two frames, outputting motion vectors.
 *
 * @param[in] stream The stream where the operation will be queued in.
 *                   + Must not be NULL.
 *                   + Stream must have enabled the backends that will execute the algorithm.
 *
 * @param[in] backend Backend that will execute the algorithm.
 *                    + Must be the backend specified during payload creation or 0 as a shorthand to use this backend.
 *
 * @param[in] payload Payload created by \ref vpiCreateOpticalFlowDense. 
 *                    + The number of pyramid levels specified in the payload must be 1.
 *
 * @param[in] prevImg Previous frame.
 *                    + Must not be NULL.
 *                    + Must have same format and dimensions as the one specified during payload creation.
 *                    + Image must have enabled the backends that will execute the algorithm.
 *
 * @param[in] curImg Current frame.
 *                   + Must not be NULL.
 *                   + Must have same format and dimensions as \p prevImg.
 *                   + Image must have enabled the backends that will execute the algorithm.
 *
 * @param[out] mvImg Motion vectors output.
 *                   + Must not be NULL.
 *                   + Image must have enabled the backends that will execute the algorithm.
 *                   + The width and height depend on the input dimensions and grid size specified on the payload.
 *                     It's calculated by:
 *                     - output_width  = (input_width  + gridSize-1)/gridSize
 *                     - output_height = (input_height + gridSize-1)/gridSize
 *                   + Supported formats:
 *                     - \ref VPI_IMAGE_FORMAT_2S16_BL is supported. Motion vector is in fixed point S10.5 format.
 * 
 * @retval #VPI_ERROR_INVALID_ARGUMENT     \p stream is NULL.
 * @retval #VPI_ERROR_INVALID_ARGUMENT     \p prevImg, \p curImg or \p mvImg are NULL.
 * @retval #VPI_ERROR_INVALID_ARGUMENT     \p payload is not generated using vpiCreateOpticalFlowDense.
 * @retval #VPI_ERROR_INVALID_ARGUMENT     number of pyramid levels specified in \p payload is not 1.
 * @retval #VPI_ERROR_INVALID_ARGUMENT     \p prevImg and \p curImg dimensions does not match the one associated with the \p payload. 
 * @retval #VPI_ERROR_INVALID_IMAGE_FORMAT \p prevImg and \p curImg format does not match the one associated with the \p payload. 
 * @retval #VPI_ERROR_INVALID_PAYLOAD_TYPE \p payload is invalid.
 * @retval #VPI_ERROR_INVALID_OPERATION    The needed backends aren't enabled in \p stream, \p prevImg, \p curImg or \p mvImg.
 * @retval #VPI_SUCCESS                    Operation executed successfully.
 */
VPI_PUBLIC VPIStatus vpiSubmitOpticalFlowDense(VPIStream stream, uint64_t backend, VPIPayload payload, VPIImage prevImg,
                                               VPIImage curImg, VPIImage mvImg);

/**
 * Runs dense Optical Flow on two frames, outputting motion vectors.
 *
 * @param[in] stream The stream where the operation will be queued in.
 *                   + Must not be NULL.
 *                   + Stream must have enabled the backends that will execute the algorithm.
 *
 * @param[in] backend Backend that will execute the algorithm.
 *                    + Must be the backend specified during payload creation or 0 as a shorthand to use this backend.
 *
 * @param[in] payload Payload created by \ref vpiCreateOpticalFlowDense. 
 *
 * @param[in] prevPyr Previous pyramid frame.
 *                    + Must not be NULL.
 *                    + Must have same format and dimensions as the one specified during payload creation.
 *                    + Pyramid height must be >= the number of pyramid levels specified in the payload.
 *                    + Pyramid must have enabled the backends that will execute the algorithm.
 *
 * @param[in] curPyr Current pyramid frame.
 *                   + Must not be NULL.
 *                   + Must have same format and dimensions as \p prevImg.
 *                   + Number of pyramid levels must be the same as specified in the payload.
 *                   + Pyramid must have enabled the backends that will execute the algorithm.
 *
 * @param[out] mvImg Motion vectors output.
 *                   + Must not be NULL.
 *                   + Image must have enabled the backends that will execute the algorithm.
 *                   + The width and height depend on the input dimensions and grid size of the bottom pyramid level
 *                     specified in the payload.
 *                     It's calculated by:
 *                     - output_width  = (input_width  + gridSize-1)/gridSize
 *                     - output_height = (input_height + gridSize-1)/gridSize
 *                   + Supported formats:
 *                     - \ref VPI_IMAGE_FORMAT_2S16_BL is supported. Motion vector is in fixed point S10.5 format.
 * 
 * @retval #VPI_ERROR_INVALID_ARGUMENT     \p stream is NULL.
 * @retval #VPI_ERROR_INVALID_ARGUMENT     \p prevPyr, \p cuurPyr or \p mvImg are NULL.
 * @retval #VPI_ERROR_INVALID_ARGUMENT     \p payload is not generated using vpiCreateOpticalFlowDense.
 * @retval #VPI_ERROR_INVALID_ARGUMENT     \p prevPyr and \p cuurPyr dimensions does not match the one associated with the \p payload. 
 * @retval #VPI_ERROR_INVALID_ARGUMENT     \p prevPyr and \p curPyr number of Levels out of valid range.
 * @retval #VPI_ERROR_INVALID_IMAGE_FORMAT \p prevPyr and \p curPyr format does not match the one associated with the \p payload. 
 * @retval #VPI_ERROR_INVALID_PAYLOAD_TYPE \p payload is invalid.
 * @retval #VPI_ERROR_INVALID_OPERATION    The needed backends aren't enabled in \p stream, \p prevPyr, \p cuurPyr or \p mvImg.
 * @retval #VPI_SUCCESS                    Operation executed successfully.
 */
VPI_PUBLIC VPIStatus vpiSubmitOpticalFlowDensePyramid(VPIStream stream, uint64_t backend, VPIPayload payload,
                                                      VPIPyramid prevPyr, VPIPyramid curPyr, VPIImage mvImg);

/** Dense optical flow parameters for semi-global matching pass.
 * Each pyramid level can be associated with different parameters.
 * The first value in the arrays corresponds to the bottom (finer) level, the last
 * corresponds to the top (coarse) level. */
typedef struct
{
    /** P1 penalty value of semi-global matching algorithm used.
     * Only used by OFA backend and ignored by others. */
    int32_t p1[VPI_MAX_PYRAMID_LEVEL_COUNT];

    /** P2 penalty value of semi-global matching algorithm used.
     * Only used by OFA backend and ignored by others. */
    int32_t p2[VPI_MAX_PYRAMID_LEVEL_COUNT];

    /** Alpha value for adaptative P2 used in semi-global matching.
     * - Valid values are 0 (disable adaptative P2), 1, 2, 4 or 8.
     * Only used by OFA backend and ignored by others. */
    int32_t p2Alpha[VPI_MAX_PYRAMID_LEVEL_COUNT];

    /** Number of semi-global matching passes.
     * - Valid range is from 1 to 3, inclusive.
     * Only used by OFA backend and ignored by others. */
    int32_t numPasses[VPI_MAX_PYRAMID_LEVEL_COUNT];

    /** Enable/disable diagonal directions in semi-global matching. *
     * To disable, set it to 0, any other values will enable it.
     * Only used by OFA backend and ignored by others. */
    int8_t includeDiagonals[VPI_MAX_PYRAMID_LEVEL_COUNT];
} VPIOpticalFlowDenseSGMParams;

/** Retrieves the semi-global matching parameters set up in the Dense Optical Flow payload.
 *
 * @param [in] payload Payload created by \ref vpiCreateOpticalFlowDense.
 *                     + Payload must be using the OFA backend.
 * 
 * @param [out] sgmParams Structure where parameters will be written to.
 *                        + Must not be NULL.
 *
 * @retval #VPI_ERROR_INVALID_PAYLOAD_TYPE \p payload is invalid.
 * @retval #VPI_ERROR_INVALID_ARGUMENT     \p sgmParams is NULL.
 * @retval #VPI_ERROR_INVALID_OPERATION    \p payload was not created for OFA dense optical flow.
 * @retval #VPI_SUCCESS                    Operation executed successfully.
 */
VPI_PUBLIC VPIStatus vpiOpticalFlowDenseGetSGMParams(VPIPayload payload, VPIOpticalFlowDenseSGMParams *sgmParams);

/** Sets the semi-global matching parameters to be used by the Dense Optical Flow operations with the given payload.
 *
 * The parameters will be only effective on future dense optical flow operations on the given payload.
 * Already submitted operations won't be affected.
 *
 * @param [in] payload Payload created by \ref vpiCreateOpticalFlowDense.
 *                     + Payload must be using the OFA backend.
 * 
 * @param [in] sgmParams SGM parameters to be used by future dense optical flow submissions with given payload.
 *                        + Must not be NULL.
 *
 * @retval #VPI_ERROR_INVALID_PAYLOAD_TYPE \p payload is invalid.
 * @retval #VPI_ERROR_INVALID_ARGUMENT     \p sgmParams is NULL.
 * @retval #VPI_ERROR_INVALID_OPERATION    \p payload was not created for OFA dense optical flow.
 * @retval #VPI_SUCCESS                    Operation executed successfully.
 */
VPI_PUBLIC VPIStatus vpiOpticalFlowDenseSetSGMParams(VPIPayload payload, const VPIOpticalFlowDenseSGMParams *sgmParams);

#ifdef __cplusplus
}
#endif

/** @} */ // end of VPI_OpticalFlowDense

#endif // NV_VPI_ALGORITHMS_OPTICALFLOWDENSE_H
// End content from: algo/OpticalFlowDense.h

// Begin content from: algo/Convolution.h
/*
 * Copyright 2019-2021 NVIDIA Corporation. All rights reserved.
 *
 * NOTICE TO LICENSEE:
 *
 * This source code and/or documentation ("Licensed Deliverables") are
 * subject to NVIDIA intellectual property rights under U.S. and
 * international Copyright laws.
 *
 * These Licensed Deliverables contained herein is PROPRIETARY and
 * CONFIDENTIAL to NVIDIA and is being provided under the terms and
 * conditions of a form of NVIDIA software license agreement by and
 * between NVIDIA and Licensee ("License Agreement") or electronically
 * accepted by Licensee. Notwithstanding any terms or conditions to
 * the contrary in the License Agreement, reproduction or disclosure
 * of the Licensed Deliverables to any third party without the express
 * written consent of NVIDIA is prohibited.
 *
 * NOTWITHSTANDING ANY TERMS OR CONDITIONS TO THE CONTRARY IN THE
 * LICENSE AGREEMENT, NVIDIA MAKES NO REPRESENTATION ABOUT THE
 * SUITABILITY OF THESE LICENSED DELIVERABLES FOR ANY PURPOSE. IT IS
 * PROVIDED "AS IS" WITHOUT EXPRESS OR IMPLIED WARRANTY OF ANY KIND.
 * NVIDIA DISCLAIMS ALL WARRANTIES WITH REGARD TO THESE LICENSED
 * DELIVERABLES, INCLUDING ALL IMPLIED WARRANTIES OF MERCHANTABILITY,
 * NONINFRINGEMENT, AND FITNESS FOR A PARTICULAR PURPOSE.
 * NOTWITHSTANDING ANY TERMS OR CONDITIONS TO THE CONTRARY IN THE
 * LICENSE AGREEMENT, IN NO EVENT SHALL NVIDIA BE LIABLE FOR ANY
 * SPECIAL, INDIRECT, INCIDENTAL, OR CONSEQUENTIAL DAMAGES, OR ANY
 * DAMAGES WHATSOEVER RESULTING FROM LOSS OF USE, DATA OR PROFITS,
 * WHETHER IN AN ACTION OF CONTRACT, NEGLIGENCE OR OTHER TORTIOUS
 * ACTION, ARISING OUT OF OR IN CONNECTION WITH THE USE OR PERFORMANCE
 * OF THESE LICENSED DELIVERABLES.
 *
 * U.S. Government End Users. These Licensed Deliverables are a
 * "commercial item" as that term is defined at 48 C.F.R. 2.101 (OCT
 * 1995), consisting of "commercial computer software" and "commercial
 * computer software documentation" as such terms are used in 48
 * C.F.R. 12.212 (SEPT 1995) and is provided to the U.S. Government
 * only as a commercial end item. Consistent with 48 C.F.R.12.212 and
 * 48 C.F.R. 227.7202-1 through 227.7202-4 (JUNE 1995), all
 * U.S. Government End Users acquire the Licensed Deliverables with
 * only those rights set forth herein.
 *
 * Any use of the Licensed Deliverables in individual and commercial
 * software must include, in the user documentation and internal
 * comments to the code, the above Disclaimer and U.S. Government End
 * Users Notice.
 */

/**
 * @file Convolution.h
 *
 * Declares functions to perform image filtering with convolution kernels.
 */

#ifndef NV_VPI_ALGORITHMS_CONVOLUTION_H
#define NV_VPI_ALGORITHMS_CONVOLUTION_H

// #include "../Export.h"
// #include "../Status.h"
// #include "../Types.h"

#include <stdint.h>

#ifdef __cplusplus
extern "C" {
#endif

/**
 * @defgroup VPI_Convolution Convolution
 * @ingroup VPI_API_Algorithms
 * @{
 *
 * Convolves an image with a 2D kernel.
 * Refer to \ref algo_convolution for more details and usage examples regarding Convolution.
 * Refer to \ref algo_sep_convolution for more details and usage examples regarding Separable Convolution.
 *
 * \ref vpiSubmitConvolution is used for generic 2D kernels, separable or not. For separable kernels,
 * it's usually more efficient to use \ref vpiSubmitSeparableConvolution.
 *
 */

/**
 * Runs a generic 2D convolution over an image.
 *
 * @param[in] stream The stream handle where the operation will be queued in.
 *                   + Must not be NULL.
 *                   + Stream must have enabled the backends that will execute the algorithm.
 *
 * @param[in] backend Backend that will execute the algorithm.
 *                    + Valid values:
 *                      - \ref VPI_BACKEND_CPU
 *                      - \ref VPI_BACKEND_CUDA
 *                      - \ref VPI_BACKEND_PVA
 *
 * @param[in] input Input image to be convolved with the kernel.
 *                  + Must not be NULL.
 *                  + On PVA backend, image dimensions must be between 65x33 and 3264x2448.
 *                  + Image must have enabled the backends that will execute the algorithm.
 *                  + The accepted image formats are:
 *                    | Formats                      | CPU | CUDA | PVA |
 *                    |------------------------------|:---:|:----:|:---:|
 *                    | \ref VPI_IMAGE_FORMAT_U8     |  *  |   *  |  *  |
 *                    | \ref VPI_IMAGE_FORMAT_S8     |  *  |   *  |  *  |
 *                    | \ref VPI_IMAGE_FORMAT_U16    |  *  |   *  |  *  |
 *                    | \ref VPI_IMAGE_FORMAT_S16    |  *  |   *  |  *  |
 *                    | \ref VPI_IMAGE_FORMAT_Y8     |  *  |   *  |  *  |
 *                    | \ref VPI_IMAGE_FORMAT_Y8_ER  |  *  |   *  |  *  |
 *                    | \ref VPI_IMAGE_FORMAT_Y16    |  *  |   *  |  *  |
 *                    | \ref VPI_IMAGE_FORMAT_Y16_ER |  *  |   *  |  *  |
 *                    | \ref VPI_IMAGE_FORMAT_F32    |  *  |   *  |     |
 *
 * @param[out] output Output image where the result is written to.
 *                    + Must not be NULL.
 *                    + Must have same dimensions as input image.
 *                    + Image must have enabled the backends that will execute the algorithm.
 *                    + With PVA, it must have same format as input image.
 *                    + With other backends, format may be:
 *                      - Equal to input format.
 *                      - \ref VPI_IMAGE_FORMAT_F32 (no matter what input format).
 *
 * @param[in] kernelWidth, kernelHeight Kernel dimensions.
 *                                      + Must be between 1x1 and 11x11 and can be non-square.
 *
 * @param[in] kernelData Convolution kernel coefficients, in row-major layout.
 *                       The kernel elements are copied to an internal buffer.
 *                       The buffers passed can be deallocated after the call.
 *                       + It cannot be NULL.
 *                       + It must point to a buffer with \p kernelWidth * \p kernelHeight elements,
 *                         if not it'll lead to undefined behavior 
 *                       + On PVA backend, kernel weights are restricted to `|weight|<=1`.
 *
 * @param[in] border How to handle pixels outside image boundaries.
 *                   + The accepted border extensions are:
 *                     - \ref VPI_BORDER_ZERO
 *                     - \ref VPI_BORDER_CLAMP
 *
 * @retval #VPI_ERROR_INVALID_ARGUMENT     \p stream is NULL.
 * @retval #VPI_ERROR_INVALID_ARGUMENT     \p input or \p output are NULL.
 * @retval #VPI_ERROR_INVALID_ARGUMENT     \p kernelWidth or \p kernelHeight are outside valid range.
 * @retval #VPI_ERROR_INVALID_ARGUMENT     \p kernelData is NULL.
 * @retval #VPI_ERROR_INVALID_ARGUMENT     Some weight in \p kernelData is outside valid range.
 * @retval #VPI_ERROR_INVALID_ARGUMENT     \p input or \p output dimensions outside valid range.
 * @retval #VPI_ERROR_INVALID_ARGUMENT     \p input and \p output image must have same dimensions.
 * @retval #VPI_ERROR_INVALID_ARGUMENT     \p border not supported.
 * @retval #VPI_ERROR_INVALID_ARGUMENT     \p backend is invalid or unknown.
 * @retval #VPI_ERROR_INVALID_IMAGE_FORMAT \p input or \p output format not supported.
 * @retval #VPI_ERROR_INVALID_IMAGE_FORMAT \p input and \p output formats are not compatible.
 * @retval #VPI_ERROR_NOT_IMPLEMENTED      Convolution algorithm is not supported by given backend.
 * @retval #VPI_ERROR_INVALID_OPERATION    Backend hardware not available.
 * @retval #VPI_ERROR_INVALID_OPERATION    The needed backends aren't enabled in \p stream, \p input or \p output.
 * @retval #VPI_SUCCESS                    Operation executed successfully.
 */
VPI_PUBLIC VPIStatus vpiSubmitConvolution(VPIStream stream, uint64_t backend, VPIImage input, VPIImage output,
                                          const float *kernelData, int32_t kernelWidth, int32_t kernelHeight,
                                          VPIBorderExtension border);

/**
 * Runs a generic 2D convolution operation over an image, optimized for separable kernels.
 *
 * @param[in] stream The stream handle where the operation will be queued in.
 *                   + Must not be NULL.
 *                   + Stream must have enabled the backends that will execute the algorithm.
 *
 * @param[in] backend Backend that will execute the algorithm.
 *                    + Valid values:
 *                      - \ref VPI_BACKEND_CPU
 *                      - \ref VPI_BACKEND_CUDA
 *                      - \ref VPI_BACKEND_PVA
 *
 * @param[in] input Input image to be convolved with the kernel.
 *                  + Must not be NULL.
 *                  + Image must have enabled the backends that will execute the algorithm.
 *                  + On PVA, image dimensions must be between 32x32 and 3264x2448.
 *                  + The accepted image formats are:
 *                    | Formats                      | CPU | CUDA | PVA |
 *                    |------------------------------|:---:|:----:|:---:|
 *                    | \ref VPI_IMAGE_FORMAT_U8     |  *  |   *  |     |
 *                    | \ref VPI_IMAGE_FORMAT_S8     |  *  |   *  |     |
 *                    | \ref VPI_IMAGE_FORMAT_U16    |  *  |   *  |     |
 *                    | \ref VPI_IMAGE_FORMAT_S16    |  *  |   *  |  *  |
 *                    | \ref VPI_IMAGE_FORMAT_Y8     |  *  |   1  |     |
 *                    | \ref VPI_IMAGE_FORMAT_Y8_ER  |  *  |   1  |     |
 *                    | \ref VPI_IMAGE_FORMAT_Y16    |  *  |   1  |     |
 *                    | \ref VPI_IMAGE_FORMAT_Y16_ER |  *  |   1  |     |
 *                    | \ref VPI_IMAGE_FORMAT_F32    |  *  |   *  |     |
 *                    | \ref VPI_IMAGE_FORMAT_RGB8p  |  2  |      |     |
 *                    | \ref VPI_IMAGE_FORMAT_RGBA8p |  2  |      |     |
 *                    | \ref VPI_IMAGE_FORMAT_BGR8p  |  2  |      |     |
 *                    | \ref VPI_IMAGE_FORMAT_BGRA8p |  2  |      |     |
 *                    (1) only for kernel dimensions <= 3x3
 *                    (2) only for kernel dimensions >= 3x3
 *
 * @param[out] output Output image where the result is written to.
 *                    + Must not be NULL.
 *                    + Must have same dimensions and format as input image.
 *                    + Image must have enabled the backends that will execute the algorithm.
 *
 * @param[in] kernelXSize, kernelYSize Kernel dimensions in X and Y directions.
 *                                     + Must be between 1x1 and 11x11.
 *
 * @param[in] kernelXData, kernelYData Convolution kernel coefficients, in both X and Y directions respectively.
 *                                     The kernel elements are copied to an internal buffer.
 *                                     The buffers passed can be deallocated after the call.
 *                                     + \p kernelXData and \p kernelYData must point to a buffer
 *                                       with \p kernelXSize and \p kernelYSize elements respectively.
 *                                     + They can't be NULL.
 *                                     + On PVA backend, kernel weights are restricted to `|weight|<1`.
 *
 * @param[in] border How to handle pixels outside image boundaries.
 *                   + The accepted border extensions are:
 *                     - \ref VPI_BORDER_ZERO
 *                     - \ref VPI_BORDER_CLAMP
 *
 * @retval #VPI_ERROR_INVALID_ARGUMENT     \p stream is NULL.
 * @retval #VPI_ERROR_INVALID_ARGUMENT     \p input or \p output are NULL.
 * @retval #VPI_ERROR_INVALID_ARGUMENT     \p kernelXData or \p kernelYData are NULL.
 * @retval #VPI_ERROR_INVALID_ARGUMENT     \p kernelXSize or \p kernelYSize outside valid range.
 * @retval #VPI_ERROR_INVALID_ARGUMENT     Some weight in \p kernelData is outside valid range.
 * @retval #VPI_ERROR_INVALID_ARGUMENT     \p input or \p output image dimensions outside valid range..
 * @retval #VPI_ERROR_INVALID_ARGUMENT     \p border not supported.
 * @retval #VPI_ERROR_INVALID_ARGUMENT     \p input and \p output image dimensions and format do not match.
 * @retval #VPI_ERROR_INVALID_ARGUMENT     \p backend is invalid or unknown.
 * @retval #VPI_ERROR_INVALID_IMAGE_FORMAT \p input and \p output formats aren't supported
 * @retval #VPI_ERROR_NOT_IMPLEMENTED      Separable Convolution algorithm is not supported by given backend.
 * @retval #VPI_ERROR_INVALID_OPERATION    Backend hardware not available.
 * @retval #VPI_ERROR_INVALID_OPERATION    The needed backends aren't enabled in \p stream, \p input or \p output.
 * @retval #VPI_SUCCESS                    Operation executed successfully.
 */
VPI_PUBLIC VPIStatus vpiSubmitSeparableConvolution(VPIStream stream, uint64_t backend, VPIImage input, VPIImage output,
                                                   const float *kernelXData, int32_t kernelXSize,
                                                   const float *kernelYData, int32_t kernelYSize,
                                                   VPIBorderExtension border);

/** @} */

#ifdef __cplusplus
}
#endif

#endif /* NV_VPI_ALGORITHMS_CONVOLUTION_H */
// End content from: algo/Convolution.h

// Begin content from: algo/TemplateMatching.h
/*
 * Copyright 2022 NVIDIA Corporation. All rights reserved.
 *
 * NOTICE TO LICENSEE:
 *
 * This source code and/or documentation ("Licensed Deliverables") are
 * subject to NVIDIA intellectual property rights under U.S. and
 * international Copyright laws.
 *
 * These Licensed Deliverables contained herein is PROPRIETARY and
 * CONFIDENTIAL to NVIDIA and is being provided under the terms and
 * conditions of a form of NVIDIA software license agreement by and
 * between NVIDIA and Licensee ("License Agreement") or electronically
 * accepted by Licensee. Notwithstanding any terms or conditions to
 * the contrary in the License Agreement, reproduction or disclosure
 * of the Licensed Deliverables to any third party without the express
 * written consent of NVIDIA is prohibited.
 *
 * NOTWITHSTANDING ANY TERMS OR CONDITIONS TO THE CONTRARY IN THE
 * LICENSE AGREEMENT, NVIDIA MAKES NO REPRESENTATION ABOUT THE
 * SUITABILITY OF THESE LICENSED DELIVERABLES FOR ANY PURPOSE. IT IS
 * PROVIDED "AS IS" WITHOUT EXPRESS OR IMPLIED WARRANTY OF ANY KIND.
 * NVIDIA DISCLAIMS ALL WARRANTIES WITH REGARD TO THESE LICENSED
 * DELIVERABLES, INCLUDING ALL IMPLIED WARRANTIES OF MERCHANTABILITY,
 * NONINFRINGEMENT, AND FITNESS FOR A PARTICULAR PURPOSE.
 * NOTWITHSTANDING ANY TERMS OR CONDITIONS TO THE CONTRARY IN THE
 * LICENSE AGREEMENT, IN NO EVENT SHALL NVIDIA BE LIABLE FOR ANY
 * SPECIAL, INDIRECT, INCIDENTAL, OR CONSEQUENTIAL DAMAGES, OR ANY
 * DAMAGES WHATSOEVER RESULTING FROM LOSS OF USE, DATA OR PROFITS,
 * WHETHER IN AN ACTION OF CONTRACT, NEGLIGENCE OR OTHER TORTIOUS
 * ACTION, ARISING OUT OF OR IN CONNECTION WITH THE USE OR PERFORMANCE
 * OF THESE LICENSED DELIVERABLES.
 *
 * U.S. Government End Users. These Licensed Deliverables are a
 * "commercial item" as that term is defined at 48 C.F.R. 2.101 (OCT
 * 1995), consisting of "commercial computer software" and "commercial
 * computer software documentation" as such terms are used in 48
 * C.F.R. 12.212 (SEPT 1995) and is provided to the U.S. Government
 * only as a commercial end item. Consistent with 48 C.F.R.12.212 and
 * 48 C.F.R. 227.7202-1 through 227.7202-4 (JUNE 1995), all
 * U.S. Government End Users acquire the Licensed Deliverables with
 * only those rights set forth herein.
 *
 * Any use of the Licensed Deliverables in individual and commercial
 * software must include, in the user documentation and internal
 * comments to the code, the above Disclaimer and U.S. Government End
 * Users Notice.
 */

/**
 * @file TemplateMatching.h
 *
 * Declares functions that implement the template matching algorithm.
 */

#ifndef NV_VPI_ALGORITHMS_TEMPLATE_MATCHING_H
#define NV_VPI_ALGORITHMS_TEMPLATE_MATCHING_H

/**
 * @defgroup VPI_TemplateMatching Template Matching Algorithm
 * @ingroup VPI_API_Algorithms
 * @{
 *
 * Runs the template matching algorithm with template image over the searched image.
 * Refer to \ref algo_template_matching for more details and usage examples.
 */

// #include "../Export.h"
// #include "../Status.h"
// #include "../Types.h"

#include <stdint.h>

#ifdef __cplusplus
extern "C" {
#endif

/**
 * Creates payload for \ref vpiSubmitTemplateMatching
 *
 * @attention For this function to succeed, the below libraries must to be installed in the system:
 *            - libnppc.so.11
 *            - libnppial.so.11
 *            - libnppidei.so.11
 *            - libnppist.so.11
 *
 * @param[in] backends VPI backends that are eligible to execute the algorithm.
 *                     + Valid values:
 *                       - \ref VPI_BACKEND_CPU
 *                       - \ref VPI_BACKEND_CUDA
 *                     + Backend must be enabled in current context.
 *
 * @param[in] imageWidth Source image width.
 * 
 * @param[in] imageHeight Source image height.
 * 
 * @param[out] payload Pointer to the payload variable that receives the created handle.
 *
 * @retval #VPI_ERROR_INVALID_ARGUMENT  \p payload is NULL.
 * @retval #VPI_ERROR_INVALID_ARGUMENT  \p imageWidth and \p imageHeight outside valid range.
 * @retval #VPI_ERROR_INVALID_ARGUMENT  \p backends refers to an invalid backend.
 * @retval #VPI_ERROR_INVALID_OPERATION Backend isn't enabled in current context.
 * @retval #VPI_ERROR_INVALID_OPERATION Required NPP libraries aren't installed in the system.
 * @retval #VPI_ERROR_NOT_IMPLEMENTED   Algorithm is not supported by given backend.
 * @retval #VPI_ERROR_INVALID_CONTEXT   Current context is destroyed.
 * @retval #VPI_ERROR_OUT_OF_MEMORY     Cannot allocate required resources.
 * @retval #VPI_SUCCESS                 Operation executed successfully.
 */
VPI_PUBLIC VPIStatus vpiCreateTemplateMatching(uint64_t backends, int32_t imageWidth, int32_t imageHeight,
                                               VPIPayload *payload);

/**
 * Set the source image
 *
 * @param[in] stream A stream handle where the operation will be queued into.
 *                   + Must not be NULL.
 *                   + Stream must have enabled the backends that will execute the algorithm.
 *
 * @param[in] backend Backend that will execute the algorithm.
 *                    + Valid values:
 *                      - \ref VPI_BACKEND_CPU
 *                      - \ref VPI_BACKEND_CUDA
 * 
 * @param[in] payload Pointer to the payload variable that receives the created handle.
 *
 * @param[in] srcImage Source image where the template image will be searching on.
 *                  + Must not be NULL.
 *                  + Image must have enabled the backends that will execute the algorithm.
 *                  + The accepted image formats are:
 *                    | Format                           | CPU | CUDA |
 *                    |----------------------------------|:---:|:----:|
 *                    | \ref VPI_IMAGE_FORMAT_U8         |  *  |   *  | 
 *                    | \ref VPI_IMAGE_FORMAT_Y8_ER      |  *  |   *  |
 *                    | \ref VPI_IMAGE_FORMAT_Y8         |  *  |   *  |
 * 
 * @retval #VPI_ERROR_INVALID_ARGUMENT  \p payload is NULL.
 * @retval #VPI_ERROR_INVALID_ARGUMENT  \p srcImage is NULL.
 * @retval #VPI_ERROR_INVALID_ARGUMENT  \p srcImage resolution does not match with the one specified in the \ref vpiCreateTemplateMatching.
 * @retval #VPI_ERROR_INVALID_OPERATION Backend isn't enabled in current context.
 * @retval #VPI_ERROR_INVALID_OPERATION The needed backends aren't enabled in \p srcImage.
 * @retval #VPI_ERROR_INVALID_CONTEXT   Current context is destroyed.
 * @retval #VPI_ERROR_OUT_OF_MEMORY     Cannot allocate required resources.
 * @retval #VPI_SUCCESS                 Operation executed successfully.
 */
VPI_PUBLIC VPIStatus vpiTemplateMatchingSetSourceImage(VPIStream stream, uint64_t backend, VPIPayload payload,
                                                       VPIImage srcImage);

/**
 * Set the template image
 *
 * @param[in] stream A stream handle where the operation will be queued into.
 *                   + Must not be NULL.
 *                   + Stream must have enabled the backends that will execute the algorithm.
 *
 * @param[in] backend Backend that will execute the algorithm.
 *                    + Valid values:
 *                      - \ref VPI_BACKEND_CPU
 *                      - \ref VPI_BACKEND_CUDA
 * 
 * @param[in] payload Pointer to the payload variable that receives the created handle.
 *
 * @param[in] templImage Template image.
 *                  + Must not be NULL.
 *                  + Image must have enabled the backends that will execute the algorithm.
 *                  + The accepted image formats are:
 *                    | Format                           | CPU | CUDA |
 *                    |----------------------------------|:---:|:----:|
 *                    | \ref VPI_IMAGE_FORMAT_U8         |  *  |   *  | 
 *                    | \ref VPI_IMAGE_FORMAT_Y8_ER      |  *  |   *  |
 *                    | \ref VPI_IMAGE_FORMAT_Y8         |  *  |   *  |
 *
 * @param[in] mask Mask used when calculating the template matching score.
 *                  + Could be NULL if not needed.
 *                  + Must have same dimension as the template image
 *                  + The accepted image formats are:
 *                    | Format                           | CPU | CUDA |
 *                    |----------------------------------|:---:|:----:|
 *                    | \ref VPI_IMAGE_FORMAT_U8         |  *  |   *  | 
 * 
 * @retval #VPI_ERROR_INVALID_ARGUMENT  \p payload is NULL.
 * @retval #VPI_ERROR_INVALID_ARGUMENT  \p templImage is NULL.
 * @retval #VPI_ERROR_INVALID_ARGUMENT  \p templImage resolution is greater than source image.
 * @retval #VPI_ERROR_INVALID_OPERATION Backend isn't enabled in current context.
 * @retval #VPI_ERROR_INVALID_OPERATION The needed backends aren't enabled in \p templImage.
 * @retval #VPI_ERROR_INVALID_CONTEXT   Current context is destroyed.
 * @retval #VPI_ERROR_OUT_OF_MEMORY     Cannot allocate required resources.
 * @retval #VPI_SUCCESS                 Operation executed successfully.
 */
VPI_PUBLIC VPIStatus vpiTemplateMatchingSetTemplateImage(VPIStream stream, uint64_t backend, VPIPayload payload,
                                                         VPIImage templImage, VPIImage mask);

/**
 * Define method to calculate the template matching score.
 */
typedef enum
{
    /** Normalized cross correlation. */
    VPI_TEMPLATE_MATCHING_NCC
} VPITemplateMatchingMethod;

/**
 * Runs the template matching algorithm with provided template.
 *
 * @param[in] stream A stream handle where the operation will be queued into.
 *                   + Must not be NULL.
 *                   + Stream must have enabled the backends that will execute the algorithm.
 *
 * @param[in] backend Backend that will execute the algorithm.
 *                    + Valid values:
 *                      - \ref VPI_BACKEND_CPU
 *                      - \ref VPI_BACKEND_CUDA
 *
 * @param[in] payload Pointer to the payload variable that receives the created handle.
 *
 * @param[out] output Output image where the template matching score is written to.
 *                  + Must not be NULL.
 *                  + Assume the source image is with resolution WxH and template image is with
 *                    resolution wxh, then the output image shall have resolution (W - w + 1) * (H - h + 1)
 *                  + Image format has to be VPI_IMAGE_FORMAT_F32.
 *                  + Image must have enabled the backends that will execute the algorithm.
 *
 * @param[in] method Specify the method when calculating the template matching score.
 *
 * @retval #VPI_ERROR_INVALID_ARGUMENT     \p stream is NULL.
 * @retval #VPI_ERROR_INVALID_ARGUMENT     \p output is NULL.
 * @retval #VPI_ERROR_INVALID_ARGUMENT     \p backend is invalid or unknown.
 * @retval #VPI_ERROR_INVALID_IMAGE_FORMAT \p output image format not supported.
 * @retval #VPI_ERROR_INVALID_OPERATION    Backend hardware is not available.
 * @retval #VPI_ERROR_INVALID_OPERATION    The needed backends aren't enabled in \p stream and \p output.
 * @retval #VPI_ERROR_NOT_IMPLEMENTED      Algorithm is not supported by given backend.
 * @retval #VPI_SUCCESS                    Operation executed successfully.
 */

VPI_PUBLIC VPIStatus vpiSubmitTemplateMatching(VPIStream stream, uint64_t backend, VPIPayload payload, VPIImage output,
                                               VPITemplateMatchingMethod method);

#ifdef __cplusplus
}
#endif

/** @} end of VPI_TemplateMatching */

#endif /* NV_VPI_ALGORITHMS_TEMPLATE_MATCHING_H */
// End content from: algo/TemplateMatching.h

// Begin content from: algo/ImageFlip.h
/*
 * Copyright 2022 NVIDIA Corporation. All rights reserved.
 *
 * NOTICE TO LICENSEE:
 *
 * This source code and/or documentation ("Licensed Deliverables") are
 * subject to NVIDIA intellectual property rights under U.S. and
 * international Copyright laws.
 *
 * These Licensed Deliverables contained herein is PROPRIETARY and
 * CONFIDENTIAL to NVIDIA and is being provided under the terms and
 * conditions of a form of NVIDIA software license agreement by and
 * between NVIDIA and Licensee ("License Agreement") or electronically
 * accepted by Licensee. Notwithstanding any terms or conditions to
 * the contrary in the License Agreement, reproduction or disclosure
 * of the Licensed Deliverables to any third party without the express
 * written consent of NVIDIA is prohibited.
 *
 * NOTWITHSTANDING ANY TERMS OR CONDITIONS TO THE CONTRARY IN THE
 * LICENSE AGREEMENT, NVIDIA MAKES NO REPRESENTATION ABOUT THE
 * SUITABILITY OF THESE LICENSED DELIVERABLES FOR ANY PURPOSE. IT IS
 * PROVIDED "AS IS" WITHOUT EXPRESS OR IMPLIED WARRANTY OF ANY KIND.
 * NVIDIA DISCLAIMS ALL WARRANTIES WITH REGARD TO THESE LICENSED
 * DELIVERABLES, INCLUDING ALL IMPLIED WARRANTIES OF MERCHANTABILITY,
 * NONINFRINGEMENT, AND FITNESS FOR A PARTICULAR PURPOSE.
 * NOTWITHSTANDING ANY TERMS OR CONDITIONS TO THE CONTRARY IN THE
 * LICENSE AGREEMENT, IN NO EVENT SHALL NVIDIA BE LIABLE FOR ANY
 * SPECIAL, INDIRECT, INCIDENTAL, OR CONSEQUENTIAL DAMAGES, OR ANY
 * DAMAGES WHATSOEVER RESULTING FROM LOSS OF USE, DATA OR PROFITS,
 * WHETHER IN AN ACTION OF CONTRACT, NEGLIGENCE OR OTHER TORTIOUS
 * ACTION, ARISING OUT OF OR IN CONNECTION WITH THE USE OR PERFORMANCE
 * OF THESE LICENSED DELIVERABLES.
 *
 * U.S. Government End Users. These Licensed Deliverables are a
 * "commercial item" as that term is defined at 48 C.F.R. 2.101 (OCT
 * 1995), consisting of "commercial computer software" and "commercial
 * computer software documentation" as such terms are used in 48
 * C.F.R. 12.212 (SEPT 1995) and is provided to the U.S. Government
 * only as a commercial end item. Consistent with 48 C.F.R.12.212 and
 * 48 C.F.R. 227.7202-1 through 227.7202-4 (JUNE 1995), all
 * U.S. Government End Users acquire the Licensed Deliverables with
 * only those rights set forth herein.
 *
 * Any use of the Licensed Deliverables in individual and commercial
 * software must include, in the user documentation and internal
 * comments to the code, the above Disclaimer and U.S. Government End
 * Users Notice.
 */

/**
 * @file ImageFlip.h
 *
 * Declares functions that implement Image flip algorithms.
 */

#ifndef NV_VPI_ALGORITHMS_IMAGEFLIP_H
#define NV_VPI_ALGORITHMS_IMAGEFLIP_H

// #include "../Export.h"
// #include "../Status.h"
// #include "../Types.h"

#include <stdint.h>

#ifdef __cplusplus
extern "C" {
#endif

/**
 * @defgroup VPI_ImageFlip Image Flip
 * @ingroup VPI_API_Algorithms
 * @{
 *
 * Flips a 2D image either horizontally, vertically or both.
 * Refer to \ref algo_image_flip for more details and usage examples.
 */

/**
 * Flips a 2D image either horizontally, vertically or both.
 * 
 *
 * @param[in] stream A stream handle where the operation will be queued into.
 *
 * @param[in] backend Backend that will execute the algorithm.
 *                    + Valid values: 
 *                      - \ref VPI_BACKEND_CPU
 *                      - \ref VPI_BACKEND_CUDA
 *                      - \ref VPI_BACKEND_VIC
 *
 * @param[in] input Input image to be flipped.
 *                  + CPU and CUDA accept all pitch-linear image formats, with at most 4 planes.
 *                  + Valid Image formats for VIC backend:
 *                     - \ref VPI_IMAGE_FORMAT_Y8
 *                     - \ref VPI_IMAGE_FORMAT_Y8_ER
 *                     - \ref VPI_IMAGE_FORMAT_RGBA8
 *                     - \ref VPI_IMAGE_FORMAT_BGRA8
 *                     - \ref VPI_IMAGE_FORMAT_NV12
 *                     - \ref VPI_IMAGE_FORMAT_NV12_ER
 *                     - \ref VPI_IMAGE_FORMAT_NV24
 *                     - \ref VPI_IMAGE_FORMAT_NV24_ER
 *                     - \ref VPI_IMAGE_FORMAT_UYVY
 *                     - \ref VPI_IMAGE_FORMAT_UYVY_ER
 *                     - \ref VPI_IMAGE_FORMAT_YUYV
 *                     - \ref VPI_IMAGE_FORMAT_YUYV_ER
 *                     - \ref VPI_IMAGE_FORMAT_Y8_BL
 *                     - \ref VPI_IMAGE_FORMAT_Y8_ER_BL
 *                     - \ref VPI_IMAGE_FORMAT_NV12_BL
 *                     - \ref VPI_IMAGE_FORMAT_NV12_ER_BL
 *                     - \ref VPI_IMAGE_FORMAT_NV24_BL
 *                     - \ref VPI_IMAGE_FORMAT_NV24_ER_BL
 *                     - \ref VPI_IMAGE_FORMAT_UYVY_BL
 *                     - \ref VPI_IMAGE_FORMAT_UYVY_ER_BL
 *                     - \ref VPI_IMAGE_FORMAT_YUYV_BL
 *                     - \ref VPI_IMAGE_FORMAT_YUYV_ER_BL
 *                  + Images whose format has either 4:2:0 or 4:2:2 chroma subsampling must have even dimensions.
 * 
 * @param[out] output Output image where the result will be written to.
 *                    + It must have the same format and dimensions as input.
 * 
 * @param[in] flipMode Direction the image needs to be flipped in.
 *                     + Accepted inputs:
 *                       - \ref VPI_FLIP_HORIZ
 *                       - \ref VPI_FLIP_VERT
 *                       - \ref VPI_FLIP_BOTH
 * 
 * @retval #VPI_ERROR_INVALID_ARGUMENT     \p stream is NULL.
 * @retval #VPI_ERROR_INVALID_ARGUMENT     \p input or \p output are NULL.
 * @retval #VPI_ERROR_INVALID_ARGUMENT     \p input and \p output image dimensions and formats do not match.
 * @retval #VPI_ERROR_INVALID_ARGUMENT     Image dimensions aren't supported for given format.
 * @retval #VPI_ERROR_INVALID_ARGUMENT     \p flipMode is not valid.
 * @retval #VPI_ERROR_INVALID_ARGUMENT     \p backend is invalid or unknown.
 * @retval #VPI_ERROR_INVALID_IMAGE_FORMAT \p input and \p output formats aren't supported
 * @retval #VPI_ERROR_NOT_IMPLEMENTED      Image Flip algorithm is not supported by given backend.
 * @retval #VPI_ERROR_INVALID_OPERATION    Backend hardware not available.
 * @retval #VPI_ERROR_INVALID_OPERATION    The needed backends aren't enabled in \p stream, \p input or \p output.
 * @retval #VPI_SUCCESS                    Operation executed successfully.
 */
VPI_PUBLIC VPIStatus vpiSubmitImageFlip(VPIStream stream, uint64_t backend, VPIImage input, VPIImage output,
                                        VPIFlipMode flipMode);
/** @} */

#ifdef __cplusplus
}
#endif

#endif /* NV_VPI_ALGORITHMS_IMAGEFLIP_H */
// End content from: algo/ImageFlip.h

// Begin content from: algo/LaplacianPyramid.h
/*
 * Copyright 2021 NVIDIA Corporation. All rights reserved.
 *
 * NOTICE TO LICENSEE:
 *
 * This source code and/or documentation ("Licensed Deliverables") are
 * subject to NVIDIA intellectual property rights under U.S. and
 * international Copyright laws.
 *
 * These Licensed Deliverables contained herein is PROPRIETARY and
 * CONFIDENTIAL to NVIDIA and is being provided under the terms and
 * conditions of a form of NVIDIA software license agreement by and
 * between NVIDIA and Licensee ("License Agreement") or electronically
 * accepted by Licensee. Notwithstanding any terms or conditions to
 * the contrary in the License Agreement, reproduction or disclosure
 * of the Licensed Deliverables to any third party without the express
 * written consent of NVIDIA is prohibited.
 *
 * NOTWITHSTANDING ANY TERMS OR CONDITIONS TO THE CONTRARY IN THE
 * LICENSE AGREEMENT, NVIDIA MAKES NO REPRESENTATION ABOUT THE
 * SUITABILITY OF THESE LICENSED DELIVERABLES FOR ANY PURPOSE. IT IS
 * PROVIDED "AS IS" WITHOUT EXPRESS OR IMPLIED WARRANTY OF ANY KIND.
 * NVIDIA DISCLAIMS ALL WARRANTIES WITH REGARD TO THESE LICENSED
 * DELIVERABLES, INCLUDING ALL IMPLIED WARRANTIES OF MERCHANTABILITY,
 * NONINFRINGEMENT, AND FITNESS FOR A PARTICULAR PURPOSE.
 * NOTWITHSTANDING ANY TERMS OR CONDITIONS TO THE CONTRARY IN THE
 * LICENSE AGREEMENT, IN NO EVENT SHALL NVIDIA BE LIABLE FOR ANY
 * SPECIAL, INDIRECT, INCIDENTAL, OR CONSEQUENTIAL DAMAGES, OR ANY
 * DAMAGES WHATSOEVER RESULTING FROM LOSS OF USE, DATA OR PROFITS,
 * WHETHER IN AN ACTION OF CONTRACT, NEGLIGENCE OR OTHER TORTIOUS
 * ACTION, ARISING OUT OF OR IN CONNECTION WITH THE USE OR PERFORMANCE
 * OF THESE LICENSED DELIVERABLES.
 *
 * U.S. Government End Users. These Licensed Deliverables are a
 * "commercial item" as that term is defined at 48 C.F.R. 2.101 (OCT
 * 1995), consisting of "commercial computer software" and "commercial
 * computer software documentation" as such terms are used in 48
 * C.F.R. 12.212 (SEPT 1995) and is provided to the U.S. Government
 * only as a commercial end item. Consistent with 48 C.F.R.12.212 and
 * 48 C.F.R. 227.7202-1 through 227.7202-4 (JUNE 1995), all
 * U.S. Government End Users acquire the Licensed Deliverables with
 * only those rights set forth herein.
 *
 * Any use of the Licensed Deliverables in individual and commercial
 * software must include, in the user documentation and internal
 * comments to the code, the above Disclaimer and U.S. Government End
 * Users Notice.
 */

/**
 * @file LaplacianPyramid.h
 *
 * Declares functions that handle Laplacian pyramids.
 */

#ifndef NV_VPI_ALGORITHMS_LAPLACIAN_PYRAMID_H
#define NV_VPI_ALGORITHMS_LAPLACIAN_PYRAMID_H

// #include "../Export.h"
// #include "../Status.h"
// #include "../Types.h"

#ifdef __cplusplus
extern "C" {
#endif

/**
 * @defgroup VPI_LaplacianPyramid Laplacian Pyramid Generator
 * @ingroup VPI_API_Algorithms
 * @{
 *
 * Creates a Laplacian pyramid from the input image.
 * Refer to \ref algo_laplacian_pyramid_generator for more details and usage examples.
 */

/**
 * Computes the Laplacian pyramid from the input image.
 *
 * @note The coarsest level of the Laplacian pyramid is equivalent in concept to that of the Gaussian pyramid.
 * However, in cases where the Laplacian pyramid output format has less positive dynamic range than the input format,
 * i.e. input format is \ref VPI_IMAGE_FORMAT_U8 and output format is \ref VPI_IMAGE_FORMAT_S8 or U16 and S16, the pixel values
 * of the output in the coarsest level are divided by 2 in order to avoid overflow.
 *
 * @param[in] stream The stream where the operation will be queued in.
 *                   + Must not be NULL.
 *                   + Stream must have enabled the backends that will execute the algorithm.
 *
 * @param[in] backend VPI backend that will execute the algorithm.
 *                    + Valid values: 
 *                      - \ref VPI_BACKEND_CPU
 *                      - \ref VPI_BACKEND_CUDA
 *
 * @param[in] input Input image.
 *                  + Must not be NULL.
 *                  + Image must have enabled the backends that will execute the algorithm.
 *                  + Supported formats are:
 *                    - \ref VPI_IMAGE_FORMAT_U8
 *                    - \ref VPI_IMAGE_FORMAT_U16
 *                    - \ref VPI_IMAGE_FORMAT_F32
 *                    - \ref VPI_IMAGE_FORMAT_Y8
 *                    - \ref VPI_IMAGE_FORMAT_Y8_ER
 *                    - \ref VPI_IMAGE_FORMAT_Y16
 *                    - \ref VPI_IMAGE_FORMAT_Y16_ER
 *
 * @param[out] output Where the resulting Laplacian pyramid will be written to. 
 *                    It must have been created with the desired scale and number of levels. 
 *                    + Must not be NULL.
 *                    + Dimensions of first level must be the same as \p input.
 *                    + Pyramid must have enabled the backends that will execute the algorithm.
 *                    + Supported formats:
 *                      - \ref VPI_IMAGE_FORMAT_S8 (only for 8-bit inputs)
 *                      - \ref VPI_IMAGE_FORMAT_S16 (only for integer inputs)
 *                      - \ref VPI_IMAGE_FORMAT_F32
 *
 * @param[out] gaussianPyr Defines where the intermediate Gaussian pyramid will be written to. 
 *                         Pass NULL if not needed.
 *                         + Must have same format as \p input.
 *                         + Must have same scale, number of levels and dimensions as \p output.
 *                         + Pyramid must have enabled the backends that will execute the algorithm.
 *
 * @param[in] border Border extension to be used when sampling pixels outside the image border.
 *                   + Valid values:
 *                    | Border                  | CPU | CUDA | PVA |
 *                    |-------------------------|:---:|:----:|:---:|
 *                    | \ref VPI_BORDER_ZERO    |  *  |   *  |  *  |
 *                    | \ref VPI_BORDER_CLAMP   |  *  |   *  |  *  |
 *                    | \ref VPI_BORDER_REFLECT |     |   *  |     |
 *                    | \ref VPI_BORDER_MIRROR  |     |   *  |     |
 *
 * @retval #VPI_ERROR_INVALID_ARGUMENT     \p stream is NULL.
 * @retval #VPI_ERROR_INVALID_ARGUMENT     \p input or \p output are NULL.
 * @retval #VPI_ERROR_INVALID_ARGUMENT     \p gaussianPyr and \p output must have the same scale, number of levels and dimensions.
 * @retval #VPI_ERROR_INVALID_IMAGE_FORMAT \p input and \p gaussianPyr must have the same format.
 * @retval #VPI_ERROR_INVALID_IMAGE_FORMAT \p output format not compatible with \p input format.
 * @retval #VPI_ERROR_INVALID_IMAGE_FORMAT Unsupported \p input image format.
 * @retval #VPI_ERROR_INVALID_OPERATION    The needed backends aren't enabled in \p stream, \p input, \p output or \p gaussianPyr.
 * @retval #VPI_ERROR_NOT_IMPLEMENTED      Laplacian Pyramid algorithm is not supported by given backend.
 * @retval #VPI_SUCCESS                    Operation executed successfully.
 */
#if NV_VPI_VERSION_API_AT_MOST(2, 3)
__asm__(".symver vpiSubmitLaplacianPyramidGenerator,vpiSubmitLaplacianPyramidGenerator@VPI_2.0");
VPI_PUBLIC VPIStatus vpiSubmitLaplacianPyramidGenerator(VPIStream stream, uint64_t backend, VPIImage input,
                                                        VPIPyramid output, VPIPyramid gaussianPyr,
                                                        VPIBorderExtension border);
#else
VPI_PUBLIC VPIStatus vpiSubmitLaplacianPyramidGenerator(VPIStream stream, uint64_t backend, VPIImage input,
                                                        VPIPyramid output, VPIPyramid gaussianPyr,
                                                        VPIBorderExtension border);
#endif

#ifdef __cplusplus
}
#endif

/** @} */

#endif /* NV_VPI_ALGORITHMS_LAPLACIAN_PYRAMID_H */
// End content from: algo/LaplacianPyramid.h

// Begin content from: algo/Remap.h
/*
 * Copyright 2020-2021 NVIDIA Corporation. All rights reserved.
 *
 * NOTICE TO LICENSEE:
 *
 * This source code and/or documentation ("Licensed Deliverables") are
 * subject to NVIDIA intellectual property rights under U.S. and
 * international Copyright laws.
 *
 * These Licensed Deliverables contained herein is PROPRIETARY and
 * CONFIDENTIAL to NVIDIA and is being provided under the terms and
 * conditions of a form of NVIDIA software license agreement by and
 * between NVIDIA and Licensee ("License Agreement") or electronically
 * accepted by Licensee. Notwithstanding any terms or conditions to
 * the contrary in the License Agreement, reproduction or disclosure
 * of the Licensed Deliverables to any third party without the express
 * written consent of NVIDIA is prohibited.
 *
 * NOTWITHSTANDING ANY TERMS OR CONDITIONS TO THE CONTRARY IN THE
 * LICENSE AGREEMENT, NVIDIA MAKES NO REPRESENTATION ABOUT THE
 * SUITABILITY OF THESE LICENSED DELIVERABLES FOR ANY PURPOSE. IT IS
 * PROVIDED "AS IS" WITHOUT EXPRESS OR IMPLIED WARRANTY OF ANY KIND.
 * NVIDIA DISCLAIMS ALL WARRANTIES WITH REGARD TO THESE LICENSED
 * DELIVERABLES, INCLUDING ALL IMPLIED WARRANTIES OF MERCHANTABILITY,
 * NONINFRINGEMENT, AND FITNESS FOR A PARTICULAR PURPOSE.
 * NOTWITHSTANDING ANY TERMS OR CONDITIONS TO THE CONTRARY IN THE
 * LICENSE AGREEMENT, IN NO EVENT SHALL NVIDIA BE LIABLE FOR ANY
 * SPECIAL, INDIRECT, INCIDENTAL, OR CONSEQUENTIAL DAMAGES, OR ANY
 * DAMAGES WHATSOEVER RESULTING FROM LOSS OF USE, DATA OR PROFITS,
 * WHETHER IN AN ACTION OF CONTRACT, NEGLIGENCE OR OTHER TORTIOUS
 * ACTION, ARISING OUT OF OR IN CONNECTION WITH THE USE OR PERFORMANCE
 * OF THESE LICENSED DELIVERABLES.
 *
 * U.S. Government End Users. These Licensed Deliverables are a
 * "commercial item" as that term is defined at 48 C.F.R. 2.101 (OCT
 * 1995), consisting of "commercial computer software" and "commercial
 * computer software documentation" as such terms are used in 48
 * C.F.R. 12.212 (SEPT 1995) and is provided to the U.S. Government
 * only as a commercial end item. Consistent with 48 C.F.R.12.212 and
 * 48 C.F.R. 227.7202-1 through 227.7202-4 (JUNE 1995), all
 * U.S. Government End Users acquire the Licensed Deliverables with
 * only those rights set forth herein.
 *
 * Any use of the Licensed Deliverables in individual and commercial
 * software must include, in the user documentation and internal
 * comments to the code, the above Disclaimer and U.S. Government End
 * Users Notice.
 */

/**
 * @file Remap.h
 *
 * Declares functions that implement the \ref algo_remap algorithm.
 *
 * Remap warps an image using a given a VPIWarpMap. This operation is used, among other
 * things, for lens distortion correction.
 *
 */

#ifndef NV_VPI_ALGORITHMS_REMAP_IMAGE_H
#define NV_VPI_ALGORITHMS_REMAP_IMAGE_H

// #include "../AlgoFlags.h"
// #include "../Export.h"
// #include "../Status.h"
// #include "../Types.h"
// #include "../WarpMap.h"

#include <stdint.h>

#ifdef __cplusplus
extern "C" {
#endif

/**
 * @defgroup VPI_Remap Remap
 * @ingroup VPI_API_Algorithms
 * @{
 *
 * Remaps the input image, effectively warping it using a user-provided mapping.
 * Refer to \ref algo_remap for more details and usage examples.
 */

/** Create a payload for \ref algo_remap algorithm.
 * This function allocates all resources needed by the Remap algorithm
 * and ties the returned payload to the given stream.
 *
 * @param[in] backends VPI backends that are eligible to execute the algorithm.
 *                     + Valid values:
 *                       - \ref VPI_BACKEND_CPU
 *                       - \ref VPI_BACKEND_CUDA
 *                       - \ref VPI_BACKEND_VIC
 *                     + Backend must be enabled in current context.
 *
 * @param[in] warpMap Mapping of output back into input. 
 *                    + It must define a grid with the same size as output image.
 *
 * @param[out] payload Pointer to the payload variable that receives the created handle.
 *
 * @retval #VPI_ERROR_INVALID_ARGUMENT  \p payload is NULL.
 * @retval #VPI_ERROR_INVALID_ARGUMENT  \p warpMap is NULL.
 * @retval #VPI_ERROR_INVALID_ARGUMENT  \p backends refers to an invalid backend.
 * @retval #VPI_ERROR_NOT_IMPLEMENTED   Remap algorithm is not supported by given backends.
 * @retval #VPI_ERROR_NOT_IMPLEMENTED   VIC hardware with Remap support is not available.
 * @retval #VPI_ERROR_INVALID_CONTEXT   Current context is destroyed.
 * @retval #VPI_ERROR_OUT_OF_MEMORY     Cannot allocate required resources.
 * @retval #VPI_ERROR_INVALID_OPERATION Backend isn't enabled in current context.
 * @retval #VPI_SUCCESS                 Operation executed successfully.
 */
VPI_PUBLIC VPIStatus vpiCreateRemap(uint64_t backends, const VPIWarpMap *warpMap, VPIPayload *payload);

/** Submits a \ref algo_remap "Remap" operation to the stream.
 *
 * @param[in] stream The stream where the operation will be queued in.
 *                   + Must not be NULL.
 *                   + Stream must have enabled the backends that will execute the algorithm.
 *
 * @param[in] backend Backend that will execute the algorithm.
 *                    + Must be the backend specified during payload creation or 0 as a shorthand to use this backend.
 *
 * @param[in] payload Payload created by \ref vpiCreateRemap.
 *
 * @param[in] input Image to be remapped.
 *                  In a lens distortion correction context, this would correspond to the distorted image.
 *                  + Must not be NULL.
 *                  + Image must have enabled the backends that will execute the algorithm.
 *                  + On VIC, maximum input dimensions is 16384x16384.
 *                  + Supported image formats are:
 *                    | Formats                          | CPU | CUDA | VIC |
 *                    |----------------------------------|:---:|:----:|:---:|
 *                    | \ref VPI_IMAGE_FORMAT_U8         |  *  |   *  |  *  |
 *                    | \ref VPI_IMAGE_FORMAT_U16        |  *  |   *  |  *  |
 *                    | \ref VPI_IMAGE_FORMAT_Y8         |  *  |   *  |  *  |
 *                    | \ref VPI_IMAGE_FORMAT_Y8_BL      |     |      |  *  |
 *                    | \ref VPI_IMAGE_FORMAT_Y8_ER      |  *  |   *  |  *  |
 *                    | \ref VPI_IMAGE_FORMAT_Y8_ER_BL   |     |      |  *  |
 *                    | \ref VPI_IMAGE_FORMAT_Y16        |  *  |   *  |  *  |
 *                    | \ref VPI_IMAGE_FORMAT_Y16_BL     |     |      |  *  |
 *                    | \ref VPI_IMAGE_FORMAT_Y16_ER     |  *  |   *  |     |
 *                    | \ref VPI_IMAGE_FORMAT_NV12       |  *  |   *  |  *  |
 *                    | \ref VPI_IMAGE_FORMAT_NV12_BL    |     |      |  *  |
 *                    | \ref VPI_IMAGE_FORMAT_NV12_ER    |  *  |   *  |  *  |
 *                    | \ref VPI_IMAGE_FORMAT_NV12_ER_BL |     |      |  *  |
 *                    | \ref VPI_IMAGE_FORMAT_NV24       |     |      |  *  |
 *                    | \ref VPI_IMAGE_FORMAT_NV24_BL    |     |      |  *  |
 *                    | \ref VPI_IMAGE_FORMAT_NV24_ER    |     |      |  *  |
 *                    | \ref VPI_IMAGE_FORMAT_NV24_ER_BL |     |      |  *  |
 *                    | \ref VPI_IMAGE_FORMAT_RGB8       |  *  |   *  |     |
 *                    | \ref VPI_IMAGE_FORMAT_BGR8       |  *  |   *  |     |
 *                    | \ref VPI_IMAGE_FORMAT_RGBA8      |  *  |   *  |     |
 *                    | \ref VPI_IMAGE_FORMAT_BGRA8      |  *  |   *  |     |
 *
 * @param[out] output Stores the remapped image.
 *                    In a lens distortion correction context, this would correspond to the corrected (distortion-free).
 *                    + Must not be NULL.
 *                    + Must have same format as input image.
 *                    + Must have the same type as input
 *                    + Must have same dimensions as the warp map specified during payload creation.
 *                    + Image must have enabled the backends that will execute the algorithm.
 *                    + On VIC, maximum input dimensions is 16384x16384.
 *
 * @param[in] interp Interpolation method to be used. Valid values:
 *                    - \ref VPI_INTERP_NEAREST
 *                    - \ref VPI_INTERP_LINEAR
 *                    - \ref VPI_INTERP_CATMULL_ROM
 *
 * @param[in] border What value to pick if remapped coordinated falls outside input image.
 *                   + The accepted border extensions are:
 *                     - \ref VPI_BORDER_ZERO (VIC only supports this one)
 *                     - \ref VPI_BORDER_CLAMP
 *                     - \ref VPI_BORDER_MIRROR
 *                     - \ref VPI_BORDER_REFLECT 
 *
 * @param[in] flags Control flags.
 *                  + Valid values are a combination of one or more of the flags:
 *                    - 0 : default, negation of all other flags.
 *                    - \ref VPI_PRECISE : precise, but potentially slower implementation.
 *
 * @retval #VPI_ERROR_INVALID_ARGUMENT     \p stream is NULL.
 * @retval #VPI_ERROR_INVALID_ARGUMENT     \p input or \p output are NULL.
 * @retval #VPI_ERROR_INVALID_ARGUMENT     \p payload is not generated using vpiCreateRemap.
 * @retval #VPI_ERROR_INVALID_ARGUMENT     Invalid \p flags.
 * @retval #VPI_ERROR_INVALID_ARGUMENT     \p input and \p output must have the same format.
 * @retval #VPI_ERROR_INVALID_ARGUMENT     \p output must have same size corresponding to the warp map passed during payload creation.
 * @retval #VPI_ERROR_INVALID_ARGUMENT     \p border not supported.
 * @retval #VPI_ERROR_INVALID_PAYLOAD_TYPE \p payload is invalid.
 * @retval #VPI_ERROR_INVALID_OPERATION    The needed backends aren't enabled in \p stream, \p input or \p output.
 * @retval #VPI_SUCCESS                    Operation executed successfully.
 */
VPI_PUBLIC VPIStatus vpiSubmitRemap(VPIStream stream, uint64_t backend, VPIPayload payload, VPIImage input,
                                    VPIImage output, VPIInterpolationType interp, VPIBorderExtension border,
                                    uint64_t flags);

#ifdef __cplusplus
}
#endif

/** @} end of VPI_Remap */

#endif /* NV_VPI_ALGORITHMS_REMAP_IMAGE_H */
// End content from: algo/Remap.h

// Begin content from: algo/MorphologicalFilter.h
/*
 * Copyright 2021 NVIDIA Corporation. All rights reserved.
 *
 * NOTICE TO LICENSEE:
 *
 * This source code and/or documentation ("Licensed Deliverables") are
 * subject to NVIDIA intellectual property rights under U.S. and
 * international Copyright laws.
 *
 * These Licensed Deliverables contained herein is PROPRIETARY and
 * CONFIDENTIAL to NVIDIA and is being provided under the terms and
 * conditions of a form of NVIDIA software license agreement by and
 * between NVIDIA and Licensee ("License Agreement") or electronically
 * accepted by Licensee. Notwithstanding any terms or conditions to
 * the contrary in the License Agreement, reproduction or disclosure
 * of the Licensed Deliverables to any third party without the express
 * written consent of NVIDIA is prohibited.
 *
 * NOTWITHSTANDING ANY TERMS OR CONDITIONS TO THE CONTRARY IN THE
 * LICENSE AGREEMENT, NVIDIA MAKES NO REPRESENTATION ABOUT THE
 * SUITABILITY OF THESE LICENSED DELIVERABLES FOR ANY PURPOSE. IT IS
 * PROVIDED "AS IS" WITHOUT EXPRESS OR IMPLIED WARRANTY OF ANY KIND.
 * NVIDIA DISCLAIMS ALL WARRANTIES WITH REGARD TO THESE LICENSED
 * DELIVERABLES, INCLUDING ALL IMPLIED WARRANTIES OF MERCHANTABILITY,
 * NONINFRINGEMENT, AND FITNESS FOR A PARTICULAR PURPOSE.
 * NOTWITHSTANDING ANY TERMS OR CONDITIONS TO THE CONTRARY IN THE
 * LICENSE AGREEMENT, IN NO EVENT SHALL NVIDIA BE LIABLE FOR ANY
 * SPECIAL, INDIRECT, INCIDENTAL, OR CONSEQUENTIAL DAMAGES, OR ANY
 * DAMAGES WHATSOEVER RESULTING FROM LOSS OF USE, DATA OR PROFITS,
 * WHETHER IN AN ACTION OF CONTRACT, NEGLIGENCE OR OTHER TORTIOUS
 * ACTION, ARISING OUT OF OR IN CONNECTION WITH THE USE OR PERFORMANCE
 * OF THESE LICENSED DELIVERABLES.
 *
 * U.S. Government End Users. These Licensed Deliverables are a
 * "commercial item" as that term is defined at 48 C.F.R. 2.101 (OCT
 * 1995), consisting of "commercial computer software" and "commercial
 * computer software documentation" as such terms are used in 48
 * C.F.R. 12.212 (SEPT 1995) and is provided to the U.S. Government
 * only as a commercial end item. Consistent with 48 C.F.R.12.212 and
 * 48 C.F.R. 227.7202-1 through 227.7202-4 (JUNE 1995), all
 * U.S. Government End Users acquire the Licensed Deliverables with
 * only those rights set forth herein.
 *
 * Any use of the Licensed Deliverables in individual and commercial
 * software must include, in the user documentation and internal
 * comments to the code, the above Disclaimer and U.S. Government End
 * Users Notice.
 */

/**
 * @file MorphologicalFilter.h
 *
 * Declares functions to perform image morphological filtering with binary kernels.
 *
 */

#ifndef NV_VPI_ALGORITHMS_MORPHOLOGICAL_FILTER_H
#define NV_VPI_ALGORITHMS_MORPHOLOGICAL_FILTER_H

// #include "../Export.h"
// #include "../Status.h"
// #include "../Types.h"

#include <stdint.h>

#ifdef __cplusplus
extern "C" {
#endif

/**
 * @defgroup VPI_Erode Erode
 * @ingroup VPI_API_Algorithms
 * @{
 *
 * Filter an image with a 2D binary kernel composed with the erode morphological operation.
 *
 * Refer to \ref algo_erode for more details and usage examples regarding Erode.
 *
 */

/**
 * Runs a 2D erode over an image.
 *
 * @param[in] stream The stream handle where the operation will be queued in.
 *                   + Must not be NULL.
 *                   + Stream must have enabled the backends that will execute the algorithm.
 *
 * @param[in] backend Backend that will execute the algorithm.
 *                    + Valid values: 
 *                      - \ref VPI_BACKEND_CPU
 *                      - \ref VPI_BACKEND_CUDA
 *
 * @param[in] input Input image to be eroded with the kernel.
 *                  + Must not be NULL.
 *                  + Image must have enabled the backends that will execute the algorithm.
 *                  + Supported formats:
 *                    - \ref VPI_IMAGE_FORMAT_U8
 *                    - \ref VPI_IMAGE_FORMAT_S8
 *                    - \ref VPI_IMAGE_FORMAT_U16
 *                    - \ref VPI_IMAGE_FORMAT_S16
 *
 * @param[out] output Output image where the result is written to.
 *                    + Must not be NULL.
 *                    + Must have same format and dimensions as input image.
 *                    + Image must have enabled the backends that will execute the algorithm.
 *
 * @param[in] kernelWidth, kernelHeight Kernel dimensions.
 *                                      + Must be between 1x1 and 11x11, and can be non-square.
 *
 * @param[in] kernelData Erode kernel binary mask, i.e. structuring element or neighborhood definition, in row-major layout.
 *                       The kernel elements are copied to an internal buffer.
 *                       The buffers passed can be deallocated after the call.
 *                       Use NULL for full neighborhood, all elements considered to be 1.
 *                       + If not NULL, it must point to a buffer with \p kernelWidth * \p kernelHeight elements.
 *
 * @param[in] border How to handle pixels outside image boundaries.
 *                   + The accepted border extensions are:
 *                    - \ref VPI_BORDER_ZERO
 *                    - \ref VPI_BORDER_CLAMP
 *                    - \ref VPI_BORDER_REFLECT
 *                    - \ref VPI_BORDER_MIRROR
 *                    - \ref VPI_BORDER_LIMITED (ignore pixels outside image boundaries)
 *
 * @retval #VPI_ERROR_INVALID_ARGUMENT     \p stream is NULL.
 * @retval #VPI_ERROR_INVALID_ARGUMENT     \p input or \p output are NULL.
 * @retval #VPI_ERROR_INVALID_ARGUMENT     \p kernelWidth or \p kernelHeight outside valid range.
 * @retval #VPI_ERROR_INVALID_ARGUMENT     \p input and \p output images must have same dimensions and format.
 * @retval #VPI_ERROR_INVALID_ARGUMENT     \p border not supported.
 * @retval #VPI_ERROR_INVALID_IMAGE_FORMAT \p input format not supported.
 * @retval #VPI_ERROR_NOT_IMPLEMENTED      Erode algorithm is not supported by given backend.
 * @retval #VPI_ERROR_INVALID_OPERATION    The needed backends aren't enabled in \p stream, \p input or \p output.
 * @retval #VPI_SUCCESS                    Operation executed successfully.
 */
VPI_PUBLIC VPIStatus vpiSubmitErode(VPIStream stream, uint64_t backend, VPIImage input, VPIImage output,
                                    const int8_t *kernelData, int32_t kernelWidth, int32_t kernelHeight,
                                    VPIBorderExtension border);

/** @} */

/**
 * @defgroup VPI_Dilate Dilate
 * @ingroup VPI_API_Algorithms
 * @{
 *
 * Filter an image with a 2D binary kernel composed with the dilate morphological operation.
 *
 * Refer to \ref algo_dilate for more details and usage examples regarding Dilate.
 *
 */

/**
 * Runs a 2D dilate over an image.
 *
 * @param[in] stream The stream handle where the operation will be queued in.
 *                   + Must not be NULL.
 *                   + Stream must have enabled the backends that will execute the algorithm.
 *
 * @param[in] backend Backend that will execute the algorithm.
 *                    + Valid values: 
 *                      - \ref VPI_BACKEND_CPU
 *                      - \ref VPI_BACKEND_CUDA
 *
 * @param[in] input Input image to be dilated with the kernel.
 *                  + Must not be NULL.
 *                  + Image must have enabled the backends that will execute the algorithm.
 *                  + Supported formats:
 *                    - \ref VPI_IMAGE_FORMAT_U8
 *                    - \ref VPI_IMAGE_FORMAT_S8
 *                    - \ref VPI_IMAGE_FORMAT_U16
 *                    - \ref VPI_IMAGE_FORMAT_S16
 *
 * @param[out] output Output image where the result is written to.
 *                    + Must not be NULL.
 *                    + Its image format and dimensions must be the same as input.
 *                    + Image must have enabled the backends that will execute the algorithm.
 *
 * @param[in] kernelWidth, kernelHeight Kernel dimensions.
 *                                      + Must be between 1x1 and 11x11, and can be non-square.
 *
 * @param[in] kernelData Dilate kernel binary mask, i.e. structuring element or neighborhood definition, in row-major layout.
 *                       The kernel elements are copied to an internal buffer.
 *                       The buffers passed can be deallocated after the call.
 *                       Use NULL for full neighborhood, all elements considered to be 1.
 *                       + If not NULL, it must point to a buffer with \p kernelWidth * \p kernelHeight elements.
 *
 * @param[in] border How to handle pixels outside image boundaries.
 *                   + The accepted border extensions are:
 *                    - \ref VPI_BORDER_ZERO
 *                    - \ref VPI_BORDER_CLAMP
 *                    - \ref VPI_BORDER_REFLECT
 *                    - \ref VPI_BORDER_MIRROR
 *                    - \ref VPI_BORDER_LIMITED (ignore pixels outside image boundaries)
 *
 * @retval #VPI_ERROR_INVALID_ARGUMENT     \p stream is NULL.
 * @retval #VPI_ERROR_INVALID_ARGUMENT     \p input or \p output are NULL.
 * @retval #VPI_ERROR_INVALID_ARGUMENT     \p kernelWidth or \p kernelHeight outside valid range.
 * @retval #VPI_ERROR_INVALID_ARGUMENT     \p input and \p output images must have same dimensions and format.
 * @retval #VPI_ERROR_INVALID_ARGUMENT     \p border not supported.
 * @retval #VPI_ERROR_INVALID_IMAGE_FORMAT \p input format not supported.
 * @retval #VPI_ERROR_NOT_IMPLEMENTED      Dilate algorithm is not supported by given backend.
 * @retval #VPI_ERROR_INVALID_OPERATION    The needed backends aren't enabled in \p stream, \p input or \p output.
 * @retval #VPI_SUCCESS                    Operation executed successfully.
 */
VPI_PUBLIC VPIStatus vpiSubmitDilate(VPIStream stream, uint64_t backend, VPIImage input, VPIImage output,
                                     const int8_t *kernelData, int32_t kernelWidth, int32_t kernelHeight,
                                     VPIBorderExtension border);

/** @} */

#ifdef __cplusplus
}
#endif

#endif /* NV_VPI_ALGORITHMS_MORPHOLOGICAL_FILTER_H */
// End content from: algo/MorphologicalFilter.h

// Begin content from: algo/EqualizeHist.h
/*
 * Copyright 2021 NVIDIA Corporation. All rights reserved.
 *
 * NOTICE TO LICENSEE:
 *
 * This source code and/or documentation ("Licensed Deliverables") are
 * subject to NVIDIA intellectual property rights under U.S. and
 * international Copyright laws.
 *
 * These Licensed Deliverables contained herein is PROPRIETARY and
 * CONFIDENTIAL to NVIDIA and is being provided under the terms and
 * conditions of a form of NVIDIA software license agreement by and
 * between NVIDIA and Licensee ("License Agreement") or electronically
 * accepted by Licensee. Notwithstanding any terms or conditions to
 * the contrary in the License Agreement, reproduction or disclosure
 * of the Licensed Deliverables to any third party without the express
 * written consent of NVIDIA is prohibited.
 *
 * NOTWITHSTANDING ANY TERMS OR CONDITIONS TO THE CONTRARY IN THE
 * LICENSE AGREEMENT, NVIDIA MAKES NO REPRESENTATION ABOUT THE
 * SUITABILITY OF THESE LICENSED DELIVERABLES FOR ANY PURPOSE. IT IS
 * PROVIDED "AS IS" WITHOUT EXPRESS OR IMPLIED WARRANTY OF ANY KIND.
 * NVIDIA DISCLAIMS ALL WARRANTIES WITH REGARD TO THESE LICENSED
 * DELIVERABLES, INCLUDING ALL IMPLIED WARRANTIES OF MERCHANTABILITY,
 * NONINFRINGEMENT, AND FITNESS FOR A PARTICULAR PURPOSE.
 * NOTWITHSTANDING ANY TERMS OR CONDITIONS TO THE CONTRARY IN THE
 * LICENSE AGREEMENT, IN NO EVENT SHALL NVIDIA BE LIABLE FOR ANY
 * SPECIAL, INDIRECT, INCIDENTAL, OR CONSEQUENTIAL DAMAGES, OR ANY
 * DAMAGES WHATSOEVER RESULTING FROM LOSS OF USE, DATA OR PROFITS,
 * WHETHER IN AN ACTION OF CONTRACT, NEGLIGENCE OR OTHER TORTIOUS
 * ACTION, ARISING OUT OF OR IN CONNECTION WITH THE USE OR PERFORMANCE
 * OF THESE LICENSED DELIVERABLES.
 *
 * U.S. Government End Users. These Licensed Deliverables are a
 * "commercial item" as that term is defined at 48 C.F.R. 2.101 (OCT
 * 1995), consisting of "commercial computer software" and "commercial
 * computer software documentation" as such terms are used in 48
 * C.F.R. 12.212 (SEPT 1995) and is provided to the U.S. Government
 * only as a commercial end item. Consistent with 48 C.F.R.12.212 and
 * 48 C.F.R. 227.7202-1 through 227.7202-4 (JUNE 1995), all
 * U.S. Government End Users acquire the Licensed Deliverables with
 * only those rights set forth herein.
 *
 * Any use of the Licensed Deliverables in individual and commercial
 * software must include, in the user documentation and internal
 * comments to the code, the above Disclaimer and U.S. Government End
 * Users Notice.
 */

/**
 * @file EqualizeHist.h
 *
 * Declares functions that equalize the histogram of the source image
 */

#ifndef NV_VPI_ALGORITHMS_EQUALIZE_HIST_H
#define NV_VPI_ALGORITHMS_EQUALIZE_HIST_H

// #include "../Export.h"
// #include "../Status.h"
// #include "../Types.h"

#ifdef __cplusplus
extern "C" {
#endif

/**
 * @defgroup VPI_EqualizeHist Equalize Image Histogram
 * @ingroup VPI_API_Algorithms
 * @{
 *
 * Equalize image histogram for the input image.
 * Refer to \ref algo_equalize_hist for more details and usage examples.
 */

/**
 * Creates payload for \ref vpiSubmitEqualizeHist
 *
 * @param[in] backend VPI backend that will execute the algorithm.
 *                    + Valid values: 
 *                      - \ref VPI_BACKEND_CPU
 *                      - \ref VPI_BACKEND_CUDA
 *                     + Backend must be enabled in current context.
 *
 * @param[in] fmt Format of input image.
 *                + The accepted image formats are:
 *                  - \ref VPI_IMAGE_FORMAT_U8
 *                  - \ref VPI_IMAGE_FORMAT_U16
 *                  - \ref VPI_IMAGE_FORMAT_NV12 (only luma channel is equalized)
 *                  - \ref VPI_IMAGE_FORMAT_NV12_ER (only luma channel is equalized)
 *
 * @param[out] payload Pointer to the payload variable that receives the created handle.
 *
 * @retval #VPI_ERROR_INVALID_ARGUMENT  \p payload is NULL.
 * @retval #VPI_ERROR_INVALID_ARGUMENT  \p backends refers to an invalid backend.
 * @retval #VPI_IMAGE_FORMAT_INVALID    \p fmt is not supported. 
 * @retval #VPI_ERROR_INVALID_CONTEXT   Current context is destroyed. 
 * @retval #VPI_ERROR_NOT_IMPLEMENTED   Equalize Histogram algorithm is not supported by given backend.
 * @retval #VPI_ERROR_OUT_OF_MEMORY     Cannot allocate required resources.
 * @retval #VPI_ERROR_INVALID_OPERATION Backend isn't enabled in current context.
 * @retval #VPI_SUCCESS                 Operation executed successfully.
 */
VPI_PUBLIC VPIStatus vpiCreateEqualizeHist(uint64_t backend, VPIImageFormat fmt, VPIPayload *payload);

/**
 * Equalize the histogram of the image
 *
 * @param[in] stream The stream where the operation will be queued in.
 *                   + Must not be NULL.
 *                   + Stream must have enabled the backends that will execute the algorithm.
 *
 * @param[in] backend VPI backend that will execute the algorithm.
 *                    + Valid values: 
 *                      - \ref VPI_BACKEND_CPU
 *                      - \ref VPI_BACKEND_CUDA
 *
 * @param[in] payload Payload created with \ref vpiCreateEqualizeHist
 *
 * @param[in] input Input image.
 *                  + Must not be NULL.
 *                  + Its format must match the one associated with \p payload.
 *                  + Image must have enabled the backends that will execute the algorithm.
 *
 * @param[out] output Where the resulting image will be written to.
 *                    + Must not be NULL.
 *                    + Must have same format and dimensions as input image.
 *                    + Image must have enabled the backends that will execute the algorithm.
 * 
 * @retval #VPI_ERROR_INVALID_ARGUMENT     \p stream is NULL.
 * @retval #VPI_ERROR_INVALID_ARGUMENT     \p input or \p output are NULL.
 * @retval #VPI_ERROR_INVALID_ARGUMENT     \p payload must be created by \ref vpiCreateEqualizeHist.
 * @retval #VPI_ERROR_INVALID_ARGUMENT     \p input and \p output must have same dimensions.
 * @retval #VPI_ERROR_INVALID_IMAGE_FORMAT \p input image format does not match with one associated with \p payload.
 * @retval #VPI_ERROR_INVALID_IMAGE_FORMAT \p output format doesn't match input's.
 * @retval #VPI_ERROR_INVALID_PAYLOAD_TYPE \p payload is invalid.
 * @retval #VPI_ERROR_INVALID_OPERATION    The needed backends aren't enabled in \p stream, \p input or \p output.
 * @retval #VPI_SUCCESS                    Operation executed successfully.
 */
VPI_PUBLIC VPIStatus vpiSubmitEqualizeHist(VPIStream stream, uint64_t backend, VPIPayload payload, VPIImage input,
                                           VPIImage output);

#ifdef __cplusplus
}
#endif

/** @} */

#endif /* NV_VPI_ALGORITHMS_EQUALIZE_HIST_H */
// End content from: algo/EqualizeHist.h

// Begin content from: algo/FFT.h
/*
 * Copyright 2019-2021 NVIDIA Corporation. All rights reserved.
 *
 * NOTICE TO LICENSEE:
 *
 * This source code and/or documentation ("Licensed Deliverables") are
 * subject to NVIDIA intellectual property rights under U.S. and
 * international Copyright laws.
 *
 * These Licensed Deliverables contained herein is PROPRIETARY and
 * CONFIDENTIAL to NVIDIA and is being provided under the terms and
 * conditions of a form of NVIDIA software license agreement by and
 * between NVIDIA and Licensee ("License Agreement") or electronically
 * accepted by Licensee. Notwithstanding any terms or conditions to
 * the contrary in the License Agreement, reproduction or disclosure
 * of the Licensed Deliverables to any third party without the express
 * written consent of NVIDIA is prohibited.
 *
 * NOTWITHSTANDING ANY TERMS OR CONDITIONS TO THE CONTRARY IN THE
 * LICENSE AGREEMENT, NVIDIA MAKES NO REPRESENTATION ABOUT THE
 * SUITABILITY OF THESE LICENSED DELIVERABLES FOR ANY PURPOSE. IT IS
 * PROVIDED "AS IS" WITHOUT EXPRESS OR IMPLIED WARRANTY OF ANY KIND.
 * NVIDIA DISCLAIMS ALL WARRANTIES WITH REGARD TO THESE LICENSED
 * DELIVERABLES, INCLUDING ALL IMPLIED WARRANTIES OF MERCHANTABILITY,
 * NONINFRINGEMENT, AND FITNESS FOR A PARTICULAR PURPOSE.
 * NOTWITHSTANDING ANY TERMS OR CONDITIONS TO THE CONTRARY IN THE
 * LICENSE AGREEMENT, IN NO EVENT SHALL NVIDIA BE LIABLE FOR ANY
 * SPECIAL, INDIRECT, INCIDENTAL, OR CONSEQUENTIAL DAMAGES, OR ANY
 * DAMAGES WHATSOEVER RESULTING FROM LOSS OF USE, DATA OR PROFITS,
 * WHETHER IN AN ACTION OF CONTRACT, NEGLIGENCE OR OTHER TORTIOUS
 * ACTION, ARISING OUT OF OR IN CONNECTION WITH THE USE OR PERFORMANCE
 * OF THESE LICENSED DELIVERABLES.
 *
 * U.S. Government End Users. These Licensed Deliverables are a
 * "commercial item" as that term is defined at 48 C.F.R. 2.101 (OCT
 * 1995), consisting of "commercial computer software" and "commercial
 * computer software documentation" as such terms are used in 48
 * C.F.R. 12.212 (SEPT 1995) and is provided to the U.S. Government
 * only as a commercial end item. Consistent with 48 C.F.R.12.212 and
 * 48 C.F.R. 227.7202-1 through 227.7202-4 (JUNE 1995), all
 * U.S. Government End Users acquire the Licensed Deliverables with
 * only those rights set forth herein.
 *
 * Any use of the Licensed Deliverables in individual and commercial
 * software must include, in the user documentation and internal
 * comments to the code, the above Disclaimer and U.S. Government End
 * Users Notice.
 */

/**
 * @file FFT.h
 *
 * Declares functions that implement the Fast Fourier Transform algorithm and its inverse.
 */

#ifndef NV_VPI_ALGORITHMS_FFT_H
#define NV_VPI_ALGORITHMS_FFT_H

// #include "../AlgoFlags.h"
// #include "../Export.h"
// #include "../Status.h"
// #include "../Types.h"

#include <stdint.h>

#ifdef __cplusplus
extern "C" {
#endif

/**
 * @defgroup VPI_FFT Fast Fourier Transform
 * @ingroup VPI_API_Algorithms
 * @{
 *
 * Operations that applies the Fast Fourier Transform and its inverse to 2D images.
 *
 * Refer to \ref algo_fft for more details and usage examples regarding FFT.
 *
 * Refer to \ref algo_ifft for more details and usage examples regarding IFFT.
 *
 * Both FFT and inverse FFT need a payload created during application
 * initialization phase, where image dimensions, input and output formats are
 * defined. The payload then can be used to submit operations on different
 * images, as long as their dimensions and formats match what was defined during
 * payload creation.
 *
 */

/**
 * Creates payload for direct Fast Fourier Transform algorithm.
 * The created payload can then be used with \ref vpiSubmitFFT.
 *
 * @attention For this function to succeed, it is required that the library
 *            libcufft.so.10 is installed in the system.
 *
 * @param[in] backends VPI backend that will execute the algorithm.
 *                     + Valid values:
 *                       - \ref VPI_BACKEND_CPU
 *                       - \ref VPI_BACKEND_CUDA 
 *                     + Backend must be enabled in current context.
 *
 * @param[in] inputWidth, inputHeight Dimensions of the input/output images to be used.
 *                                    + Must be >= 1x1.
 *                                    + With CPU backend, image width must be even.
 *
 * @param[in] inFormat Input image format.
 *                     + Supported formats:
 *                       - \ref VPI_IMAGE_FORMAT_F32, real input.
 *                       - \ref VPI_IMAGE_FORMAT_2F32, complex input.
 *
 * @param[in] outFormat Output image format.
 *                      + Supported format:
 *                        - \ref VPI_IMAGE_FORMAT_2F32, complex output.
 *
 * @param[out] payload Pointer to the payload variable that receives the created handle.
 *
 * @retval #VPI_ERROR_INVALID_ARGUMENT  \p payload is NULL.
 * @retval #VPI_ERROR_INVALID_ARGUMENT  \p inputWidth or \p inputHeight outside valid range.
 * @retval #VPI_ERROR_INVALID_ARGUMENT  \p backend refers to an invalid backend.
 * @retval #VPI_ERROR_NOT_IMPLEMENTED   FFT algorithm is not supported by given backend.
 * @retval #VPI_ERROR_INVALID_CONTEXT   Current context is destroyed.
 * @retval #VPI_IMAGE_FORMAT_INVALID    \p outFormat is not supported.
 * @retval #VPI_ERROR_OUT_OF_MEMORY     Cannot allocate required resources.
 * @retval #VPI_ERROR_INVALID_OPERATION Backend isn't enabled in current context.
 * @retval #VPI_ERROR_INVALID_OPERATION Library libcufft.so.10 isn't installed in the system.
 * @retval #VPI_SUCCESS                 Operation executed successfully.
 */
VPI_PUBLIC VPIStatus vpiCreateFFT(uint64_t backends, int32_t inputWidth, int32_t inputHeight,
                                  const VPIImageFormat inFormat, const VPIImageFormat outFormat, VPIPayload *payload);

/**
 * Runs the direct Fast Fourier Transform on single image.
 *
 * @param[in] stream The stream where the operation will be queued in.
 *                   + Must not be NULL.
 *                   + Stream must have enabled the backends that will execute the algorithm.
 *
 * @param[in] backend Backend that will execute the algorithm.
 *                    + Must be the backend specified during payload creation or 0 as a shorthand to use this backend.
 *
 * @param[in] payload Payload created with \ref vpiCreateFFT
 *
 * @param[in] input Input image in space domain.
 *                  + Must not be NULL.
 *                  + Must have same format and dimensions as the one specified during payload creation.
 *                  + Image must have enabled the backends that will execute the algorithm.
 *                  + When using the CPU backend, input rows must be aligned to 4 bytes.
 *
 * @param[out] output Image where the result in frequency domain will be written to.
 *                    The top left pixel of the output represents the DC (0 Hz) component.
 *                    + Must not be NULL.
 *                    + Must have same format as the one specified during payload creation.
 *                    + Image must have enabled the backends that will execute the algorithm.
 *                    + When using the CPU backend, output rows must be aligned to 4 bytes.
 *                    + Output dimensions depends on input's based on input's format, as shown below:
 *                      | Input Format               | Output Size      |
 *                      |----------------------------|------------------|
 *                      | \ref VPI_IMAGE_FORMAT_2F32 | W x H            |
 *                      | \ref VPI_IMAGE_FORMAT_F32  | floor(W/2)+1 x H |
 *                    + When input is real, output contains only the left half of the full Hermitian (symmetric-conjugate).
 *
 * @param[in] flags Control flags.
 *                  + Currently it must be 0.
 * 
 * @retval #VPI_ERROR_INVALID_ARGUMENT     \p stream is NULL.
 * @retval #VPI_ERROR_INVALID_ARGUMENT     \p input or \p output are NULL.
 * @retval #VPI_ERROR_INVALID_ARGUMENT     \p payload is not created using vpiCreateFFT.
 * @retval #VPI_ERROR_INVALID_ARGUMENT     \p input image dimension and format does not match the ones associated with \p payload.
 * @retval #VPI_ERROR_INVALID_ARGUMENT     \p output image format does not match the one associated with \p payload.
 * @retval #VPI_ERROR_INVALID_ARGUMENT     Non-supported \p flags.
 * @retval #VPI_ERROR_INVALID_ARGUMENT     \p output dimensions are non-conformant with input's.
 * @retval #VPI_ERROR_INVALID_PAYLOAD_TYPE \p payload is invalid.
 * @retval #VPI_ERROR_INVALID_OPERATION    The needed backends aren't enabled in \p stream, \p input or \p output.
 * @retval #VPI_SUCCESS                    Operation executed successfully.
 */
VPI_PUBLIC VPIStatus vpiSubmitFFT(VPIStream stream, uint64_t backend, VPIPayload payload, VPIImage input,
                                  VPIImage output, uint64_t flags);

/**
 * Creates payload for inverse Fast Fourier Transform algorithm.
 * The created payload can then be used with \ref vpiSubmitIFFT.
 *
 * @attention For this function to succeed, it is required that the library
 *            libcufft.so.10 is installed in the system.
 *
 * @param[in] backends VPI backend that will execute the algorithm.
 *                     + Valid values:
 *                       - \ref VPI_BACKEND_CPU
 *                       - \ref VPI_BACKEND_CUDA 
 *                     + Backend must be enabled in current context.
 *
 * @param[in] outputWidth, outputHeight Output image dimensions.
 *                                      + Must be >= 1.
 *
 * @param[in] inFormat Input image format.
 *                     + Supported format:
 *                       - \ref VPI_IMAGE_FORMAT_2F32, complex input.
 *
 * @param[in] outFormat Output image format.
 *                      + Must have same format as the one specified during payload creation.
 *                      + With CPU backend, output width must be even.
 *                      + Supported formats:
 *                        - \ref VPI_IMAGE_FORMAT_F32, real output.
 *                        - \ref VPI_IMAGE_FORMAT_2F32, complex output.
 *
 * @param[out] payload Pointer to the payload variable that receives the created handle.
 *
 * @retval #VPI_ERROR_INVALID_ARGUMENT  \p payload is NULL.
 * @retval #VPI_ERROR_INVALID_ARGUMENT  \p outputWidth or \p outputHeight outside valid range.
 * @retval #VPI_ERROR_INVALID_ARGUMENT  \p backends refers to an invalid backend.
 * @retval #VPI_ERROR_NOT_IMPLEMENTED   IFFT algorithm is not supported by given backend.
 * @retval #VPI_ERROR_INVALID_CONTEXT   Current context is destroyed.
 * @retval #VPI_IMAGE_FORMAT_INVALID    \p outFormat is not supported.
 * @retval #VPI_ERROR_OUT_OF_MEMORY     Cannot allocate required resources.
 * @retval #VPI_ERROR_INVALID_OPERATION Backend isn't enabled in current context.
 * @retval #VPI_ERROR_INVALID_OPERATION Library libcufft.so.10 isn't installed in the system.
 * @retval #VPI_SUCCESS                 Operation executed successfully.
 */
VPI_PUBLIC VPIStatus vpiCreateIFFT(uint64_t backends, int32_t outputWidth, int32_t outputHeight,
                                   const VPIImageFormat inFormat, const VPIImageFormat outFormat, VPIPayload *payload);

/**
 * Runs the inverse Fast Fourier Transform on single image.
 *
 * @param[in] stream A stream handle where the operation will be queued in.
 *                   + Must not be NULL.
 *                   + Stream must have enabled the backends that will execute the algorithm.
 *
 * @param[in] backend Backend that will execute the algorithm.
 *                    + Must be the backend specified during payload creation or 0 as a shorthand to use this backend.
 *
 * @param[in] payload Payload created with \ref vpiCreateIFFT
 *
 * @param[in] input Input image in frequency domain.
 *                  The top left pixel of the input represents the DC (0 Hz) component.
 *                  + Must not be NULL.
 *                  + Must have same format and dimensions as the one specified during payload creation.
 *                  + Image must have enabled the backends that will execute the algorithm.
 *                  + When using the CPU backend, input rows must be aligned to 4 bytes.
 *                  + When output is real, input contains only the left half of the full Hermitian (symmetric-conjugate).
 *                  + Input dimensions depends on output's based on output's format, as shown below:
 *                    | Output Format              | Input Size       |
 *                    |----------------------------|------------------|
 *                    | \ref VPI_IMAGE_FORMAT_2F32 | W x H            |
 *                    | \ref VPI_IMAGE_FORMAT_F32  | floor(W/2)+1 x H |
 *
 * @param[out] output Image where the result in space domain will be written to.
 *                    + Must not be NULL.
 *                    + Must have same format as the one specified during payload creation.
 *                    + Image must have enabled the backends that will execute the algorithm.
 *                    + When using the CPU backend, output rows must be aligned to 4 bytes.
 *
 * @param[in] flags Control flags.
 *                  + Valid values are a combination of one or more of the following flags:
 *                    - 0 for default processing, where output scaled. 
 *                    - \ref VPI_DENORMALIZED_OUTPUT : Output is left denormalized. This leads to
 *                                                     faster execution as normalization isn't usually needed.
 *                                                     Absence of this flag will scale the output, dividing it by the
 *                                                     total pixel count. This makes the output the exact inverse of
 *                                                     direct Fast Fourier Transform.
 * 
 * @retval #VPI_ERROR_INVALID_ARGUMENT     \p stream is NULL.
 * @retval #VPI_ERROR_INVALID_ARGUMENT     \p input or \p output are NULL.
 * @retval #VPI_ERROR_INVALID_ARGUMENT     \p payload is not created using vpiCreateIFFT.
 * @retval #VPI_ERROR_INVALID_ARGUMENT     \p input image dimension and format does not match the ones associated with \p payload.
 * @retval #VPI_ERROR_INVALID_ARGUMENT     \p output image format does not match the one associated with \p payload.
 * @retval #VPI_ERROR_INVALID_ARGUMENT     \p flags includes a non-supported flag.
 * @retval #VPI_ERROR_INVALID_ARGUMENT     \p output dimensions are non-conformant with input's.
 * @retval #VPI_ERROR_INVALID_PAYLOAD_TYPE \p payload is invalid.
 * @retval #VPI_ERROR_INVALID_OPERATION    The needed backends aren't enabled in \p stream, \p input or \p output.
 * @retval #VPI_SUCCESS                    Operation executed successfully.
 */
VPI_PUBLIC VPIStatus vpiSubmitIFFT(VPIStream stream, uint64_t backend, VPIPayload payload, VPIImage input,
                                   VPIImage output, uint64_t flags);

/** @} end of VPI_FFT */

#ifdef __cplusplus
}
#endif

#endif /* NV_VPI_ALGORITHMS_FFT_H */
// End content from: algo/FFT.h

// Begin content from: algo/MedianFilter.h
/*
 * Copyright 2022 NVIDIA Corporation. All rights reserved.
 *
 * NOTICE TO LICENSEE:
 *
 * This source code and/or documentation ("Licensed Deliverables") are
 * subject to NVIDIA intellectual property rights under U.S. and
 * international Copyright laws.
 *
 * These Licensed Deliverables contained herein is PROPRIETARY and
 * CONFIDENTIAL to NVIDIA and is being provided under the terms and
 * conditions of a form of NVIDIA software license agreement by and
 * between NVIDIA and Licensee ("License Agreement") or electronically
 * accepted by Licensee. Notwithstanding any terms or conditions to
 * the contrary in the License Agreement, reproduction or disclosure
 * of the Licensed Deliverables to any third party without the express
 * written consent of NVIDIA is prohibited.
 *
 * NOTWITHSTANDING ANY TERMS OR CONDITIONS TO THE CONTRARY IN THE
 * LICENSE AGREEMENT, NVIDIA MAKES NO REPRESENTATION ABOUT THE
 * SUITABILITY OF THESE LICENSED DELIVERABLES FOR ANY PURPOSE. IT IS
 * PROVIDED "AS IS" WITHOUT EXPRESS OR IMPLIED WARRANTY OF ANY KIND.
 * NVIDIA DISCLAIMS ALL WARRANTIES WITH REGARD TO THESE LICENSED
 * DELIVERABLES, INCLUDING ALL IMPLIED WARRANTIES OF MERCHANTABILITY,
 * NONINFRINGEMENT, AND FITNESS FOR A PARTICULAR PURPOSE.
 * NOTWITHSTANDING ANY TERMS OR CONDITIONS TO THE CONTRARY IN THE
 * LICENSE AGREEMENT, IN NO EVENT SHALL NVIDIA BE LIABLE FOR ANY
 * SPECIAL, INDIRECT, INCIDENTAL, OR CONSEQUENTIAL DAMAGES, OR ANY
 * DAMAGES WHATSOEVER RESULTING FROM LOSS OF USE, DATA OR PROFITS,
 * WHETHER IN AN ACTION OF CONTRACT, NEGLIGENCE OR OTHER TORTIOUS
 * ACTION, ARISING OUT OF OR IN CONNECTION WITH THE USE OR PERFORMANCE
 * OF THESE LICENSED DELIVERABLES.
 *
 * U.S. Government End Users. These Licensed Deliverables are a
 * "commercial item" as that term is defined at 48 C.F.R. 2.101 (OCT
 * 1995), consisting of "commercial computer software" and "commercial
 * computer software documentation" as such terms are used in 48
 * C.F.R. 12.212 (SEPT 1995) and is provided to the U.S. Government
 * only as a commercial end item. Consistent with 48 C.F.R.12.212 and
 * 48 C.F.R. 227.7202-1 through 227.7202-4 (JUNE 1995), all
 * U.S. Government End Users acquire the Licensed Deliverables with
 * only those rights set forth herein.
 *
 * Any use of the Licensed Deliverables in individual and commercial
 * software must include, in the user documentation and internal
 * comments to the code, the above Disclaimer and U.S. Government End
 * Users Notice.
 */

/**
 * @file MedianFilter.h
 *
 * Declares functions that implement median filter algorithms.
 */

#ifndef NV_VPI_ALGORITHMS_MEDIAN_FILTER_H
#define NV_VPI_ALGORITHMS_MEDIAN_FILTER_H

// #include "../Export.h"
// #include "../Status.h"
// #include "../Types.h"

#include <stdint.h>

#ifdef __cplusplus
extern "C" {
#endif

/**
 * @defgroup VPI_MedianFilter Median Filter
 * @ingroup VPI_API_Algorithms
 * @{
 *
 * Runs a 2D median filter over the input image.
 *
 * Refer to \ref algo_median_filter for more details and usage examples regarding Median Filter.
 */

/**
 * Runs a 2D median filter over an image.
 *
 * @param[in] stream A stream handle where the operation will be queued into.
 *
 * @param[in] backend Backend that will execute the algorithm.
 *                    + Valid values: 
 *                      - \ref VPI_BACKEND_CPU
 *                      - \ref VPI_BACKEND_CUDA
 *                      - \ref VPI_BACKEND_PVA
 *
 * @param[in] input Input image to be denoised.
 *                  + Valid Image formats:
 *                    | Formats                      | CPU | CUDA | PVA |
 *                    |------------------------------|:---:|:----:|:---:|
 *                    | \ref VPI_IMAGE_FORMAT_U8     |  *  |   *  |  *  |
 *                    | \ref VPI_IMAGE_FORMAT_S8     |  *  |   *  |  *  |
 *                    | \ref VPI_IMAGE_FORMAT_U16    |  *  |   *  |  *  |
 *                    | \ref VPI_IMAGE_FORMAT_S16    |  *  |   *  |  *  |
 *                    | \ref VPI_IMAGE_FORMAT_Y8     |  *  |   *  |  *  |
 *                    | \ref VPI_IMAGE_FORMAT_Y8_ER  |  *  |   *  |  *  |
 *                    | \ref VPI_IMAGE_FORMAT_Y16    |  *  |   *  |  *  |
 *                    | \ref VPI_IMAGE_FORMAT_Y16_ER |  *  |   *  |  *  |
 *                    | \ref VPI_IMAGE_FORMAT_U32    |  *  |   *  |  *  |
 *                    | \ref VPI_IMAGE_FORMAT_S32    |  *  |   *  |  *  |
 *                    | \ref VPI_IMAGE_FORMAT_RGB8p  |  *  |   *  |     |
 *                    | \ref VPI_IMAGE_FORMAT_RGBA8p |  *  |   *  |     |
 *                    | \ref VPI_IMAGE_FORMAT_BGR8p  |  *  |   *  |     |
 *                    | \ref VPI_IMAGE_FORMAT_BGRA8p |  *  |   *  |     |
 *                    | \ref VPI_IMAGE_FORMAT_2S16   |     |      |  *  |

 * @param[out] output Output image where the result is written to.
 *                    + Must not be NULL.
 *                    + Must have same format and dimensions as input image.
 *                    + Image must have enabled the backends that will execute the algorithm.
 * 
 * @param[in] kernelWidth, kernelHeight Kernel dimensions.
 *                                      The coordinate of the kernel weight that is aligned with the source pixel 
 *                                      is given by the following formula:
 *                                      \f{align*}{
 *                                          k_x &= \mathit{kernelWidth}/2    \\
 *                                          k_y &= \mathit{kernelHeight}/2
 *                                      \f}
 *                                      + Must be between 1x1 and 11x11, can be non square.
 *
 * @param[in] kernelData Median kernel binary mask.
 *                       It defines the structuring element or median calculation mask, in row-major layout.
 *                       The pixel under a non-zero kernel element be used in median calculation.
 *                       Size the kernel elements are copied to an internal buffer,
 *                       the given buffer can be deallocated after the call.
 *                       Use NULL for all elements in median calculation, i.e. all kernel elements considered to be non-zero.
 *                       + If not NULL, it must point to a buffer with `kernelWidth * kernelHeight` elements.
 *
 * @param[in] border How to handle pixels outside image boundaries.
 *                   + The accepted border extensions are:
 *                    - \ref VPI_BORDER_ZERO
 *                    - \ref VPI_BORDER_CLAMP
 *                    - \ref VPI_BORDER_REFLECT
 *                    - \ref VPI_BORDER_MIRROR
 *                    - \ref VPI_BORDER_LIMITED (ignores pixels outside image boundaries)
 * 
 * @retval #VPI_ERROR_INVALID_ARGUMENT     \p stream is NULL.
 * @retval #VPI_ERROR_INVALID_ARGUMENT     \p input or \p output are NULL.
 * @retval #VPI_ERROR_INVALID_ARGUMENT     \p input and \p output image dimensions and formats do not match.
 * @retval #VPI_ERROR_INVALID_ARGUMENT     Image dimensions aren't supported for given format.
 * @retval #VPI_ERROR_INVALID_ARGUMENT     \p border not supported.
 * @retval #VPI_ERROR_INVALID_ARGUMENT     \p backend is invalid or unknown.
 * @retval #VPI_ERROR_INVALID_IMAGE_FORMAT \p input and \p output formats aren't supported
 * @retval #VPI_ERROR_NOT_IMPLEMENTED      Median filter algorithm is not supported by given backend.
 * @retval #VPI_ERROR_INVALID_OPERATION    Backend hardware not available.
 * @retval #VPI_ERROR_INVALID_OPERATION    The needed backends aren't enabled in \p stream, \p input or \p output.
 * @retval #VPI_SUCCESS                    Operation executed successfully.
 */
VPI_PUBLIC VPIStatus vpiSubmitMedianFilter(VPIStream stream, uint64_t backend, VPIImage input, VPIImage output,
                                           int32_t kernelWidth, int32_t kernelHeight, const int8_t *kernelData,
                                           VPIBorderExtension border);
/** @} */

#ifdef __cplusplus
}
#endif

#endif /* NV_VPI_ALGORITHMS_MEDIAN_FILTER_H */
// End content from: algo/MedianFilter.h

// Begin content from: experimental/HOG.h
/*
 * Copyright 2019-2021 NVIDIA Corporation. All rights reserved.
 *
 * NOTICE TO LICENSEE:
 *
 * This source code and/or documentation ("Licensed Deliverables") are
 * subject to NVIDIA intellectual property rights under U.S. and
 * international Copyright laws.
 *
 * These Licensed Deliverables contained herein is PROPRIETARY and
 * CONFIDENTIAL to NVIDIA and is being provided under the terms and
 * conditions of a form of NVIDIA software license agreement by and
 * between NVIDIA and Licensee ("License Agreement") or electronically
 * accepted by Licensee. Notwithstanding any terms or conditions to
 * the contrary in the License Agreement, reproduction or disclosure
 * of the Licensed Deliverables to any third party without the express
 * written consent of NVIDIA is prohibited.
 *
 * NOTWITHSTANDING ANY TERMS OR CONDITIONS TO THE CONTRARY IN THE
 * LICENSE AGREEMENT, NVIDIA MAKES NO REPRESENTATION ABOUT THE
 * SUITABILITY OF THESE LICENSED DELIVERABLES FOR ANY PURPOSE. IT IS
 * PROVIDED "AS IS" WITHOUT EXPRESS OR IMPLIED WARRANTY OF ANY KIND.
 * NVIDIA DISCLAIMS ALL WARRANTIES WITH REGARD TO THESE LICENSED
 * DELIVERABLES, INCLUDING ALL IMPLIED WARRANTIES OF MERCHANTABILITY,
 * NONINFRINGEMENT, AND FITNESS FOR A PARTICULAR PURPOSE.
 * NOTWITHSTANDING ANY TERMS OR CONDITIONS TO THE CONTRARY IN THE
 * LICENSE AGREEMENT, IN NO EVENT SHALL NVIDIA BE LIABLE FOR ANY
 * SPECIAL, INDIRECT, INCIDENTAL, OR CONSEQUENTIAL DAMAGES, OR ANY
 * DAMAGES WHATSOEVER RESULTING FROM LOSS OF USE, DATA OR PROFITS,
 * WHETHER IN AN ACTION OF CONTRACT, NEGLIGENCE OR OTHER TORTIOUS
 * ACTION, ARISING OUT OF OR IN CONNECTION WITH THE USE OR PERFORMANCE
 * OF THESE LICENSED DELIVERABLES.
 *
 * U.S. Government End Users. These Licensed Deliverables are a
 * "commercial item" as that term is defined at 48 C.F.R. 2.101 (OCT
 * 1995), consisting of "commercial computer software" and "commercial
 * computer software documentation" as such terms are used in 48
 * C.F.R. 12.212 (SEPT 1995) and is provided to the U.S. Government
 * only as a commercial end item. Consistent with 48 C.F.R.12.212 and
 * 48 C.F.R. 227.7202-1 through 227.7202-4 (JUNE 1995), all
 * U.S. Government End Users acquire the Licensed Deliverables with
 * only those rights set forth herein.
 *
 * Any use of the Licensed Deliverables in individual and commercial
 * software must include, in the user documentation and internal
 * comments to the code, the above Disclaimer and U.S. Government End
 * Users Notice.
 */

/**
 * @file HOG.h
 *
 * Declares functions that implement the Histogram of Oriented Gradients algorithm.
 */

#ifndef NV_VPI_ALGORITHMS_HOG_H
#define NV_VPI_ALGORITHMS_HOG_H

// #include "../Export.h"
// #include "../Status.h"
// #include "../Types.h"

#include <stdint.h>

#ifdef __cplusplus
extern "C" {
#endif

/**
 * @defgroup VPI_HOG Histogram of Oriented Gradients
 * @ingroup VPI_API_Algorithms
 * @{
 *
 * Extracts Histogram of Oriented Gradients features from input image.
 */

/** @name HOG flags 
 * Defines what features will be returned.
 * @{ */
#define VPI_HOG_CONTRAST_SENSITIVE 0x01   /**< Return contrast sensitive features. */
#define VPI_HOG_CONTRAST_INSENSITIVE 0x02 /**< Return contrast insensitive features. */
#define VPI_HOG_TEXTURE 0x04              /**< Return texture-related features. */

/** Helper flag to return all features. */
#define VPI_HOG_ALL_FEATURES (VPI_HOG_CONTRAST_SENSITIVE | VPI_HOG_CONTRAST_INSENSITIVE | VPI_HOG_TEXTURE)
/** @} */

/**
 * Create a payload for the non-batch version of HOG algorithm.
 *
 * @param[in] backends VPI backends that are eligible to execute the algorithm.
 *                     + Valid values:
 *                       - \ref VPI_BACKEND_CPU
 *                       - \ref VPI_BACKEND_CUDA
 *
 * @param[in] width,height Dimensions of the input image to be used.
 *                         + Must be >= 0.
 *
 * @param[in] features Flags to specify what features will be returned.
 *                     + Must be a bitwise combination of one or more of the following flags:
 *                       - \ref VPI_HOG_CONTRAST_SENSITIVE
 *                       - \ref VPI_HOG_CONTRAST_INSENSITIVE
 *                       - \ref VPI_HOG_TEXTURE
 *                       - \ref VPI_HOG_ALL_FEATURES (it's the combination of all flags above)
 *
 * @param[in] cellSize Cell size, typically 8 or 16 for 8x8 and 16x16 cells respectively.
 *                     + Must be >=2 and <= 32 and power of two.
 *
 * @param[in] numOrientations Number of orientations used. This is typically 18.
 *                            + Must be between 4 and 18.
 *
 * @param[out] outNumFeatures Receives the number of features that will be returned. Pass NULL if not needed.
 *
 * @param[out] payload Pointer to the payload variable that receives the created handle.
 * 
 * @retval #VPI_ERROR_INVALID_ARGUMENT \p payload handle is NULL.
 * @retval #VPI_ERROR_INVALID_ARGUMENT \p width or \p height outside valid range.
 * @retval #VPI_ERROR_NOT_IMPLEMENTED  HOG is not implemented for given backend.
 * @retval #VPI_ERROR_INVALID_CONTEXT  Current context is destroyed.
 * @retval #VPI_ERROR_OUT_OF_MEMORY    Cannot allocate required resources.
 * @retval #VPI_SUCCESS                Operation executed successfully.
 */
VPI_PUBLIC VPIStatus vpiCreateExtractHOGFeatures(uint64_t backends, int32_t width, int32_t height, int32_t features,
                                                 int32_t cellSize, int32_t numOrientations, int32_t *outNumFeatures,
                                                 VPIPayload *payload);

/**
 * Create a payload for the batch version of HOG algorithm.
 * The input images are assumed to be laid out in memory as a 2D matrix of images. All images must have the same dimensions.
 *
 * @param[in] backends VPI backends that are eligible to execute the algorithm.
 *                     + Valid values:
 *                       - \ref VPI_BACKEND_CPU
 *                       - \ref VPI_BACKEND_CUDA
 *
 * @param[in] maxBatchWidth,maxBatchHeight Maximum number of images horizontally and vertically, respectively.
 *                                         + Must be >= 0.
 * @param[in] imgWidth,imgHeight Dimensions each of the batch images.
 *                               + Must be >= 0.
 *                               + \p imgWidth and \p imgHeight must be multiple of cell width and height respectively.
 *
 * @param[in] features Flags to specify which features will be returned.
 *                     + Must be a bitwise combination of one or more of the following flags:
 *                       - \ref VPI_HOG_CONTRAST_SENSITIVE
 *                       - \ref VPI_HOG_CONTRAST_INSENSITIVE
 *                       - \ref VPI_HOG_TEXTURE
 *                       - \ref VPI_HOG_ALL_FEATURES (it's the combination of all flags above)
 *
 * @param[in] cellSize Cell size, typically 8 or 16 for 8x8 and 16x16 cells respectively.
 *                     + Must be >=2 and <= 32 and power of two.
 *
 * @param[in] numOrientations Number of orientations used. This is typically 18.
 *                            + Must be between 4 and 18.
 *
 * @param[out] outNumFeatures Receives the number of features that will be returned. Pass NULL if not needed.
 *
 * @param[out] payload Pointer to a payload handle that will receive the allocated payload.
 * 
 * @retval #VPI_ERROR_INVALID_ARGUMENT \p payload handle is NULL.
 * @retval #VPI_ERROR_INVALID_ARGUMENT \p maxBatchWidth or \p maxBatchHeight outside valid range.
 * @retval #VPI_ERROR_INVALID_ARGUMENT \p imgWidth or \p imgHeight outside valid range.
 * @retval #VPI_ERROR_INVALID_ARGUMENT Invalid \p features.
 * @retval #VPI_ERROR_INVALID_ARGUMENT \p cellSize or \p numOrientations outside valid range.
 * @retval #VPI_ERROR_INVALID_ARGUMENT \p imgWidth must be a multiple of cell width.
 * @retval #VPI_ERROR_INVALID_ARGUMENT \p imgHeight must be a multiple of cell height.
 * @retval #VPI_ERROR_INVALID_ARGUMENT \p backends refers to an invalid backend.
 * @retval #VPI_ERROR_NOT_IMPLEMENTED  HOG is not implemented for given backend.
 * @retval #VPI_ERROR_INVALID_CONTEXT  Current context is destroyed.
 * @retval #VPI_ERROR_OUT_OF_MEMORY    Cannot allocate required resources.
 * @retval #VPI_SUCCESS                Operation executed successfully.
 */
VPI_PUBLIC VPIStatus vpiCreateExtractHOGFeaturesBatch(uint64_t backends, int32_t maxBatchWidth, int32_t maxBatchHeight,
                                                      int32_t imgWidth, int32_t imgHeight, int32_t features,
                                                      int32_t cellSize, int32_t numOrientations,
                                                      int32_t *outNumFeatures, VPIPayload *payload);

/**
 * Submits a HOG operation to the stream.
 * It handles both batch and non-batch payloads.
 *
 * @param[in] stream The stream where the operation will be queued in.
 *                   + Must not be NULL.
 *                   + Stream must have enabled the backends that will execute the algorithm.
 *
 * @param[in] backend Backend that will execute the algorithm.
 *                    Must be the backend specified during payload creation or 0 as a shorthand to use this backend.
 *
 * @param[in] payload Payload to be submitted along the other parameters.
 *
 * @param[in] input If using a non batch payload, this is the input image to be processed.
 *                  + Must not be NULL.
 *                  + Its dimensions must match what was passed to \ref vpiCreateExtractHOGFeatures.
 *                  + If using a batch payload, the image dimensions must be a multiple of (`imgWidth`,`imgHeight`),
 *                    and it must be at most (`imgWidth*maxBatchWidth`, `imgHeight*maxBatchHeight`).
 *                  + Image must have enabled the backends that will execute the algorithm.
 *
 * @param[out] outFeatures Pointer to an array of images that will receive the features. 
 *                         + Must not be NULL.
 *                         + The dimensions of each image must be (`input.width / cellSize`, `input.height / cellSize`).
 *                         + In case of batch processing, the output features position in the 2D matrix be the same position
 *                           of the corresponding input image.
 *                         + All images must have same format.
 *                         + All image must have enabled the backends that will execute the algorithm.
 *
 * @param[in] numFeatures Number of images in the output array. Must be between 1 and 32.
 *
 * @retval #VPI_ERROR_INVALID_ARGUMENT     \p stream is NULL.
 * @retval #VPI_ERROR_INVALID_ARGUMENT     \p input or \p outFeatures are NULL.
 * @retval #VPI_ERROR_INVALID_ARGUMENT     \p payload is not generated using vpiCreateExtractHOGFeatures.
 * @retval #VPI_ERROR_INVALID_ARGUMENT     \p numFeatures outside valid range.
 * @retval #VPI_ERROR_INVALID_ARGUMENT     Batch input width must be a multiple of configured input width.
 * @retval #VPI_ERROR_INVALID_ARGUMENT     Batch input height must be a multiple of configured input height.
 * @retval #VPI_ERROR_INVALID_ARGUMENT     \p outFeatures must all have the same format.
 * @retval #VPI_ERROR_INVALID_PAYLOAD_TYPE \p payload is invalid.
 * @retval #VPI_ERROR_INVALID_OPERATION    The needed backends aren't enabled in \p stream, \p input or \p outFeatures.
 * @retval #VPI_SUCCESS                    Operation executed successfully.
 */
VPI_PUBLIC VPIStatus vpiSubmitExtractHOGFeatures(VPIStream stream, uint64_t backend, VPIPayload payload, VPIImage input,
                                                 VPIImage *outFeatures, int32_t numFeatures);

/** @} */

#ifdef __cplusplus
}
#endif

#endif /* NV_VPI_ALGORITHMS_HOG_H */
// End content from: experimental/HOG.h

// Begin content from: experimental/ColorNames.h
/*
 * Copyright 2019-2021 NVIDIA Corporation. All rights reserved.
 *
 * NOTICE TO LICENSEE:
 *
 * This source code and/or documentation ("Licensed Deliverables") are
 * subject to NVIDIA intellectual property rights under U.S. and
 * international Copyright laws.
 *
 * These Licensed Deliverables contained herein is PROPRIETARY and
 * CONFIDENTIAL to NVIDIA and is being provided under the terms and
 * conditions of a form of NVIDIA software license agreement by and
 * between NVIDIA and Licensee ("License Agreement") or electronically
 * accepted by Licensee. Notwithstanding any terms or conditions to
 * the contrary in the License Agreement, reproduction or disclosure
 * of the Licensed Deliverables to any third party without the express
 * written consent of NVIDIA is prohibited.
 *
 * NOTWITHSTANDING ANY TERMS OR CONDITIONS TO THE CONTRARY IN THE
 * LICENSE AGREEMENT, NVIDIA MAKES NO REPRESENTATION ABOUT THE
 * SUITABILITY OF THESE LICENSED DELIVERABLES FOR ANY PURPOSE. IT IS
 * PROVIDED "AS IS" WITHOUT EXPRESS OR IMPLIED WARRANTY OF ANY KIND.
 * NVIDIA DISCLAIMS ALL WARRANTIES WITH REGARD TO THESE LICENSED
 * DELIVERABLES, INCLUDING ALL IMPLIED WARRANTIES OF MERCHANTABILITY,
 * NONINFRINGEMENT, AND FITNESS FOR A PARTICULAR PURPOSE.
 * NOTWITHSTANDING ANY TERMS OR CONDITIONS TO THE CONTRARY IN THE
 * LICENSE AGREEMENT, IN NO EVENT SHALL NVIDIA BE LIABLE FOR ANY
 * SPECIAL, INDIRECT, INCIDENTAL, OR CONSEQUENTIAL DAMAGES, OR ANY
 * DAMAGES WHATSOEVER RESULTING FROM LOSS OF USE, DATA OR PROFITS,
 * WHETHER IN AN ACTION OF CONTRACT, NEGLIGENCE OR OTHER TORTIOUS
 * ACTION, ARISING OUT OF OR IN CONNECTION WITH THE USE OR PERFORMANCE
 * OF THESE LICENSED DELIVERABLES.
 *
 * U.S. Government End Users. These Licensed Deliverables are a
 * "commercial item" as that term is defined at 48 C.F.R. 2.101 (OCT
 * 1995), consisting of "commercial computer software" and "commercial
 * computer software documentation" as such terms are used in 48
 * C.F.R. 12.212 (SEPT 1995) and is provided to the U.S. Government
 * only as a commercial end item. Consistent with 48 C.F.R.12.212 and
 * 48 C.F.R. 227.7202-1 through 227.7202-4 (JUNE 1995), all
 * U.S. Government End Users acquire the Licensed Deliverables with
 * only those rights set forth herein.
 *
 * Any use of the Licensed Deliverables in individual and commercial
 * software must include, in the user documentation and internal
 * comments to the code, the above Disclaimer and U.S. Government End
 * Users Notice.
 */

/**
 * @file ColorNames.h
 *
 * Declares functions that implement the Color Names algorithm.
 */

#ifndef NV_VPI_ALGORITHMS_COLORNAMES_H
#define NV_VPI_ALGORITHMS_COLORNAMES_H

// #include "../Export.h"
// #include "../Status.h"
// #include "../Types.h"

#ifdef __cplusplus
extern "C" {
#endif

/**
 * @defgroup VPI_Colornames Color Names Features Extractor
 * @ingroup VPI_API_Algorithms
 * @{
 *
 * Extracts the Color Names features of the input image.
 */

/**
 * Creates the payload for the Color Names algorithm.
 * @param[in] backends VPI backends that are eligible to execute the algorithm.
 *                     + Valid values:
 *                       - \ref VPI_BACKEND_CPU
 *                       - \ref VPI_BACKEND_CUDA
 *
 * @param[in] outFormat Format of the output images.
 *                      16-bit types will return more precise values, in exchange of some minor performance hit. 
 *                      8-bit types will be less precise, but typically lead to faster execution time.
 *                      + Supported formats:
 *                        - \ref VPI_IMAGE_FORMAT_S8
 *                        - \ref VPI_IMAGE_FORMAT_U8
 *                        - \ref VPI_IMAGE_FORMAT_S16
 *                        - \ref VPI_IMAGE_FORMAT_U16 
 *
 * @param[out] payload Pointer to a handle that will receive the created payload.
 * 
 * @retval #VPI_IMAGE_FORMAT_INVALID   \p outType is not supported.
 * @retval #VPI_ERROR_INVALID_ARGUMENT \p payload is NULL.
 * @retval #VPI_ERROR_INVALID_ARGUMENT \p backends refers to an invalid backend.
 * @retval #VPI_ERROR_NOT_IMPLEMENTED  ColorNames is not supported by given backend.
 * @retval #VPI_ERROR_INVALID_CONTEXT  Current context is destroyed.
 * @retval #VPI_ERROR_OUT_OF_MEMORY    Cannot allocate required resources.
 * @retval #VPI_SUCCESS                Operation executed successfully.
 */
VPI_PUBLIC VPIStatus vpiCreateExtractColorNameFeatures(uint64_t backends, VPIImageFormat outFormat,
                                                       VPIPayload *payload);

/** Submits the Color Names algorithm to the stream.
 * 
 * @param[in] stream The stream where the operation will be queued in.
 *                   + Must not be NULL.
 *                   + Stream must have enabled the backends that will execute the algorithm.
 *
 * @param[in] backend Backend that will execute the algorithm.
 *                    Must be the backend specified during payload creation or 0 as a shorthand to use this backend.
 *
 * @param[in] payload Payload to be submitted along the other parameters.
 *
 * @param[in] input Input image.
 *                  + Must not be NULL.
 *                  + Image must have enabled the backends that will execute the algorithm.
 *                  + Supported formats:
 *                   - \ref VPI_IMAGE_FORMAT_RGB8
 *                   - \ref VPI_IMAGE_FORMAT_RGBA8
 *                   - \ref VPI_IMAGE_FORMAT_NV12
 *
 * @param[out] output Pointer to an array of \ref VPIImage where the features will be written to.
 *                    Returned features have \p numOutputs dimensions,
 *                    each dimension will be written to each image in sequence.
 *                    + Must not be NULL.
 *                    + The images must have the same format as specified during payload creation.
 *                    + All images must have same format.
 *                    + All images must have same dimensions as input image.
 *                    + All Image must have enabled the backends that will execute the algorithm.
 *
 * @param[in] numOutputs Number of images in output array.
 *                       It specifies the number of dimensions each feature has.
 *                       + It must be equal to 10.
 *
 * @retval #VPI_ERROR_INVALID_ARGUMENT     \p stream is NULL.
 * @retval #VPI_ERROR_INVALID_ARGUMENT     \p input or \p output are NULL.
 * @retval #VPI_ERROR_INVALID_ARGUMENT     \p numOutputs outside valid range.
 * @retval #VPI_ERROR_INVALID_ARGUMENT     \p payload is not generated using vpiCreateExtractColorNameFeatures.
 * @retval #VPI_ERROR_INVALID_ARGUMENT     Number of \p output images outside valid range.
 * @retval #VPI_ERROR_INVALID_ARGUMENT     All \p output images must have same format.
 * @retval #VPI_ERROR_INVALID_ARGUMENT     All \p output images must have same dimensions as input.
 * @retval #VPI_ERROR_INVALID_PAYLOAD_TYPE \p payload is invalid.
 * @retval #VPI_ERROR_INVALID_OPERATION    The needed backends aren't enabled in \p stream, \p input or \p output.
 * @retval #VPI_SUCCESS                    Operation executed successfully.
 */
VPI_PUBLIC VPIStatus vpiSubmitExtractColorNameFeatures(VPIStream stream, uint64_t backend, VPIPayload payload,
                                                       VPIImage input, VPIImage *output, int32_t numOutputs);

/** @} */

#ifdef __cplusplus
}
#endif

#endif /* NV_VPI_ALGORITHMS_COLORNAMES_H */
// End content from: experimental/ColorNames.h

// Begin content from: LensDistortionModels.h
/*
 * Copyright 2020-2021 NVIDIA Corporation. All rights reserved.
 *
 * NOTICE TO LICENSEE:
 *
 * This source code and/or documentation ("Licensed Deliverables") are
 * subject to NVIDIA intellectual property rights under U.S. and
 * international Copyright laws.
 *
 * These Licensed Deliverables contained herein is PROPRIETARY and
 * CONFIDENTIAL to NVIDIA and is being provided under the terms and
 * conditions of a form of NVIDIA software license agreement by and
 * between NVIDIA and Licensee ("License Agreement") or electronically
 * accepted by Licensee. Notwithstanding any terms or conditions to
 * the contrary in the License Agreement, reproduction or disclosure
 * of the Licensed Deliverables to any third party without the express
 * written consent of NVIDIA is prohibited.
 *
 * NOTWITHSTANDING ANY TERMS OR CONDITIONS TO THE CONTRARY IN THE
 * LICENSE AGREEMENT, NVIDIA MAKES NO REPRESENTATION ABOUT THE
 * SUITABILITY OF THESE LICENSED DELIVERABLES FOR ANY PURPOSE. IT IS
 * PROVIDED "AS IS" WITHOUT EXPRESS OR IMPLIED WARRANTY OF ANY KIND.
 * NVIDIA DISCLAIMS ALL WARRANTIES WITH REGARD TO THESE LICENSED
 * DELIVERABLES, INCLUDING ALL IMPLIED WARRANTIES OF MERCHANTABILITY,
 * NONINFRINGEMENT, AND FITNESS FOR A PARTICULAR PURPOSE.
 * NOTWITHSTANDING ANY TERMS OR CONDITIONS TO THE CONTRARY IN THE
 * LICENSE AGREEMENT, IN NO EVENT SHALL NVIDIA BE LIABLE FOR ANY
 * SPECIAL, INDIRECT, INCIDENTAL, OR CONSEQUENTIAL DAMAGES, OR ANY
 * DAMAGES WHATSOEVER RESULTING FROM LOSS OF USE, DATA OR PROFITS,
 * WHETHER IN AN ACTION OF CONTRACT, NEGLIGENCE OR OTHER TORTIOUS
 * ACTION, ARISING OUT OF OR IN CONNECTION WITH THE USE OR PERFORMANCE
 * OF THESE LICENSED DELIVERABLES.
 *
 * U.S. Government End Users. These Licensed Deliverables are a
 * "commercial item" as that term is defined at 48 C.F.R. 2.101 (OCT
 * 1995), consisting of "commercial computer software" and "commercial
 * computer software documentation" as such terms are used in 48
 * C.F.R. 12.212 (SEPT 1995) and is provided to the U.S. Government
 * only as a commercial end item. Consistent with 48 C.F.R.12.212 and
 * 48 C.F.R. 227.7202-1 through 227.7202-4 (JUNE 1995), all
 * U.S. Government End Users acquire the Licensed Deliverables with
 * only those rights set forth herein.
 *
 * Any use of the Licensed Deliverables in individual and commercial
 * software must include, in the user documentation and internal
 * comments to the code, the above Disclaimer and U.S. Government End
 * Users Notice.
 */

/**
 * @file LensDistortionModels.h
 *
 * Declares functions to generate warp maps based on common lens distortion models.
 */

#ifndef NV_VPI_LENSDISTORTIONMODELS_H
#define NV_VPI_LENSDISTORTIONMODELS_H

// #include "Export.h"
// #include "Status.h"
// #include "WarpMap.h"

#include <stdint.h>

#ifdef __cplusplus
extern "C" {
#endif

/**
 * @defgroup VPI_LDC Lens Distortion Correction
 * @ingroup VPI_API_Algorithms
 * @{
 */

/** Supported fisheye lens mapping types */
typedef enum
{
    /** Specifies the equidistant fisheye mapping.
     * Mapping is defined by:
     * \f[r = f\theta\f]
     * where:
     * - \f$\theta\f$ is the angle from the optical axis.
     * - \f$f\f$ is the focal length.
     * - \f$r\f$ is the distance of a pixel from the image center.
     */
    VPI_FISHEYE_EQUIDISTANT,
    /** Specifies the equisolid fisheye mapping.
     * Mapping is defined by:
     * \f[r = 2f\sin\left(\frac{\theta}{2}\right)\f]
     * where:
     * - \f$\theta\f$ is the angle from the optical axis.
     * - \f$f\f$ is the focal length.
     * - \f$r\f$ is the distance of a pixel from the image center.
     */
    VPI_FISHEYE_EQUISOLID,
    /** Specifies the orthographic fisheye mapping.
     * Mapping is defined by:
     * \f[r = f\sin(\theta)\f]
     * where:
     * - \f$\theta\f$ is the angle from the optical axis.
     * - \f$f\f$ is the focal length.
     * - \f$r\f$ is the distance of a pixel from the image center.
     */
    VPI_FISHEYE_ORTHOGRAPHIC,
    /** Specifies the stereographic fisheye mapping.
     * Mapping is defined by:
     * \f[r = 2f\tan\left(\frac{\theta}{2}\right)\f]
     * where:
     * - \f$\theta\f$ is the angle from the optical axis.
     * - \f$f\f$ is the focal length.
     * - \f$r\f$ is the distance of a pixel from the image center.
     */
    VPI_FISHEYE_STEREOGRAPHIC
} VPIFisheyeMapping;

/**
 * Holds coefficients for fisheye lens distortion model.
 *
 * The fisheye lens distortion model is defined by:
 *
 * \f{align*}{
 * r &= \sqrt{u^2 + v^2} \\
 * \theta &= \arctan(r) \\
 * r_d &= D(\theta + k_1 * \theta^3 + k_2 * \theta^5 + k_3 * \theta^7 + k_4 * \theta^9) \\
 * c_d &= r_d/r \\
 * u_d &= u*c_d \\
 * v_d &= v*c_d
 * \f}
 *
 * where:
 * - \f$k_1,k_2,k_3,k_4\f$ are the distortion coefficients.
 * - \f$(u_d,v_d)\f$ is the coordinate of a point in the distorted image.
 * - \f$(u,v)\f$ is the coordinate of a point in the corrected image.
 * - \f$D(\theta)\f$ defines the mapping from point angle and pixel
 *   distance to image center. See \ref VPIFisheyeMapping for details.
 */
typedef struct
{
    /** Mapping between pixel angle and pixel distance to image center.
     *    + Valid mapping values: 
     *      - \ref VPI_FISHEYE_EQUIDISTANT
     *      - \ref VPI_FISHEYE_EQUISOLID
     *      - \ref VPI_FISHEYE_ORTHOGRAPHIC
     *      - \ref VPI_FISHEYE_STEREOGRAPHIC
     */
    VPIFisheyeMapping mapping;

    /**@{ Fisheye distortion coefficients.
     */
    float k1, k2, k3, k4;
    /**@} */
} VPIFisheyeLensDistortionModel;

/** Generates a mapping that corrects image distortions caused by fisheye lenses.
 * Given camera intrinsic and extrinsic parameters, and fisheye lens distortion
 * model, generates a \ref VPIWarpMap suitable to be used by \ref
 * algo_remap to undistort images captured by cameras equipped with
 * fisheye lens.
 *
 * The mapping is defined by the following matrix equation:
 *
 * \f[
 * y = (K_{out} L X K_{in}) x
 * \f]
 *
 * where:
 * - \f$x\f$ is the input homogeneous coordinate
 * - \f$y\f$ is the corresponding homogeneous coordinate on the distorted image.
 * - \f$L\f$ is the fisheye lens distortion model (not a matrix), see \ref VPIFisheyeLensDistortionModel.
 * - remaining variables are the input parameters to this function.
 *
 * @param[in] Kin Camera intrinsic parameters.
 * 
 * @param[in] X Camera extrinsic parameters that defines the camera center position and its heading in world coordinates.
 * 
 * @param[in] Kout New camera intrinsic parameters applied to the undistorted image. 
 *                 For monocular cameras, Kout is usually equal to Kin.
 * 
 * @param[in] distModel Fisheye lens distortion model.
 * 
 * @param[out] warpMap Resulting warp map that serves as input to \ref algo_remap algorithm.
 * 
 * @retval #VPI_ERROR_INVALID_ARGUMENT \p warpMap is NULL.
 * @retval #VPI_ERROR_INVALID_ARGUMENT \p Kin is NULL.
 * @retval #VPI_ERROR_INVALID_ARGUMENT \p X is NULL.
 * @retval #VPI_ERROR_INVALID_ARGUMENT Output \p Kout is NULL.
 * @retval #VPI_ERROR_INVALID_ARGUMENT \p distModel is NULL.
 * @retval #VPI_ERROR_INVALID_ARGUMENT Fisheye model in \p distModel is invalid.
 * @retval #VPI_SUCCESS                Operation executed successfully.
 */
VPI_PUBLIC VPIStatus vpiWarpMapGenerateFromFisheyeLensDistortionModel(const VPICameraIntrinsic Kin,
                                                                      const VPICameraExtrinsic X,
                                                                      const VPICameraIntrinsic Kout,
                                                                      const VPIFisheyeLensDistortionModel *distModel,
                                                                      VPIWarpMap *warpMap);

/**
 * Holds coefficients for polynomial lens distortion model.
 *
 * The polynomial lens distortion model is defined by:
 *
 * \f{align*}{
 * r &= \sqrt{u^2 + v^2} \\
 * k_r &= \frac{1 + k_1r^2 + k_2 r^4 + k_3 r^6}{1 + k_4 r^2 + k_5 r^4 + k_6 r^6} \\
 * u_d &= k_r u + p_1(2uv) + p_2 * (r^2 + 2u^2) \\
 * v_d &= k_r v + p_1(r^2 + 2v^2) + p_2(2uv)
 * \f}
 *
 * where:
 * - \f$k_1,k_2,k_3,k_4,k_5,k_6\f$ are the radial distortion coefficients.
 * - \f$p_1,p_2\f$ are the tangential distortion coefficients.
 * - \f$(u_d,v_d)\f$ is the coordinate of a point in the distorted image.
 * - \f$(u,v)\f$ is the coordinate of a point in the corrected image.
 */
typedef struct
{
    /**@{ Radial distortion coefficients. */
    float k1;
    float k2;
    float k3;
    float k4;
    float k5;
    float k6;
    /**@}*/

    /**@{ Tangential distortion coefficients. */
    float p1;
    float p2;
    /**@}*/
} VPIPolynomialLensDistortionModel;

/** Generates a mapping that corrects image using polynomial lens distortion model.
 * Given camera intrinsic and extrinsic parameters, and the polynomial lens
 * distortion model, generates a \ref VPIWarpMap suitable to be used by \ref
 * algo_remap to undistort images.
 *
 * The mapping is defined by the following matrix equation:
 *
 * \f[
 * y = (K_{out} L X K_{in}) x
 * \f]
 *
 * where:
 * - \f$x\f$ is the input homogeneous coordinate
 * - \f$y\f$ is the corresponding homogeneous coordinate on the distorted image.
 * - \f$L\f$ is the polynomial lens distortion model (not a matrix), see \ref VPIPolynomialLensDistortionModel
 * - remaining variables are the input parameters to this function.
 *
 * @param[in] Kin Camera intrinsic parameters.
 * 
 * @param[in] X Camera extrinsic parameters that defines the camera center position and its heading in world coordinates.
 * 
 * @param[in] Kout New camera intrinsic parameters applied to the undistorted image.
 *                 For monocular cameras, Kout is usually equal to Kin.
 * 
 * @param[in] distModel Polynomial lens distortion model.
 * 
 * @param[out] warpMap Resulting warp map that serves as input to \ref algo_remap algorithm.
 * 
 * @retval #VPI_ERROR_INVALID_ARGUMENT \p warpMap is NULL.
 * @retval #VPI_ERROR_INVALID_ARGUMENT \p Kin is NULL.
 * @retval #VPI_ERROR_INVALID_ARGUMENT \p X is NULL.
 * @retval #VPI_ERROR_INVALID_ARGUMENT Output \p Kout is NULL.
 * @retval #VPI_ERROR_INVALID_ARGUMENT \p distModel is NULL.
 * @retval #VPI_ERROR_INVALID_ARGUMENT Polynomial model in \p distModel is invalid.
 * @retval #VPI_SUCCESS                Operation executed successfully.
 */
VPI_PUBLIC VPIStatus vpiWarpMapGenerateFromPolynomialLensDistortionModel(
    const VPICameraIntrinsic Kin, const VPICameraExtrinsic X, const VPICameraIntrinsic Kout,
    const VPIPolynomialLensDistortionModel *distModel, VPIWarpMap *warpMap);

/** @} */

#ifdef __cplusplus
}
#endif

#endif /* NV_VPI_LENSMODELS_H */
// End content from: LensDistortionModels.h

// Begin content from: VPI.h
/*
 * Copyright 2019 NVIDIA Corporation. All rights reserved.
 *
 * NOTICE TO LICENSEE:
 *
 * This source code and/or documentation ("Licensed Deliverables") are
 * subject to NVIDIA intellectual property rights under U.S. and
 * international Copyright laws.
 *
 * These Licensed Deliverables contained herein is PROPRIETARY and
 * CONFIDENTIAL to NVIDIA and is being provided under the terms and
 * conditions of a form of NVIDIA software license agreement by and
 * between NVIDIA and Licensee ("License Agreement") or electronically
 * accepted by Licensee. Notwithstanding any terms or conditions to
 * the contrary in the License Agreement, reproduction or disclosure
 * of the Licensed Deliverables to any third party without the express
 * written consent of NVIDIA is prohibited.
 *
 * NOTWITHSTANDING ANY TERMS OR CONDITIONS TO THE CONTRARY IN THE
 * LICENSE AGREEMENT, NVIDIA MAKES NO REPRESENTATION ABOUT THE
 * SUITABILITY OF THESE LICENSED DELIVERABLES FOR ANY PURPOSE. IT IS
 * PROVIDED "AS IS" WITHOUT EXPRESS OR IMPLIED WARRANTY OF ANY KIND.
 * NVIDIA DISCLAIMS ALL WARRANTIES WITH REGARD TO THESE LICENSED
 * DELIVERABLES, INCLUDING ALL IMPLIED WARRANTIES OF MERCHANTABILITY,
 * NONINFRINGEMENT, AND FITNESS FOR A PARTICULAR PURPOSE.
 * NOTWITHSTANDING ANY TERMS OR CONDITIONS TO THE CONTRARY IN THE
 * LICENSE AGREEMENT, IN NO EVENT SHALL NVIDIA BE LIABLE FOR ANY
 * SPECIAL, INDIRECT, INCIDENTAL, OR CONSEQUENTIAL DAMAGES, OR ANY
 * DAMAGES WHATSOEVER RESULTING FROM LOSS OF USE, DATA OR PROFITS,
 * WHETHER IN AN ACTION OF CONTRACT, NEGLIGENCE OR OTHER TORTIOUS
 * ACTION, ARISING OUT OF OR IN CONNECTION WITH THE USE OR PERFORMANCE
 * OF THESE LICENSED DELIVERABLES.
 *
 * U.S. Government End Users. These Licensed Deliverables are a
 * "commercial item" as that term is defined at 48 C.F.R. 2.101 (OCT
 * 1995), consisting of "commercial computer software" and "commercial
 * computer software documentation" as such terms are used in 48
 * C.F.R. 12.212 (SEPT 1995) and is provided to the U.S. Government
 * only as a commercial end item. Consistent with 48 C.F.R.12.212 and
 * 48 C.F.R. 227.7202-1 through 227.7202-4 (JUNE 1995), all
 * U.S. Government End Users acquire the Licensed Deliverables with
 * only those rights set forth herein.
 *
 * Any use of the Licensed Deliverables in individual and commercial
 * software must include, in the user documentation and internal
 * comments to the code, the above Disclaimer and U.S. Government End
 * Users Notice.
 */

#ifndef NV_VPI_VPI_H
#define NV_VPI_VPI_H

/**
 * @file VPI.h
 * This is the main include file for applications using the VPI API.
 * It includes all the other standard API header files.
 */

// #include "Array.h"
// #include "Context.h"
// #include "Event.h"
// #include "Image.h"
// #include "Pyramid.h"
// #include "Stream.h"
// #include "Version.h"

#endif /* NV_VPI_VPI_H */
// End content from: VPI.h

// Begin content from: HostFunction.h
/*
 * Copyright 2019-2021 NVIDIA Corporation. All rights reserved.
 *
 * NOTICE TO LICENSEE:
 *
 * This source code and/or documentation ("Licensed Deliverables") are
 * subject to NVIDIA intellectual property rights under U.S. and
 * international Copyright laws.
 *
 * These Licensed Deliverables contained herein is PROPRIETARY and
 * CONFIDENTIAL to NVIDIA and is being provided under the terms and
 * conditions of a form of NVIDIA software license agreement by and
 * between NVIDIA and Licensee ("License Agreement") or electronically
 * accepted by Licensee. Notwithstanding any terms or conditions to
 * the contrary in the License Agreement, reproduction or disclosure
 * of the Licensed Deliverables to any third party without the express
 * written consent of NVIDIA is prohibited.
 *
 * NOTWITHSTANDING ANY TERMS OR CONDITIONS TO THE CONTRARY IN THE
 * LICENSE AGREEMENT, NVIDIA MAKES NO REPRESENTATION ABOUT THE
 * SUITABILITY OF THESE LICENSED DELIVERABLES FOR ANY PURPOSE. IT IS
 * PROVIDED "AS IS" WITHOUT EXPRESS OR IMPLIED WARRANTY OF ANY KIND.
 * NVIDIA DISCLAIMS ALL WARRANTIES WITH REGARD TO THESE LICENSED
 * DELIVERABLES, INCLUDING ALL IMPLIED WARRANTIES OF MERCHANTABILITY,
 * NONINFRINGEMENT, AND FITNESS FOR A PARTICULAR PURPOSE.
 * NOTWITHSTANDING ANY TERMS OR CONDITIONS TO THE CONTRARY IN THE
 * LICENSE AGREEMENT, IN NO EVENT SHALL NVIDIA BE LIABLE FOR ANY
 * SPECIAL, INDIRECT, INCIDENTAL, OR CONSEQUENTIAL DAMAGES, OR ANY
 * DAMAGES WHATSOEVER RESULTING FROM LOSS OF USE, DATA OR PROFITS,
 * WHETHER IN AN ACTION OF CONTRACT, NEGLIGENCE OR OTHER TORTIOUS
 * ACTION, ARISING OUT OF OR IN CONNECTION WITH THE USE OR PERFORMANCE
 * OF THESE LICENSED DELIVERABLES.
 *
 * U.S. Government End Users. These Licensed Deliverables are a
 * "commercial item" as that term is defined at 48 C.F.R. 2.101 (OCT
 * 1995), consisting of "commercial computer software" and "commercial
 * computer software documentation" as such terms are used in 48
 * C.F.R. 12.212 (SEPT 1995) and is provided to the U.S. Government
 * only as a commercial end item. Consistent with 48 C.F.R.12.212 and
 * 48 C.F.R. 227.7202-1 through 227.7202-4 (JUNE 1995), all
 * U.S. Government End Users acquire the Licensed Deliverables with
 * only those rights set forth herein.
 *
 * Any use of the Licensed Deliverables in individual and commercial
 * software must include, in the user documentation and internal
 * comments to the code, the above Disclaimer and U.S. Government End
 * Users Notice.
 */

/**
 * @file HostFunction.h
 *
 * Declares functions that implement the User Function feature.
 */

#ifndef NV_VPI_HOSTFUNCTION_H
#define NV_VPI_HOSTFUNCTION_H

// #include "Export.h"
// #include "Status.h"
// #include "Types.h"

#ifdef __cplusplus
extern "C" {
#endif

/**
 * @defgroup VPI_HostFunction User-Defined Function
 * @ingroup VPI_API_Algorithms
 * @{
 *
 * Submits a user-defined function to be executed on the stream.
 */

/** Pointer to a host function.
 *
 * @ingroup VPI_HostFunction
 *
 * @param[in] hostData Callback data passed to submission function.
 */
typedef void (*VPIHostFunction)(void *hostData);

/**
 * Pushes a command that will invoke a custom host-side function after all prior commands have been
 * processed.
 *
 * The execution of commands submitted after this call is suspended until the callback
 * is finished. The function will be executed at most once. It won't be executed if a previous stream task
 * failed.
 *
 * This operation will implicitly flush the stream.
 *
 * @param[in] stream Stream that will execute the host function call.
 *                   + Mandatory, cannot be NULL.
 * 
 * @param[in] hostFunc Host function to be executed.
 *                   + Mandatory, cannot be NULL.
 * 
 * @param[in] hostData Pointer that will be passed unchanged to the user function when it's called.
 *
 * @retval #VPI_ERROR_INVALID_ARGUMENT \p hostFunc is NULL.
 * @retval #VPI_ERROR_INVALID_ARGUMENT \p hostData is NULL.
 * @retval #VPI_SUCCESS                Operation executed successfully.
 */
VPI_PUBLIC VPIStatus vpiSubmitHostFunction(VPIStream stream, VPIHostFunction hostFunc, void *hostData);

/** Pointer to a host function that handles stream status.
 *
 * Most often the function will return the same \p status passed.
 * In some scenarios some other status values can be returned. Specifically, if
 * \p status is \ref VPI_SUCCESS and an error status is returned, the stream
 * will be set to error state. Conversely, if \p status is not \ref VPI_SUCCESS
 * and \ref VPI_SUCCESS is returned, the stream's error state will be reset.
 * Further tasks in it will be executed.
 *
 * @ingroup VPI_HostFunction
 *
 * @param[in] stream Stream that is executing the host function.
 *
 * @param[in] status Status of the last operation executed by the stream.
 *
 * @param[in] hostData Callback data passed to submission function.
 *
 * @returns The new stream status. Mostly often \p status is returned.
 */
typedef VPIStatus (*VPIHostFunctionEx)(VPIStream stream, VPIStatus status, void *hostData);

/**
 * Pushes a command that will invoke a custom host-side function after all prior commands have been
 * processed.
 *
 * The execution of commands submitted after this call is suspended until the
 * callback is finished. The function is guaranteed to be executed exactly
 * once. In case the stream is in error state, the corresponding error status
 * will be passed to hostFunc. 
 *
 * This operation will implicitly flush the stream.
 *
 * @param[in] stream Stream that will execute the host function call.
 *                   + Mandatory, cannot be NULL.
 * 
 * @param[in] hostFunc Host function to be executed.
 *                   + Mandatory, cannot be NULL.
 * 
 * @param[in] hostData Pointer that will be passed unchanged to the user function.
 *
 * @retval #VPI_ERROR_INVALID_ARGUMENT \p stream is NULL or doesn't correspond to a \ref VPIStream instance.
 * @retval #VPI_ERROR_INVALID_ARGUMENT \p hostFunc is NULL. 
 * @retval #VPI_SUCCESS                Operation executed successfully.
 */
VPI_PUBLIC VPIStatus vpiSubmitHostFunctionEx(VPIStream stream, VPIHostFunctionEx hostFunc, void *hostData);

/** @}  end of VPI_HostFunction */

#ifdef __cplusplus
}
#endif

#endif /* NV_VPI_HOSTFUNCTION_H */
// End content from: HostFunction.h

